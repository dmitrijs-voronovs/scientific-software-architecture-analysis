id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:22,Testability,benchmark,benchmark,22,"""""""; This module will benchmark preprocessing operations in Scanpy that run on counts; API documentation: https://scanpy.readthedocs.io/en/stable/api/preprocessing.html; """"""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_counts.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:8,Modifiability,variab,variables,8,"# setup variables",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_counts.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:16,Modifiability,variab,variables,16,"""""""Setup global variables before each benchmark.""""""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_counts.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:38,Testability,benchmark,benchmark,38,"""""""Setup global variables before each benchmark.""""""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_counts.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:25,Testability,assert,assert,25,"# TODO: This would fail: assert ""log1p"" not in adata.uns, ""ASV bug?""; # https://github.com/scverse/scanpy/issues/3052",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_counts.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py:22,Testability,benchmark,benchmark,22,"""""""; This module will benchmark preprocessing operations in Scanpy that run on log-transformed data; API documentation: https://scanpy.readthedocs.io/en/stable/api/preprocessing.html; """"""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_log.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py:79,Testability,log,log-transformed,79,"""""""; This module will benchmark preprocessing operations in Scanpy that run on log-transformed data; API documentation: https://scanpy.readthedocs.io/en/stable/api/preprocessing.html; """"""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_log.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py:8,Modifiability,variab,variables,8,"# setup variables",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_log.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py:16,Modifiability,variab,variables,16,"""""""Setup global variables before each benchmark.""""""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_log.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py:38,Testability,benchmark,benchmark,38,"""""""Setup global variables before each benchmark.""""""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/preprocessing_log.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/tools.py:22,Testability,benchmark,benchmark,22,"""""""; This module will benchmark tool operations in Scanpy; API documentation: https://scanpy.readthedocs.io/en/stable/api/tools.html; """"""",MatchSource.CODE_COMMENT,benchmarks/benchmarks/tools.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/tools.py
https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/tools.py:8,Modifiability,variab,variables,8,"# setup variables",MatchSource.CODE_COMMENT,benchmarks/benchmarks/tools.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/tools.py
https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py:40,Integrability,depend,dependency,40,"# If we are referring to other optional dependency lists, resolve them",MatchSource.CODE_COMMENT,ci/scripts/min-deps.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py
https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py:110,Deployability,install,install,110,"""""""Parse a pyproject.toml file and output a list of minimum dependencies. Output is directly passable to `pip install`.""""""",MatchSource.CODE_COMMENT,ci/scripts/min-deps.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py
https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py:60,Integrability,depend,dependencies,60,"""""""Parse a pyproject.toml file and output a list of minimum dependencies. Output is directly passable to `pip install`.""""""",MatchSource.CODE_COMMENT,ci/scripts/min-deps.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:13,Deployability,configurat,configuration,13,"# -- General configuration ------------------------------------------------",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:13,Modifiability,config,configuration,13,"# -- General configuration ------------------------------------------------",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:22,Deployability,update,updates,22,"# Bumping the version updates all docs, so don't do that",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:116,Deployability,patch,patches,116,"# -- Options for HTML output ----------------------------------------------; # The theme is sphinx-book-theme, with patches for readthedocs-sphinx-search",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:12,Usability,undo,undocumented,12,"# Currently undocumented; # https://github.com/mwaskom/seaborn/issues/1810",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:30,Deployability,release,released,30,"# Will work once scipy 1.8 is released",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:27,Modifiability,config,config,27,"# Project root; # extlinks config",MatchSource.CODE_COMMENT,docs/conf.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:16,Integrability,inject,inject,16,"""""""Extension to inject ``html_theme_options[""repository_branch""]``.""""""",MatchSource.CODE_COMMENT,docs/extensions/git_ref.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:16,Security,inject,inject,16,"""""""Extension to inject ``html_theme_options[""repository_branch""]``.""""""",MatchSource.CODE_COMMENT,docs/extensions/git_ref.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:79,Security,hash,hash,79,"""""""Current git reference. Uses branch/tag name if found, otherwise uses commit hash""""""",MatchSource.CODE_COMMENT,docs/extensions/git_ref.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:48,Security,hash,hash,48,"# (if no name found or relative ref, use commit hash instead)",MatchSource.CODE_COMMENT,docs/extensions/git_ref.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/has_attr_test.py:57,Testability,test,tests,57,"# https://jinja.palletsprojects.com/en/3.0.x/api/#custom-tests",MatchSource.CODE_COMMENT,docs/extensions/has_attr_test.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/has_attr_test.py
https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/patch_myst_nb.py:16,Deployability,patch,patch,16,"""""""Extension to patch https://github.com/executablebooks/MyST-NB/pull/599.""""""",MatchSource.CODE_COMMENT,docs/extensions/patch_myst_nb.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/patch_myst_nb.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:3,Testability,Log,Logging,3,"""""""Logging and Profiling""""""",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:155,Integrability,depend,dependency,155,"""""""\; Versions that might influence the numerical results.; Matplotlib and Seaborn are excluded from this. Parameters; ----------; file; Optional path for dependency output.; """"""",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:28,Testability,test,test,28,"# Special module present if test coverage being calculated; # https://gitlab.com/joelostblom/session_info/-/issues/10",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:10,Integrability,message,message,10,"""""""\; Log message with specific level and return current time. Parameters; ----------; msg; Message to display.; time; A time in the past. If this is passed, the time difference from then; to now is appended to `msg` as ` (HH:MM:SS)`.; If `msg` contains `{time_passed}`, the time difference is instead; inserted at that position.; deep; If the current verbosity is higher than the log function’s level,; this gets displayed as well; extra; Additional values you can specify in `msg` like `{time_passed}`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:92,Integrability,Message,Message,92,"""""""\; Log message with specific level and return current time. Parameters; ----------; msg; Message to display.; time; A time in the past. If this is passed, the time difference from then; to now is appended to `msg` as ` (HH:MM:SS)`.; If `msg` contains `{time_passed}`, the time difference is instead; inserted at that position.; deep; If the current verbosity is higher than the log function’s level,; this gets displayed as well; extra; Additional values you can specify in `msg` like `{time_passed}`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:6,Testability,Log,Log,6,"""""""\; Log message with specific level and return current time. Parameters; ----------; msg; Message to display.; time; A time in the past. If this is passed, the time difference from then; to now is appended to `msg` as ` (HH:MM:SS)`.; If `msg` contains `{time_passed}`, the time difference is instead; inserted at that position.; deep; If the current verbosity is higher than the log function’s level,; this gets displayed as well; extra; Additional values you can specify in `msg` like `{time_passed}`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:381,Testability,log,log,381,"""""""\; Log message with specific level and return current time. Parameters; ----------; msg; Message to display.; time; A time in the past. If this is passed, the time difference from then; to now is appended to `msg` as ` (HH:MM:SS)`.; If `msg` contains `{time_passed}`, the time difference is instead; inserted at that position.; deep; If the current verbosity is higher than the log function’s level,; this gets displayed as well; extra; Additional values you can specify in `msg` like `{time_passed}`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:3,Availability,Avail,Available,3,"""""""Available file formats for reading data. """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:101,Performance,cache,cache,101,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:138,Performance,cache,cache,138,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:434,Performance,load,load,434,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:502,Performance,load,loading,502,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:1229,Performance,cache,cache,1229,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:1299,Performance,cache,cache,1299,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:554,Modifiability,variab,variables,554,"""""""\; Read 10x-Genomics-formatted hdf5 file. Parameters; ----------; filename; Path to a 10x hdf5 file.; genome; Filter expression to genes within this genome. For legacy 10x h5; files, this must be provided if the data contains more than one genome.; gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; backup_url; Retrieve the file from an URL if not present on disk. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:361,Usability,Guid,Guide,361,"""""""\; Read 10x-Genomics-formatted hdf5 file. Parameters; ----------; filename; Path to a 10x hdf5 file.; genome; Filter expression to genes within this genome. For legacy 10x h5; files, this must be provided if the data contains more than one genome.; gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; backup_url; Retrieve the file from an URL if not present on disk. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:384,Deployability,pipeline,pipelines,384,"""""""\; Read 10x-Genomics-formatted visum dataset. In addition to reading regular 10x output,; this looks for the `spatial` folder and loads images,; coordinates and scale factors.; Based on the `Space Ranger output docs`_. See :func:`~scanpy.pl.spatial` for a compatible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.Ann",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:1066,Modifiability,variab,variables,1066,"ed visum dataset. In addition to reading regular 10x output,; this looks for the `spatial` folder and loads images,; coordinates and scale factors.; Based on the `Space Ranger output docs`_. See :func:`~scanpy.pl.spatial` for a compatible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.AnnData.uns`\\ `['spatial'][libra",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:133,Performance,load,loads,133,"""""""\; Read 10x-Genomics-formatted visum dataset. In addition to reading regular 10x output,; this looks for the `spatial` folder and loads images,; coordinates and scale factors.; Based on the `Space Ranger output docs`_. See :func:`~scanpy.pl.spatial` for a compatible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.Ann",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:2207,Usability,usab,usable,2207,"patible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['metadata']`; Files metadata: 'chemistry_description', 'software_version', 'source_image_path'; :attr:`~anndata.AnnData.obsm`\\ `['spatial']`; Spatial spot coordinates, usable as `basis` by :func:`~scanpy.pl.embedding`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:185,Modifiability,variab,variables,185,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:236,Modifiability,variab,variables,236,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:298,Performance,cache,cache,298,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:368,Performance,cache,cache,368,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:587,Usability,Guid,Guide,587,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:131,Modifiability,variab,variables,131,"# Convert the Python list of lists to a Numpy array and transpose to match; # the Scanpy convention of storing samples in rows and variables in colums.",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:17,Performance,race condition,race condition,17,"# This catches a race condition where a process ends; # before we can examine its files",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:36,Availability,down,downloaded,36,"# Make sure file doesn’t exist half-downloaded",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:48,Availability,down,download,48,"""""""Check whether the file is present, otherwise download.""""""",MatchSource.CODE_COMMENT,src/scanpy/readwrite.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:3,Testability,Log,Logging,3,"""""""Logging verbosity levels.""""""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:6,Modifiability,Config,Config,6,"""""""\; Config manager for scanpy.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:2,Testability,log,logging,2,"# logging",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:3,Modifiability,Variab,Variable,3,"""""""Variable for timing program parts.""""""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:62,Availability,error,error,62,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:69,Integrability,message,messages,69,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:109,Integrability,message,messages,109,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:146,Integrability,message,messages,146,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:183,Integrability,message,messages,183,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:20,Performance,cache,cache,20,"""""""\; Directory for cache files (default `'./cache/'`).; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:45,Performance,cache,cache,45,"""""""\; Directory for cache files (default `'./cache/'`).; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:36,Performance,cache,cache,36,"""""""\; Compression for `sc.read(..., cache=True)` (default `'lzf'`). May be `'lzf'`, `'gzip'`, or `None`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:98,Availability,avail,available,98,"""""""\; Default number of jobs/ CPUs to use for parallel computing. Set to `-1` in order to use all available cores.; Not all algorithms support special behavior for numbers < `-1`,; so make sure to leave this setting as >= `-1`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:21,Testability,log,logfile,21,"""""""\; The file path `logfile` was set to.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:34,Testability,log,logfile,34,"# set via “file object” branch of logfile.setter",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:29,Testability,log,logs,29,"""""""\; The open file to write logs to. Set it to a :class:`~pathlib.Path` or :class:`str` to open a new one.; The default `None` corresponds to :obj:`sys.stdout` in jupyter notebooks; and to :obj:`sys.stderr` otherwise. For backwards compatibility, setting it to `''` behaves like setting it to `None`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_settings.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:162,Performance,load,loading,162,"""""""\; Development of Myeloid Progenitors :cite:p:`Paul2015`. Non-logarithmized raw data. The data has been sent out by Email from the Amit Lab. An R version for; loading the data can be found `here; <https://github.com/theislab/scAnalysisTutorial>`_. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.paul15(); AnnData object with n_obs × n_vars = 2730 × 3451; obs: 'paul15_clusters'; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:65,Testability,log,logarithmized,65,"""""""\; Development of Myeloid Progenitors :cite:p:`Paul2015`. Non-logarithmized raw data. The data has been sent out by Email from the Amit Lab. An R version for; loading the data can be found `here; <https://github.com/theislab/scAnalysisTutorial>`_. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.paul15(); AnnData object with n_obs × n_vars = 2730 × 3451; obs: 'paul15_clusters'; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:16,Deployability,toggle,toggleswitch,16,"""""""\; Simulated toggleswitch. Data obtained simulating a simple toggleswitch :cite:p:`Gardner2000`. Simulate via :func:`~scanpy.tl.sim`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.toggleswitch(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); AnnData object with n_obs × n_vars = 200 × 2; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:64,Deployability,toggle,toggleswitch,64,"""""""\; Simulated toggleswitch. Data obtained simulating a simple toggleswitch :cite:p:`Gardner2000`. Simulate via :func:`~scanpy.tl.sim`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.toggleswitch(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); AnnData object with n_obs × n_vars = 200 × 2; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:239,Deployability,toggle,toggleswitch,239,"""""""\; Simulated toggleswitch. Data obtained simulating a simple toggleswitch :cite:p:`Gardner2000`. Simulate via :func:`~scanpy.tl.sim`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.toggleswitch(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); AnnData object with n_obs × n_vars = 200 × 2; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:57,Usability,simpl,simple,57,"""""""\; Simulated toggleswitch. Data obtained simulating a simple toggleswitch :cite:p:`Gardner2000`. Simulate via :func:`~scanpy.tl.sim`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.toggleswitch(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); AnnData object with n_obs × n_vars = 200 × 2; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:278,Modifiability,variab,variable,278,"""""""\; Subsampled and processed 68k PBMCs. `PBMC 68k dataset`_ from 10x Genomics. The original PBMC 68k dataset was preprocessed with steps including; :func:`~scanpy.pp.normalize_total`\\ [#norm]_ and :func:`~scanpy.pp.scale`.; It was saved keeping only 724 cells and 221 highly variable genes. The saved file contains the annotation of cell types (key: `'bulk_labels'`),; UMAP coordinates, louvain clustering and gene rankings based on the; `bulk_labels`. .. [#norm] Back when the dataset was created, :func:`~scanpy.pp.normalize_per_cell` was used instead.; .. _PBMC 68k dataset: https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc68k_reduced(); AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:99,Availability,avail,available,99,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:542,Availability,down,downloads,542,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:893,Modifiability,variab,variable,893,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:909,Modifiability,variab,variables-axis,909,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:969,Performance,cache,cache,969,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:1011,Performance,cache,cache,1011,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:363,Modifiability,variab,variables,363,"""""""\; Processed 3k PBMCs from 10x Genomics. Processed using the basic tutorial :doc:`/tutorials/basics/clustering-2017`. For preprocessing, cells are filtered out that have few gene counts or too high a `percent_mito`.; The counts are logarithmized and only genes marked by :func:`~scanpy.pp.highly_variable_genes` are retained.; The :attr:`~anndata.AnnData.obs` variables `n_counts` and `percent_mito` are corrected for; using :func:`~scanpy.pp.regress_out`, and values are scaled and clipped by :func:`~scanpy.pp.scale`.; Finally, :func:`~scanpy.pp.pca` and :func:`~scanpy.pp.neighbors` are calculated. As analysis steps, the embeddings :func:`~scanpy.tl.tsne` and :func:`~scanpy.tl.umap` are performed.; Communities are identified using :func:`~scanpy.tl.louvain` and marker genes using :func:`~scanpy.tl.rank_genes_groups`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k_processed(); AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:695,Performance,perform,performed,695,"""""""\; Processed 3k PBMCs from 10x Genomics. Processed using the basic tutorial :doc:`/tutorials/basics/clustering-2017`. For preprocessing, cells are filtered out that have few gene counts or too high a `percent_mito`.; The counts are logarithmized and only genes marked by :func:`~scanpy.pp.highly_variable_genes` are retained.; The :attr:`~anndata.AnnData.obs` variables `n_counts` and `percent_mito` are corrected for; using :func:`~scanpy.pp.regress_out`, and values are scaled and clipped by :func:`~scanpy.pp.scale`.; Finally, :func:`~scanpy.pp.pca` and :func:`~scanpy.pp.neighbors` are calculated. As analysis steps, the embeddings :func:`~scanpy.tl.tsne` and :func:`~scanpy.tl.umap` are performed.; Communities are identified using :func:`~scanpy.tl.louvain` and marker genes using :func:`~scanpy.tl.rank_genes_groups`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k_processed(); AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:235,Testability,log,logarithmized,235,"""""""\; Processed 3k PBMCs from 10x Genomics. Processed using the basic tutorial :doc:`/tutorials/basics/clustering-2017`. For preprocessing, cells are filtered out that have few gene counts or too high a `percent_mito`.; The counts are logarithmized and only genes marked by :func:`~scanpy.pp.highly_variable_genes` are retained.; The :attr:`~anndata.AnnData.obs` variables `n_counts` and `percent_mito` are corrected for; using :func:`~scanpy.pp.regress_out`, and values are scaled and clipped by :func:`~scanpy.pp.scale`.; Finally, :func:`~scanpy.pp.pca` and :func:`~scanpy.pp.neighbors` are calculated. As analysis steps, the embeddings :func:`~scanpy.tl.tsne` and :func:`~scanpy.tl.umap` are performed.; Communities are identified using :func:`~scanpy.tl.louvain` and marker genes using :func:`~scanpy.tl.rank_genes_groups`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k_processed(); AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:6,Availability,Down,Download,6,"""""""\; Download Visium spatial data from 10x Genomics’ database. Params; ------; sample_id; String name of example visium dataset.; base_dir; Where to download the dataset to.; download_image; Whether to download the high-resolution tissue section.; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:150,Availability,down,download,150,"""""""\; Download Visium spatial data from 10x Genomics’ database. Params; ------; sample_id; String name of example visium dataset.; base_dir; Where to download the dataset to.; download_image; Whether to download the high-resolution tissue section.; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:203,Availability,down,download,203,"""""""\; Download Visium spatial data from 10x Genomics’ database. Params; ------; sample_id; String name of example visium dataset.; base_dir; Where to download the dataset to.; download_image; Whether to download the high-resolution tissue section.; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:2,Availability,Down,Download,2,"# Download spatial data",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:2,Availability,Down,Download,2,"# Download counts",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:2,Availability,Down,Download,2,"# Download image",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:342,Availability,Down,Download,342,"""""""\; Processed Visium Spatial Gene Expression data from 10x Genomics’ database. The database_ can be browsed online to find the ``sample_id`` you want. .. _database: https://support.10xgenomics.com/spatial-gene-expression/datasets. Parameters; ----------; sample_id; The ID of the data sample in 10x’s spatial database.; include_hires_tiff; Download and include the high-resolution tissue image (tiff) in; `adata.uns[""spatial""][sample_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix. Examples; --------. >>> import scanpy as sc; >>> sc.datasets.visium_sge(sample_id='V1_Breast_Cancer_Block_A_Section_1'); AnnData object with n_obs × n_vars = 3798 × 36601; obs: 'in_tissue', 'array_row', 'array_col'; var: 'gene_ids', 'feature_types', 'genome'; uns: 'spatial'; obsm: 'spatial'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:20,Availability,down,downloaded,20,"# Note that data is downloaded from gxa/sc/experiment, not experiments",MatchSource.CODE_COMMENT,src/scanpy/datasets/_ebi_expression_atlas.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:134,Availability,Down,Downloaded,134,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_ebi_expression_atlas.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:6,Performance,Load,Load,6,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_ebi_expression_atlas.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:111,Security,access,accession,111,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_ebi_expression_atlas.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:315,Security,access,accession,315,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_ebi_expression_atlas.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:334,Security,access,accession,334,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_ebi_expression_atlas.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_utils.py:63,Integrability,wrap,wrapped,63,"""""""; Filters anndata.OldFormatWarning from being thrown by the wrapped function.; """"""",MatchSource.CODE_COMMENT,src/scanpy/datasets/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:39,Modifiability,variab,variable,39,"""""""\; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:98,Modifiability,variab,variable,98,"""""""\; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:705,Energy Efficiency,reduce,reduce,705,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:36,Modifiability,variab,variable,36,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:161,Modifiability,variab,variable,161,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:251,Safety,avoid,avoids,251,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:236,Usability,simpl,simple,236,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:140,Performance,optimiz,optimization,140,"""""""\; n_comps; Number of principal components to compute in the PCA step.; random_state; Random seed for setting the initial states for the optimization in the PCA step.; kwargs_pca; Dictionary of further keyword arguments passed on to `scanpy.pp.pca()`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:26,Deployability,update,update,26,"""""""\; inplace; If `True`, update `adata` with results. Otherwise, return results. See below for; details of what is returned.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:90,Modifiability,variab,variable,90,"# Get rank per gene within each batch; # argsort twice gives ranks, small rank means most variable",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:850,Deployability,update,updated,850,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:20,Modifiability,variab,variable,20,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:516,Modifiability,variab,variable,516,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:674,Modifiability,variab,variable,674,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:743,Modifiability,variab,variable,743,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:1013,Modifiability,variab,variable,1013,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:1653,Modifiability,variab,variable,1653,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:1533,Safety,detect,detected,1533,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:486,Deployability,update,updated,486,"""""""\; Applies analytic Pearson residual normalization, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`; and overdispersion `theta=100` is used. Expects raw count input. Params; ------; {adata}; {dist_params}; {check_values}; {layer}; {inplace}; {copy}. Returns; -------; If `inplace=True`, `adata.X` or the selected layer in `adata.layers` is updated; with the normalized values. `adata.uns` is updated with the following fields.; If `inplace=False`, the same fields are returned as dictionary with the; normalized values in `results_dict['X']`. `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter.; `.uns['pearson_residuals_normalization']['computed_on']`; The name of the layer on which the residuals were computed.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:538,Deployability,update,updated,538,"""""""\; Applies analytic Pearson residual normalization, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`; and overdispersion `theta=100` is used. Expects raw count input. Params; ------; {adata}; {dist_params}; {check_values}; {layer}; {inplace}; {copy}. Returns; -------; If `inplace=True`, `adata.X` or the selected layer in `adata.layers` is updated; with the normalized values. `adata.uns` is updated with the following fields.; If `inplace=False`, the same fields are returned as dictionary with the; normalized values in `results_dict['X']`. `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter.; `.uns['pearson_residuals_normalization']['computed_on']`; The name of the layer on which the residuals were computed.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:475,Modifiability,layers,layers,475,"""""""\; Applies analytic Pearson residual normalization, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`; and overdispersion `theta=100` is used. Expects raw count input. Params; ------; {adata}; {dist_params}; {check_values}; {layer}; {inplace}; {copy}. Returns; -------; If `inplace=True`, `adata.X` or the selected layer in `adata.layers` is updated; with the normalized values. `adata.uns` is updated with the following fields.; If `inplace=False`, the same fields are returned as dictionary with the; normalized values in `results_dict['X']`. `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter.; `.uns['pearson_residuals_normalization']['computed_on']`; The name of the layer on which the residuals were computed.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:687,Deployability,update,updates,687,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:360,Modifiability,variab,variable,360,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:819,Modifiability,variab,variable,819,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:1244,Performance,load,loadings,1244,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:12,Availability,mask,mask,12,"# Unify new mask argument and deprecated use_highly_varible argument",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:11,Deployability,pipeline,pipeline,11,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:572,Deployability,update,updates,572,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:706,Modifiability,variab,variable,706,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1305,Modifiability,variab,variable,1305,"ormalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1513,Modifiability,variab,variable,1513,"ormalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:227,Performance,perform,performed,227,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1922,Performance,load,loadings,1922,"ormalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1178,Safety,detect,detected,1178,"sed on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained v",MatchSource.CODE_COMMENT,src/scanpy/experimental/pp/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:190,Deployability,continuous,continuous,190,"""""""\; Exports to a SPRING project directory :cite:p:`Weinreb2017`. Visualize annotation present in `adata`. By default, export all gene expression data; from `adata.raw` and categorical and continuous annotations present in `adata.obs`. See `SPRING <https://github.com/AllonKleinLab/SPRING>`__ or :cite:t:`Weinreb2017` for details. Parameters; ----------; adata; Annotated data matrix: `adata.uns['neighbors']` needs to; be present.; project_dir; Path to directory for exported SPRING files.; embedding_method; Name of a 2-D embedding in `adata.obsm`; subplot_name; Name of subplot folder to be created at `project_dir+""/""+subplot_name`; cell_groupings; Instead of importing all categorical annotations when `None`,; pass a list of keys for `adata.obs`.; custom_color_tracks; Specify specific `adata.obs` keys for continuous coloring.; total_counts_key; Name of key for total transcript counts in `adata.obs`.; overwrite; When `True`, existing counts matrices in `project_dir` are overwritten. Examples; --------; See this `tutorial <https://github.com/scverse/scanpy_usage/tree/master/171111_SPRING_export>`__.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:814,Deployability,continuous,continuous,814,"""""""\; Exports to a SPRING project directory :cite:p:`Weinreb2017`. Visualize annotation present in `adata`. By default, export all gene expression data; from `adata.raw` and categorical and continuous annotations present in `adata.obs`. See `SPRING <https://github.com/AllonKleinLab/SPRING>`__ or :cite:t:`Weinreb2017` for details. Parameters; ----------; adata; Annotated data matrix: `adata.uns['neighbors']` needs to; be present.; project_dir; Path to directory for exported SPRING files.; embedding_method; Name of a 2-D embedding in `adata.obsm`; subplot_name; Name of subplot folder to be created at `project_dir+""/""+subplot_name`; cell_groupings; Instead of importing all categorical annotations when `None`,; pass a list of keys for `adata.obs`.; custom_color_tracks; Specify specific `adata.obs` keys for continuous coloring.; total_counts_key; Name of key for total transcript counts in `adata.obs`.; overwrite; When `True`, existing counts matrices in `project_dir` are overwritten. Examples; --------; See this `tutorial <https://github.com/scverse/scanpy_usage/tree/master/171111_SPRING_export>`__.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:167,Performance,load,loading,167,"# Write counts matrices as hdf5 files and npz if they do not already exist; # or if user requires overwrite.; # To do: check if Alex's h5sparse format will allow fast loading from just; # one file.",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:22,Deployability,continuous,continuous,22,"# Get categorical and continuous metadata",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:8,Deployability,continuous,continuous,8,"# Write continuous colors",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:24,Availability,redundant,redundant,24,"# make link list, avoid redundant encoding (graph is undirected)",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:18,Safety,avoid,avoid,18,"# make link list, avoid redundant encoding (graph is undirected)",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:24,Safety,redund,redundant,24,"# make link list, avoid redundant encoding (graph is undirected)",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:1896,Availability,avail,available,1896,"ted with pointers to these files.; As a result, each adata object should have its own project_dir.; data_name; Name of dataset in Cell Browser, a string without special characters.; This is written to `data_dir/cellbrowser.conf`.; Ideally this is a short unique name for the dataset,; like `""pbmc3k""` or `""tabulamuris""`.; embedding_keys; 2-D embeddings in `adata.obsm` to export.; The prefix `X_` or `X_draw_graph_` is not necessary.; Coordinates missing from `adata` are skipped.; By default (or when specifying `'all'` or `None`), these keys are tried:; [`""tsne""`, `""umap""`, `""pagaFa""`, `""pagaFr""`, `""pagaUmap""`, `""phate""`,; `""fa""`, `""fr""`, `""kk""`, `""drl""`, `""rt""`, `""trimap""`].; For these, default display labels are automatically used.; For other values, you can specify a mapping from coordinate name to; display label, e.g. `{""tsne"": ""t-SNE by Scanpy""}`.; annot_keys; Annotations in `adata.obsm` to export.; Can be a mapping from annotation column name to display label.; Specify `None` for all available columns in `.obs`.; skip_matrix; Do not export the matrix.; If you had previously exported this adata into the same `data_dir`,; then there is no need to export the whole matrix again.; This option will make the export a lot faster,; e.g. when only coordinates or meta data were changed.; html_dir; If this variable is set, the export will build html; files from `data_dir` to `html_dir`, creating html/js/json files.; Usually there is one global html output directory for all datasets.; Often, `html_dir` is located under a webserver's (like Apache); htdocs directory or is copied to one.; A directory `html_dir`/`project_name` will be created and; an index.html will be created under `html_dir` for all subdirectories.; Existing files will be overwritten.; If do not to use html_dir,; you can use the command line tool `cbBuild` to build the html directory.; port; If this variable and `html_dir` are set,; Python's built-in web server will be spawned as a daemon in the; background and ",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:2213,Modifiability,variab,variable,2213,"name for the dataset,; like `""pbmc3k""` or `""tabulamuris""`.; embedding_keys; 2-D embeddings in `adata.obsm` to export.; The prefix `X_` or `X_draw_graph_` is not necessary.; Coordinates missing from `adata` are skipped.; By default (or when specifying `'all'` or `None`), these keys are tried:; [`""tsne""`, `""umap""`, `""pagaFa""`, `""pagaFr""`, `""pagaUmap""`, `""phate""`,; `""fa""`, `""fr""`, `""kk""`, `""drl""`, `""rt""`, `""trimap""`].; For these, default display labels are automatically used.; For other values, you can specify a mapping from coordinate name to; display label, e.g. `{""tsne"": ""t-SNE by Scanpy""}`.; annot_keys; Annotations in `adata.obsm` to export.; Can be a mapping from annotation column name to display label.; Specify `None` for all available columns in `.obs`.; skip_matrix; Do not export the matrix.; If you had previously exported this adata into the same `data_dir`,; then there is no need to export the whole matrix again.; This option will make the export a lot faster,; e.g. when only coordinates or meta data were changed.; html_dir; If this variable is set, the export will build html; files from `data_dir` to `html_dir`, creating html/js/json files.; Usually there is one global html output directory for all datasets.; Often, `html_dir` is located under a webserver's (like Apache); htdocs directory or is copied to one.; A directory `html_dir`/`project_name` will be created and; an index.html will be created under `html_dir` for all subdirectories.; Existing files will be overwritten.; If do not to use html_dir,; you can use the command line tool `cbBuild` to build the html directory.; port; If this variable and `html_dir` are set,; Python's built-in web server will be spawned as a daemon in the; background and serve the files under `html_dir`.; To kill the process, call `cellbrowser.cellbrowser.stop()`.; do_debug; Activate debugging output. Examples; --------; See this; `tutorial <https://github.com/scverse/scanpy_usage/tree/master/181126_Cellbrowser_exports>`__.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:2781,Modifiability,variab,variable,2781,"name for the dataset,; like `""pbmc3k""` or `""tabulamuris""`.; embedding_keys; 2-D embeddings in `adata.obsm` to export.; The prefix `X_` or `X_draw_graph_` is not necessary.; Coordinates missing from `adata` are skipped.; By default (or when specifying `'all'` or `None`), these keys are tried:; [`""tsne""`, `""umap""`, `""pagaFa""`, `""pagaFr""`, `""pagaUmap""`, `""phate""`,; `""fa""`, `""fr""`, `""kk""`, `""drl""`, `""rt""`, `""trimap""`].; For these, default display labels are automatically used.; For other values, you can specify a mapping from coordinate name to; display label, e.g. `{""tsne"": ""t-SNE by Scanpy""}`.; annot_keys; Annotations in `adata.obsm` to export.; Can be a mapping from annotation column name to display label.; Specify `None` for all available columns in `.obs`.; skip_matrix; Do not export the matrix.; If you had previously exported this adata into the same `data_dir`,; then there is no need to export the whole matrix again.; This option will make the export a lot faster,; e.g. when only coordinates or meta data were changed.; html_dir; If this variable is set, the export will build html; files from `data_dir` to `html_dir`, creating html/js/json files.; Usually there is one global html output directory for all datasets.; Often, `html_dir` is located under a webserver's (like Apache); htdocs directory or is copied to one.; A directory `html_dir`/`project_name` will be created and; an index.html will be created under `html_dir` for all subdirectories.; Existing files will be overwritten.; If do not to use html_dir,; you can use the command line tool `cbBuild` to build the html directory.; port; If this variable and `html_dir` are set,; Python's built-in web server will be spawned as a daemon in the; background and serve the files under `html_dir`.; To kill the process, call `cellbrowser.cellbrowser.stop()`.; do_debug; Activate debugging output. Examples; --------; See this; `tutorial <https://github.com/scverse/scanpy_usage/tree/master/181126_Cellbrowser_exports>`__.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/exporting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py:667,Deployability,Update,Updates,667,"""""""\; Plot marker trends along trajectory, and return trajectory branches for further; analysis and visualization (heatmap, etc..). Parameters; ----------; adata; Annotated data matrix.; markers; Iterable of markers/genes to be plotted.; show_variance; Logical indicating if the trends should be accompanied with variance.; no_bins; Number of bins for calculating marker density.; smoothing_factor; Parameter controlling the degree of smoothing.; min_delta; Minimum difference in marker expression after normalization to show; separate trends for the two branches.; figsize; width, height; return_fig; Return the matplotlib figure.; {show_save_ax}. Returns; -------; Updates `adata` with the following fields:. `trunk_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values before branching; `branch1_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the first branch; `branch2_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the second branch.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pl.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py:253,Testability,Log,Logical,253,"""""""\; Plot marker trends along trajectory, and return trajectory branches for further; analysis and visualization (heatmap, etc..). Parameters; ----------; adata; Annotated data matrix.; markers; Iterable of markers/genes to be plotted.; show_variance; Logical indicating if the trends should be accompanied with variance.; no_bins; Number of bins for calculating marker density.; smoothing_factor; Parameter controlling the degree of smoothing.; min_delta; Minimum difference in marker expression after normalization to show; separate trends for the two branches.; figsize; width, height; return_fig; Return the matplotlib figure.; {show_save_ax}. Returns; -------; Updates `adata` with the following fields:. `trunk_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values before branching; `branch1_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the first branch; `branch2_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the second branch.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pl.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:1300,Availability,avail,available,1300," final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sklearn.neighbors.KDTree.valid_metrics; ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity']. .. note:: check the relevant documentation for up-to-date lists.; copy; If `True`, return a copy instead of writing to the supplied adata.; neighbors_wi",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_bbknn.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:3796,Deployability,install,installed,3796,"e this number times the number; of batches. This then serves as the basis for the construction of a symmetrical; matrix of connectivities.; n_pcs; How many dimensions (in case of PCA, principal components) to use in the analysis.; trim; Trim the neighbours of each cell to these many top connectivities. May help with; population independence and improve the tidiness of clustering. The lower the value the; more independent the individual populations, at the cost of more conserved batch effect.; If `None`, sets the parameter value automatically to 10 times `neighbors_within_batch`; times the number of batches. Set to 0 to skip.; annoy_n_trees; Only used with annoy neighbour identification. The number of trees to construct in the; annoy forest. More trees give higher precision when querying, at the cost of increased; run time and resource intensity.; pynndescent_n_neighbors; Only used with pyNNDescent neighbour identification. The number of neighbours to include; in the approximate neighbour graph. More neighbours give higher precision when querying,; at the cost of increased run time and resource intensity.; pynndescent_random_state; Only used with pyNNDescent neighbour identification. The RNG seed to use when creating; the graph.; use_faiss; If `approx=False` and the metric is ""euclidean"", use the faiss package to compute; nearest neighbours if installed. This improves performance at a minor cost to numerical; precision as faiss operates on float32.; set_op_mix_ratio; UMAP connectivity computation parameter, float between 0 and 1, controlling the; blend between a connectivity matrix formed exclusively from mutual nearest neighbour; pairs (0) and a union of all observed neighbour relationships with the mutual pairs; emphasised (1); local_connectivity; UMAP connectivity computation parameter, how many nearest neighbors of each cell; are assumed to be fully connected (and given a connectivity value of 1). Returns; -------; The `adata` with the batch-corrected graph.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_bbknn.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:485,Integrability,wrap,wrapper,485,"""""""\; Batch balanced kNN :cite:p:`Polanski2019`. Batch balanced kNN alters the kNN procedure to identify each cell's top neighbours in; each batch separately instead of the entire cell pool with no accounting for batch.; The nearest neighbours for each batch are then merged to create a final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sk",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_bbknn.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:1219,Integrability,depend,depend,1219,"eighbours for each batch are then merged to create a final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sklearn.neighbors.KDTree.valid_metrics; ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity']. .. note:: check the relevant documentation for up-to-date lists.; copy; If `True`, return a copy ins",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_bbknn.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:3821,Performance,perform,performance,3821,"e this number times the number; of batches. This then serves as the basis for the construction of a symmetrical; matrix of connectivities.; n_pcs; How many dimensions (in case of PCA, principal components) to use in the analysis.; trim; Trim the neighbours of each cell to these many top connectivities. May help with; population independence and improve the tidiness of clustering. The lower the value the; more independent the individual populations, at the cost of more conserved batch effect.; If `None`, sets the parameter value automatically to 10 times `neighbors_within_batch`; times the number of batches. Set to 0 to skip.; annoy_n_trees; Only used with annoy neighbour identification. The number of trees to construct in the; annoy forest. More trees give higher precision when querying, at the cost of increased; run time and resource intensity.; pynndescent_n_neighbors; Only used with pyNNDescent neighbour identification. The number of neighbours to include; in the approximate neighbour graph. More neighbours give higher precision when querying,; at the cost of increased run time and resource intensity.; pynndescent_random_state; Only used with pyNNDescent neighbour identification. The RNG seed to use when creating; the graph.; use_faiss; If `approx=False` and the metric is ""euclidean"", use the faiss package to compute; nearest neighbours if installed. This improves performance at a minor cost to numerical; precision as faiss operates on float32.; set_op_mix_ratio; UMAP connectivity computation parameter, float between 0 and 1, controlling the; blend between a connectivity matrix formed exclusively from mutual nearest neighbour; pairs (0) and a union of all observed neighbour relationships with the mutual pairs; emphasised (1); local_connectivity; UMAP connectivity computation parameter, how many nearest neighbors of each cell; are assumed to be fully connected (and given a connectivity value of 1). Returns; -------; The `adata` with the batch-corrected graph.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_bbknn.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:807,Safety,detect,detection,807,"""""""\; Batch balanced kNN :cite:p:`Polanski2019`. Batch balanced kNN alters the kNN procedure to identify each cell's top neighbours in; each batch separately instead of the entire cell pool with no accounting for batch.; The nearest neighbours for each batch are then merged to create a final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sk",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_bbknn.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1967,Energy Efficiency,Reduce,Reduces,1967,"rmalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:901,Integrability,depend,dependant,901,"""""""\; Deep count autoencoder :cite:p:`Eraslan2019`. Fits a count autoencoder to the raw count data given in the anndata object; in order to denoise the data and to capture hidden representation of; cells in low dimensions. Type of the autoencoder and return values are; determined by the parameters. .. note::; More information and bug reports `here <https://github.com/theislab/dca>`__. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; mode; `denoise` overwrites `adata.X` with denoised expression values.; In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validatio",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1577,Modifiability,layers,layers,1577," mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword a",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1780,Modifiability,layers,layers,1780," determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:972,Performance,perform,performed,972,"""""""\; Deep count autoencoder :cite:p:`Eraslan2019`. Fits a count autoencoder to the raw count data given in the anndata object; in order to denoise the data and to capture hidden representation of; cells in low dimensions. Type of the autoencoder and return values are; determined by the parameters. .. note::; More information and bug reports `here <https://github.com/theislab/dca>`__. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; mode; `denoise` overwrites `adata.X` with denoised expression values.; In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validatio",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1726,Performance,perform,performed,1726,"e autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all add",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2202,Performance,optimiz,optimizer,2202,"If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, `adata.X` is overwritten with the denoised values.; In ""latent"" mode, latent low dimensional representation of cells are stored; in `",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2221,Performance,optimiz,optimization,2221,"If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, `adata.X` is overwritten with the denoised values.; In ""latent"" mode, latent low dimensional representation of cells are stored; in `",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1992,Security,validat,validation,1992,"rmalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2083,Security,validat,validation,2083," library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1464,Testability,log,log,1464,"ting raw counts.; mode; `denoise` overwrites `adata.X` with denoised expression values.; In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1975,Usability,learn,learning,1975,"rmalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2409,Usability,Learn,Learning,2409,"1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, `adata.X` is overwritten with the denoised values.; In ""latent"" mode, latent low dimensional representation of cells are stored; in `adata.obsm['X_dca']` and `adata.X` is not modified.; Note that these values are not corrected for library size effects. If `return_info` is true, all estimated distribution parameters are s",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_dca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:20,Deployability,integrat,integrate,20,"""""""; Use harmony to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:20,Integrability,integrat,integrate,20,"""""""; Use harmony to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:47,Deployability,integrat,integrate,47,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:132,Deployability,integrat,integrating,132,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:255,Deployability,integrat,integrate,255,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:1061,Deployability,Update,Updates,1061,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:1212,Deployability,integrat,integrated,1212,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:47,Integrability,integrat,integrate,47,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:132,Integrability,integrat,integrating,132,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:255,Integrability,integrat,integrate,255,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:1212,Integrability,integrat,integrated,1212,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:1493,Modifiability,variab,variable,1493,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:403,Performance,perform,performing,403,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:1249,Performance,load,load,1249,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:228,Deployability,update,updates,228,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:5,Security,Hash,HashSolo,5,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:51,Security,hash,hashing,51,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:153,Security,hash,hashing,153,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:383,Security,hash,hashing,383,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:437,Security,hash,hashing,437,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:503,Security,hash,hashing,503,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:558,Security,hash,hashing,558,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:971,Testability,test,test,971,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:117,Security,hash,hashing,117,"""""""Calculate log likelihoods for each hypothesis, negative, singlet, doublet. Parameters; ----------; data; cells by hashing counts matrix; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; log_likelihoods_for_each_hypothesis; a 2d np.array log likelihood of each hypothesis; all_indices; counter_to_barcode_combo; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:13,Testability,log,log,13,"""""""Calculate log likelihoods for each hypothesis, negative, singlet, doublet. Parameters; ----------; data; cells by hashing counts matrix; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; log_likelihoods_for_each_hypothesis; a 2d np.array log likelihood of each hypothesis; all_indices; counter_to_barcode_combo; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:296,Testability,log,log,296,"""""""Calculate log likelihoods for each hypothesis, negative, singlet, doublet. Parameters; ----------; data; cells by hashing counts matrix; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; log_likelihoods_for_each_hypothesis; a 2d np.array log likelihood of each hypothesis; all_indices; counter_to_barcode_combo; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:3,Deployability,Update,Update,3,"""""""Update parameters of your gaussian; https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf. Parameters; ----------; data; 1-d array of counts; mu_o; global mean for hashing count distribution; std_o; global std for hashing count distribution. Returns; -------; mean; of gaussian; std; of gaussian; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:166,Security,hash,hashing,166,"""""""Update parameters of your gaussian; https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf. Parameters; ----------; data; 1-d array of counts; mu_o; global mean for hashing count distribution; std_o; global std for hashing count distribution. Returns; -------; mean; of gaussian; std; of gaussian; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:216,Security,hash,hashing,216,"""""""Update parameters of your gaussian; https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf. Parameters; ----------; data; 1-d array of counts; mu_o; global mean for hashing count distribution; std_o; global std for hashing count distribution. Returns; -------; mean; of gaussian; std; of gaussian; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:9,Testability,log,log,9,"# assume log normal",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:63,Modifiability,parameteriz,parameterization,63,"# for each barcode get empirical noise and signal distribution parameterization",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:56,Deployability,update,update,56,"# get parameters of distribution, assuming lognormal do update from global values",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:43,Testability,log,lognormal,43,"# get parameters of distribution, assuming lognormal do update from global values",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:110,Security,hash,hashing,110,"""""""; Calculate bayes rule from log likelihoods. Parameters; ----------; data; Anndata object filled only with hashing counts; priors; a list of your prior for each hypothesis; first element is your prior for the negative hypothesis; second element is your prior for the singlet hypothesis; third element is your prior for the doublet hypothesis; We use [0.01, 0.8, 0.19] by default because we assume the barcodes; in your cell hashing matrix are those cells which have passed QC; in the transcriptome space, e.g. UMI counts, pct mito reads, etc.; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; A dict of bayes key results with the following entries:. `""most_likely_hypothesis""`; A 1d np.array of the most likely hypothesis; `""probs_hypotheses""`; A 2d np.array probability of each hypothesis; `""log_likelihoods_for_each_hypothesis""`; A 2d np.array log likelihood of each hypothesis; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:427,Security,hash,hashing,427,"""""""; Calculate bayes rule from log likelihoods. Parameters; ----------; data; Anndata object filled only with hashing counts; priors; a list of your prior for each hypothesis; first element is your prior for the negative hypothesis; second element is your prior for the singlet hypothesis; third element is your prior for the doublet hypothesis; We use [0.01, 0.8, 0.19] by default because we assume the barcodes; in your cell hashing matrix are those cells which have passed QC; in the transcriptome space, e.g. UMI counts, pct mito reads, etc.; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; A dict of bayes key results with the following entries:. `""most_likely_hypothesis""`; A 1d np.array of the most likely hypothesis; `""probs_hypotheses""`; A 2d np.array probability of each hypothesis; `""log_likelihoods_for_each_hypothesis""`; A 2d np.array log likelihood of each hypothesis; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:31,Testability,log,log,31,"""""""; Calculate bayes rule from log likelihoods. Parameters; ----------; data; Anndata object filled only with hashing counts; priors; a list of your prior for each hypothesis; first element is your prior for the negative hypothesis; second element is your prior for the singlet hypothesis; third element is your prior for the doublet hypothesis; We use [0.01, 0.8, 0.19] by default because we assume the barcodes; in your cell hashing matrix are those cells which have passed QC; in the transcriptome space, e.g. UMI counts, pct mito reads, etc.; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; A dict of bayes key results with the following entries:. `""most_likely_hypothesis""`; A 1d np.array of the most likely hypothesis; `""probs_hypotheses""`; A 2d np.array probability of each hypothesis; `""log_likelihoods_for_each_hypothesis""`; A 2d np.array log likelihood of each hypothesis; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:905,Testability,log,log,905,"""""""; Calculate bayes rule from log likelihoods. Parameters; ----------; data; Anndata object filled only with hashing counts; priors; a list of your prior for each hypothesis; first element is your prior for the negative hypothesis; second element is your prior for the singlet hypothesis; third element is your prior for the doublet hypothesis; We use [0.01, 0.8, 0.19] by default because we assume the barcodes; in your cell hashing matrix are those cells which have passed QC; in the transcriptome space, e.g. UMI counts, pct mito reads, etc.; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; A dict of bayes key results with the following entries:. `""most_likely_hypothesis""`; A 1d np.array of the most likely hypothesis; `""probs_hypotheses""`; A 2d np.array probability of each hypothesis; `""log_likelihoods_for_each_hypothesis""`; A 2d np.array log likelihood of each hypothesis; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:1041,Deployability,update,update,1041,"ic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.obs.head(); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:845,Performance,perform,performed,845,"""""""Probabilistic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.ob",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:40,Security,hash,hashing,40,"""""""Probabilistic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.ob",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:59,Security,Hash,HashSolo,59,"""""""Probabilistic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.ob",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:372,Security,hash,hashing,372,"""""""Probabilistic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.ob",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:1943,Security,hash,hashsolo,1943,"ic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.obs.head(); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_hashsolo.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:140,Availability,recover,recover,140,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:284,Availability,recover,recover,284,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:460,Energy Efficiency,adapt,adaptive,460,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1325,Energy Efficiency,power,power,1325,"hanged primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1366,Energy Efficiency,power,powered,1366,"hanged primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:2484,Integrability,message,messages,2484,"tes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'all_genes'` or `'pca_only'`. `copy` may only be False; if `genes` is `'all_genes'` or `'pca_only'`, as the resultant data; will otherwise have different column names from the input data.; kwargs; Additional arguments to `magic.MAGIC`. Returns; -------; If `copy` is True, AnnData object is returned. If `subset_genes` is not `all_genes`, PCA on MAGIC values of cells are; stored in `adata.obsm['X_magic']` and `adata.X` is not modified. The raw counts are stored in `.raw` attribute of AnnData object. Examples; --------; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.paul15(); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.sqrt(adata) # or sc.pp.log1p(adata); >>> adata_magic = sce.pp.magic(adata, name_list=['Mpo', 'Klf1', 'Ifitm1'], knn=5); >>> adata_magic.shape; (2730, 3); >>> sce.pp.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:460,Modifiability,adapt,adaptive,460,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1714,Performance,perform,performed,1714,"com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'all_genes'` or `'pca_only'`. `copy` may only be False; if `genes` is `'all_",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1873,Performance,perform,performs,1873,"s.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'all_genes'` or `'pca_only'`. `copy` may only be False; if `genes` is `'all_genes'` or `'pca_only'`, as the resultant data; will otherwise have different column names from the input data.; kwargs; Additional arguments to `magic.MAGIC`. Returns; -------; If",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:140,Safety,recover,recover,140,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:284,Safety,recover,recover,284,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1672,Testability,log,log,1672,"emory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:2,Deployability,update,update,2,"# update AnnData instance",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:17,Deployability,update,update,17,"# special case – update adata.obsm with smoothed values",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_magic.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:168,Integrability,Depend,Depending,168,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:3237,Integrability,depend,depending,3237,"pplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biological components will not be removed; from the correction vectors.; var_adj; Whether to adjust variance of the correction vectors. Note this step; takes most computing time.; compute_angle; Whether to compute the angle between each cell’s correction vector and; the biological subspace of the reference batch.; mnn_order; The order in which batches are to be corrected. When set to None, datas; are corrected sequentially.; svd_mode; `'svd'` computes SVD using a non-randomized SVD-via-ID algorithm,; while `'rsvd'` uses a randomized version. `'irlb'` perfores; truncated SVD by implicitly restarted Lanczos bidiagonalization; (forked from https://github.com/airysen/irlbpy).; do_concatenate; Whether to concatenate the corrected matrices or AnnData objects. Default is True.; save_raw; Whether to save the original expression data in the; :attr:`~anndata.AnnData.raw` attribute.; n_jobs; The number of jobs. When set to `None`, automatically uses; :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; kwargs; optional keyword arguments for irlb. Returns; -------; datas; Corrected matrix/matrices or AnnData object/objects, depending on the; input type and `do_concatenate`.; mnn_list; A list containing MNN pairing information as DataFrames in each iteration step.; angle_list; A list containing angles of each batch.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:770,Modifiability,variab,variables,770,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1124,Modifiability,variab,variable,1124,"he implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biologic",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:881,Performance,perform,perform,881,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1068,Performance,perform,performing,1068,"rest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for su",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1815,Performance,perform,performed,1815,"(genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biological components will not be removed; from the correction vectors.; var_adj; Whether to adjust variance of the correction vectors. Note this step; takes most computing time.; compute_angle; Whether to compute the angle between each cell’s correction vector and; the biological subspace of the reference batch.; mnn_order; The order in which batches are to be corrected. When set to None, datas; are corrected sequentially.; svd_mode; `'svd'` computes SVD using a non-randomized SVD-via-ID algorithm,; while `'rsvd'` uses a randomized version. `'irlb'` perfores; truncated SVD by implicitly restarted Lanczos bidiagonalization; (forked from https://github.com/airysen/irlbpy).; do_concatenate; Whether to con",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1944,Performance,perform,performed,1944,"`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biological components will not be removed; from the correction vectors.; var_adj; Whether to adjust variance of the correction vectors. Note this step; takes most computing time.; compute_angle; Whether to compute the angle between each cell’s correction vector and; the biological subspace of the reference batch.; mnn_order; The order in which batches are to be corrected. When set to None, datas; are corrected sequentially.; svd_mode; `'svd'` computes SVD using a non-randomized SVD-via-ID algorithm,; while `'rsvd'` uses a randomized version. `'irlb'` perfores; truncated SVD by implicitly restarted Lanczos bidiagonalization; (forked from https://github.com/airysen/irlbpy).; do_concatenate; Whether to concatenate the corrected matrices or AnnData objects. Default is True.; save_raw; Whether to save the original expression ",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:443,Testability,test,testing,443,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_mnn_correct.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:22,Deployability,integrat,integrate,22,"""""""; Use Scanorama to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:22,Integrability,integrat,integrate,22,"""""""; Use Scanorama to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1411,Availability,avail,available,1411," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:41,Deployability,integrat,integrate,41,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:122,Deployability,integrat,integrating,122,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:888,Deployability,integrat,integrated,888,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1325,Deployability,integrat,integrating,1325,"ses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing da",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1526,Deployability,Update,Updates,1526," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1657,Deployability,integrat,integrated,1657," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:41,Integrability,integrat,integrate,41,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:122,Integrability,integrat,integrating,122,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:888,Integrability,integrat,integrated,888,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1325,Integrability,integrat,integrating,1325,"ses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing da",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1657,Integrability,integrat,integrated,1657," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1938,Modifiability,variab,variable,1938," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:242,Performance,perform,performing,242,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1694,Performance,load,load,1694," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:2,Deployability,Integrat,Integrate,2,"# Integrate.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:2,Integrability,Integrat,Integrate,2,"# Integrate.",MatchSource.CODE_COMMENT,src/scanpy/external/pp/_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:2582,Availability,avail,available,2582,"uted in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for highly expressed genes. >>> sc.pp.normalize_total(adata, target_sum=10000); >>> sc.pp.log1p(adata); >>> sc.pp.highly_variable_genes(adata, n_top_genes=1000, subset=True). Run harmony_timeseries. >>> sce.tl.harmony_timeseries(adata, tp=""time_points"", n_components=500). Plot time points:. >>> sce.pl.harmony_timeseries(adata). For further demonstrat",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:1709,Deployability,update,updates,1709,"ps://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three ",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:1677,Integrability,Depend,Depending,1677,"ps://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three ",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:2203,Modifiability,variab,variable,2203,"e used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for hi",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:2537,Performance,Load,Load,2537,"; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for highly expressed genes. >>> sc.pp.normalize_total(adata, target_sum=10000); >>> sc.pp.log1p(adata); >>> sc.pp.highly_variable_genes(adata, n_top_genes=1000, subset=True). Run harmony_timeseries. >>> sce.tl.harmony_timeseries(adata, tp=""time_points"", n_components=500). Plot time points:. >>> sce.pl.harmony_timeserie",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:202,Safety,detect,detection,202,"""""""\; Harmony time series for data visualization with augmented affinity matrix; at discrete time points :cite:p:`Nowotschin2019`. Harmony time series is a framework for data visualization, trajectory; detection and interpretation for scRNA-seq data measured at discrete; time points. Harmony constructs an augmented affinity matrix by augmenting; the kNN graph affinity matrix with mutually nearest neighbors between; successive time points. This augmented affinity matrix forms the basis for; generated a force directed layout for visualization and also serves as input; for computing the diffusion operator which can be used for trajectory; detection using Palantir_. .. _Palantir: https://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:644,Safety,detect,detection,644,"""""""\; Harmony time series for data visualization with augmented affinity matrix; at discrete time points :cite:p:`Nowotschin2019`. Harmony time series is a framework for data visualization, trajectory; detection and interpretation for scRNA-seq data measured at discrete; time points. Harmony constructs an augmented affinity matrix by augmenting; the kNN graph affinity matrix with mutually nearest neighbors between; successive time points. This augmented affinity matrix forms the basis for; generated a force directed layout for visualization and also serves as input; for computing the diffusion operator which can be used for trajectory; detection using Palantir_. .. _Palantir: https://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:3790,Usability,guid,guide,3790,"ce directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for highly expressed genes. >>> sc.pp.normalize_total(adata, target_sum=10000); >>> sc.pp.log1p(adata); >>> sc.pp.highly_variable_genes(adata, n_top_genes=1000, subset=True). Run harmony_timeseries. >>> sce.tl.harmony_timeseries(adata, tp=""time_points"", n_components=500). Plot time points:. >>> sce.pl.harmony_timeseries(adata). For further demonstration of Harmony visualizations please follow the notebook; `Harmony_sample_notebook.ipynb; <https://github.com/dpeerlab/Harmony/blob/master/notebooks/; Harmony_sample_notebook.ipynb>`_.; It provides a comprehensive guide to draw *gene expression trends*,; amongst other things.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_harmony_timeseries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,Energy Efficiency,adapt,adaptive,35,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,Modifiability,adapt,adaptive,35,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:2710,Availability,avail,available,2710,"ulti-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC imputation). Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. A sample data is available `here <https://github.com/dpeerlab/Palantir/tree/master/data>`_. **Load sample data**. >>> adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). *Cleanup and normalize*. >>> sc.pp.filter_cells(adata, min_counts=1000); >>> sc.pp.filter_genes(adata, min_counts=10); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.log1p(adata). **Data preprocessing**. Palantir builds diffusion maps using one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visua",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:4842,Availability,down,downstream,4842,"g one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visualization*. important for Palantir!. Palantir constructs the tSNE map in the embedded space since these maps better; represent the differentiation trajectories. >>> sc.tl.tsne(adata, n_pcs=2, use_rep='X_palantir_multiscale', perplexity=150). *tsne by cell size*. >>> sc.pl.tsne(adata, color=""n_counts""). *Imputed gene expression visualized on tSNE maps*. >>> sc.pl.tsne(; ... adata,; ... gene_symbols=['CD34', 'MPO', 'GATA1', 'IRF8'],; ... layer='palantir_imp',; ... color=['CD34', 'MPO', 'GATA1', 'IRF8']; ... ). **Running Palantir**. Palantir can be run by specifying an approximate early cell. While Palantir; automatically determines the terminal states, they can also be specified using the; `termine_states` parameter. >>> start_cell = 'Run5_164698952452459'; >>> pr_res = sce.tl.palantir_results(; ... adata,; ... early_cell=start_cell,; ... ms_data='X_palantir_multiscale',; ... num_waypoints=500,; ... ). .. note::; A `start_cell` must be defined for every data set. The start cell for; this dataset was chosen based on high expression of CD34. At this point the returned Palantir object `pr_res` can be used for all downstream; analysis and plotting. Please consult this notebook; `Palantir_sample_notebook.ipynb; <https://github.com/dpeerlab/Palantir/blob/master/notebooks/Palantir_sample_notebook.ipynb>`_.; It provides a comprehensive guide to draw *gene expression trends*, amongst other; things.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:1608,Deployability,update,updates,1608," RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC im",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,Energy Efficiency,adapt,adaptive,35,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel :cite:p:`Setty2019`. Palantir is an algorithm to align cells along differentiation trajectories.; Palantir models differentiation as a stochastic process where stem cells; differentiate to terminally differentiated cells by a series of steps through; a low dimensional phenotypic manifold. Palantir effectively captures the; continuity in cell states and the stochasticity in cell fate determination.; Palantir has been designed to work with multidimensional single cell data; from diverse technologies such as Mass cytometry and single cell RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen value",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:949,Energy Efficiency,adapt,adaptive,949,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel :cite:p:`Setty2019`. Palantir is an algorithm to align cells along differentiation trajectories.; Palantir models differentiation as a stochastic process where stem cells; differentiate to terminally differentiated cells by a series of steps through; a low dimensional phenotypic manifold. Palantir effectively captures the; continuity in cell states and the stochasticity in cell fate determination.; Palantir has been designed to work with multidimensional single cell data; from diverse technologies such as Mass cytometry and single cell RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen value",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:1576,Integrability,Depend,Depending,1576," RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC im",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,Modifiability,adapt,adaptive,35,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel :cite:p:`Setty2019`. Palantir is an algorithm to align cells along differentiation trajectories.; Palantir models differentiation as a stochastic process where stem cells; differentiate to terminally differentiated cells by a series of steps through; a low dimensional phenotypic manifold. Palantir effectively captures the; continuity in cell states and the stochasticity in cell fate determination.; Palantir has been designed to work with multidimensional single cell data; from diverse technologies such as Mass cytometry and single cell RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen value",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:949,Modifiability,adapt,adaptive,949,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel :cite:p:`Setty2019`. Palantir is an algorithm to align cells along differentiation trajectories.; Palantir models differentiation as a stochastic process where stem cells; differentiate to terminally differentiated cells by a series of steps through; a low dimensional phenotypic manifold. Palantir effectively captures the; continuity in cell states and the stochasticity in cell fate determination.; Palantir has been designed to work with multidimensional single cell data; from diverse technologies such as Mass cytometry and single cell RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen value",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:2550,Modifiability,layers,layers,2550,"ing on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC imputation). Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. A sample data is available `here <https://github.com/dpeerlab/Palantir/tree/master/data>`_. **Load sample data**. >>> adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). *Cleanup and normalize*. >>> sc.pp.filter_cells(adata, min_counts=1000); >>> sc.pp.filter_genes(adata, min_counts=10); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.log1p(adata). **Data preprocessing**. Palantir builds diffusion maps using one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_component",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:2787,Performance,Load,Load,2787,"tr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC imputation). Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. A sample data is available `here <https://github.com/dpeerlab/Palantir/tree/master/data>`_. **Load sample data**. >>> adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). *Cleanup and normalize*. >>> sc.pp.filter_cells(adata, min_counts=1000); >>> sc.pp.filter_genes(adata, min_counts=10); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.log1p(adata). **Data preprocessing**. Palantir builds diffusion maps using one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visualization*. important for Palantir!. Palantir constructs the tSNE map in the em",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:5064,Usability,guid,guide,5064,"g one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visualization*. important for Palantir!. Palantir constructs the tSNE map in the embedded space since these maps better; represent the differentiation trajectories. >>> sc.tl.tsne(adata, n_pcs=2, use_rep='X_palantir_multiscale', perplexity=150). *tsne by cell size*. >>> sc.pl.tsne(adata, color=""n_counts""). *Imputed gene expression visualized on tSNE maps*. >>> sc.pl.tsne(; ... adata,; ... gene_symbols=['CD34', 'MPO', 'GATA1', 'IRF8'],; ... layer='palantir_imp',; ... color=['CD34', 'MPO', 'GATA1', 'IRF8']; ... ). **Running Palantir**. Palantir can be run by specifying an approximate early cell. While Palantir; automatically determines the terminal states, they can also be specified using the; `termine_states` parameter. >>> start_cell = 'Run5_164698952452459'; >>> pr_res = sce.tl.palantir_results(; ... adata,; ... early_cell=start_cell,; ... ms_data='X_palantir_multiscale',; ... num_waypoints=500,; ... ). .. note::; A `start_cell` must be defined for every data set. The start cell for; this dataset was chosen based on high expression of CD34. At this point the returned Palantir object `pr_res` can be used for all downstream; analysis and plotting. Please consult this notebook; `Palantir_sample_notebook.ipynb; <https://github.com/dpeerlab/Palantir/blob/master/notebooks/Palantir_sample_notebook.ipynb>`_.; It provides a comprehensive guide to draw *gene expression trends*, amongst other; things.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:56,Integrability,wrap,wraps,56,"""""""\; **Running Palantir**. A convenience function that wraps `palantir.core.run_palantir` to compute branch; probabilities and waypoints. Parameters; ----------; adata; An AnnData object.; early_cell; Start cell for pseudotime construction.; ms_data; Palantir multi scale data matrix,; terminal_states; List of user defined terminal states; knn; Number of nearest neighbors for graph construction.; num_waypoints; Number of waypoints to sample.; n_jobs; Number of jobs for parallel processing.; scale_components; Transform features by scaling each feature to a given range. Consult the; documentation for `sklearn.preprocessing.minmax_scale`.; use_early_cell_as_start; Use `early_cell` as `start_cell`, instead of determining it from the boundary; cells closest to the defined `early_cell`.; max_iterations; Maximum number of iterations for pseudotime convergence. Returns; -------; PResults object with pseudotime, entropy, branch probabilities and waypoints.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_palantir.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:2441,Deployability,update,updates,2441," to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Additional arguments to `phate.PHATE`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_phate** : `np.ndarray`, (`adata.obs`, shape=[n_samples, n_components], dtype `float`); PHATE coordinates of data. Examples; --------; >>> from anndata import AnnData; >>> import scanpy.external as sce; >>> import phate; >>> tree_data, tree_clusters = phate.tree.gen_dla(; ... n_dim=100,; ... n_branch=20,; ... branch_length=100,; ... ); >>> tree_data.shape; (2000, 100); >>> adata = AnnData(tree_data); >>> sce.tl.phate(adata, k=5, a=20, t=150); >>> adata.obsm['X_phate'].shape; (2000, 2); >>> sce.pl.phate(adata); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:892,Energy Efficiency,power,power,892,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:933,Energy Efficiency,power,powered,933,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:281,Integrability,interface,interface,281,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:2236,Integrability,message,messages,2236," to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Additional arguments to `phate.PHATE`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_phate** : `np.ndarray`, (`adata.obs`, shape=[n_samples, n_components], dtype `float`); PHATE coordinates of data. Examples; --------; >>> from anndata import AnnData; >>> import scanpy.external as sce; >>> import phate; >>> tree_data, tree_clusters = phate.tree.gen_dla(; ... n_dim=100,; ... n_branch=20,; ... branch_length=100,; ... ); >>> tree_data.shape; (2000, 100); >>> adata = AnnData(tree_data); >>> sce.tl.phate(adata, k=5, a=20, t=150); >>> adata.obsm['X_phate'].shape; (2000, 2); >>> sce.pl.phate(adata); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:2409,Integrability,Depend,Depending,2409," to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Additional arguments to `phate.PHATE`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_phate** : `np.ndarray`, (`adata.obs`, shape=[n_samples, n_components], dtype `float`); PHATE coordinates of data. Examples; --------; >>> from anndata import AnnData; >>> import scanpy.external as sce; >>> import phate; >>> tree_data, tree_clusters = phate.tree.gen_dla(; ... n_dim=100,; ... n_branch=20,; ... branch_length=100,; ... ); >>> tree_data.shape; (2000, 100); >>> adata = AnnData(tree_data); >>> sce.tl.phate(adata, k=5, a=20, t=150); >>> adata.obsm['X_phate'].shape; (2000, 2); >>> sce.pl.phate(adata); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:251,Security,access,access,251,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:1164,Testability,log,log,1164," for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; I",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:1389,Testability,log,log,1389,">`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Ad",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:2,Deployability,update,update,2,"# update AnnData instance",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:6,Performance,Perform,Perform,6,"""""""\; Perform clustering using PhenoGraph; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:1968,Availability,Toler,Tolerance,1968,"ther to use a symmetric (default) or asymmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; U",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2445,Availability,avail,available,2445,"the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - ",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:3270,Deployability,update,updates,3270,"nsional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>>",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:1999,Energy Efficiency,monitor,monitoring,1999,"symmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.;",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:3238,Integrability,Depend,Depending,3238,"nsional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>>",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:1682,Performance,perform,performance,1682,"rray, n-by-d array of n cells in d dimensions. if sparse matrix,; n-by-n adjacency matrix.; clustering_algo; Choose between `'Louvain'` or `'Leiden'` algorithm for clustering.; k; Number of nearest neighbors to use in first step of graph construction.; directed; Whether to use a symmetric (default) or asymmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2021,Performance,optimiz,optimization,2021,"symmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.;",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2100,Performance,optimiz,optimization,2100,"roduces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2326,Performance,perform,performs,2326,"product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the fo",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:3045,Performance,optimiz,optimization,3045,".; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:342,Safety,detect,detection,342,"""""""\; PhenoGraph clustering :cite:p:`Levine2015`. **PhenoGraph** is a clustering method designed for high-dimensional single-cell; data. It works by creating a graph (""network"") representing phenotypic similarities; between cells and then identifying communities in this graph. It supports both; Louvain_ and Leiden_ algorithms for community detection. .. _Louvain: https://louvain-igraph.readthedocs.io/en/latest/. .. _Leiden: https://leidenalg.readthedocs.io/en/latest/reference.html. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/PhenoGraph>`__. Parameters; ----------; data; AnnData, or Array of data to cluster, or sparse matrix of k-nearest neighbor; graph. If ndarray, n-by-d array of n cells in d dimensions. if sparse matrix,; n-by-n adjacency matrix.; clustering_algo; Choose between `'Louvain'` or `'Leiden'` algorithm for clustering.; k; Number of nearest neighbors to use in first step of graph construction.; directed; Whether to use a symmetric (default) or asymmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for mo",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:4067,Safety,detect,detection,4067,"copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>> sce.tl.phenograph(adata, clustering_algo=None, k=30). Now to show phenograph on tSNE (for example):. Compute tSNE:. >>> sc.tl.tsne(adata, random_state=7). Plot phenograph clusters on tSNE:. >>> sc.pl.tsne(; ... adata, color = [""pheno_louvain"", ""pheno_leiden""], s = 100,; ... palette = sc.pl.palettes.vega_20_scanpy, legend_fontsize = 10; ... ). Cluster and cluster centroids for input Numpy ndarray. >>> df = np.random.rand(1000, 40); >>> dframe = pd.DataFrame(df); >>> dframe.index, dframe.columns = (map(str, dframe.index), map(str, dframe.columns)); >>> adata = AnnData(dframe); >>> sc.pp.pca(adata, n_comps=20); >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=50); >>> sc.tl.tsne(adata, random_state=1); >>> sc.pl.tsne(; ... adata, color=['pheno_leiden'], s=100,; ... palette=sc.pl",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:4162,Safety,detect,detection,4162,"al arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>> sce.tl.phenograph(adata, clustering_algo=None, k=30). Now to show phenograph on tSNE (for example):. Compute tSNE:. >>> sc.tl.tsne(adata, random_state=7). Plot phenograph clusters on tSNE:. >>> sc.pl.tsne(; ... adata, color = [""pheno_louvain"", ""pheno_leiden""], s = 100,; ... palette = sc.pl.palettes.vega_20_scanpy, legend_fontsize = 10; ... ). Cluster and cluster centroids for input Numpy ndarray. >>> df = np.random.rand(1000, 40); >>> dframe = pd.DataFrame(df); >>> dframe.index, dframe.columns = (map(str, dframe.index), map(str, dframe.columns)); >>> adata = AnnData(dframe); >>> sc.pp.pca(adata, n_comps=20); >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=50); >>> sc.tl.tsne(adata, random_state=1); >>> sc.pl.tsne(; ... adata, color=['pheno_leiden'], s=100,; ... palette=sc.pl.palettes.vega_20_scanpy, legend_fontsize=10; ... ); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_phenograph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_pypairs.py:25,Safety,predict,predicted,25,"""""""\; Assigns scores and predicted class to observations :cite:p:`Scialdone2015` :cite:p:`Fechtner2018`. Calculates scores for each observation and each phase and assigns prediction; based on marker pairs indentified by :func:`~scanpy.external.tl.sandbag`. This reproduces the approach of :cite:t:`Scialdone2015` in the implementation of; :cite:t:`Fechtner2018`. Parameters; ----------; adata; The annotated data matrix.; marker_pairs; Mapping of categories to lists of marker pairs.; See :func:`~scanpy.external.tl.sandbag` output.; iterations; An integer scalar specifying the number of; iterations for random sampling to obtain a cycle score.; min_iter; An integer scalar specifying the minimum number of iterations; for score estimation.; min_pairs; An integer scalar specifying the minimum number of pairs; for score estimation. Returns; -------; A :class:`~pandas.DataFrame` with samples as index and categories as columns; with scores for each category for each sample and a additional column with; the name of the max scoring category for each sample. If `marker_pairs` contains only the cell cycle categories G1, S and G2M an; additional column `pypairs_cc_prediction` will be added.; Where category S is assigned to samples where G1 and G2M score are < 0.5.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_pypairs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_pypairs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_pypairs.py:171,Safety,predict,prediction,171,"""""""\; Assigns scores and predicted class to observations :cite:p:`Scialdone2015` :cite:p:`Fechtner2018`. Calculates scores for each observation and each phase and assigns prediction; based on marker pairs indentified by :func:`~scanpy.external.tl.sandbag`. This reproduces the approach of :cite:t:`Scialdone2015` in the implementation of; :cite:t:`Fechtner2018`. Parameters; ----------; adata; The annotated data matrix.; marker_pairs; Mapping of categories to lists of marker pairs.; See :func:`~scanpy.external.tl.sandbag` output.; iterations; An integer scalar specifying the number of; iterations for random sampling to obtain a cycle score.; min_iter; An integer scalar specifying the minimum number of iterations; for score estimation.; min_pairs; An integer scalar specifying the minimum number of pairs; for score estimation. Returns; -------; A :class:`~pandas.DataFrame` with samples as index and categories as columns; with scores for each category for each sample and a additional column with; the name of the max scoring category for each sample. If `marker_pairs` contains only the cell cycle categories G1, S and G2M an; additional column `pypairs_cc_prediction` will be added.; Where category S is assigned to samples where G1 and G2M score are < 0.5.; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_pypairs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_pypairs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:4481,Availability,avail,available,4481,"e kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by foll",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:5070,Deployability,install,installed,5070,"ality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by following the instructions in the; self-assembling-manifold README. """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:4917,Integrability,interface,interface,4917,"ality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by following the instructions in the; self-assembling-manifold README. """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:5050,Integrability,Depend,Dependencies,5050,"ality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by following the instructions in the; self-assembling-manifold README. """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:5290,Integrability,interface,interface,5290,"ality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by following the instructions in the; self-assembling-manifold README. """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:197,Modifiability,variab,variable,197,"""""""\; Self-Assembling Manifolds single-cell RNA sequencing analysis tool :cite:p:`Tarashansky2019`. SAM iteratively rescales the input gene expression matrix to emphasize; genes that are spatially variable along the intrinsic manifold of the data.; It outputs the gene weights, nearest neighbor matrix, and a 2D projection. The AnnData input should contain unstandardized, non-negative values.; Preferably, the data should be log-normalized and no genes should be filtered out. Parameters; ----------. k; The number of nearest neighbors to identify for each cell. distance; The distance metric to use when identifying nearest neighbors.; Can be any of the distance metrics supported by; :func:`~scipy.spatial.distance.pdist`. max_iter; The maximum number of iterations SAM will run. projection; If 'tsne', generates a t-SNE embedding. If 'umap', generates a UMAP; embedding. If 'None', no embedding will be generated. standardization; If 'Normalizer', use sklearn.preprocessing.Normalizer, which; normalizes expression data prior to PCA such that each cell has; unit L2 norm. If 'StandardScaler', use; sklearn.preprocessing.StandardScaler, which normalizes expression; data prior to PCA such that each gene has zero mean and unit; variance. Otherwise, do not normalize the expression data. We; recommend using 'StandardScaler' for large datasets with many; expected cell types and 'Normalizer' otherwise. If 'None', no; transformation is applied. num_norm_avg; The top 'num_norm_avg' dispersions are averaged to determine the; normalization factor when calculating the weights. This prevents; genes with large spatial dispersions from skewing the distribution; of weights. weight_pcs; If True, scale the principal components by their eigenvalues. In; datasets with many expected cell types, setting this to False might; improve the resolution as these cell types might be encoded by lower-; variance principal components. sparse_pca; If True, uses an implementation of PCA that accepts sparse inputs.;",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:3807,Modifiability,layers,layers,3807,"prove; clustering resolution. inplace; Set fields in `adata` if True. Otherwise, returns a copy. verbose; If True, displays SAM log statements. Returns; -------; sam_obj if inplace is True or (sam_obj,AnnData) otherwise. adata - AnnData; `.var['weights']`; SAM weights for each gene.; `.var['spatial_dispersions']`; Spatial dispersions for each gene (these are used to compute the; SAM weights); `.uns['sam']`; Dictionary of SAM-specific outputs, such as the parameters; used for preprocessing ('preprocess_args') and running; ('run_args') SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` functi",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:3888,Modifiability,layers,layers,3888,"e; If True, displays SAM log statements. Returns; -------; sam_obj if inplace is True or (sam_obj,AnnData) otherwise. adata - AnnData; `.var['weights']`; SAM weights for each gene.; `.var['spatial_dispersions']`; Spatial dispersions for each gene (these are used to compute the; SAM weights); `.uns['sam']`; Dictionary of SAM-specific outputs, such as the parameters; used for preprocessing ('preprocess_args') and running; ('run_args') SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly`",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:426,Testability,log,log-normalized,426,"""""""\; Self-Assembling Manifolds single-cell RNA sequencing analysis tool :cite:p:`Tarashansky2019`. SAM iteratively rescales the input gene expression matrix to emphasize; genes that are spatially variable along the intrinsic manifold of the data.; It outputs the gene weights, nearest neighbor matrix, and a 2D projection. The AnnData input should contain unstandardized, non-negative values.; Preferably, the data should be log-normalized and no genes should be filtered out. Parameters; ----------. k; The number of nearest neighbors to identify for each cell. distance; The distance metric to use when identifying nearest neighbors.; Can be any of the distance metrics supported by; :func:`~scipy.spatial.distance.pdist`. max_iter; The maximum number of iterations SAM will run. projection; If 'tsne', generates a t-SNE embedding. If 'umap', generates a UMAP; embedding. If 'None', no embedding will be generated. standardization; If 'Normalizer', use sklearn.preprocessing.Normalizer, which; normalizes expression data prior to PCA such that each cell has; unit L2 norm. If 'StandardScaler', use; sklearn.preprocessing.StandardScaler, which normalizes expression; data prior to PCA such that each gene has zero mean and unit; variance. Otherwise, do not normalize the expression data. We; recommend using 'StandardScaler' for large datasets with many; expected cell types and 'Normalizer' otherwise. If 'None', no; transformation is applied. num_norm_avg; The top 'num_norm_avg' dispersions are averaged to determine the; normalization factor when calculating the weights. This prevents; genes with large spatial dispersions from skewing the distribution; of weights. weight_pcs; If True, scale the principal components by their eigenvalues. In; datasets with many expected cell types, setting this to False might; improve the resolution as these cell types might be encoded by lower-; variance principal components. sparse_pca; If True, uses an implementation of PCA that accepts sparse inputs.;",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:2973,Testability,log,log,2973,"n of PCA that accepts sparse inputs.; This way, we no longer need a temporary dense copy of the sparse data.; However, this implementation is slower and so is only worth using when; memory constraints become noticeable. n_pcs; Determines the number of top principal components selected at each; iteration of the SAM algorithm. If None, this number is chosen; automatically based on the size of the dataset. If weight_pcs is; set to True, this parameter primarily affects the runtime of the SAM; algorithm (more PCs = longer runtime). n_genes; Determines the number of top SAM-weighted genes to use at each iteration; of the SAM algorithm. If None, this number is chosen automatically; based on the size of the dataset. This parameter primarily affects; the runtime of the SAM algorithm (more genes = longer runtime). For; extremely homogeneous datasets, decreasing `n_genes` may improve; clustering resolution. inplace; Set fields in `adata` if True. Otherwise, returns a copy. verbose; If True, displays SAM log statements. Returns; -------; sam_obj if inplace is True or (sam_obj,AnnData) otherwise. adata - AnnData; `.var['weights']`; SAM weights for each gene.; `.var['spatial_dispersions']`; Spatial dispersions for each gene (these are used to compute the; SAM weights); `.uns['sam']`; Dictionary of SAM-specific outputs, such as the parameters; used for preprocessing ('preprocess_args') and running; ('run_args') SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for ",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:4374,Testability,log,log-normalized,4374," SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_sam.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py:1539,Deployability,update,updates,1539,"""""""\; TriMap: Large-scale Dimensionality Reduction Using Triplets :cite:p:`Amid2019`. TriMap is a dimensionality reduction method that uses triplet constraints; to form a low-dimensional embedding of a set of points. The triplet; constraints are of the form ""point i is closer to point j than point k"".; The triplets are sampled from the high-dimensional representation of the; points and a weighting scheme is used to reflect the importance of each; triplet. TriMap provides a significantly better global view of the data than the; other dimensionality reduction methods such t-SNE, LargeVis, and UMAP.; The global structure includes relative distances of the clusters, multiple; scales in the data, and the existence of possible outliers. We define a; global score to quantify the quality of an embedding in reflecting the; global structure of the data. Parameters; ----------; adata; Annotated data matrix.; n_components; Number of dimensions of the embedding.; n_inliers; Number of inlier points for triplet constraints.; n_outliers; Number of outlier points for triplet constraints.; n_random; Number of random triplet constraints per point.; metric; Distance measure: 'angular', 'euclidean', 'hamming', 'manhattan'.; weight_adj; Adjusting the weights using a non-linear transformation.; lr; Learning rate.; n_iters; Number of iterations.; verbose; If `True`, print the progress report.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_trimap** : :class:`~numpy.ndarray`, (:attr:`~anndata.AnnData.obsm`, shape=(n_samples, n_components), dtype `float`); TriMap coordinates of data. Example; -------. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> pbmc = sce.tl.trimap(pbmc, copy=True); >>> sce.pl.trimap(pbmc, color=['bulk_labels'], s=10); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_trimap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py:1507,Integrability,Depend,Depending,1507,"""""""\; TriMap: Large-scale Dimensionality Reduction Using Triplets :cite:p:`Amid2019`. TriMap is a dimensionality reduction method that uses triplet constraints; to form a low-dimensional embedding of a set of points. The triplet; constraints are of the form ""point i is closer to point j than point k"".; The triplets are sampled from the high-dimensional representation of the; points and a weighting scheme is used to reflect the importance of each; triplet. TriMap provides a significantly better global view of the data than the; other dimensionality reduction methods such t-SNE, LargeVis, and UMAP.; The global structure includes relative distances of the clusters, multiple; scales in the data, and the existence of possible outliers. We define a; global score to quantify the quality of an embedding in reflecting the; global structure of the data. Parameters; ----------; adata; Annotated data matrix.; n_components; Number of dimensions of the embedding.; n_inliers; Number of inlier points for triplet constraints.; n_outliers; Number of outlier points for triplet constraints.; n_random; Number of random triplet constraints per point.; metric; Distance measure: 'angular', 'euclidean', 'hamming', 'manhattan'.; weight_adj; Adjusting the weights using a non-linear transformation.; lr; Learning rate.; n_iters; Number of iterations.; verbose; If `True`, print the progress report.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_trimap** : :class:`~numpy.ndarray`, (:attr:`~anndata.AnnData.obsm`, shape=(n_samples, n_components), dtype `float`); TriMap coordinates of data. Example; -------. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> pbmc = sce.tl.trimap(pbmc, copy=True); >>> sce.pl.trimap(pbmc, color=['bulk_labels'], s=10); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_trimap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py:1297,Usability,Learn,Learning,1297,"""""""\; TriMap: Large-scale Dimensionality Reduction Using Triplets :cite:p:`Amid2019`. TriMap is a dimensionality reduction method that uses triplet constraints; to form a low-dimensional embedding of a set of points. The triplet; constraints are of the form ""point i is closer to point j than point k"".; The triplets are sampled from the high-dimensional representation of the; points and a weighting scheme is used to reflect the importance of each; triplet. TriMap provides a significantly better global view of the data than the; other dimensionality reduction methods such t-SNE, LargeVis, and UMAP.; The global structure includes relative distances of the clusters, multiple; scales in the data, and the existence of possible outliers. We define a; global score to quantify the quality of an embedding in reflecting the; global structure of the data. Parameters; ----------; adata; Annotated data matrix.; n_components; Number of dimensions of the embedding.; n_inliers; Number of inlier points for triplet constraints.; n_outliers; Number of outlier points for triplet constraints.; n_random; Number of random triplet constraints per point.; metric; Distance measure: 'angular', 'euclidean', 'hamming', 'manhattan'.; weight_adj; Adjusting the weights using a non-linear transformation.; lr; Learning rate.; n_iters; Number of iterations.; verbose; If `True`, print the progress report.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_trimap** : :class:`~numpy.ndarray`, (:attr:`~anndata.AnnData.obsm`, shape=(n_samples, n_components), dtype `float`); TriMap coordinates of data. Example; -------. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> pbmc = sce.tl.trimap(pbmc, copy=True); >>> sce.pl.trimap(pbmc, color=['bulk_labels'], s=10); """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_trimap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py:949,Deployability,Update,Updates,949,"""""""\; Wishbone identifies bifurcating developmental trajectories from single-cell data; :cite:p:`Setty2016`. Wishbone is an algorithm for positioning single cells along bifurcating; developmental trajectories with high resolution. Wishbone uses multi-dimensional; single-cell data, such as mass cytometry or RNA-Seq data, as input and orders cells; according to their developmental progression, and it pinpoints bifurcation points; by labeling each cell as pre-bifurcation or as one of two post-bifurcation cell; fates. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/wishbone>`__. Parameters; ----------; adata; Annotated data matrix.; start_cell; Desired start cell from `obs_names`.; branch; Use True for Wishbone and False for Wanderlust.; k; Number of nearest neighbors for graph construction.; components; Components to use for running Wishbone.; num_waypoints; Number of waypoints to sample. Returns; -------; Updates `adata` with the following fields:. `trajectory_wishbone` : (`adata.obs`, dtype `float64`); Computed trajectory positions.; `branch_wishbone` : (`adata.obs`, dtype `int64`); Assigned branches. Example; -------. >>> import scanpy.external as sce; >>> import scanpy as sc. **Loading Data and Pre-processing**. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.pca(adata); >>> sc.tl.tsne(adata=adata, n_pcs=5, perplexity=30); >>> sc.pp.neighbors(adata, n_pcs=15, n_neighbors=10); >>> sc.tl.diffmap(adata, n_comps=10). **Running Wishbone Core Function**. Usually, the start cell for a dataset should be chosen based on high expression of; the gene of interest:. >>> sce.tl.wishbone(; ... adata=adata, start_cell='ACAAGAGACTTATC-1',; ... components=[2, 3], num_waypoints=150,; ... ). **Visualizing Wishbone results**. >>> sc.pl.tsne(adata, color=['trajectory_wishbone', 'branch_wishbone']); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ', 'MALAT1']; >>> sce.pl.wishbone_marker_trajectory(adata, markers",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_wishbone.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py:1230,Performance,Load,Loading,1230,"ishbone uses multi-dimensional; single-cell data, such as mass cytometry or RNA-Seq data, as input and orders cells; according to their developmental progression, and it pinpoints bifurcation points; by labeling each cell as pre-bifurcation or as one of two post-bifurcation cell; fates. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/wishbone>`__. Parameters; ----------; adata; Annotated data matrix.; start_cell; Desired start cell from `obs_names`.; branch; Use True for Wishbone and False for Wanderlust.; k; Number of nearest neighbors for graph construction.; components; Components to use for running Wishbone.; num_waypoints; Number of waypoints to sample. Returns; -------; Updates `adata` with the following fields:. `trajectory_wishbone` : (`adata.obs`, dtype `float64`); Computed trajectory positions.; `branch_wishbone` : (`adata.obs`, dtype `int64`); Assigned branches. Example; -------. >>> import scanpy.external as sce; >>> import scanpy as sc. **Loading Data and Pre-processing**. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.pca(adata); >>> sc.tl.tsne(adata=adata, n_pcs=5, perplexity=30); >>> sc.pp.neighbors(adata, n_pcs=15, n_neighbors=10); >>> sc.tl.diffmap(adata, n_comps=10). **Running Wishbone Core Function**. Usually, the start cell for a dataset should be chosen based on high expression of; the gene of interest:. >>> sce.tl.wishbone(; ... adata=adata, start_cell='ACAAGAGACTTATC-1',; ... components=[2, 3], num_waypoints=150,; ... ). **Visualizing Wishbone results**. >>> sc.pl.tsne(adata, color=['trajectory_wishbone', 'branch_wishbone']); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ', 'MALAT1']; >>> sce.pl.wishbone_marker_trajectory(adata, markers, show=True). For further demonstration of Wishbone methods and visualization please follow the; notebooks in the package `Wishbone_for_single_cell_RNAseq.ipynb; <https://github.com/dpeerlab/wishbone/tree/master/notebooks>`_.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/external/tl/_wishbone.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:45,Security,access,accessing,45,"""""""This module contains helper functions for accessing data.""""""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:461,Testability,log,logfc,461,"""""""\; :func:`scanpy.tl.rank_genes_groups` results in the form of a; :class:`~pandas.DataFrame`. Params; ------; adata; Object to get results from.; group; Which group (as in :func:`scanpy.tl.rank_genes_groups`'s `groupby`; argument) to return results from. Can be a list. All groups are; returned if groups is `None`.; key; Key differential expression groups were stored under.; pval_cutoff; Return only adjusted p-values below the cutoff.; log2fc_min; Minimum logfc to return.; log2fc_max; Maximum logfc to return.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. Specifying; this will add that column to the returned dataframe. Example; -------; >>> import scanpy as sc; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", use_raw=True); >>> dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:499,Testability,log,logfc,499,"""""""\; :func:`scanpy.tl.rank_genes_groups` results in the form of a; :class:`~pandas.DataFrame`. Params; ------; adata; Object to get results from.; group; Which group (as in :func:`scanpy.tl.rank_genes_groups`'s `groupby`; argument) to return results from. Can be a list. All groups are; returned if groups is `None`.; key; Key differential expression groups were stored under.; pval_cutoff; Return only adjusted p-values below the cutoff.; log2fc_min; Minimum logfc to return.; log2fc_max; Maximum logfc to return.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. Specifying; this will add that column to the returned dataframe. Example; -------; >>> import scanpy as sc; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", use_raw=True); >>> dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:10,Testability,log,logic,10,"""""""Common logic for checking indices for obs_df and var_df.""""""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:14,Availability,mask,mask,14,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:90,Availability,mask,mask,90,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:100,Availability,mask,mask,100,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:193,Availability,mask,mask,193,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:225,Availability,mask,masked,225,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:5,Security,Validat,Validate,5,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:695,Availability,mask,mask,695,"""""""\; Functionality for generic grouping and aggregating. There is currently support for count_nonzero, sum, mean, and variance. **Implementation**. Moments are computed using weighted sum aggregation of data by some feature; via multiplication by a sparse coordinate matrix A. Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero); entries in X with multiplicity the number of group memberships for that entry.; This is `O(data)` for partitions (each observation belonging to exactly one group),; independent of the number of groups. Params; ------; groupby; :class:`~pandas.Categorical` containing values for grouping by.; data; Data matrix for aggregation.; mask; Mask to be used for aggregation.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:701,Availability,Mask,Mask,701,"""""""\; Functionality for generic grouping and aggregating. There is currently support for count_nonzero, sum, mean, and variance. **Implementation**. Moments are computed using weighted sum aggregation of data by some feature; via multiplication by a sparse coordinate matrix A. Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero); entries in X with multiplicity the number of group memberships for that entry.; This is `O(data)` for partitions (each observation belonging to exactly one group),; independent of the number of groups. Params; ------; groupby; :class:`~pandas.Categorical` containing values for grouping by.; data; Data matrix for aggregation.; mask; Mask to be used for aggregation.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:52,Energy Efficiency,power,power,52,"# sparse matrices do not support ** for elementwise power.",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:2,Safety,detect,detects,2,"# detects loss of precision in mean_sq - sq_mean, which suggests variance is 0",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:27,Energy Efficiency,power,power,27,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:126,Energy Efficiency,power,power,126,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:183,Energy Efficiency,power,power,183,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:207,Energy Efficiency,power,power,207,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:222,Energy Efficiency,power,power,222,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:266,Energy Efficiency,power,power,266,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:597,Availability,mask,mask,597,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:611,Availability,mask,mask,611,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:645,Availability,mask,mask,645,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:1328,Modifiability,layers,layers,1328,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:1681,Modifiability,layers,layers,1681,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:142,Performance,perform,perform,142,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:32,Modifiability,layers,layers,32,"# i.e., all of `varm`, `obsm`, `layers` are None so we use `X` which must be transposed",MatchSource.CODE_COMMENT,src/scanpy/get/_aggregated.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py:322,Performance,perform,performance,322,"###############################################################################; # Calculation; ###############################################################################; # Some notes on the implementation:; # * This could be phrased as tensor multiplication. However that does not get; # parallelized, which boosts performance almost linearly with cores.; # * Due to the umap setting the default threading backend, a parallel numba; # function that calls another parallel numba function can get stuck. This; # ends up meaning code re-use will be limited until umap 0.4.; # See: https://github.com/lmcinnes/umap/issues/306; # * There can be a fair amount of numerical instability here (big reductions),; # so data is cast to float64. Removing these casts/ conversion will cause the; # tests to fail.",MatchSource.CODE_COMMENT,src/scanpy/metrics/_gearys_c.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py:791,Testability,test,tests,791,"###############################################################################; # Calculation; ###############################################################################; # Some notes on the implementation:; # * This could be phrased as tensor multiplication. However that does not get; # parallelized, which boosts performance almost linearly with cores.; # * Due to the umap setting the default threading backend, a parallel numba; # function that calls another parallel numba function can get stuck. This; # ends up meaning code re-use will be limited until umap 0.4.; # See: https://github.com/lmcinnes/umap/issues/306; # * There can be a fair amount of numerical instability here (big reductions),; # so data is cast to float64. Removing these casts/ conversion will cause the; # tests to fail.",MatchSource.CODE_COMMENT,src/scanpy/metrics/_gearys_c.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py:83,Integrability,Interface,Interface,83,"###############################################################################; # Interface; ###############################################################################",MatchSource.CODE_COMMENT,src/scanpy/metrics/_gearys_c.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_morans_i.py:83,Integrability,Interface,Interface,83,"###############################################################################; # Interface (taken from gearys C); ###############################################################################",MatchSource.CODE_COMMENT,src/scanpy/metrics/_morans_i.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_morans_i.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_common.py:126,Safety,detect,detected,126,"# account for the fact that there might be more than n_neighbors; # due to an approximate search; # [the point itself was not detected as its own neighbor during the search]",MatchSource.CODE_COMMENT,src/scanpy/neighbors/_common.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_common.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py:58,Availability,mask,mask,58,"# restrict number of neighbors to ~k; # build a symmetric mask",MatchSource.CODE_COMMENT,src/scanpy/neighbors/_connectivity.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py:157,Usability,simpl,simplicial,157,"""""""\; This is from umap.fuzzy_simplicial_set :cite:p:`McInnes2018`. Given a set of data X, a neighborhood size, and a measure of distance; compute the fuzzy simplicial set (here represented as a fuzzy graph in; the form of a sparse matrix) associated to the data. This is done by; locally approximating geodesic distance at each point, creating a fuzzy; simplicial set for each such point, and then combining all the local; fuzzy simplicial sets into a global one via a fuzzy union.; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/_connectivity.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py:354,Usability,simpl,simplicial,354,"""""""\; This is from umap.fuzzy_simplicial_set :cite:p:`McInnes2018`. Given a set of data X, a neighborhood size, and a measure of distance; compute the fuzzy simplicial set (here represented as a fuzzy graph in; the form of a sparse matrix) associated to the data. This is done by; locally approximating geodesic distance at each point, creating a fuzzy; simplicial set for each such point, and then combining all the local; fuzzy simplicial sets into a global one via a fuzzy union.; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/_connectivity.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py:430,Usability,simpl,simplicial,430,"""""""\; This is from umap.fuzzy_simplicial_set :cite:p:`McInnes2018`. Given a set of data X, a neighborhood size, and a measure of distance; compute the fuzzy simplicial set (here represented as a fuzzy graph in; the form of a sparse matrix) associated to the data. This is done by; locally approximating geodesic distance at each point, creating a fuzzy; simplicial set for each such point, and then combining all the local; fuzzy simplicial sets into a global one via a fuzzy union.; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/_connectivity.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:103,Deployability,update,update,103,"""""""Keyword arguments passed to a _KnownTransformer. IMPORTANT: when changing the parameters set here,; update the “*ignored*” part in the parameter docs!; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:427,Energy Efficiency,adapt,adaption,427,"""""""\; Computes the nearest neighbors distance matrix and a neighborhood graph of observations :cite:p:`McInnes2018`. The neighbor search efficiency of this heavily relies on UMAP :cite:p:`McInnes2018`,; which also provides a method for estimating connectivities of data points -; the connectivity of the manifold (`method=='umap'`). If `method=='gauss'`,; connectivities are computed according to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.n",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:1406,Energy Efficiency,adapt,adaptive,1406,"ording to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.neighbors.NearestNeighbors`. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.pp.neighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:1731,Integrability,depend,depends,1731,"s result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.neighbors.NearestNeighbors`. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.pp.neighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key_added; If not specified, the neighbors data is stored in `.uns['neighbors']`,; distances and connectivities are stored in `.obsp['distances']` and; `.obsp['connectivities']` respectively.; If specified, the neighbors data is added to .uns[key_added],; distances are stored in `.obsp[key_added+'_distances']` and; connectivities in `.obsp",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:427,Modifiability,adapt,adaption,427,"""""""\; Computes the nearest neighbors distance matrix and a neighborhood graph of observations :cite:p:`McInnes2018`. The neighbor search efficiency of this heavily relies on UMAP :cite:p:`McInnes2018`,; which also provides a method for estimating connectivities of data points -; the connectivity of the manifold (`method=='umap'`). If `method=='gauss'`,; connectivities are computed according to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.n",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:1406,Modifiability,adapt,adaptive,1406,"ording to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.neighbors.NearestNeighbors`. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.pp.neighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:3992,Security,access,access,3992,"ighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key_added; If not specified, the neighbors data is stored in `.uns['neighbors']`,; distances and connectivities are stored in `.obsp['distances']` and; `.obsp['connectivities']` respectively.; If specified, the neighbors data is added to .uns[key_added],; distances are stored in `.obsp[key_added+'_distances']` and; connectivities in `.obsp[key_added+'_connectivities']`.; copy; Return a copy instead of writing to adata. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsp['distances' | key_added+'_distances']` : :class:`scipy.sparse.csr_matrix` (dtype `float`); Distance matrix of the nearest neighbors search. Each row (cell) has `n_neighbors`-1 non-zero entries. These are the distances to their `n_neighbors`-1 nearest neighbors (excluding the cell itself).; `adata.obsp['connectivities' | key_added+'_connectivities']` : :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Weighted adjacency matrix of the neighborhood graph of data; points. Weights should be interpreted as connectivities.; `adata.uns['neighbors' | key_added]` : :class:`dict`; neighbors parameters. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> # Basic usage; >>> sc.pp.neighbors(adata, 20, metric='cosine'); >>> # Provide your own transformer for more control and flexibility; >>> from sklearn.neighbors import KNeighborsTransformer; >>> transformer = KNeighborsTransformer(n_neighbors=10, metric='manhattan', algorithm='kd_tree'); >>> sc.pp.neighbors(adata, transformer=transformer); >>> # now you can e.g. access the index: `transformer._tree`. See also; --------; :doc:`/how-to/knn-transformers`; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:286,Testability,test,tested,286,"""""""Transition matrix (sparse matrix). Is conjugate to the symmetrized transition matrix via::. self.transitions = self.Z * self.transitions_sym / self.Z. where ``self.Z`` is the diagonal matrix storing the normalization of the; underlying kernel matrix. Notes; -----; This has not been tested, in contrast to `transitions_sym`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:17,Performance,cache,cached,17,"# do not use the cached rp_forest",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:9,Testability,log,logic,9,"# legacy logic",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:2,Security,Validat,Validate,2,"# Validate `knn`",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:270,Availability,avail,available,270,"""""""\; Compute transition matrix. Parameters; ----------; density_normalize; The density rescaling of Coifman and Lafon (2006): Then only the; geometry of the data matters, not the sampled density. Returns; -------; Makes attributes `.transitions_sym` and `.transitions` available.; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:714,Usability,simpl,simply,714,"""""""\; Compute eigen decomposition of transition matrix. Parameters; ----------; n_comps; Number of eigenvalues/vectors to be computed, set `n_comps = 0` if; you need all eigenvectors.; sym; Instead of computing the eigendecomposition of the assymetric; transition matrix, computed the eigendecomposition of the symmetric; Ktilde matrix.; random_state; A numpy random seed. Returns; -------; Writes the following attributes. eigen_values : :class:`~numpy.ndarray`; Eigenvalues of transition matrix.; eigen_basis : :class:`~numpy.ndarray`; Matrix of eigenvectors (stored in columns). `.eigen_basis` is; projection of data matrix on right eigenvectors, that is, the; projection on the diffusion components. these are simply the; components of the right eigenvectors and can directly be used for; plotting.; """"""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_backends/rapids.py:3,Performance,Perform,Perform,3,"""""""Perform knn search on the index.""""""",MatchSource.CODE_COMMENT,src/scanpy/neighbors/_backends/rapids.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_backends/rapids.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py:2,Energy Efficiency,green,green,2,"# green",MatchSource.CODE_COMMENT,src/scanpy/plotting/palettes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py:139,Deployability,update,update,139,"# https://graphicdesign.stackexchange.com/questions/3682/where-can-i-find-a-large-palette-set-of-contrasting-colors-for-coloring-many-d; # update 1; # orig reference https://research.wu.ac.at/en/publications/escaping-rgbland-selecting-colors-for-statistical-graphics-26",MatchSource.CODE_COMMENT,src/scanpy/plotting/palettes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:41,Modifiability,variab,variables,41,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:116,Modifiability,variab,variables,116,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:319,Modifiability,variab,variables,319,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:515,Modifiability,layers,layers,515,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:532,Modifiability,layers,layers,532,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:622,Modifiability,layers,layers,622,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:669,Modifiability,layers,layers,669,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:677,Modifiability,layers,layers,677,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:685,Modifiability,layers,layers,685,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:10,Modifiability,layers,layers,10,"# Process layers",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:21,Deployability,continuous,continuous,21,"# by default, assume continuous or flat color",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:37,Deployability,continuous,continuous,37,"# test whether we have categorial or continuous annotation",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:2,Testability,test,test,2,"# test whether we have categorial or continuous annotation",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:292,Security,access,access,292,"""""""\; Plot rankings. See, for example, how this is used in pl.pca_loadings. Parameters; ----------; adata; The data.; attr; The attribute of AnnData that contains the score.; keys; The scores to look up an array from the attribute of adata. Returns; -------; Returns matplotlib gridspec with access to the axes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:19,Integrability,Wrap,Wraps,19,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:163,Modifiability,variab,variables,163,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:153,Security,access,accessing,153,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:270,Testability,log,log,270,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:283,Testability,log,logarithmic,283,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:36,Energy Efficiency,adapt,adapting,36,"# This is a quick and dirty way for adapting scales across several; # keys if groupby is None.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:36,Modifiability,adapt,adapting,36,"# This is a quick and dirty way for adapting scales across several; # keys if groupby is None.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:52,Modifiability,extend,extend,52,"# set by default the violin plot cut=0 to limit the extend; # of the violin plot (see stacked_violin code) for more info.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:40,Integrability,Wrap,Wraps,40,"""""""\; Hierarchically-clustered heatmap. Wraps :func:`seaborn.clustermap` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; obs_keys; Categorical annotation to plot with a different color map.; Currently, only a single key is supported.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; {show_save_ax}; **kwds; Keyword arguments passed to :func:`~seaborn.clustermap`. Returns; -------; If `show` is `False`, a :class:`~seaborn.matrix.ClusterGrid` object; (see :func:`~seaborn.clustermap`). Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.krumsiek11(); sc.pl.clustermap(adata). .. plot::; :context: close-figs. sc.pl.clustermap(adata, obs_keys='cell_type'); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:15,Energy Efficiency,efficient,efficiently,15,"# do this more efficiently... just a quick solution",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:520,Modifiability,variab,variable,520,"""""""\; Heatmap of the expression values of genes. If `groupby` is given, the heatmap is ordered by the respective group. For; example, a list of marker genes can be plotted, ordered by clustering. If; the `groupby` observation annotation is not categorical the observation; annotation is turned into a categorical by binning the data into the number; specified in `num_categories`. Parameters; ----------; {common_plot_args}; standard_scale; Whether or not to standardize that dimension between 0 and 1, meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis the `groupby`; categories (if any). By setting `swap_axes` then x are the `groupby` categories and y the `var_names`.; show_gene_labels; By default gene labels are shown when there are 50 or less genes. Otherwise the labels are removed.; {show_save_ax}; {vminmax}; **kwds; Are passed to :func:`matplotlib.pyplot.imshow`. Returns; -------; Dict of :class:`~matplotlib.axes.Axes`. Examples; -------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.heatmap(adata, markers, groupby='bulk_labels', swap_axes=True). .. currentmodule:: scanpy. See also; --------; pl.rank_genes_groups_heatmap; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:218,Testability,log,log,218,"""""""\; In this type of plot each var_name is plotted as a filled line plot where the; y values correspond to the var_name values and x is each of the cells. Best results; are obtained when using raw counts that are not log. `groupby` is required to sort and order the values using the respective group; and should be a categorical value. Parameters; ----------; {common_plot_args}; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.heatmap`. Returns; -------; A list of :class:`~matplotlib.axes.Axes`. Examples; --------. Using var_names as list:. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.tracksplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.tracksplot(adata, markers, groupby='bulk_labels', dendrogram=True). .. currentmodule:: scanpy. See also; --------; pl.rank_genes_groups_tracksplot: to plot marker genes identified using the :func:`~scanpy.tl.rank_genes_groups` function.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:107,Availability,redundant,redundant,107,"# remove the xticks labels except for the last processed plot.; # Because the plots share the x axis it is redundant and less compact; # to plot the axis for each plot",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:107,Safety,redund,redundant,107,"# remove the xticks labels except for the last processed plot.; # Because the plots share the x axis it is redundant and less compact; # to plot the axis for each plot",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:575,Testability,log,log,575,"""""""; Given the anndata object, prepares a data frame in which the row index are the categories; defined by group by and the columns correspond to var_names. Parameters; ----------; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; groupby; The key of the observation grouping to consider. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; log; Use the log of the values.; layer; AnnData layer to use. Takes precedence over `use_raw`; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; gene_symbols; Key for field in .var that stores gene symbols. Returns; -------; Tuple of `pandas.DataFrame` and list of categories.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:588,Testability,log,log,588,"""""""; Given the anndata object, prepares a data frame in which the row index are the categories; defined by group by and the columns correspond to var_names. Parameters; ----------; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; groupby; The key of the observation grouping to consider. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; log; Use the log of the values.; layer; AnnData layer to use. Takes precedence over `use_raw`; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; gene_symbols; Key for field in .var that stores gene symbols. Returns; -------; Tuple of `pandas.DataFrame` and list of categories.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:19,Availability,avail,available,19,"# cut label to fit available space",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:239,Integrability,depend,depending,239,"""""""\; transforms the dendrogram coordinates to a given new position.; The xlabel_pos and orig_ticks should be of the same; length. This is mostly done for the heatmap case, where the position of the; dendrogram leaves needs to be adjusted depending on the category size. Parameters; ----------; pos_list; list of dendrogram positions that should be translated; new_ticks; sorted list of goal tick positions (e.g. [0,1,2,3] ); old_ticks; sorted list of original tick positions (e.g. [5, 15, 25, 35]),; This list is usually the default position used by; `scipy.cluster.hierarchy.dendrogram`. Returns; -------; translated list of positions. Examples; --------; >>> translate_pos(; ... [5, 15, 20, 21],; ... [0, 1, 2, 3 ],; ... [5, 15, 25, 35],; ... ); [0, 1, 1.5, 1.6]; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_anndata.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:261,Modifiability,variab,variable,261,"""""""\; title; Title for the figure; colorbar_title; Title for the color bar. New line character (\\n) can be used.; cmap; String denoting matplotlib color map.; standard_scale; Whether or not to standardize the given dimension between 0 and 1, meaning for; each variable or group, subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the; `groupby` categories and y the `var_names`.; return_fig; Returns :class:`DotPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:258,Energy Efficiency,adapt,adapt,258,"""""""\; Generic class for the visualization of AnnData categories and; selected `var` (features or genes). Takes care of the visual location of a main plot, additional plots; in the margins (e.g. dendrogram, margin totals) and legends. Also; understand how to adapt the visual parameter if the plot is rotated. Classed based on BasePlot implement their own _mainplot() method. The BasePlot works by method chaining. For example:; BasePlot(adata, ...).legend(title='legend').style(cmap='binary').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:258,Modifiability,adapt,adapt,258,"""""""\; Generic class for the visualization of AnnData categories and; selected `var` (features or genes). Takes care of the visual location of a main plot, additional plots; in the margins (e.g. dendrogram, margin totals) and legends. Also; understand how to adapt the visual parameter if the plot is rotated. Classed based on BasePlot implement their own _mainplot() method. The BasePlot works by method chaining. For example:; BasePlot(adata, ...).legend(title='legend').style(cmap='binary').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:145,Deployability,update,updates,145,"""""""; Plots a horizontal colorbar given the ax an normalize values. Parameters; ----------; color_legend_ax; normalize. Returns; -------; `None`, updates color_legend_ax; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:67,Modifiability,variab,variable,67,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at top and bottom.; # The structure for the legends is:; # first row: variable space to keep the first rows of the same size; # second row: size legend",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:162,Modifiability,variab,variable,162,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at top and bottom.; # The structure for the legends is:; # first row: variable space to keep the first rows of the same size; # second row: size legend",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:214,Safety,avoid,avoid,214,"""""""; Save the current figure. Parameters; ----------; filename; Figure filename. Figure *format* is taken from the file ending unless; the parameter `format` is given.; bbox_inches; By default is set to 'tight' to avoid cropping of the legends.; kwargs; Passed to :func:`matplotlib.pyplot.savefig`. See also; --------; `render()`: Renders the plot but does not call :func:`matplotlib.pyplot.show`; `show()`: Renders and shows the plot. Examples; -------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = [""C1QA"", ""PSAP"", ""CD79A"", ""CD79B"", ""CST3"", ""LYZ""]; >>> sc.pl._baseplot_class.BasePlot(; ... adata, markers, groupby=""bulk_labels""; ... ).savefig(""plot.pdf""); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:400,Deployability,update,updates,400,"""""""\; Function used by plotting functions that need to reorder the the groupby; observations based on the dendrogram results. The function checks if a dendrogram has already been precomputed.; If not, `sc.tl.dendrogram` is run with default parameters. The results found in `.uns[dendrogram_key]` are used to reorder; `var_group_labels` and `var_group_positions`. Returns; -------; `None`, internally updates; 'categories_idx_ordered', 'var_group_names_idx_ordered',; 'var_group_labels' and 'var_group_positions'; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:28,Integrability,message,message,28,"""""""used to clean up warning message""""""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:19,Availability,avail,available,19,"# cut label to fit available space",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:133,Deployability,update,updates,133,"""""""; checks if var_names is a dict. Is this is the cases, then set the; correct values for var_group_labels and var_group_positions. updates var_names, var_group_labels, var_group_positions; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_baseplot_class.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:90,Modifiability,variab,variables,90,"""""""\; adata; Annotated data matrix.; color; Keys for annotations of observations/cells or variables/genes, e.g.,; `'ann1'` or `['ann1', 'ann2']`.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. By default `var_names`; refer to the index column of the `.var` DataFrame. Setting this option allows; alternative names to be used.; use_raw; Use `.raw` attribute of `adata` for coloring with gene expression. If `None`,; defaults to `True` if `layer` isn't provided and `adata.raw` is present.; layer; Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:48,Modifiability,variab,variables,48,"""""""\; color_map; Color map to use for continous variables. Can be a name or a; :class:`~matplotlib.colors.Colormap` instance (e.g. `""magma`"", `""viridis""`; or `mpl.cm.cividis`), see :func:`~matplotlib.pyplot.get_cmap`.; If `None`, the value of `mpl.rcParams[""image.cmap""]` is used.; The default `color_map` can be set using :func:`~scanpy.set_figure_params`.; palette; Colors to use for plotting categorical annotation groups.; The palette can be a valid :class:`~matplotlib.colors.ListedColormap` name; (`'Set2'`, `'tab20'`, …), a :class:`~cycler.Cycler` object, a dict mapping; categories to colors, or a sequence of colors. Colors must be valid to; matplotlib. (see :func:`~matplotlib.colors.is_color_like`).; If `None`, `mpl.rcParams[""axes.prop_cycle""]` is used unless the categorical; variable already has colors stored in `adata.uns[""{var}_colors""]`.; If provided, values of `adata.uns[""{var}_colors""]` will be set.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:789,Modifiability,variab,variable,789,"""""""\; color_map; Color map to use for continous variables. Can be a name or a; :class:`~matplotlib.colors.Colormap` instance (e.g. `""magma`"", `""viridis""`; or `mpl.cm.cividis`), see :func:`~matplotlib.pyplot.get_cmap`.; If `None`, the value of `mpl.rcParams[""image.cmap""]` is used.; The default `color_map` can be set using :func:`~scanpy.set_figure_params`.; palette; Colors to use for plotting categorical annotation groups.; The palette can be a valid :class:`~matplotlib.colors.ListedColormap` name; (`'Set2'`, `'tab20'`, …), a :class:`~cycler.Cycler` object, a dict mapping; categories to colors, or a sequence of colors. Colors must be valid to; matplotlib. (see :func:`~matplotlib.colors.is_color_like`).; If `None`, `mpl.rcParams[""axes.prop_cycle""]` is used unless the categorical; variable already has colors stored in `adata.uns[""{var}_colors""]`.; If provided, values of `adata.uns[""{var}_colors""]` will be set.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:115,Modifiability,enhance,enhance,115,"""""""\; add_outline; If set to True, this will add a thin border around groups of dots. In some situations; this can enhance the aesthetics of the resulting image; outline_color; Tuple with two valid color names used to adjust the add_outline. The first color is the; border color (default: black), while the second color is a gap color between the; border color and the scatter dot (default: white).; outline_width; Tuple with two width numbers used to adjust the outline. The first value is the width; of the border color as a fraction of the scatter dot size (default: 0.3). The second value is; width of the gap color (default: 0.05).\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:366,Integrability,depend,depending,366,"""""""\; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; If `var_names` is a mapping, then the key is used as label; to group the values (see `var_group_labels`). The mapping values; should be sequences of valid `adata.var_names`. In this; case either coloring or 'brackets' are used for the grouping; of var names depending on the plot. When `var_names` is a mapping,; then the `var_group_labels` and `var_group_positions` are set.; groupby; The key of the observation grouping to consider.; use_raw; Use `raw` attribute of `adata` if present.; log; Plot on logarithmic axis.; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; categories_order; Order in which to show the categories. Note: add_dendrogram or add_totals; can change the categories order.; figsize; Figure size when `multi_panel=True`.; Otherwise the `rcParam['figure.figsize]` value is used.; Format is (width, height); dendrogram; If True or a valid dendrogram key, a dendrogram based on the hierarchical; clustering between the `groupby` categories is added.; The dendrogram information is computed using :func:`scanpy.tl.dendrogram`.; If `tl.dendrogram` has not been called previously the function is called; with default parameters.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols.; By default `var_names` refer to the index column of the `.var` DataFrame.; Setting this option allows alternative names to be used.; var_group_positions; Use this parameter to highlight groups of `var_names`.; This will draw a 'bracket' or a color block between the given start and end; positions. If the parameter `var_group_labels` is set, the corresponding; labels are added on top/left. E.g. `var_group_positions=[(4,10)]`; will add a bracket between the fourth `var_name` and the tenth `var_name`.; By giving more positions, more brackets/color b",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:597,Testability,log,log,597,"""""""\; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; If `var_names` is a mapping, then the key is used as label; to group the values (see `var_group_labels`). The mapping values; should be sequences of valid `adata.var_names`. In this; case either coloring or 'brackets' are used for the grouping; of var names depending on the plot. When `var_names` is a mapping,; then the `var_group_labels` and `var_group_positions` are set.; groupby; The key of the observation grouping to consider.; use_raw; Use `raw` attribute of `adata` if present.; log; Plot on logarithmic axis.; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; categories_order; Order in which to show the categories. Note: add_dendrogram or add_totals; can change the categories order.; figsize; Figure size when `multi_panel=True`.; Otherwise the `rcParam['figure.figsize]` value is used.; Format is (width, height); dendrogram; If True or a valid dendrogram key, a dendrogram based on the hierarchical; clustering between the `groupby` categories is added.; The dendrogram information is computed using :func:`scanpy.tl.dendrogram`.; If `tl.dendrogram` has not been called previously the function is called; with default parameters.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols.; By default `var_names` refer to the index column of the `.var` DataFrame.; Setting this option allows alternative names to be used.; var_group_positions; Use this parameter to highlight groups of `var_names`.; This will draw a 'bracket' or a color block between the given start and end; positions. If the parameter `var_group_labels` is set, the corresponding; labels are added on top/left. E.g. `var_group_positions=[(4,10)]`; will add a bracket between the fourth `var_name` and the tenth `var_name`.; By giving more positions, more brackets/color b",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:610,Testability,log,logarithmic,610,"""""""\; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; If `var_names` is a mapping, then the key is used as label; to group the values (see `var_group_labels`). The mapping values; should be sequences of valid `adata.var_names`. In this; case either coloring or 'brackets' are used for the grouping; of var names depending on the plot. When `var_names` is a mapping,; then the `var_group_labels` and `var_group_positions` are set.; groupby; The key of the observation grouping to consider.; use_raw; Use `raw` attribute of `adata` if present.; log; Plot on logarithmic axis.; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; categories_order; Order in which to show the categories. Note: add_dendrogram or add_totals; can change the categories order.; figsize; Figure size when `multi_panel=True`.; Otherwise the `rcParam['figure.figsize]` value is used.; Format is (width, height); dendrogram; If True or a valid dendrogram key, a dendrogram based on the hierarchical; clustering between the `groupby` categories is added.; The dendrogram information is computed using :func:`scanpy.tl.dendrogram`.; If `tl.dendrogram` has not been called previously the function is called; with default parameters.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols.; By default `var_names` refer to the index column of the `.var` DataFrame.; Setting this option allows alternative names to be used.; var_group_positions; Use this parameter to highlight groups of `var_names`.; This will draw a 'bracket' or a color block between the given start and end; positions. If the parameter `var_group_labels` is set, the corresponding; labels are added on top/left. E.g. `var_group_positions=[(4,10)]`; will add a bracket between the fourth `var_name` and the tenth `var_name`.; By giving more positions, more brackets/color b",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:182,Availability,down,down,182,"""""""\; adata; Annotated data matrix.; groups; The groups for which to show the gene ranking.; n_genes; Number of genes to show. This can be a negative number to show for; example the down regulated genes. eg: num_genes=-10. Is ignored if; `gene_names` is passed.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. By default `var_names`; refer to the index column of the `.var` DataFrame. Setting this option allows; alternative names to be used.; groupby; The key of the observation grouping to consider. By default,; the groupby is chosen from the rank genes groups parameter but; other groupby options can be used. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories` (see :func:`~scanpy.pl.dotplot`).; min_logfoldchange; Value to filter genes in groups if their logfoldchange is less than the; min_logfoldchange; key; Key used to store the ranking results in `adata.uns`.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:872,Testability,log,logfoldchange,872,"""""""\; adata; Annotated data matrix.; groups; The groups for which to show the gene ranking.; n_genes; Number of genes to show. This can be a negative number to show for; example the down regulated genes. eg: num_genes=-10. Is ignored if; `gene_names` is passed.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. By default `var_names`; refer to the index column of the `.var` DataFrame. Setting this option allows; alternative names to be used.; groupby; The key of the observation grouping to consider. By default,; the groupby is chosen from the rank genes groups parameter but; other groupby options can be used. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories` (see :func:`~scanpy.pl.dotplot`).; min_logfoldchange; Value to filter genes in groups if their logfoldchange is less than the; min_logfoldchange; key; Key used to store the ranking results in `adata.uns`.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:136,Testability,log,logfoldchanges,136,"""""""\; values_to_plot; Instead of the mean gene value, plot the values computed by `sc.rank_genes_groups`.; The options are: ['scores', 'logfoldchanges', 'pvals', 'pvals_adj',; 'log10_pvals', 'log10_pvals_adj']. When plotting logfoldchanges a divergent; colormap is recommended. See examples below.; var_names; Genes to plot. Sometimes is useful to pass a specific list of var names (e.g. genes); to check their fold changes or p-values, instead of the top/bottom genes. The; var_names could be a dictionary or a list as in :func:`~scanpy.pl.dotplot` or; :func:`~scanpy.pl.matrixplot`. See examples below.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:225,Testability,log,logfoldchanges,225,"""""""\; values_to_plot; Instead of the mean gene value, plot the values computed by `sc.rank_genes_groups`.; The options are: ['scores', 'logfoldchanges', 'pvals', 'pvals_adj',; 'log10_pvals', 'log10_pvals_adj']. When plotting logfoldchanges a divergent; colormap is recommended. See examples below.; var_names; Genes to plot. Sometimes is useful to pass a specific list of var names (e.g. genes); to check their fold changes or p-values, instead of the top/bottom genes. The; var_names could be a dictionary or a list as in :func:`~scanpy.pl.dotplot` or; :func:`~scanpy.pl.matrixplot`. See examples below.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:1367,Modifiability,variab,variable,1367,"fraction; of cells (obs) that have a non-zero value for genes (var). For each var_name and each `groupby` category a dot is plotted.; Each dot represents two values: mean expression within each category; (visualized by color) and fraction of cells expressing the `var_name` in the; category (visualized by the size of the dot). If `groupby` is not given,; the dotplot assumes that all data belongs to a single category. .. note::; A gene is considered expressed if the expression value in the `adata` (or; `adata.raw`) is above the specified threshold which is zero by default. An example of dotplot usage is to visualize, for multiple marker genes,; the mean value and the percentage of cells expressing the gene; across multiple clusters. Parameters; ----------; {common_plot_args}; title; Title for the figure; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.dotplot`: Simpler way to call DotPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_dotplot`: to plot marker; genes identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). Using var_names as dict:. >>> markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:1544,Usability,Simpl,Simpler,1544,"fraction; of cells (obs) that have a non-zero value for genes (var). For each var_name and each `groupby` category a dot is plotted.; Each dot represents two values: mean expression within each category; (visualized by color) and fraction of cells expressing the `var_name` in the; category (visualized by the size of the dot). If `groupby` is not given,; the dotplot assumes that all data belongs to a single category. .. note::; A gene is considered expressed if the expression value in the `adata` (or; `adata.raw`) is above the specified threshold which is zero by default. An example of dotplot usage is to visualize, for multiple marker genes,; the mean value and the percentage of cells expressing the gene; across multiple clusters. Parameters; ----------; {common_plot_args}; title; Title for the figure; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.dotplot`: Simpler way to call DotPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_dotplot`: to plot marker; genes identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). Using var_names as dict:. >>> markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:6,Modifiability,Config,Configures,6,"""""""\; Configures dot size and the colorbar legends. Parameters; ----------; show; Set to `False` to hide the default plot of the legends. This sets the; legend width to zero, which will result in a wider main plot.; show_size_legend; Set to `False` to hide the dot size legend; show_colorbar; Set to `False` to hide the colorbar legend; size_title; Title for the dot size legend. Use '\\n' to add line breaks. Appears on top; of dot sizes; colorbar_title; Title for the color bar. Use '\\n' to add line breaks. Appears on top of the; color bar; width; Width of the legends area. The unit is the same as in matplotlib (inches). Returns; -------; :class:`~scanpy.pl.DotPlot`. Examples; --------. Set color bar title:. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}; >>> dp = sc.pl.DotPlot(adata, markers, groupby='bulk_labels'); >>> dp.legend(colorbar_title='log(UMI counts + 1)').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:949,Testability,log,log,949,"""""""\; Configures dot size and the colorbar legends. Parameters; ----------; show; Set to `False` to hide the default plot of the legends. This sets the; legend width to zero, which will result in a wider main plot.; show_size_legend; Set to `False` to hide the dot size legend; show_colorbar; Set to `False` to hide the colorbar legend; size_title; Title for the dot size legend. Use '\\n' to add line breaks. Appears on top; of dot sizes; colorbar_title; Title for the color bar. Use '\\n' to add line breaks. Appears on top of the; color bar; width; Width of the legends area. The unit is the same as in matplotlib (inches). Returns; -------; :class:`~scanpy.pl.DotPlot`. Examples; --------. Set color bar title:. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}; >>> dp = sc.pl.DotPlot(adata, markers, groupby='bulk_labels'); >>> dp.legend(colorbar_title='log(UMI counts + 1)').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:67,Modifiability,variab,variable,67,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at the bottom.; # The structure for the legends is:; # first row: variable space to keep the other rows of; # the same size (avoid stretching); # second row: legend for dot size; # third row: spacer to avoid color and size legend titles to overlap; # fourth row: colorbar",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:158,Modifiability,variab,variable,158,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at the bottom.; # The structure for the legends is:; # first row: variable space to keep the other rows of; # the same size (avoid stretching); # second row: legend for dot size; # third row: spacer to avoid color and size legend titles to overlap; # fourth row: colorbar",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:217,Safety,avoid,avoid,217,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at the bottom.; # The structure for the legends is:; # first row: variable space to keep the other rows of; # the same size (avoid stretching); # second row: legend for dot size; # third row: spacer to avoid color and size legend titles to overlap; # fourth row: colorbar",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:294,Safety,avoid,avoid,294,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at the bottom.; # The structure for the legends is:; # first row: variable space to keep the other rows of; # the same size (avoid stretching); # second row: legend for dot size; # third row: spacer to avoid color and size legend titles to overlap; # fourth row: colorbar",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:47,Safety,avoid,avoid,47,"# work on a copy of the dataframes. This is to avoid changes; # on the original data frames after repetitive calls to the; # DotPlot object, for example once with swap_axes and other without",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:1306,Modifiability,variab,variable,1306," plotted using :func:`matplotlib.pyplot.scatter`. Thus, additional; arguments can be passed. Parameters; ----------; dot_size: Data frame containing the dot_size.; dot_color: Data frame containing the dot_color, should have the same,; shape, columns and indices as dot_size.; dot_ax: matplotlib axis; cmap; String denoting matplotlib color map.; color_on; Options are 'dot' or 'square'. Be default the colomap is applied to; the color of the dot. Optionally, the colormap can be applied to an; square behind the dot, in which case the dot is transparent and only; the edge is shown.; y_label: String. Label for y axis; dot_max; If none, the maximum dot size is set to the maximum fraction value found; (e.g. 0.6). If given, the value should be a number between 0 and 1.; All fractions larger than dot_max are clipped to this value.; dot_min; If none, the minimum dot size is set to 0. If given,; the value should be a number between 0 and 1.; All fractions smaller than dot_min are clipped to this value.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; smallest_dot; If none, the smallest dot has size 0.; All expression levels with `dot_min` are plotted with this size.; edge_color; Dot edge color. When `color_on='dot'` the default is no edge. When; `color_on='square'`, edge color is white; edge_lw; Dot edge line width. When `color_on='dot'` the default is no edge. When; `color_on='square'`, line width = 1.5; grid; Adds a grid to the plot; x_paddding; Space between the plot left/right borders and the dots center. A unit; is the distance between the x ticks. Only applied when color_on = dot; y_paddding; Space between the plot top/bottom borders and the dots center. A unit is; the distance between the y ticks. Only applied when color_on = dot; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. Returns; -------; matplotlib.colors.Normalize, dot_min, dot_max. """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:50,Integrability,depend,depending,50,"# use either black or white for the edge color; # depending on the luminance of the background; # square color",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:2241,Availability,avail,available,2241,"; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; dot_max; If none, the maximum dot size is set to the maximum fraction value found; (e.g. 0.6). If given, the value should be a number between 0 and 1.; All fractions larger than dot_max are clipped to this value.; dot_min; If none, the minimum dot size is set to 0. If given,; the value should be a number between 0 and 1.; All fractions smaller than dot_min are clipped to this value.; smallest_dot; If none, the smallest dot has size 0.; All expression levels with `dot_min` are plotted with this size.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.DotPlot` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.DotPlot`: The DotPlot class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_dotplot`: to plot marker genes; identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Create a dot plot using the given markers and the PBMC example dataset grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True). Get DotPlot object for fine tuning. .. plot::; :context: close-figs. dp = sc.pl.dotplot(adata, markers, 'bulk_labels', return_fig=True); dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). The axes used can be obtained using the ge",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:774,Integrability,interface,interface,774,"""""""\; Makes a *dot plot* of the expression values of `var_names`. For each var_name and each `groupby` category a dot is plotted.; Each dot represents two values: mean expression within each category; (visualized by color) and fraction of cells expressing the `var_name` in the; category (visualized by the size of the dot). If `groupby` is not given,; the dotplot assumes that all data belongs to a single category. .. note::; A gene is considered expressed if the expression value in the `adata` (or; `adata.raw`) is above the specified threshold which is zero by default. An example of dotplot usage is to visualize, for multiple marker genes,; the mean value and the percentage of cells expressing the gene; across multiple clusters. This function provides a convenient interface to the :class:`~scanpy.pl.DotPlot`; class. If you need more flexibility, you should use :class:`~scanpy.pl.DotPlot`; directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; size_title; Title for the size legend. New line character (\\n) can be used.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; dot_max; If none, the maximum dot size is set to the maximum fraction value found; (e.g. 0.6). If given, the value should be a number between 0 and 1.; All fractions larger than dot_max are clipped to this value.; dot_min; If none, the minimum dot size is set to 0. If given,; the value should be a number between 0 and 1.; All fractions smaller than dot_min are clipped to this value.; smallest_dot; If none, the smallest dot has size 0.; All expression levels with `dot_min` are plotted with this size.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. Returns; -------; I",MatchSource.CODE_COMMENT,src/scanpy/plotting/_dotplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:569,Modifiability,variab,variable,569,"""""""\; Allows the visualization of values using a color map. Parameters; ----------; {common_plot_args}; title; Title for the figure.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; values_df; Optionally, a dataframe with the values to plot can be given. The; index should be the grouby categories and the columns the genes names. kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.matrixplot`: Simpler way to call MatrixPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Simple visualization of the average expression of a few genes grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_matrixplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:898,Usability,Simpl,Simpler,898,"""""""\; Allows the visualization of values using a color map. Parameters; ----------; {common_plot_args}; title; Title for the figure.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; values_df; Optionally, a dataframe with the values to plot can be given. The; index should be the grouby categories and the columns the genes names. kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.matrixplot`: Simpler way to call MatrixPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Simple visualization of the average expression of a few genes grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_matrixplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:1112,Usability,Simpl,Simple,1112,"""""""\; Allows the visualization of values using a color map. Parameters; ----------; {common_plot_args}; title; Title for the figure.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; values_df; Optionally, a dataframe with the values to plot can be given. The; index should be the grouby categories and the columns the genes names. kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.matrixplot`: Simpler way to call MatrixPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Simple visualization of the average expression of a few genes grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_matrixplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:47,Safety,avoid,avoid,47,"# work on a copy of the dataframes. This is to avoid changes; # on the original data frames after repetitive calls to the; # MatrixPlot object, for example once with swap_axes and other without",MatchSource.CODE_COMMENT,src/scanpy/plotting/_matrixplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:677,Availability,avail,available,677,"""""""\; Creates a heatmap of the mean expression values per group of each var_names. This function provides a convenient interface to the :class:`~scanpy.pl.MatrixPlot`; class. If you need more flexibility, you should use :class:`~scanpy.pl.MatrixPlot`; directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.pcolor`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.MatrixPlot` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.MatrixPlot`: The MatrixPlot class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes; identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Get Matrix object for fine tuning:. .. plot::; :context: close-figs. mp = sc.pl.matrixplot(adata, markers, 'bulk_labels', return_fig=True); mp.add_totals().style(edge_color='black').show(). The axes used can be obtained using the get_axes() method. .. plot::; :context: close-figs. axes_dict = mp.get_axes(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_matrixplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:119,Integrability,interface,interface,119,"""""""\; Creates a heatmap of the mean expression values per group of each var_names. This function provides a convenient interface to the :class:`~scanpy.pl.MatrixPlot`; class. If you need more flexibility, you should use :class:`~scanpy.pl.MatrixPlot`; directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.pcolor`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.MatrixPlot` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.MatrixPlot`: The MatrixPlot class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes; identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Get Matrix object for fine tuning:. .. plot::; :context: close-figs. mp = sc.pl.matrixplot(adata, markers, 'bulk_labels', return_fig=True); mp.add_totals().style(edge_color='black').show(). The axes used can be obtained using the get_axes() method. .. plot::; :context: close-figs. axes_dict = mp.get_axes(); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_matrixplot.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:136,Modifiability,Variab,VariableFeaturePlot,136,"""""""Plot dispersions or normalized variance versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() and; VariableFeaturePlot() of Seurat. Parameters; ----------; adata; Result of :func:`~scanpy.pp.highly_variable_genes`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:253,Testability,log,log,253,"""""""Plot dispersions or normalized variance versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() and; VariableFeaturePlot() of Seurat. Parameters; ----------; adata; Result of :func:`~scanpy.pp.highly_variable_genes`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:266,Testability,log,logarithmic,266,"""""""Plot dispersions or normalized variance versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() and; VariableFeaturePlot() of Seurat. Parameters; ----------; adata; Result of :func:`~scanpy.pp.highly_variable_genes`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:209,Testability,log,log,209,"""""""\; Plot dispersions versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() of Seurat. Parameters; ----------; result; Result of :func:`~scanpy.pp.filter_genes_dispersion`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:222,Testability,log,logarithmic,222,"""""""\; Plot dispersions versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() of Seurat. Parameters; ----------; result; Result of :func:`~scanpy.pp.filter_genes_dispersion`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py:762,Safety,predict,predicted,762,"""""""\; Fraction of counts assigned to each gene over all cells. Computes, for each gene, the fraction of counts assigned to that gene within; a cell. The `n_top` genes with the highest mean fraction over all cells are; plotted as boxplots. This plot is similar to the `scater` package function `plotHighestExprs(type; = ""highest-expression"")`, see `here; <https://bioconductor.org/packages/devel/bioc/vignettes/scater/inst/doc/vignette-qc.html>`__. Quoting; from there:. *We expect to see the “usual suspects”, i.e., mitochondrial genes, actin,; ribosomal protein, MALAT1. A few spike-in transcripts may also be; present here, though if all of the spike-ins are in the top 50, it; suggests that too much spike-in RNA was added. A large number of; pseudo-genes or predicted genes may indicate problems with alignment.*; -- Davis McCarthy and Aaron Lun. Parameters; ----------; adata; Annotated data matrix.; n_top; Number of top; {show_save_ax}; gene_symbols; Key for field in .var that stores gene symbols if you do not want to use .var_names.; log; Plot x-axis in log scale; **kwds; Are passed to :func:`~seaborn.boxplot`. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py:1044,Testability,log,log,1044,"""""""\; Fraction of counts assigned to each gene over all cells. Computes, for each gene, the fraction of counts assigned to that gene within; a cell. The `n_top` genes with the highest mean fraction over all cells are; plotted as boxplots. This plot is similar to the `scater` package function `plotHighestExprs(type; = ""highest-expression"")`, see `here; <https://bioconductor.org/packages/devel/bioc/vignettes/scater/inst/doc/vignette-qc.html>`__. Quoting; from there:. *We expect to see the “usual suspects”, i.e., mitochondrial genes, actin,; ribosomal protein, MALAT1. A few spike-in transcripts may also be; present here, though if all of the spike-ins are in the top 50, it; suggests that too much spike-in RNA was added. A large number of; pseudo-genes or predicted genes may indicate problems with alignment.*; -- Davis McCarthy and Aaron Lun. Parameters; ----------; adata; Annotated data matrix.; n_top; Number of top; {show_save_ax}; gene_symbols; Key for field in .var that stores gene symbols if you do not want to use .var_names.; log; Plot x-axis in log scale; **kwds; Are passed to :func:`~seaborn.boxplot`. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py:1064,Testability,log,log,1064,"""""""\; Fraction of counts assigned to each gene over all cells. Computes, for each gene, the fraction of counts assigned to that gene within; a cell. The `n_top` genes with the highest mean fraction over all cells are; plotted as boxplots. This plot is similar to the `scater` package function `plotHighestExprs(type; = ""highest-expression"")`, see `here; <https://bioconductor.org/packages/devel/bioc/vignettes/scater/inst/doc/vignette-qc.html>`__. Quoting; from there:. *We expect to see the “usual suspects”, i.e., mitochondrial genes, actin,; ribosomal protein, MALAT1. A few spike-in transcripts may also be; present here, though if all of the spike-ins are in the top 50, it; suggests that too much spike-in RNA was added. A large number of; pseudo-genes or predicted genes may indicate problems with alignment.*; -- Davis McCarthy and Aaron Lun. Parameters; ----------; adata; Annotated data matrix.; n_top; Number of top; {show_save_ax}; gene_symbols; Key for field in .var that stores gene symbols if you do not want to use .var_names.; log; Plot x-axis in log scale; **kwds; Are passed to :func:`~seaborn.boxplot`. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:202,Integrability,Wrap,Wraps,202,"""""""\; Stacked violin plots. Makes a compact image composed of individual violin plots; (from :func:`~seaborn.violinplot`) stacked on top of each other.; Useful to visualize gene expression per cluster. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; {common_plot_args}; title; Title for the figure; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; density_norm; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; row_palette; The row palette determines the colors to use for the stacked violins.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; standard_scale; Whether or not to standardize a dimension between 0 and 1,; meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the `groupby`; categories and y the `var_names`. When swapping; axes var_group_positions are no longer used; kwds; Are passed to :func:`~seaborn.violinplot`. See also; --------; :func:`~scanpy.pl.stacked_violin`: simpler way to call StackedViolin but with less; options.; :func:`~scanpy.pl.violin` and :func:`~scanpy.pl.rank_genes_groups_stacked_violin`:; to plot marker genes identified using :func:`~scanpy.tl.rank_genes_groups`.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:1346,Modifiability,variab,variable,1346,"; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; density_norm; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; row_palette; The row palette determines the colors to use for the stacked violins.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; standard_scale; Whether or not to standardize a dimension between 0 and 1,; meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the `groupby`; categories and y the `var_names`. When swapping; axes var_group_positions are no longer used; kwds; Are passed to :func:`~seaborn.violinplot`. See also; --------; :func:`~scanpy.pl.stacked_violin`: simpler way to call StackedViolin but with less; options.; :func:`~scanpy.pl.violin` and :func:`~scanpy.pl.rank_genes_groups_stacked_violin`:; to plot marker genes identified using :func:`~scanpy.tl.rank_genes_groups`. Examples; -------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.StackedViolin(adata, markers, groupby='bulk_labels', dendrogram=True) # doctest: +ELLIPSIS; <scanpy.plotting._stacked_violin.StackedViolin object at 0x...>. Using var_names a",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:1783,Usability,simpl,simpler,1783,"the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; density_norm; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; row_palette; The row palette determines the colors to use for the stacked violins.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; standard_scale; Whether or not to standardize a dimension between 0 and 1,; meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the `groupby`; categories and y the `var_names`. When swapping; axes var_group_positions are no longer used; kwds; Are passed to :func:`~seaborn.violinplot`. See also; --------; :func:`~scanpy.pl.stacked_violin`: simpler way to call StackedViolin but with less; options.; :func:`~scanpy.pl.violin` and :func:`~scanpy.pl.rank_genes_groups_stacked_violin`:; to plot marker genes identified using :func:`~scanpy.tl.rank_genes_groups`. Examples; -------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.StackedViolin(adata, markers, groupby='bulk_labels', dendrogram=True) # doctest: +ELLIPSIS; <scanpy.plotting._stacked_violin.StackedViolin object at 0x...>. Using var_names as dict:. >>> markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; >>> sc.pl.StackedViolin(adata, markers, groupby='bulk_labels', dendrogram=True) # doctest: +ELLIPSIS; <scanpy.plotting._stacked_violin.StackedViolin object at 0x...>; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:103,Modifiability,extend,extend,103,"# a unit is the distance between two y-axis ticks; # set by default the violin plot cut=0 to limit the extend; # of the violin plot as this produces better plots that wont extend; # to negative values for example. From seaborn.violin documentation:; #; # cut: Distance, in units of bandwidth size, to extend the density past; # the extreme datapoints. Set to 0 to limit the violin range within; # the range of the observed data (i.e., to have the same effect as; # trim=True in ggplot.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:172,Modifiability,extend,extend,172,"# a unit is the distance between two y-axis ticks; # set by default the violin plot cut=0 to limit the extend; # of the violin plot as this produces better plots that wont extend; # to negative values for example. From seaborn.violin documentation:; #; # cut: Distance, in units of bandwidth size, to extend the density past; # the extreme datapoints. Set to 0 to limit the violin range within; # the range of the observed data (i.e., to have the same effect as; # trim=True in ggplot.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:301,Modifiability,extend,extend,301,"# a unit is the distance between two y-axis ticks; # set by default the violin plot cut=0 to limit the extend; # of the violin plot as this produces better plots that wont extend; # to negative values for example. From seaborn.violin documentation:; #; # cut: Distance, in units of bandwidth size, to extend the density past; # the extreme datapoints. Set to 0 to limit the violin range within; # the range of the observed data (i.e., to have the same effect as; # trim=True in ggplot.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:31,Security,access,accessing,31,"""""""Called unconditionally when accessing an instance attribute""""""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:75,Security,access,accesses,75,"# If the user has set the deprecated version on the class,; # and our code accesses the new version from the instance,; # return the user-specified version instead and warn.; # This is done because class properties are hard to do.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:29,Safety,avoid,avoid,29,"# space needs to be added to avoid overlapping; # of labels and legend or dendrogram/totals.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:188,Safety,avoid,avoid,188,"# to make the stacked violin plots, the; # `ax` is subdivided horizontally and in each horizontal sub ax; # a seaborn violin plot is added.; # work on a copy of the dataframes. This is to avoid changes; # on the original data frames after repetitive calls to the; # StackedViolin object, for example once with swap_axes and other without",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:5,Modifiability,Config,Configures,5,"""""""; Configures each of the violin plot axes ticks like remove or add labels etc. """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:36,Modifiability,extend,extend,36,"# make line a bit ticker to see the extend of the yaxis in the; # final plot",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:135,Safety,avoid,avoid,135,"# use only the smallest and the largest y ticks; # and align the firts label on top of the tick and; # the second below the tick. This avoid overlapping; # of nearby ticks",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:1960,Availability,avail,available,1960,"ale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; yticklabels; Set to true to view the y tick labels.; row_palette; Be default, median values are mapped to the violin color using a; color map (see `cmap` argument). Alternatively, a 'row_palette` can; be given to color each violin plot row using a different colors.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.StackedViolin` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.StackedViolin`: The StackedViolin class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_stacked_violin` to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; -------. Visualization of violin plots of a few genes grouped by the category `bulk_labels`:. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', dendrogram=True). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', dendrogram=True). Get StackedViolin object for fine tuning. .. plot::; :context: close-figs. vp = sc.pl.stacked_violin(adata, markers, 'bulk_labels', return_fig=True); vp.add_totals().sty",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:202,Integrability,Wrap,Wraps,202,"""""""\; Stacked violin plots. Makes a compact image composed of individual violin plots; (from :func:`~seaborn.violinplot`) stacked on top of each other.; Useful to visualize gene expression per cluster. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. This function provides a convenient interface to the; :class:`~scanpy.pl.StackedViolin` class. If you need more flexibility,; you should use :class:`~scanpy.pl.StackedViolin` directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; yticklabels; Set to true to view the y tick labels.; row_palette; Be default, median values are mapped to the violin color using a; color map (see `cmap` argument). Alternatively, a 'row_palette` can; be given to color each violin plot row using a different colors.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.StackedViolin` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.StackedViolin`: The StackedViolin class can be used to to control; several visual parameters not available in this function.; :func:`~scan",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:302,Integrability,interface,interface,302,"""""""\; Stacked violin plots. Makes a compact image composed of individual violin plots; (from :func:`~seaborn.violinplot`) stacked on top of each other.; Useful to visualize gene expression per cluster. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. This function provides a convenient interface to the; :class:`~scanpy.pl.StackedViolin` class. If you need more flexibility,; you should use :class:`~scanpy.pl.StackedViolin` directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; yticklabels; Set to true to view the y tick labels.; row_palette; Be default, median values are mapped to the violin color using a; color map (see `cmap` argument). Alternatively, a 'row_palette` can; be given to color each violin plot row using a different colors.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.StackedViolin` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.StackedViolin`: The StackedViolin class can be used to to control; several visual parameters not available in this function.; :func:`~scan",MatchSource.CODE_COMMENT,src/scanpy/plotting/_stacked_violin.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:85,Usability,Simpl,Simple,85,"# -------------------------------------------------------------------------------; # Simple plotting functions; # -------------------------------------------------------------------------------",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:122,Deployability,continuous,continuous,122,"""""""\; Plot X. Parameters; ----------; X; Call this with:; X with one column, color categorical.; X with one column, color continuous.; X with n columns, color is of length n.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:109,Modifiability,variab,variables,109,"""""""\; Plot timeseries as heatmap. Parameters; ----------; X; Data array.; var_names; Array of strings naming variables stored in columns of X.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:2,Deployability,update,update,2,"# update variables",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:9,Modifiability,variab,variables,9,"# update variables",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:2,Usability,clear,clear,2,"# clear figure",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:78,Deployability,update,updates,78,"""""""; checks if the list of colors in adata.uns[f'{key}_colors'] is valid; and updates the color list in adata.uns[f'{key}_colors'] if needed. Not only valid matplotlib colors are checked but also if the color name; is a valid R color name, in which case it will be translated to a valid name; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:100,Integrability,Depend,Depending,100,"""""""Plot scatter plot of data. Parameters; ----------; Y; Data array.; projection. Returns; -------; Depending on whether supplying a single array or a list of arrays,; return a single axis or a list of axes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:433,Energy Efficiency,allocate,allocated,433,"""""""Tree layout for networkx graph. See https://stackoverflow.com/questions/29586520/can-one-get-hierarchical-graphs-from-networkx-with-python-3; answer by burubum. If there is a cycle that is reachable from root, then this will see; infinite recursion. Parameters; ----------; G: the graph; root: the root node; levels: a dictionary; key: level number (starting from 0); value: number of nodes in this level; width: horizontal space allocated for drawing; height: vertical space allocated for drawing; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:479,Energy Efficiency,allocate,allocated,479,"""""""Tree layout for networkx graph. See https://stackoverflow.com/questions/29586520/can-one-get-hierarchical-graphs-from-networkx-with-python-3; answer by burubum. If there is a cycle that is reachable from root, then this will see; infinite recursion. Parameters; ----------; G: the graph; root: the root node; levels: a dictionary; key: level number (starting from 0); value: number of nodes in this level; width: horizontal space allocated for drawing; height: vertical space allocated for drawing; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:3,Security,Validat,Validation,3,"""""""Validation for projection argument.""""""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:49,Deployability,patch,patch,49,"# You can set `facecolor` with an array for each patch,; # while you can only set `facecolors` with a value for all.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:166,Availability,error,errors,166,"""""""; Given a dictionary of plot parameters (kwds_dict) and a dict of kwds,; merge the parameters into a single consolidated dictionary to avoid; argument duplication errors. If kwds_dict an kwargs have the same key, only the value in kwds_dict is kept. Parameters; ----------; kwds_dict kwds_dictionary; kwargs. Returns; -------; kwds_dict merged with kwargs. Examples; --------. >>> def _example(**kwds):; ... return fix_kwds(kwds, key1=""value1"", key2=""value2""); >>> _example(key1=""value10"", key3=""value3""); {'key1': 'value10', 'key2': 'value2', 'key3': 'value3'}; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:138,Safety,avoid,avoid,138,"""""""; Given a dictionary of plot parameters (kwds_dict) and a dict of kwds,; merge the parameters into a single consolidated dictionary to avoid; argument duplication errors. If kwds_dict an kwargs have the same key, only the value in kwds_dict is kept. Parameters; ----------; kwds_dict kwds_dictionary; kwargs. Returns; -------; kwds_dict merged with kwargs. Examples; --------. >>> def _example(**kwds):; ... return fix_kwds(kwds, key1=""value1"", key2=""value2""); >>> _example(key1=""value10"", key3=""value3""); {'key1': 'value10', 'key2': 'value2', 'key3': 'value3'}; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_utils.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:2,Performance,Perform,Performance,2,"# Performance",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:2,Availability,Toler,Tolerance,2,"# Tolerance",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:2,Testability,Log,Log,2,"# Log",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:3450,Deployability,patch,patches,3450,"the matrix that stores the; arrows, for instance `'transitions_confidence'`.; solid_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn solid black.; dashed_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn dashed grey. If `None`, no dashed edges are drawn.; single_component; Restrict to largest connected component.; fontsize; Font size for node labels.; fontoutline; Width of the white outline around fonts.; text_kwds; Keywords for :meth:`~matplotlib.axes.Axes.text`.; node_size_scale; Increase or decrease the size of the nodes.; node_size_power; The power with which groups sizes influence the radius of the nodes.; edge_width_scale; Edge with scale in units of `rcParams['lines.linewidth']`.; min_edge_width; Min width of solid edges.; max_edge_width; Max width of solid and dashed edges.; arrowsize; For directed graphs, choose the size of the arrow head head's length and; width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute; `mutation_scale` for more info.; export_to_gexf; Export to gexf format to be read by graph visualization programs such as; Gephi.; normalize_to_color; Whether to normalize categorical plots to `color` or the underlying; grouping.; cmap; The color map.; cax; A matplotlib axes object for a potential colorbar.; cb_kwds; Keyword arguments for :class:`~matplotlib.colorbar.Colorbar`,; for instance, `ticks`.; add_pos; Add the positions to `adata.uns['paga']`.; title; Provide a title.; frameon; Draw a frame around the PAGA graph.; plot; If `False`, do not create the figure, simply compute the layout.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on \\{`'.pdf'`, `'.png'`, `'.svg'`\\}.; ax; A matplotlib axes object. Returns; -------; If `show==False`, one or more :class:`~matplotlib.axes.Axes` objects.; Adds `'pos'` to `adata.uns['paga']` if `add_pos` is `True`. Examples; --------. ..",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:3090,Energy Efficiency,power,power,3090,"node or a list; of root node indices. If this is a non-empty vector then the supplied; node IDs are used as the roots of the trees (or a single tree if the; graph is connected). If this is `None` or an empty list, the root; vertices are automatically calculated based on topological sorting.; transitions; Key for `.uns['paga']` that specifies the matrix that stores the; arrows, for instance `'transitions_confidence'`.; solid_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn solid black.; dashed_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn dashed grey. If `None`, no dashed edges are drawn.; single_component; Restrict to largest connected component.; fontsize; Font size for node labels.; fontoutline; Width of the white outline around fonts.; text_kwds; Keywords for :meth:`~matplotlib.axes.Axes.text`.; node_size_scale; Increase or decrease the size of the nodes.; node_size_power; The power with which groups sizes influence the radius of the nodes.; edge_width_scale; Edge with scale in units of `rcParams['lines.linewidth']`.; min_edge_width; Min width of solid edges.; max_edge_width; Max width of solid and dashed edges.; arrowsize; For directed graphs, choose the size of the arrow head head's length and; width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute; `mutation_scale` for more info.; export_to_gexf; Export to gexf format to be read by graph visualization programs such as; Gephi.; normalize_to_color; Whether to normalize categorical plots to `color` or the underlying; grouping.; cmap; The color map.; cax; A matplotlib axes object for a potential colorbar.; cb_kwds; Keyword arguments for :class:`~matplotlib.colorbar.Colorbar`,; for instance, `ticks`.; add_pos; Add the positions to `adata.uns['paga']`.; title; Provide a title.; frameon; Draw a frame around the PAGA graph.; plot; If `False`, do not create the figure, simply compute the layout.; save; If `True` or a",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:1981,Performance,optimiz,optimization,1981,"`. If the fractions; do not sum to 1, a new category called `'rest'` colored grey will be created.; labels; The node labels. If `None`, this defaults to the group labels stored in; the categorical for which :func:`~scanpy.tl.paga` has been computed.; pos; Two-column array-like storing the x and y coordinates for drawing.; Otherwise, path to a `.gdf` file that has been exported from Gephi or; a similar graph visualization software.; layout; Plotting layout that computes positions.; `'fa'` stands for “ForceAtlas2”,; `'fr'` stands for “Fruchterman-Reingold”,; `'rt'` stands for “Reingold-Tilford”,; `'eq_tree'` stands for “eqally spaced tree”.; All but `'fa'` and `'eq_tree'` are igraph layouts.; All other igraph layouts are also permitted.; See also parameter `pos` and :func:`~scanpy.tl.draw_graph`.; layout_kwds; Keywords for the layout.; init_pos; Two-column array storing the x and y coordinates for initializing the; layout.; random_state; For layouts with random initialization like `'fr'`, change this to use; different intial states for the optimization. If `None`, the initial; state is not reproducible.; root; If choosing a tree layout, this is the index of the root node or a list; of root node indices. If this is a non-empty vector then the supplied; node IDs are used as the roots of the trees (or a single tree if the; graph is connected). If this is `None` or an empty list, the root; vertices are automatically calculated based on topological sorting.; transitions; Key for `.uns['paga']` that specifies the matrix that stores the; arrows, for instance `'transitions_confidence'`.; solid_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn solid black.; dashed_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn dashed grey. If `None`, no dashed edges are drawn.; single_component; Restrict to largest connected component.; fontsize; Font size for node labels.; fontoutline; Width of the white outli",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:599,Usability,clear,clearer,599,"""""""\; Plot the PAGA graph through thresholding low-connectivity edges. Compute a coarse-grained layout of the data. Reuse this by passing; `init_pos='paga'` to :func:`~scanpy.tl.umap` or; :func:`~scanpy.tl.draw_graph` and obtain embeddings with more meaningful; global topology :cite:p:`Wolf2019`. This uses ForceAtlas2 or igraph's layout algorithms for most layouts :cite:p:`Csardi2006`. Parameters; ----------; adata; Annotated data matrix.; threshold; Do not draw edges for weights below this threshold. Set to 0 if you want; all edges. Discarding low-connectivity edges helps in getting a much; clearer picture of the graph.; color; Gene name or `obs` annotation defining the node colors.; Also plots the degree of the abstracted graph when; passing {`'degree_dashed'`, `'degree_solid'`}. Can be also used to visualize pie chart at each node in the following form:; `{<group name or index>: {<color>: <fraction>, ...}, ...}`. If the fractions; do not sum to 1, a new category called `'rest'` colored grey will be created.; labels; The node labels. If `None`, this defaults to the group labels stored in; the categorical for which :func:`~scanpy.tl.paga` has been computed.; pos; Two-column array-like storing the x and y coordinates for drawing.; Otherwise, path to a `.gdf` file that has been exported from Gephi or; a similar graph visualization software.; layout; Plotting layout that computes positions.; `'fa'` stands for “ForceAtlas2”,; `'fr'` stands for “Fruchterman-Reingold”,; `'rt'` stands for “Reingold-Tilford”,; `'eq_tree'` stands for “eqally spaced tree”.; All but `'fa'` and `'eq_tree'` are igraph layouts.; All other igraph layouts are also permitted.; See also parameter `pos` and :func:`~scanpy.tl.draw_graph`.; layout_kwds; Keywords for the layout.; init_pos; Two-column array storing the x and y coordinates for initializing the; layout.; random_state; For layouts with random initialization like `'fr'`, change this to use; different intial states for the optimization. If `No",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:4063,Usability,simpl,simply,4063," of the nodes.; node_size_power; The power with which groups sizes influence the radius of the nodes.; edge_width_scale; Edge with scale in units of `rcParams['lines.linewidth']`.; min_edge_width; Min width of solid edges.; max_edge_width; Max width of solid and dashed edges.; arrowsize; For directed graphs, choose the size of the arrow head head's length and; width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute; `mutation_scale` for more info.; export_to_gexf; Export to gexf format to be read by graph visualization programs such as; Gephi.; normalize_to_color; Whether to normalize categorical plots to `color` or the underlying; grouping.; cmap; The color map.; cax; A matplotlib axes object for a potential colorbar.; cb_kwds; Keyword arguments for :class:`~matplotlib.colorbar.Colorbar`,; for instance, `ticks`.; add_pos; Add the positions to `adata.uns['paga']`.; title; Provide a title.; frameon; Draw a frame around the PAGA graph.; plot; If `False`, do not create the figure, simply compute the layout.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on \\{`'.pdf'`, `'.png'`, `'.svg'`\\}.; ax; A matplotlib axes object. Returns; -------; If `show==False`, one or more :class:`~matplotlib.axes.Axes` objects.; Adds `'pos'` to `adata.uns['paga']` if `add_pos` is `True`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, groups='louvain'); sc.pl.paga(adata). You can increase node and edge sizes by specifying additional arguments. .. plot::; :context: close-figs. sc.pl.paga(adata, node_size_scale=10, edge_width_scale=2). Notes; -----; When initializing the positions, note that – for some reason – igraph; mirrors coordinates along the x axis... that is, you should increase the; `maxiter` parameter by 1 if the layout is flipped. .. currentmodule:: scanpy. See also; --------; tl.paga; pl.paga_compare; pl.",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:7,Deployability,continuous,continuous,7,"# plot continuous annotation",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:300,Modifiability,variab,variables,300,"""""""\; Gene expression and annotation changes along paths in the abstracted graph. Parameters; ----------; adata; An annotated data matrix.; nodes; A path through nodes of the abstracted graph, that is, names or indices; (within `.categories`) of groups that have been used to run PAGA.; keys; Either variables in `adata.var_names` or annotations in; `adata.obs`. They are plotted using `color_map`.; use_raw; Use `adata.raw` for retrieving gene expressions if it has been set.; annotations; Plot these keys with `color_maps_annotations`. Need to be keys for; `adata.obs`.; color_map; Matplotlib colormap.; color_maps_annotations; Color maps for plotting the annotations. Keys of the dictionary must; appear in `annotations`.; palette_groups; Ususally, use the same `sc.pl.palettes...` as used for coloring the; abstracted graph.; n_avg; Number of data points to include in computation of running average.; groups_key; Key of the grouping used to run PAGA. If `None`, defaults to; `adata.uns['paga']['groups']`.; as_heatmap; Plot the timeseries as heatmap. If not plotting as heatmap,; `annotations` have no effect.; show_node_names; Plot the node names on the nodes bar.; show_colorbar; Show the colorbar.; show_yticks; Show the y ticks.; normalize_to_zero_one; Shift and scale the running average to [0, 1] per gene.; return_data; Return the timeseries data in addition to the axes if `True`.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on \\{`'.pdf'`, `'.png'`, `'.svg'`\\}.; ax; A matplotlib axes object. Returns; -------; A :class:`~matplotlib.axes.Axes` object, if `ax` is `None`, else `None`.; If `return_data`, return the timeseries data in addition to an axes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:15,Availability,mask,mask,15,"# Checking the mask format and if used together with groups",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:87,Energy Efficiency,reduce,reduce,87,"# by default turn off edge color. Otherwise, for; # very small sizes the edge will not reduce its size; # (https://github.com/scverse/scanpy/issues/293)",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:3,Deployability,Update,Update,3,"""""""Update the wrapper function to use the correct signature.""""""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:14,Integrability,wrap,wrapper,14,"""""""Update the wrapper function to use the correct signature.""""""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:368,Modifiability,variab,variable,368,"""""""\; Scatter plot in UMAP basis. Parameters; ----------; {adata_color_etc}; {edges_arrows}; {scatter_bulk}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.umap(adata). Colour points by discrete variable (Louvain clusters). .. plot::; :context: close-figs. sc.pl.umap(adata, color=""louvain""). Colour points by gene expression. .. plot::; :context: close-figs. sc.pl.umap(adata, color=""HES4""). Plot muliple umaps for different gene expressions. .. plot::; :context: close-figs. sc.pl.umap(adata, color=[""HES4"", ""TNFRSF4""]). .. currentmodule:: scanpy. See also; --------; tl.umap; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:460,Modifiability,variab,variable,460,"""""""\; Scatter plot in PCA coordinates. Use the parameter `annotate_var_explained` to annotate the explained variance. Parameters; ----------; {adata_color_etc}; annotate_var_explained; {scatter_bulk}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(); sc.pl.pca(adata). Colour points by discrete variable (Louvain clusters). .. plot::; :context: close-figs. sc.pl.pca(adata, color=""louvain""). Colour points by gene expression. .. plot::; :context: close-figs. sc.pl.pca(adata, color=""CST3""). .. currentmodule:: scanpy. See also; --------; pp.pca; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:30,Availability,avail,available,30,"# get default image params if available",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:96,Availability,error,error,96,"# We should probably just make an index for this, and share it over runs; # TODO: Throw helpful error if this doesn't work",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:190,Deployability,continuous,continuous,190,"""""""; Map array of values to array of hex (plus alpha) codes. For categorical data, the return value is list of colors taken; from the category palette or from the given `palette` value. For continuous values, the input array is returned (may change in future).; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:109,Deployability,continuous,continuous,109,"###; # when plotting, the color of the dots is determined for each plot; # the data is either categorical or continuous and the data could be in; # 'obs' or in 'var'",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:23,Availability,Error,Error,23,"# Throws StopIteration Error if keys not present",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/scatterplots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:245,Modifiability,variab,variables,245,"""""""\; Rank genes according to contributions to PCs. Parameters; ----------; adata; Annotated data matrix.; components; For example, ``'1,2,3'`` means ``[1, 2, 3]``, first, second, third; principal component.; include_lowest; Whether to show the variables with both highest and lowest loadings.; show; Show the plot, do not return axis.; n_points; Number of variables to plot for each component.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}. Examples; --------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(). Show first 3 components loadings. .. plot::; :context: close-figs. sc.pl.pca_loadings(adata, components = '1,2,3'). """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:357,Modifiability,variab,variables,357,"""""""\; Rank genes according to contributions to PCs. Parameters; ----------; adata; Annotated data matrix.; components; For example, ``'1,2,3'`` means ``[1, 2, 3]``, first, second, third; principal component.; include_lowest; Whether to show the variables with both highest and lowest loadings.; show; Show the plot, do not return axis.; n_points; Number of variables to plot for each component.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}. Examples; --------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(). Show first 3 components loadings. .. plot::; :context: close-figs. sc.pl.pca_loadings(adata, components = '1,2,3'). """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:284,Performance,load,loadings,284,"""""""\; Rank genes according to contributions to PCs. Parameters; ----------; adata; Annotated data matrix.; components; For example, ``'1,2,3'`` means ``[1, 2, 3]``, first, second, third; principal component.; include_lowest; Whether to show the variables with both highest and lowest loadings.; show; Show the plot, do not return axis.; n_points; Number of variables to plot for each component.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}. Examples; --------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(). Show first 3 components loadings. .. plot::; :context: close-figs. sc.pl.pca_loadings(adata, components = '1,2,3'). """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:691,Performance,load,loadings,691,"""""""\; Rank genes according to contributions to PCs. Parameters; ----------; adata; Annotated data matrix.; components; For example, ``'1,2,3'`` means ``[1, 2, 3]``, first, second, third; principal component.; include_lowest; Whether to show the variables with both highest and lowest loadings.; show; Show the plot, do not return axis.; n_points; Number of variables to plot for each component.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}. Examples; --------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(). Show first 3 components loadings. .. plot::; :context: close-figs. sc.pl.pca_loadings(adata, components = '1,2,3'). """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:86,Testability,log,log,86,"""""""\; Plot the variance ratio. Parameters; ----------; n_pcs; Number of PCs to show.; log; Plot on logarithmic scale..; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:99,Testability,log,logarithmic,99,"""""""\; Plot the variance ratio. Parameters; ----------; n_pcs; Number of PCs to show.; log; Plot on logarithmic scale..; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}.; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:51,Testability,log,logfoldchange,51,"# these two types of plots can also; # show score, logfoldchange and pvalues, in general any value from rank; # genes groups",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:919,Testability,log,logfoldchanges,919,"""""""\; Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`DotPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.dotplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; ",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1167,Testability,log,log,1167,":`DotPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.dotplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1310,Testability,log,logfoldchanges,1310,"If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """,MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1397,Testability,log,log,1397,"If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """,MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1665,Testability,log,logfoldchanges,1665,"`return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1753,Testability,log,log,1753,"`return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1825,Testability,log,log,1825,"`return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:2152,Testability,log,logfoldchanges,2152,"`return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:2240,Testability,log,log,2240,"`return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:646,Testability,log,logfoldchanges,646,"""""""\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """,MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:894,Testability,log,log,894,"""""""\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """,MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1040,Testability,log,logfoldchanges,1040,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1128,Testability,log,log,1128,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1400,Testability,log,logfoldchanges,1400,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1488,Testability,log,log,1488,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1560,Testability,log,log,1560,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1890,Testability,log,logfoldchanges,1890,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1978,Testability,log,log,1978,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:36,Testability,test,tested,36,"""""""\; Plot ranking of genes for all tested comparisons. Parameters; ----------; adata; Annotated data matrix.; groups; List of group names.; n_genes; Number of genes to show. Is ignored if `gene_names` is passed.; gene_names; List of genes to plot. Is only useful if interested in a custom gene list,; which is not the result of :func:`scanpy.tl.rank_genes_groups`.; gene_symbols; Key for field in `.var` that stores gene symbols if you do not want to; use `.var_names` displayed in the plot.; use_raw; Use `raw` attribute of `adata` if present. Defaults to the value that; was used in :func:`~scanpy.tl.rank_genes_groups`.; split; Whether to split the violins or not.; density_norm; See :func:`~seaborn.violinplot`.; strip; Show a strip plot on top of the violin plot.; jitter; If set to 0, no points are drawn. See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; {show_save_ax}; """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:2,Testability,Test,Test,2,"# Test user inputs",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:51,Safety,avoid,avoid,51,"# a name to store the density values is needed. To avoid; # overwriting a user name a new random name is created",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:107,Testability,log,logfoldchange,107,"""""""; If rank_genes_groups has been called, this function; prepares a dataframe containing scores, pvalues, logfoldchange etc to be plotted; as dotplot or matrixplot. The dataframe index are the given groups and the columns are the gene_names. used by rank_genes_groups_dotplot. Parameters; ----------; adata; values_to_plot; name of the value to plot; gene_names; gene names; groups; groupby categories; key; adata.uns key where the rank_genes_groups is stored.; By default 'rank_genes_groups'; gene_symbols; Key for field in .var that stores gene symbols.; Returns; -------; pandas DataFrame index=groups, columns=gene_names. """"""",MatchSource.CODE_COMMENT,src/scanpy/plotting/_tools/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:17,Usability,simpl,simple,17,"""""""\; Computes a simple design matrix. Parameters; --------; model; Contains the batch annotation; batch_key; Name of the batch column; batch_levels; Levels of the batch annotation. Returns; --------; The design matrix for the regression problem; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:166,Energy Efficiency,power,power,166,"""""""\; ComBat function for batch effect correction :cite:p:`Johnson2006,Leek2012,Pedersen2012`. Corrects for batch effects by fitting linear models, gains statistical power; via an EB framework where information is borrowed across genes.; This uses the implementation `combat.py`_ :cite:p:`Pedersen2012`. .. _combat.py: https://github.com/brentp/combat.py. Parameters; ----------; adata; Annotated data matrix; key; Key to a categorical annotation from :attr:`~anndata.AnnData.obs`; that will be used for batch effect removal.; covariates; Additional covariates besides the batch variable such as adjustment; variables or biological condition. This parameter refers to the design; matrix `X` in Equation 2.1 in :cite:t:`Johnson2006` and to the `mod` argument in; the original combat function in the sva R package.; Note that not including covariates may introduce bias or lead to the; removal of biological signal in unbalanced designs.; inplace; Whether to replace adata.X or to return the corrected data. Returns; -------; Returns :class:`numpy.ndarray` if `inplace=True`, else returns `None` and sets the following field in the `adata` object:. `adata.X` : :class:`numpy.ndarray` (dtype `float`); Corrected data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:579,Modifiability,variab,variable,579,"""""""\; ComBat function for batch effect correction :cite:p:`Johnson2006,Leek2012,Pedersen2012`. Corrects for batch effects by fitting linear models, gains statistical power; via an EB framework where information is borrowed across genes.; This uses the implementation `combat.py`_ :cite:p:`Pedersen2012`. .. _combat.py: https://github.com/brentp/combat.py. Parameters; ----------; adata; Annotated data matrix; key; Key to a categorical annotation from :attr:`~anndata.AnnData.obs`; that will be used for batch effect removal.; covariates; Additional covariates besides the batch variable such as adjustment; variables or biological condition. This parameter refers to the design; matrix `X` in Equation 2.1 in :cite:t:`Johnson2006` and to the `mod` argument in; the original combat function in the sva R package.; Note that not including covariates may introduce bias or lead to the; removal of biological signal in unbalanced designs.; inplace; Whether to replace adata.X or to return the corrected data. Returns; -------; Returns :class:`numpy.ndarray` if `inplace=True`, else returns `None` and sets the following field in the `adata` object:. `adata.X` : :class:`numpy.ndarray` (dtype `float`); Corrected data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:608,Modifiability,variab,variables,608,"""""""\; ComBat function for batch effect correction :cite:p:`Johnson2006,Leek2012,Pedersen2012`. Corrects for batch effects by fitting linear models, gains statistical power; via an EB framework where information is borrowed across genes.; This uses the implementation `combat.py`_ :cite:p:`Pedersen2012`. .. _combat.py: https://github.com/brentp/combat.py. Parameters; ----------; adata; Annotated data matrix; key; Key to a categorical annotation from :attr:`~anndata.AnnData.obs`; that will be used for batch effect removal.; covariates; Additional covariates besides the batch variable such as adjustment; variables or biological condition. This parameter refers to the design; matrix `X` in Equation 2.1 in :cite:t:`Johnson2006` and to the `mod` argument in; the original combat function in the sva R package.; Note that not including covariates may introduce bias or lead to the; removal of biological signal in unbalanced designs.; inplace; Whether to replace adata.X or to return the corrected data. Returns; -------; Returns :class:`numpy.ndarray` if `inplace=True`, else returns `None` and sets the following field in the `adata` object:. `adata.X` : :class:`numpy.ndarray` (dtype `float`); Corrected data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:304,Integrability,depend,depend,304,"""""""\; Iteratively compute the conditional posterior means for gamma and delta. gamma is an estimator for the additive batch effect, deltat is an estimator; for the multiplicative batch effect. We use an EB framework to estimate these; two. Analytical expressions exist for both parameters, which however depend on each other.; We therefore iteratively evalutate these two expressions until convergence is reached. Parameters; --------; s_data; Contains the standardized Data; g_hat; Initial guess for gamma; d_hat; Initial guess for delta; g_bar, t2, a, b; Hyperparameters; conv: float, optional (default: `0.0001`); convergence criterium. Returns:; --------; gamma; estimated value for gamma; delta; estimated value for delta; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:122,Deployability,update,updated,122,"# we place a normally distributed prior on gamma and and inverse gamma prior on delta; # in the loop, gamma and delta are updated together. they depend on each other. we iterate until convergence.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:145,Integrability,depend,depend,145,"# we place a normally distributed prior on gamma and and inverse gamma prior on delta; # in the loop, gamma and delta are updated together. they depend on each other. we iterate until convergence.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:37,Modifiability,layers,layers,37,"""""""\; layer; If provided, use `adata.layers[layer]` for expression values instead; of `adata.X`.; use_raw; If True, use `adata.raw.X` for expression values instead of `adata.X`.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:194,Availability,avail,available,194,"""""""\; mask_var; To run only on a certain set of genes given by a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.var`.; By default, uses `.var['highly_variable']` if available, else everything.; use_highly_variable; Whether to use highly variable genes only, stored in; `.var['highly_variable']`.; By default uses them if they have been determined beforehand. .. deprecated:: 1.10.0; Use `mask_var` instead; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:266,Modifiability,variab,variable,266,"""""""\; mask_var; To run only on a certain set of genes given by a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.var`.; By default, uses `.var['highly_variable']` if available, else everything.; use_highly_variable; Whether to use highly variable genes only, stored in; `.var['highly_variable']`.; By default uses them if they have been determined beforehand. .. deprecated:: 1.10.0; Use `mask_var` instead; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:65,Modifiability,variab,variables,65,"""""""\; qc_vars; Keys for boolean columns of `.var` which identify variables you could; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top; List of ranks (where genes are ranked by expression) at which the cumulative; proportion of expression will be reported as a percentage. This can be used to; assess library complexity. Ranks are considered 1-indexed, and if empty or None; don't calculate. E.g. `percent_top=[50]` finds cumulative proportion to the 50th most expressed gene.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:79,Modifiability,variab,variables,79,"""""""\; expr_type; Name of kind of values in X.; var_type; The kind of thing the variables are.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:521,Modifiability,variab,variables,521,"""""""\; Observation level metrics include:. `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts in a cell.; `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; `pct_{expr_type}_in_top_{n}_{var_type}` – for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts; for 50 most expressed genes in a cell.; `total_{expr_type}_{qc_var}` – for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number of counts for variables in; `qc_vars`.; `pct_{expr_type}_{qc_var}` – for `qc_var` in `qc_vars`; E.g. ""pct_counts_mito"". Proportion of total counts for a cell which; are mitochondrial.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:6,Modifiability,Variab,Variable,6,"""""""\; Variable level metrics include:. `total_{expr_type}`; E.g. ""total_counts"". Sum of counts for a gene.; `n_genes_by_{expr_type}`; E.g. ""n_genes_by_counts"". The number of genes with at least 1 count in a cell. Calculated for all cells.; `mean_{expr_type}`; E.g. ""mean_counts"". Mean expression over all cells.; `n_cells_by_{expr_type}`; E.g. ""n_cells_by_counts"". Number of cells this expression is; measured in.; `pct_dropout_by_{expr_type}`; E.g. ""pct_dropout_by_counts"". Percentage of cells this feature does; not appear in.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_docs.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:215,Deployability,update,updates,215,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:136,Integrability,Depend,Depending,136,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:319,Modifiability,variab,variable,319,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:735,Safety,detect,detected,735,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:51,Modifiability,variab,variable,51,"# argsort twice gives ranks, small rank means most variable",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:56,Integrability,wrap,wrapper,56,"# Doesn't actually copy memory, just removes View class wrapper",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:2,Testability,log,logarithmized,2,"# logarithmized mean as in Seurat",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:15,Availability,mask,mask,15,"""""""Get boolean mask of genes with normalized dispersion in bounds.""""""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:467,Deployability,install,installing,467,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:196,Integrability,Depend,Depending,196,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:506,Integrability,depend,dependency,506,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:22,Modifiability,variab,variable,22,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:888,Modifiability,variab,variable,888,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:2347,Modifiability,layers,layers,2347,"3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flavor='seurat_v3_paper'`, this mimics Seurat's `SelectIntegrationFeatures`. See also `scanpy.experimental.pp._highly_variable_genes` for additional flavors; (e.g. Pearson residuals). Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; layer; If provided, use `adata.layers[layer]` for expression values instead of `adata.X`.; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'`.; min_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:2437,Modifiability,variab,variable,2437," rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flavor='seurat_v3_paper'`, this mimics Seurat's `SelectIntegrationFeatures`. See also `scanpy.experimental.pp._highly_variable_genes` for additional flavors; (e.g. Pearson residuals). Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; layer; If provided, use `adata.layers[layer]` for expression values instead of `adata.X`.; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'`.; min_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the no",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3597,Modifiability,variab,variable,3597,"ns and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3778,Modifiability,variab,variable,3778,"d if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` ",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3837,Modifiability,variab,variable,3837,"d if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` ",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3958,Modifiability,variab,variable,3958,"seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['d",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:4867,Modifiability,variab,variable,4867,"; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `adata.var['dispersions_norm']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, normalized dispersions per gene; `adata.var['variances']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, variance per gene; `adata.var['variances_norm']`/`'seurat_v3_paper'` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, normalized variance per gene, averaged in; the case of multiple batches; `adata.var['highly_variable_rank']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, rank of the gene according to normalized; variance, in case of multiple batches description above; `adata.var['highly_variable_nbatches']` : :class:`pandas.Series` (d",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:6100,Modifiability,variab,variable,6100,"ow many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `adata.var['dispersions_norm']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, normalized dispersions per gene; `adata.var['variances']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, variance per gene; `adata.var['variances_norm']`/`'seurat_v3_paper'` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, normalized variance per gene, averaged in; the case of multiple batches; `adata.var['highly_variable_rank']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, rank of the gene according to normalized; variance, in case of multiple batches description above; `adata.var['highly_variable_nbatches']` : :class:`pandas.Series` (dtype `int`); If `batch_key` is given, this denotes in how many batches genes are detected as HVG; `adata.var['highly_variable_intersection']` : :class:`pandas.Series` (dtype `bool`); If `batch_key` is given, this denotes the genes that are highly variable in all batches. Notes; -----; This function replaces :func:`~scanpy.pp.filter_genes_dispersion`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:4048,Safety,avoid,avoids,4048,"rmalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `a",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:5934,Safety,detect,detected,5934,"ow many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `adata.var['dispersions_norm']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, normalized dispersions per gene; `adata.var['variances']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, variance per gene; `adata.var['variances_norm']`/`'seurat_v3_paper'` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, normalized variance per gene, averaged in; the case of multiple batches; `adata.var['highly_variable_rank']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, rank of the gene according to normalized; variance, in case of multiple batches description above; `adata.var['highly_variable_nbatches']` : :class:`pandas.Series` (dtype `int`); If `batch_key` is given, this denotes in how many batches genes are detected as HVG; `adata.var['highly_variable_intersection']` : :class:`pandas.Series` (dtype `bool`); If `batch_key` is given, this denotes the genes that are highly variable in all batches. Notes; -----; This function replaces :func:`~scanpy.pp.filter_genes_dispersion`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:88,Testability,log,logarithmized,88,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:4033,Usability,simpl,simple,4033,"rmalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `a",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2007,Deployability,update,update,2007,".; target_sum; If `None`, after normalization, each observation (cell) has a total; count equal to the median of total counts for observations (cells); before normalization.; exclude_highly_expressed; Exclude (very) highly expressed genes for the computation of the; normalization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2277,Deployability,update,updates,2277,"lization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expresse",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2364,Integrability,depend,depending,2364,"ighly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expressed genes are not considered during normalization factor computation:;",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2091,Modifiability,layers,layers,2091,"(cell) has a total; count equal to the median of total counts for observations (cells); before normalization.; exclude_highly_expressed; Exclude (very) highly expressed genes for the computation of the; normalization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=flo",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2265,Modifiability,layers,layers,2265,"lization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expresse",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2355,Modifiability,layers,layers,2355,"ighly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expressed genes are not considered during normalization factor computation:;",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2533,Testability,log,logfile,2533,"rgument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expressed genes are not considered during normalization factor computation:; ['1', '3', '4']; finished (0:00:00); >>> X_norm; array([[ 0.5, 0.5, 0.5, 1. , 1. ],; [ 0.5, 0.5, 0.5, 1. , 1. ],; [ 0.5, 11. , 0.5, 1. , 1. ]], dtype=float32); """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1902,Availability,avail,available,1902,"ix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.Increm",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2193,Availability,avail,available,2193,".; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as e",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2237,Availability,avail,available,2237,"e`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data ty",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:4175,Deployability,update,updated,4175,".TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n_comps)`); The principal components containing the loadings.; `.uns['pca']['variance_ratio']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Ratio of explained variance.; `.uns['pca']['variance']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Explained variance, equivalent to the eigenvalues of the; covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1122,Energy Efficiency,efficient,efficiently,1122,"riance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automat",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2466,Energy Efficiency,Efficient,Efficient,2466,"earn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignore",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1332,Integrability,Depend,Depending,1332,"implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arp",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1844,Integrability,wrap,wrapper,1844,"rs to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* co",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2109,Integrability,depend,depending,2109,"parse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :c",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:821,Modifiability,layers,layers,821,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:947,Modifiability,variab,variables,947,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:86,Performance,load,loadings,86,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:3047,Performance,optimiz,optimization,3047,"s will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this f",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:3418,Performance,perform,perform,3418,"ed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:3713,Performance,perform,perform,3713,"class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n_comps)`); The principal components containing the loadings.; `.uns['pca']['variance_ratio']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Ratio of explained variance.; `.uns['pca']['variance']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Explained variance, equivalent to the eigenvalues of",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:4486,Performance,load,loadings,4486,".TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n_comps)`); The principal components containing the loadings.; `.uns['pca']['variance_ratio']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Ratio of explained variance.; `.uns['pca']['variance']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Explained variance, equivalent to the eigenvalues of the; covariance matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:159,Usability,learn,learn,159,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:972,Usability,learn,learn,972,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1427,Usability,learn,learn,1427," exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value chan",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1513,Usability,learn,learn,1513,"ass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the princi",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2816,Usability,learn,learn,2816,"pack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomp",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:12,Availability,mask,mask,12,"# Unify new mask argument and deprecated use_highly_varible argument",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:68,Availability,error,error,68,"# This is for backwards compat. Better behaviour would be to either error or use arpack.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:17,Integrability,wrap,wrapper,17,"# this is just a wrapper for the results",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:16,Availability,mask,mask,16,"""""""\; Unify new mask argument and deprecated use_highly_varible argument. Returns both the normalized mask parameter and the validated mask array.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:102,Availability,mask,mask,102,"""""""\; Unify new mask argument and deprecated use_highly_varible argument. Returns both the normalized mask parameter and the validated mask array.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:135,Availability,mask,mask,135,"""""""\; Unify new mask argument and deprecated use_highly_varible argument. Returns both the normalized mask parameter and the validated mask array.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:125,Security,validat,validated,125,"""""""\; Unify new mask argument and deprecated use_highly_varible argument. Returns both the normalized mask parameter and the validated mask array.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:48,Availability,mask,mask,48,"# Without highly variable genes, we don’t use a mask by default",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:17,Modifiability,variab,variable,17,"# Without highly variable genes, we don’t use a mask by default",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:60,Usability,learn,learn,60,"# u_based_decision was changed in https://github.com/scikit-learn/scikit-learn/pull/27491",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:73,Usability,learn,learn,73,"# u_based_decision was changed in https://github.com/scikit-learn/scikit-learn/pull/27491",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:259,Performance,cache,cached,259,"""""""\; Describe observations of anndata. Calculates a number of qc metrics for observations in AnnData object. See; section `Returns` for a description of those metrics. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Params; ------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; log1p; Add `log1p` transformed metrics.; inplace; Whether to place calculated metrics in `adata.obs`.; X; Matrix to calculate values on. Meant for internal usage. Returns; -------; QC metrics for observations in adata. If inplace, values are placed into; the AnnData's `.obs` dataframe. {doc_obs_qc_returns}; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:15,Modifiability,variab,variables,15,"""""""\; Describe variables of anndata. Calculates a number of qc metrics for variables in AnnData object. See; section `Returns` for a description of those metrics. Params; ------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata.var`.; X; Matrix to calculate values on. Meant for internal usage. Returns; -------; QC metrics for variables in adata. If inplace, values are placed into the; AnnData's `.var` dataframe. {doc_var_qc_returns}; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:75,Modifiability,variab,variables,75,"""""""\; Describe variables of anndata. Calculates a number of qc metrics for variables in AnnData object. See; section `Returns` for a description of those metrics. Params; ------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata.var`.; X; Matrix to calculate values on. Meant for internal usage. Returns; -------; QC metrics for variables in adata. If inplace, values are placed into the; AnnData's `.var` dataframe. {doc_var_qc_returns}; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:394,Modifiability,variab,variables,394,"""""""\; Describe variables of anndata. Calculates a number of qc metrics for variables in AnnData object. See; section `Returns` for a description of those metrics. Params; ------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata.var`.; X; Matrix to calculate values on. Meant for internal usage. Returns; -------; QC metrics for variables in adata. If inplace, values are placed into the; AnnData's `.var` dataframe. {doc_var_qc_returns}; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:17,Performance,bottleneck,bottleneck,17,"# Current memory bottleneck for csr matrices:",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:753,Deployability,update,updates,753,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:229,Energy Efficiency,efficient,efficient,229,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:667,Integrability,Depend,Depending,667,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:362,Performance,cache,cached,362,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:18,Usability,simpl,simple,18,"# Just to keep it simple, as a dense matrix",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_qc.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:75,Testability,log,logarithmized,75,"""""""\; Normalization and filtering as of :cite:p:`Weinreb2017`. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:105,Testability,log,logarithmized,105,"""""""\; Normalization and filtering as of :cite:p:`Weinreb2017`. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:131,Testability,log,log,131,"""""""\; Normalization and filtering as of :cite:p:`Weinreb2017`. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:198,Testability,log,log,198,"""""""\; Normalization and filtering as of :cite:p:`Weinreb2017`. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:203,Testability,Log,Logarithmize,203,"""""""\; Normalization and filtering as of :cite:p:`Weinreb2017`. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:2,Deployability,update,update,2,"# update adata",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:119,Testability,log,logarithmized,119,"""""""\; Normalization and filtering as of Seurat :cite:p:`Satija2015`. This uses a particular preprocessing. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:149,Testability,log,logarithmized,149,"""""""\; Normalization and filtering as of Seurat :cite:p:`Satija2015`. This uses a particular preprocessing. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:175,Testability,log,log,175,"""""""\; Normalization and filtering as of Seurat :cite:p:`Satija2015`. This uses a particular preprocessing. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:242,Testability,log,log,242,"""""""\; Normalization and filtering as of Seurat :cite:p:`Satija2015`. This uses a particular preprocessing. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:247,Testability,Log,Logarithmize,247,"""""""\; Normalization and filtering as of Seurat :cite:p:`Satija2015`. This uses a particular preprocessing. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:1161,Deployability,update,updates,1161,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:1177,Integrability,depend,depending,1177,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:547,Modifiability,variab,variable,547,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:167,Testability,log,logarithmized,167,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:197,Testability,log,logarithmized,197,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:223,Testability,log,log,223,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:619,Testability,log,log,619,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:763,Testability,log,log,763,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:789,Testability,log,log,789,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:814,Testability,log,log,814,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:994,Testability,log,log,994,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:1004,Testability,log,logarithm,1004,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:2,Testability,log,log,2,"# log transform: X = log(X + 1)",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:21,Testability,log,log,21,"# log transform: X = log(X + 1)",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_recipes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:18,Availability,avail,available,18,"# install dask if available",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:2,Deployability,install,install,2,"# install dask if available",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:957,Availability,mask,mask,957,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:1198,Deployability,update,updated,1198,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:497,Energy Efficiency,efficient,efficiently,497,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:60,Modifiability,Variab,Variables,60,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:449,Modifiability,variab,variables,449,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:764,Modifiability,layers,layers,764,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:1271,Modifiability,layers,layers,1271,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:630,Performance,perform,performed,630,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:49,Testability,log,logic,49,"# need to add the following here to make inplace logic work",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scale.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:3,Usability,Simpl,Simple,3,"""""""Simple Preprocessing Functions. Compositions of these functions are found in sc.preprocess.recipes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:18,Availability,avail,available,18,"# install dask if available",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:2,Deployability,install,install,2,"# install dask if available",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1020,Availability,mask,mask,1020,"outliers based on counts and numbers of genes expressed. For instance, only keep cells with at least `min_counts` counts or; `min_genes` genes expressed. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_copy.obs['n_genes",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:886,Integrability,Depend,Depending,886,"""""""\; Filter cell outliers based on counts and numbers of genes expressed. For instance, only keep cells with at least `min_counts` counts or; `min_genes` genes expressed. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1136,Integrability,Depend,Depending,1136,"d. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_copy.obs['n_genes'].min(); 3; >>> # actually do some filtering; >>> sc.pp.filter_cells(adata, min_genes=3); >>> adata.n_obs; 554; >>> adata.obs['n_genes'].min(); 3; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:822,Performance,Perform,Perform,822,"""""""\; Filter cell outliers based on counts and numbers of genes expressed. For instance, only keep cells with at least `min_counts` counts or; `min_genes` genes expressed. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1744,Usability,simpl,simply,1744,"d. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_copy.obs['n_genes'].min(); 3; >>> # actually do some filtering; >>> sc.pp.filter_cells(adata, min_genes=3); >>> adata.n_obs; 554; >>> adata.obs['n_genes'].min(); 3; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1007,Availability,mask,mask,1007,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:875,Integrability,Depend,Depending,875,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1123,Integrability,Depend,Depending,1123,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:811,Performance,Perform,Perform,811,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:721,Deployability,update,updates,721,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:737,Integrability,depend,depending,737,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:636,Modifiability,layers,layers,636,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:6,Testability,Log,Logarithmize,6,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:58,Testability,log,log,58,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:85,Testability,log,log,85,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:110,Testability,log,logarithm,110,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:308,Testability,log,logarithm,308,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:327,Testability,log,logarithm,327,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:500,Deployability,update,updates,500,"""""""\; Square root the data matrix. Computes :math:`X = \\sqrt(X)`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; copy; If an :class:`~anndata.AnnData` object is passed,; determines whether a copy is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:516,Integrability,depend,depending,516,"""""""\; Square root the data matrix. Computes :math:`X = \\sqrt(X)`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; copy; If an :class:`~anndata.AnnData` object is passed,; determines whether a copy is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1320,Deployability,update,updated,1320,"ts per cell. .. warning::; .. deprecated:: 1.3.7; Use :func:`~scanpy.pp.normalize_total` instead.; The new function is equivalent to the present; function, except that. * the new function doesn't filter cells based on `min_counts`,; use :func:`~scanpy.pp.filter_cells` if filtering is needed.; * some arguments were renamed; * `copy` is replaced by `inplace`. Normalize each cell by total counts over all genes, so that every cell has; the same total count after normalization. Similar functions are used, for example, by Seurat :cite:p:`Satija2015`, Cell Ranger; :cite:p:`Zheng2017` or SPRING :cite:p:`Weinreb2017`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; counts_per_cell_after; If `None`, after normalization, each cell has a total count equal; to the median of the *counts_per_cell* before normalization.; counts_per_cell; Precomputed counts per cell.; key_n_counts; Name of the field in `adata.obs` where the total counts per cell are; stored.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; min_counts; Cells with counts less than `min_counts` are filtered out during; normalization. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Normalized count data matrix. Examples; --------; >>> import scanpy as sc; >>> adata = AnnData(np.array([[1, 0], [3, 0], [5, 6]], dtype=np.float32)); >>> print(adata.X.sum(axis=1)); [ 1. 3. 11.]; >>> sc.pp.normalize_per_cell(adata); >>> print(adata.obs); n_counts; 0 1.0; 1 3.0; 2 11.0; >>> print(adata.X.sum(axis=1)); [3. 3. 3.]; >>> sc.pp.normalize_per_cell(; ... adata, counts_per_cell_after=1,; ... key_n_counts='n_counts2',; ... ); >>> print(adata.obs); n_counts n_counts2; 0 1.0 3.0; 1 3.0 3.0; 2 11.0 3.0; >>> print(adata.X.sum(axis=1)); [1. 1. 1.]; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:689,Deployability,update,updated,689,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:428,Modifiability,layers,layers,428,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:762,Modifiability,layers,layers,762,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:63,Usability,simpl,simple,63,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:34,Modifiability,variab,variable,34,"# regress on a single categorical variable",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:36,Modifiability,variab,variables,36,"# regress on one or several ordinal variables",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:26,Testability,test,test,26,"# TODO: figure out how to test that this doesn't oversubscribe resources",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:64,Availability,error,error,64,"# if all values are identical, the statsmodel.api.GLM throws an error;; # but then no regression is necessary anyways...",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:6,Availability,Down,Downsample,6,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:93,Availability,down,downsampled,93,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:165,Availability,down,downsampled,165,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:370,Availability,down,downsampled,370,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:646,Availability,down,downsampled,646,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1034,Availability,Down,Downsampled,1034,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:7,Testability,log,logic,7,"# This logic is all dispatch",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:13,Energy Efficiency,reduce,reduce,13,"""""""\; Evenly reduce counts in cell to target amount. This is an internal function and has some restrictions:. * total counts in cell must be less than target; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:125,Performance,perform,performance,125,"# calculate eigenvectors & eigenvalues of the covariance matrix; # use 'eigh' rather than 'eig' since C is symmetric,; # the performance gain is substantial; # evals, evecs = np.linalg.eigh(C)",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_simple.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2444,Deployability,update,updates,2444,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:574,Integrability,Depend,Depending,574,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2460,Integrability,depend,depending,2460,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:21,Modifiability,variab,variable,21,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:933,Modifiability,variab,variable,933,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2086,Modifiability,variab,variable,2086,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2186,Modifiability,variab,variable,2186,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2253,Modifiability,variab,variable,2253,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:391,Safety,detect,detect,391,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:264,Testability,log,logarithmized,264,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1300,Testability,log,logarithmized,1300,"rely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed,",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1325,Testability,log,logarithm,1325,"rely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed,",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1385,Testability,log,log,1385,"rely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed,",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1469,Testability,log,logarithmized,1469,"` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1520,Testability,log,log,1520,"` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2111,Testability,log,log,2111,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2124,Testability,log,logarithm,2124,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2570,Testability,Log,Logarithmized,2570,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2590,Testability,log,log,2590,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2658,Testability,Log,Logarithmized,2658,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2678,Testability,log,log,2678,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2762,Testability,Log,Logarithmized,2762,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2782,Testability,log,log,2782,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2,Testability,log,logarithmized,2,"# logarithmized mean as in Seurat",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:109,Availability,error,error,109,"# Circumvent pandas 0.23 bug. Both sides of the assignment have dtype==float32,; # but there’s still a dtype error without “.value”.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/__init__.py:31,Modifiability,variab,variable,31,"""""""\; Z-score standardize each variable/gene in X :cite:p:`Weinreb2017`. Use `scale` instead. Parameters; ----------; X; Data matrix. Rows correspond to cells and columns to genes. Returns; -------; Z-score standardized version of the data matrix.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_deprecated/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:64,Safety,predict,prediction,64,"""""""\; Initialize Scrublet object with counts matrix and doublet prediction parameters. Parameters; ----------; counts_obs; Matrix with shape (n_cells, n_genes) containing raw (unnormalized); UMI-based transcript counts.; Converted into a :class:`scipy.sparse.csc_matrix`. total_counts_obs; Array with shape (n_cells,) of total UMI counts per cell.; If `None`, this is calculated as the row sums of `counts_obs`. sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets.; If `None`, this is set to round(0.5 * sqrt(n_cells)). expected_doublet_rate; The estimated doublet rate for the experiment. stdev_doublet_rate; Uncertainty in the expected doublet rate. random_state; Random state for doublet simulation, approximate; nearest neighbor search, and PCA/TruncatedSVD.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:29,Availability,mask,mask,29,"""""""(shape: n_cells); Boolean mask of predicted doublets in the observed transcriptomes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:37,Safety,predict,predicted,37,"""""""(shape: n_cells); Boolean mask of predicted doublets in the observed transcriptomes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:30,Availability,error,error,30,"""""""(shape: n_cells); Standard error in the doublet scores for observed transcriptomes.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:33,Availability,error,error,33,"""""""(shape: n_doublets); Standard error in the doublet scores for simulated doublets.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:43,Safety,detect,detectable,43,"""""""Estimated fraction of doublets that are detectable, i.e.,; fraction of simulated doublets with doublet scores above `threshold_`; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:377,Usability,simpl,simply,377,"""""""Simulate doublets by adding the counts of random observed transcriptome pairs. Arguments; ---------; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. If `None`, self.sim_doublet_ratio is used. synthetic_doublet_umi_subsampling; Rate for sampling UMIs when creating synthetic doublets.; If 1.0, each doublet is created by simply adding the UMIs from two randomly; sampled observed transcriptomes.; For values less than 1, the UMI counts are added and then randomly sampled; at the specified rate. Sets; ----; doublet_parents_; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:406,Safety,predict,predicted,406,"""""""\; Call trancriptomes as doublets or singlets. Arguments; ---------; threshold; Doublet score threshold for calling a transcriptome; a doublet. If `None`, this is set automatically by looking; for the minimum between the two modes of the `doublet_scores_sim_`; histogram. It is best practice to check the threshold visually; using the `doublet_scores_sim_` histogram and/or based on; co-localization of predicted doublets in a 2-D embedding. verbose; If True, log summary statistics. Sets; ----; predicted_doublets_, z_scores_, threshold_,; detected_doublet_rate_, detectable_doublet_fraction,; overall_doublet_rate_; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:463,Testability,log,log,463,"""""""\; Call trancriptomes as doublets or singlets. Arguments; ---------; threshold; Doublet score threshold for calling a transcriptome; a doublet. If `None`, this is set automatically by looking; for the minimum between the two modes of the `doublet_scores_sim_`; histogram. It is best practice to check the threshold visually; using the `doublet_scores_sim_` histogram and/or based on; co-localization of predicted doublets in a 2-D embedding. verbose; If True, log summary statistics. Sets; ----; predicted_doublets_, z_scores_, threshold_,; detected_doublet_rate_, detectable_doublet_fraction,; overall_doublet_rate_; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:22,Safety,detect,detection,22,"# automatic threshold detection; # http://scikit-image.org/docs/dev/api/skimage.filters.html",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/core.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:3862,Deployability,update,updates,3862,"transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately for advanced usage.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for ob",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:336,Integrability,wrap,wrapper,336,"""""""\; Predict doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Works best if the input is a raw; (unnormalized) counts matrix from a single sample or a collection of; similar samples from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, t",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:1330,Modifiability,variab,variable,1330," from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, the UMI counts are added and then randomly sampled; at the specified rate.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:6,Safety,Predict,Predict,6,"""""""\; Predict doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Works best if the input is a raw; (unnormalized) counts matrix from a single sample or a collection of; similar samples from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, t",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:60,Safety,Predict,Predict,60,"""""""\; Predict doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Works best if the input is a raw; (unnormalized) counts matrix from a single sample or a collection of; similar samples from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, t",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:3783,Safety,predict,predicted,3783,"` will be used for dimensionality; reduction.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:4305,Safety,predict,predicted,4305,"onstruction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately for advanced usage.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for observed transcriptomes and simulated doublets.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2587,Testability,log,log-transform,2587,"estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, the UMI counts are added and then randomly sampled; at the specified rate.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; :class:`sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; log_transform; Whether to use :func:`~scanpy.pp.log1p` to log-transform the data; prior to PCA.; mean_center; If True, center the data such that each gene has a mean of 0.; :class:`sklearn.decomposition.PCA` will be used for dimensionality; reduction.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the ",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:3849,Testability,log,log,3849,"transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately for advanced usage.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for ob",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:1894,Usability,simpl,simply,1894," objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, the UMI counts are added and then randomly sampled; at the specified rate.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; :class:`sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; log_transform; Whether to use :func:`~scanpy.pp.log1p` to log-transform the data; prior to PCA.; mean_center; If True, center the data such that each gene has a mean of 0.; :class:`sklearn.decomposition.PCA` will be used for dimensionality; reduction.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_appro",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:125,Modifiability,variab,variability,125,"# Doublet simulation will be based on the un-normalised counts, but on the; # selection of genes following normalisation and variability filtering. So; # we need to save the raw and subset at the same time.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:20,Testability,log,log,20,"# HVG process needs log'd data.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2564,Deployability,update,updates,2564,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:432,Modifiability,variab,variable,432,"""""""\; Core function for predicting doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Parameters; ----------; adata_obs; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Should be normalised with; :func:`~scanpy.pp.normalize_total` and filtered to include only highly; variable genes.; adata_sim; Anndata object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata_obs. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; expected_doublet_rate; The estimated doublet rate for the experiment.; stdev_doublet_rate; Uncertainty in the expected doublet rate.; mean_center; If True, center the data such that each gene has a mean of 0.; `sklearn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:672,Modifiability,variab,variable,672,"""""""\; Core function for predicting doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Parameters; ----------; adata_obs; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Should be normalised with; :func:`~scanpy.pp.normalize_total` and filtered to include only highly; variable genes.; adata_sim; Anndata object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata_obs. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; expected_doublet_rate; The estimated doublet rate for the experiment.; stdev_doublet_rate; Uncertainty in the expected doublet rate.; mean_center; If True, center the data such that each gene has a mean of 0.; `sklearn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:24,Safety,predict,predicting,24,"""""""\; Core function for predicting doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Parameters; ----------; adata_obs; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Should be normalised with; :func:`~scanpy.pp.normalize_total` and filtered to include only highly; variable genes.; adata_sim; Anndata object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata_obs. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; expected_doublet_rate; The estimated doublet rate for the experiment.; stdev_doublet_rate; Uncertainty in the expected doublet rate.; mean_center; If True, center the data such that each gene has a mean of 0.; `sklearn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:81,Safety,Predict,Predict,81,"""""""\; Core function for predicting doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Parameters; ----------; adata_obs; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Should be normalised with; :func:`~scanpy.pp.normalize_total` and filtered to include only highly; variable genes.; adata_sim; Anndata object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata_obs. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; expected_doublet_rate; The estimated doublet rate for the experiment.; stdev_doublet_rate; Uncertainty in the expected doublet rate.; mean_center; If True, center the data such that each gene has a mean of 0.; `sklearn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2410,Safety,predict,predicted,2410,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2780,Safety,predict,predicted,2780,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2551,Testability,log,log,2551,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:188,Integrability,wrap,wrapper,188,"# Do PCA. Scrublet fits to the observed matrix and decomposes both observed; # and simulated based on that fit, so we'll just let it do its thing rather; # than trying to use Scanpy's PCA wrapper of the same functions.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:179,Availability,down,downstream,179,"# If threshold hasn't been located successfully then we couldn't make any; # predictions. The user will get a warning from Scrublet, but we need to; # set the boolean so that any downstream filtering on; # predicted_doublet=False doesn't incorrectly filter cells. The user can; # still use this object to generate the plot and derive a threshold; # manually.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:77,Safety,predict,predictions,77,"# If threshold hasn't been located successfully then we couldn't make any; # predictions. The user will get a warning from Scrublet, but we need to; # set the boolean so that any downstream filtering on; # predicted_doublet=False doesn't incorrectly filter cells. The user can; # still use this object to generate the plot and derive a threshold; # manually.",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:275,Modifiability,variab,variability,275,"""""""\; Simulate doublets by adding the counts of random observed transcriptome pairs. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Genes should have been; filtered for expression and variability, and the object should contain; raw expression of the same dimensions.; layer; Layer of adata where raw values are stored, or 'X' if values are in .X.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. If `None`, self.sim_doublet_ratio is used.; synthetic_doublet_umi_subsampling; Rate for sampling UMIs when creating synthetic doublets. If 1.0,; each doublet is created by simply adding the UMIs from two randomly; sampled observed transcriptomes. For values less than 1, the; UMI counts are added and then randomly sampled at the specified; rate. Returns; -------; adata : anndata.AnnData with simulated doublets in .X; Adds fields to ``adata``:. ``.obsm['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet`: Main way of running Scrublet, runs; preprocessing, doublet simulation (this function) and calling.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for observed transcriptomes and simulated doublets.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:713,Usability,simpl,simply,713,"""""""\; Simulate doublets by adding the counts of random observed transcriptome pairs. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Genes should have been; filtered for expression and variability, and the object should contain; raw expression of the same dimensions.; layer; Layer of adata where raw values are stored, or 'X' if values are in .X.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. If `None`, self.sim_doublet_ratio is used.; synthetic_doublet_umi_subsampling; Rate for sampling UMIs when creating synthetic doublets. If 1.0,; each doublet is created by simply adding the UMIs from two randomly; sampled observed transcriptomes. For values less than 1, the; UMI counts are added and then randomly sampled at the specified; rate. Returns; -------; adata : anndata.AnnData with simulated doublets in .X; Adds fields to ``adata``:. ``.obsm['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet`: Main way of running Scrublet, runs; preprocessing, doublet simulation (this function) and calling.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for observed transcriptomes and simulated doublets.; """"""",MatchSource.CODE_COMMENT,src/scanpy/preprocessing/_scrublet/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:48,Performance,cache,cache,48,"""""""\; use_cache; Whether pybiomart should use a cache for requests. Will create a; `.pybiomart.sqlite` file in current directory if used.\; """"""",MatchSource.CODE_COMMENT,src/scanpy/queries/_queries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:15,Integrability,interface,interface,15,"""""""\; A simple interface to biomart. Params; ------; {doc_org}; attrs; What you want returned.; filters; What you want to pick out.; {doc_host}; {doc_use_cache}; """"""",MatchSource.CODE_COMMENT,src/scanpy/queries/_queries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:8,Usability,simpl,simple,8,"""""""\; A simple interface to biomart. Params; ------; {doc_org}; attrs; What you want returned.; filters; What you want to pick out.; {doc_host}; {doc_use_cache}; """"""",MatchSource.CODE_COMMENT,src/scanpy/queries/_queries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:64,Integrability,wrap,wrapper,64,"""""""\; Get enrichment for DE results. This is a thin convenience wrapper around the very useful gprofiler_. This method dispatches on the first argument, leading to the following two; signatures::. enrich(container, ...); enrich(adata: AnnData, group, key: str, ...). Where::. enrich(adata, group, key, ...) = enrich(adata.uns[key][""names""][group], ...). .. _gprofiler: https://pypi.org/project/gprofiler-official/#description. Parameters; ----------; container; Contains list of genes you'd like to search. If container is a `dict` all; enrichment queries are made at once.; adata; AnnData object whose group will be looked for.; group; The group whose genes should be used for enrichment.; key; Key in `uns` to find group under.; {doc_org}; gprofiler_kwargs; Keyword arguments to pass to `GProfiler.profile`, see gprofiler_. Some; useful options are `no_evidences=False` which reports gene intersections,; `sources=['GO:BP']` which limits gene sets to only GO biological processes and; `all_results=True` which returns all results including the non-significant ones.; **kwargs; All other keyword arguments are passed to `sc.get.rank_genes_groups_df`. E.g.; pval_cutoff, log2fc_min. Returns; -------; Dataframe of enrichment results. Examples; --------; Using `sc.queries.enrich` on a list of genes:. >>> import scanpy as sc; >>> sc.queries.enrich(['KLF4', 'PAX5', 'SOX2', 'NANOG'], org=""hsapiens""); >>> sc.queries.enrich({{'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}}, org=""hsapiens""). Using `sc.queries.enrich` on an :class:`anndata.AnnData` object:. >>> pbmcs = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(pbmcs, ""bulk_labels""); >>> sc.queries.enrich(pbmcs, ""CD34+""); """"""",MatchSource.CODE_COMMENT,src/scanpy/queries/_queries.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py:784,Availability,avail,available,784,"""""""\; Computes a hierarchical clustering for the given `groupby` categories. By default, the PCA representation is used unless `.X`; has less than 50 variables. Alternatively, a list of `var_names` (e.g. genes) can be given. Average values of either `var_names` or components are used; to compute a correlation matrix. The hierarchical clustering can be visualized using; :func:`scanpy.pl.dendrogram` or multiple other visualizations that can; include a dendrogram: :func:`~scanpy.pl.matrixplot`,; :func:`~scanpy.pl.heatmap`, :func:`~scanpy.pl.dotplot`,; and :func:`~scanpy.pl.stacked_violin`. .. note::; The computation of the hierarchical clustering is based on predefined; groups and not per cell. The correlation matrix is computed using by; default pearson but other methods are available. Parameters; ----------; adata; Annotated data matrix; {n_pcs}; {use_rep}; var_names; List of var_names to use for computing the hierarchical clustering.; If `var_names` is given, then `use_rep` and `n_pcs` is ignored.; use_raw; Only when `var_names` is not None.; Use `raw` attribute of `adata` if present.; cor_method; correlation method to use.; Options are 'pearson', 'kendall', and 'spearman'; linkage_method; linkage method to use. See :func:`scipy.cluster.hierarchy.linkage`; for more information.; optimal_ordering; Same as the optimal_ordering argument of :func:`scipy.cluster.hierarchy.linkage`; which reorders the linkage matrix so that the distance between successive; leaves is minimal.; key_added; By default, the dendrogram information is added to; `.uns[f'dendrogram_{{groupby}}']`.; Notice that the `groupby` information is added to the dendrogram.; inplace; If `True`, adds dendrogram information to `adata.uns[key_added]`,; else this function returns the information. Returns; -------; Returns `None` if `inplace=True`, else returns a `dict` with dendrogram information. Sets the following field if `inplace=True`:. `adata.uns[f'dendrogram_{{group_by}}' | key_added]` : :class:`dict`; Den",MatchSource.CODE_COMMENT,src/scanpy/tools/_dendrogram.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py:150,Modifiability,variab,variables,150,"""""""\; Computes a hierarchical clustering for the given `groupby` categories. By default, the PCA representation is used unless `.X`; has less than 50 variables. Alternatively, a list of `var_names` (e.g. genes) can be given. Average values of either `var_names` or components are used; to compute a correlation matrix. The hierarchical clustering can be visualized using; :func:`scanpy.pl.dendrogram` or multiple other visualizations that can; include a dendrogram: :func:`~scanpy.pl.matrixplot`,; :func:`~scanpy.pl.heatmap`, :func:`~scanpy.pl.dotplot`,; and :func:`~scanpy.pl.stacked_violin`. .. note::; The computation of the hierarchical clustering is based on predefined; groups and not per cell. The correlation matrix is computed using by; default pearson but other methods are available. Parameters; ----------; adata; Annotated data matrix; {n_pcs}; {use_rep}; var_names; List of var_names to use for computing the hierarchical clustering.; If `var_names` is given, then `use_rep` and `n_pcs` is ignored.; use_raw; Only when `var_names` is not None.; Use `raw` attribute of `adata` if present.; cor_method; correlation method to use.; Options are 'pearson', 'kendall', and 'spearman'; linkage_method; linkage method to use. See :func:`scipy.cluster.hierarchy.linkage`; for more information.; optimal_ordering; Same as the optimal_ordering argument of :func:`scipy.cluster.hierarchy.linkage`; which reorders the linkage matrix so that the distance between successive; leaves is minimal.; key_added; By default, the dendrogram information is added to; `.uns[f'dendrogram_{{groupby}}']`.; Notice that the `groupby` information is added to the dendrogram.; inplace; If `True`, adds dendrogram information to `adata.uns[key_added]`,; else this function returns the information. Returns; -------; Returns `None` if `inplace=True`, else returns a `dict` with dendrogram information. Sets the following field if `inplace=True`:. `adata.uns[f'dendrogram_{{group_by}}' | key_added]` : :class:`dict`; Den",MatchSource.CODE_COMMENT,src/scanpy/tools/_dendrogram.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py:202,Energy Efficiency,adapt,adapted,202,"""""""\; Diffusion Maps :cite:p:`Coifman2005,Haghverdi2015,Wolf2018`. Diffusion maps :cite:p:`Coifman2005` has been proposed for visualizing single-cell; data by :cite:t:`Haghverdi2015`. The tool uses the adapted Gaussian kernel suggested; by :cite:t:`Haghverdi2016` in the implementation of :cite:t:`Wolf2018`. The width (""sigma"") of the connectivity kernel is implicitly determined by; the number of neighbors used to compute the single-cell graph in; :func:`~scanpy.pp.neighbors`. To reproduce the original implementation; using a Gaussian kernel, use `method=='gauss'` in; :func:`~scanpy.pp.neighbors`. To use an exponential kernel, use the default; `method=='umap'`. Differences between these options shouldn't usually be; dramatic. Parameters; ----------; adata; Annotated data matrix.; n_comps; The number of dimensions of the representation.; neighbors_key; If not specified, diffmap looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, diffmap looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; random_state; A numpy random seed; copy; Return a copy instead of writing to adata. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_diffmap']` : :class:`numpy.ndarray` (dtype `float`); Diffusion map representation of data, which is the right eigen basis of; the transition matrix with eigenvectors as columns. `adata.uns['diffmap_evals']` : :class:`numpy.ndarray` (dtype `float`); Array of size (number of eigen vectors).; Eigenvalues of transition matrix. Notes; -----; The 0-th column in `adata.obsm[""X_diffmap""]` is the steady-state solution,; which is non-informative in diffusion maps.; Therefore, the first diffusion com",MatchSource.CODE_COMMENT,src/scanpy/tools/_diffmap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py:202,Modifiability,adapt,adapted,202,"""""""\; Diffusion Maps :cite:p:`Coifman2005,Haghverdi2015,Wolf2018`. Diffusion maps :cite:p:`Coifman2005` has been proposed for visualizing single-cell; data by :cite:t:`Haghverdi2015`. The tool uses the adapted Gaussian kernel suggested; by :cite:t:`Haghverdi2016` in the implementation of :cite:t:`Wolf2018`. The width (""sigma"") of the connectivity kernel is implicitly determined by; the number of neighbors used to compute the single-cell graph in; :func:`~scanpy.pp.neighbors`. To reproduce the original implementation; using a Gaussian kernel, use `method=='gauss'` in; :func:`~scanpy.pp.neighbors`. To use an exponential kernel, use the default; `method=='umap'`. Differences between these options shouldn't usually be; dramatic. Parameters; ----------; adata; Annotated data matrix.; n_comps; The number of dimensions of the representation.; neighbors_key; If not specified, diffmap looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, diffmap looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; random_state; A numpy random seed; copy; Return a copy instead of writing to adata. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_diffmap']` : :class:`numpy.ndarray` (dtype `float`); Diffusion map representation of data, which is the right eigen basis of; the transition matrix with eigenvectors as columns. `adata.uns['diffmap_evals']` : :class:`numpy.ndarray` (dtype `float`); Array of size (number of eigen vectors).; Eigenvalues of transition matrix. Notes; -----; The 0-th column in `adata.obsm[""X_diffmap""]` is the steady-state solution,; which is non-informative in diffusion maps.; Therefore, the first diffusion com",MatchSource.CODE_COMMENT,src/scanpy/tools/_diffmap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2567,Performance,perform,perform,2567,"y.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion of :cite:t:`Haghverdi2016` to; stabilize the splitting.; neighbors_key; If not specified, dpt looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, dpt looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; copy; Copy instance before computation and return a copy.; Otherwise, perform computation inplace and return `None`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields (If `n_branchings==0`, no field `adata.obs['dpt_groups']` will be written):. `adata.obs['dpt_pseudotime']` : :class:`pandas.Series` (dtype `float`); Array of dim (number of samples) that stores the pseudotime of each; cell, that is, the DPT distance with respect to the root cell.; `adata.obs['dpt_groups']` : :class:`pandas.Series` (dtype `category`); Array of dim (number of samples) that stores the subgroup id ('0',; '1', ...) for each cell. The groups typically correspond to; 'progenitor cells', 'undecided cells' or 'branches' of a process. Notes; -----; The tool is similar to the R package `destiny` of :cite:t:`Angerer2015`.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:609,Safety,detect,detect,609,"""""""\; Infer progression of cells through geodesic distance along the graph; :cite:p:`Haghverdi2016,Wolf2019`. Reconstruct the progression of a biological process from snapshot; data. `Diffusion Pseudotime` has been introduced by :cite:t:`Haghverdi2016` and; implemented within Scanpy :cite:p:`Wolf2018`. Here, we use a further developed; version, which is able to deal with disconnected graphs :cite:p:`Wolf2019` and can; be run in a `hierarchical` mode by setting the parameter; `n_branchings>1`. We recommend, however, to only use; :func:`~scanpy.tl.dpt` for computing pseudotime (`n_branchings=0`) and; to detect branchings via :func:`~scanpy.tl.paga`. For pseudotime, you need; to annotate your data with a root cell. For instance::. adata.uns['iroot'] = np.flatnonzero(adata.obs['cell_types'] == 'Stem')[0]. This requires to run :func:`~scanpy.pp.neighbors`, first. In order to; reproduce the original implementation of DPT, use `method=='gauss'` in; this. Using the default `method=='umap'` only leads to minor quantitative; differences, though. .. versionadded:: 1.1. :func:`~scanpy.tl.dpt` also requires to run; :func:`~scanpy.tl.diffmap` first. As previously,; :func:`~scanpy.tl.dpt` came with a default parameter of ``n_dcs=10`` but; :func:`~scanpy.tl.diffmap` has a default parameter of ``n_comps=15``,; you need to pass ``n_comps=10`` in :func:`~scanpy.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion o",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:1593,Safety,detect,detect,1593,"otime (`n_branchings=0`) and; to detect branchings via :func:`~scanpy.tl.paga`. For pseudotime, you need; to annotate your data with a root cell. For instance::. adata.uns['iroot'] = np.flatnonzero(adata.obs['cell_types'] == 'Stem')[0]. This requires to run :func:`~scanpy.pp.neighbors`, first. In order to; reproduce the original implementation of DPT, use `method=='gauss'` in; this. Using the default `method=='umap'` only leads to minor quantitative; differences, though. .. versionadded:: 1.1. :func:`~scanpy.tl.dpt` also requires to run; :func:`~scanpy.tl.diffmap` first. As previously,; :func:`~scanpy.tl.dpt` came with a default parameter of ``n_dcs=10`` but; :func:`~scanpy.tl.diffmap` has a default parameter of ``n_comps=15``,; you need to pass ``n_comps=10`` in :func:`~scanpy.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion of :cite:t:`Haghverdi2016` to; stabilize the splitting.; neighbors_key; If not specified, dpt looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, dpt looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; copy; Copy instance before computation and return a copy.; Otherwise, perform co",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:1913,Safety,detect,detected,1913,"his. Using the default `method=='umap'` only leads to minor quantitative; differences, though. .. versionadded:: 1.1. :func:`~scanpy.tl.dpt` also requires to run; :func:`~scanpy.tl.diffmap` first. As previously,; :func:`~scanpy.tl.dpt` came with a default parameter of ``n_dcs=10`` but; :func:`~scanpy.tl.diffmap` has a default parameter of ``n_comps=15``,; you need to pass ``n_comps=10`` in :func:`~scanpy.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion of :cite:t:`Haghverdi2016` to; stabilize the splitting.; neighbors_key; If not specified, dpt looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, dpt looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; copy; Copy instance before computation and return a copy.; Otherwise, perform computation inplace and return `None`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields (If `n_branchings==0`, no field `adata.obs['dpt_groups']` will be written):. `adata.obs['dpt_pseudotime']` : :class:`pandas.Series` (dtype `float`); Array of dim (number of samples) that stores the pseudotime of each; cell, that is, t",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:11,Availability,error,errors,11,"# standard errors, warnings etc.",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,Deployability,update,update,2,"# update iroot, might have changed when subsampling, for example",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,Safety,detect,detect,2,"# detect branchings and partition the data into segments",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:254,Availability,mask,mask,254,"""""""\; Detect branchings and partition the data into corresponding segments. Detect all branchings up to `n_branchings`. Writes; ------; segs : :class:`~numpy.ndarray`; Array of dimension (number of segments) × (number of data; points). Each row stores a mask array that defines a segment.; segs_tips : :class:`~numpy.ndarray`; Array of dimension (number of segments) × 2. Each row stores the; indices of the two tip points of each segment.; segs_names : :class:`~numpy.ndarray`; Array of dimension (number of data points). Stores an integer label; for each segment.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Safety,Detect,Detect,6,"""""""\; Detect branchings and partition the data into corresponding segments. Detect all branchings up to `n_branchings`. Writes; ------; segs : :class:`~numpy.ndarray`; Array of dimension (number of segments) × (number of data; points). Each row stores a mask array that defines a segment.; segs_tips : :class:`~numpy.ndarray`; Array of dimension (number of segments) × 2. Each row stores the; indices of the two tip points of each segment.; segs_names : :class:`~numpy.ndarray`; Array of dimension (number of data points). Stores an integer label; for each segment.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:76,Safety,Detect,Detect,76,"""""""\; Detect branchings and partition the data into corresponding segments. Detect all branchings up to `n_branchings`. Writes; ------; segs : :class:`~numpy.ndarray`; Array of dimension (number of segments) × (number of data; points). Each row stores a mask array that defines a segment.; segs_tips : :class:`~numpy.ndarray`; Array of dimension (number of segments) × 2. Each row stores the; indices of the two tip points of each segment.; segs_names : :class:`~numpy.ndarray`; Array of dimension (number of data points). Stores an integer label; for each segment.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Safety,Detect,Detect,6,"""""""\; Detect all branchings up to `n_branchings`. Writes Attributes; -----------------; segs : :class:`~numpy.ndarray`; List of integer index arrays.; segs_tips : :class:`~numpy.ndarray`; List of indices of the tips of segments.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:10,Safety,safe,safe,10,"# this is safe, but not compatible with on-the-fly computation",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:44,Deployability,update,update,44,"# [third start end]; # detect branching and update segs and segs_tips",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:23,Safety,detect,detect,23,"# [third start end]; # detect branching and update segs and segs_tips",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:49,Modifiability,variab,variable,49,"# noqa: F841 TODO Evaluate whether to assign the variable or not",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,Deployability,update,update,2,"# update adjacency matrix within the loop!; # self.segs_adjacency[iseg, neighbor_segs > 0] = 0; # self.segs_adjacency[iseg, closest_segs] = np.array(distance_segs)[closest_segs]; # self.segs_adjacency[neighbor_segs > 0, iseg] = 0; # self.segs_adjacency[closest_segs, iseg] = np.array(distance_segs)[closest_segs].reshape(len(closest_segs), 1); # n_edges_per_seg = np.sum(self.segs_adjacency > 0, axis=1).A1",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,Testability,log,logg,2,"# logg.debug(; # ' group', iseg, 'with tip', segs_tips[iseg][itip],; # 'connects with', jseg, 'with tip', segs_tips[jseg][1],; # ); # logg.debug(' do not use the tip for ""triangulation""')",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:134,Testability,log,logg,134,"# logg.debug(; # ' group', iseg, 'with tip', segs_tips[iseg][itip],; # 'connects with', jseg, 'with tip', segs_tips[jseg][1],; # ); # logg.debug(' do not use the tip for ""triangulation""')",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:234,Usability,simpl,simply,234,"# compute the score as ratio of the added distance to the third tip,; # to what it would be if it were on the straight line between the; # two first tips, given by Dseg[tips[:2]]; # if we did not normalize, there would be a danger of simply; # assigning the highest score to the longest segment",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,Usability,simpl,simply,2,"# simply the number of points",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:22,Availability,mask,mask,22,"# make segs a list of mask arrays, it's easier to store; # as there is a hdf5 equivalent",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:41,Deployability,Update,Updates,41,"""""""\; Detect branching on given segment. Updates all list parameters inplace. Call function _detect_branching and perform bookkeeping on segs and; segs_tips. Parameters; ----------; segs; Dchosen distance matrix restricted to segment.; segs_tips; Stores all tip points for the segments in segs.; iseg; Position of segment under study in segs.; tips3; The three tip points. They form a 'triangle' that contains the data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:114,Performance,perform,perform,114,"""""""\; Detect branching on given segment. Updates all list parameters inplace. Call function _detect_branching and perform bookkeeping on segs and; segs_tips. Parameters; ----------; segs; Dchosen distance matrix restricted to segment.; segs_tips; Stores all tip points for the segments in segs.; iseg; Position of segment under study in segs.; tips3; The three tip points. They form a 'triangle' that contains the data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Safety,Detect,Detect,6,"""""""\; Detect branching on given segment. Updates all list parameters inplace. Call function _detect_branching and perform bookkeeping on segs and; segs_tips. Parameters; ----------; segs; Dchosen distance matrix restricted to segment.; segs_tips; Stores all tip points for the segments in segs.; iseg; Position of segment under study in segs.; tips3; The three tip points. They form a 'triangle' that contains the data.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:53,Safety,detect,detect,53,"# given the three tip points and the distance matrix detect the; # branching on the segment, return the list ssegs of segments that; # are defined by splitting this segment",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:38,Modifiability,variab,variable,38,"# TODO Evaluate whether to assign the variable or not",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Safety,Detect,Detect,6,"""""""\; Detect branching on given segment. Call function __detect_branching three times for all three orderings of; tips. Points that do not belong to the same segment in all three; orderings are assigned to a fourth segment. The latter is, by Haghverdi; et al. (2016) referred to as 'undecided cells'. Parameters; ----------; Dseg; Dchosen distance matrix restricted to segment.; tips; The three tip points. They form a 'triangle' that contains the data. Returns; -------; ssegs; List of segments obtained from splitting the single segment defined; via the first two tip cells.; ssegs_tips; List of tips of segments in ssegs.; ssegs_adjacency; ?; ssegs_connects; ?; trunk; ?; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:3,Safety,Detect,Detect,3,"""""""Detect branching on given segment.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Safety,Detect,Detect,6,"""""""\; Detect branching on given segment. Compute point that maximizes kendall tau correlation of the sequences of; distances to the second and the third tip, respectively, when 'moving; away' from the first tip: tips[0]. 'Moving away' means moving in the; direction of increasing distance from the first tip. Parameters; ----------; Dseg; Dchosen distance matrix restricted to segment.; tips; The three tip points. They form a 'triangle' that contains the data. Returns; -------; Segments obtained from ""splitting away the first tip cell"".; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_dpt.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:630,Availability,avail,available,630,"""""""\; Force-directed graph drawing :cite:p:`Islam2011,Jacomy2014,Chippada2018`. An alternative to tSNE that often preserves the topology of the data; better. This requires to run :func:`~scanpy.pp.neighbors`, first. The default layout ('fa', `ForceAtlas2`, :cite:t:`Jacomy2014`) uses the package |fa2|_; :cite:p:`Chippada2018`, which can be installed via `pip install fa2`. `Force-directed graph drawing`_ describes a class of long-established; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for con",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:341,Deployability,install,installed,341,"""""""\; Force-directed graph drawing :cite:p:`Islam2011,Jacomy2014,Chippada2018`. An alternative to tSNE that often preserves the topology of the data; better. This requires to run :func:`~scanpy.pp.neighbors`, first. The default layout ('fa', `ForceAtlas2`, :cite:t:`Jacomy2014`) uses the package |fa2|_; :cite:p:`Chippada2018`, which can be installed via `pip install fa2`. `Force-directed graph drawing`_ describes a class of long-established; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for con",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:360,Deployability,install,install,360,"""""""\; Force-directed graph drawing :cite:p:`Islam2011,Jacomy2014,Chippada2018`. An alternative to tSNE that often preserves the topology of the data; better. This requires to run :func:`~scanpy.pp.neighbors`, first. The default layout ('fa', `ForceAtlas2`, :cite:t:`Jacomy2014`) uses the package |fa2|_; :cite:p:`Chippada2018`, which can be installed via `pip install fa2`. `Force-directed graph drawing`_ describes a class of long-established; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for con",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:1493,Performance,optimiz,optimization,1493,"hed; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, draw_graph looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Return a copy instead of writing to adata.; **kwds; Parameters of chosen igraph layout. See e.g.; :meth:`~igraph.GraphBase.layout_fruchterman_reingold` :cite:p:`Fruchterm",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:21,Deployability,install,installed,21,"# see whether fa2 is installed",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:2,Performance,Perform,Performance,2,"# Performance",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:2,Availability,Toler,Tolerance,2,"# Tolerance",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:2,Testability,Log,Log,2,"# Log",MatchSource.CODE_COMMENT,src/scanpy/tools/_draw_graph.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:182,Performance,perform,performed,182,"""""""\; Calculate the density of cells in an embedding (per condition). Gaussian kernel density estimation is used to calculate the density of; cells in an embedded space. This can be performed per category over a; categorical cell annotation. The cell density can be plotted using the; `pl.embedding_density` function. Note that density values are scaled to be between 0 and 1. Thus, the; density value at each cell is only comparable to densities in; the same category. Beware that the KDE estimate used (`scipy.stats.gaussian_kde`) becomes; unreliable if you don't have enough cells in a category. This function was written by Sophie Tritschler and implemented into; Scanpy by Malte Luecken. Parameters; ----------; adata; The annotated data matrix.; basis; The embedding over which the density will be calculated. This embedded; representation should be found in `adata.obsm['X_[basis]']``.; groupby; Key for categorical observation/cell annotation for which densities; are calculated per category.; key_added; Name of the `.obs` covariate that will be added with the density; estimates.; components; The embedding dimensions over which the density should be calculated.; This is limited to two components. Returns; -------; Sets the following fields (`key_added` defaults to `[basis]_density_[groupby]`, where `[basis]` is one of `umap`, `diffmap`, `pca`, `tsne`, or `draw_graph_fa` and `[groupby]` denotes the parameter input):. `adata.obs[key_added]` : :class:`numpy.ndarray` (dtype `float`); Embedding density values for each cell.; `adata.uns['[key_added]_params']` : :class:`dict`; A dict with the values for the parameters `covariate` (for the `groupby` parameter) and `components`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.umap(adata); sc.tl.embedding_density(adata, basis='umap', groupby='phase'); sc.pl.embedding_density(; adata, basis='umap', key='umap_density_phase', group='G1'; ). .. plot::; :context: close",MatchSource.CODE_COMMENT,src/scanpy/tools/_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:64,Testability,test,test,64,"# to ensure that newly created covariates are categorical; # to test for category numbers",MatchSource.CODE_COMMENT,src/scanpy/tools/_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:2,Testability,Test,Test,2,"# Test user inputs",MatchSource.CODE_COMMENT,src/scanpy/tools/_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:2,Energy Efficiency,Reduce,Reduce,2,"# Reduce diffmap components for labeling; # Note: plot_scatter takes care of correcting diffmap components; # for plotting automatically",MatchSource.CODE_COMMENT,src/scanpy/tools/_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:89,Deployability,integrat,integrating-data-using-ingest,89,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:121,Deployability,Integrat,Integrates,121,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:481,Deployability,integrat,integration,481,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:615,Deployability,integrat,integrates,615,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:89,Integrability,integrat,integrating-data-using-ingest,89,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:121,Integrability,Integrat,Integrates,121,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:481,Integrability,integrat,integration,481,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:615,Integrability,integrat,integrates,615,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:1114,Modifiability,Variab,Variables,1114,"ns of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; inplace; Only works if `return_joint=False`.; Add labels and embeddings to the passed `adata` (if `True`); or return a copy of `adata` with mapped embeddings",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:578,Usability,learn,learning,578,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:202,Modifiability,Variab,Variables,202,"""""""\; Map `adata_new` to the same representation as `adata`. This function identifies the representation which was used to; calculate neighbors in 'adata' and maps `adata_new` to; this representation.; Variables (`n_vars` and `var_names`) of `adata_new` should be the same; as in `adata`. `adata` refers to the :class:`~anndata.AnnData` object; that is passed during the initialization of an Ingest instance.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:221,Deployability,update,updates,221,"""""""\; Returns `adata_new` with mapped embeddings and labels. If `inplace=False` returns a copy of `adata_new`; with mapped embeddings and labels in `obsm` and `obs` correspondingly.; If `inplace=True` returns nothing and updates `adata_new.obsm`; and `adata_new.obs` with mapped embeddings and labels.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_ingest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:1584,Availability,avail,available,1584,"ution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Whether to copy `adata` or modify it inplace.; flavor; Which package's implementation to use.; **clustering_args; Any further arguments to pass to :func:`~leidenalg.find_partition` (which in turn passes arguments to the `partition_type`); or :meth:`igraph.Graph.community_leiden` from `igraph`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obs['leiden' | key_added]` : :class:`pandas.Series` (dtype ``category``); Array of dim (number of samples) that stores the subgroup id; (``'0'",MatchSource.CODE_COMMENT,src/scanpy/tools/_leiden.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:679,Performance,optimiz,optimization,679,"""""""\; Cluster cells into subgroups :cite:p:`Traag2019`. Cluster cells using the Leiden algorithm :cite:p:`Traag2019`,; an improved version of the Louvain algorithm :cite:p:`Blondel2008`.; It has been proposed for single-cell analysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first. Parameters; ----------; adata; The annotated data matrix.; resolution; A parameter value controlling the coarseness of the clustering.; Higher values lead to more clusters.; Set to `None` if overriding `partition_type`; to one that doesn’t accept a `resolution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify bo",MatchSource.CODE_COMMENT,src/scanpy/tools/_leiden.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:1262,Performance,perform,perform,1262,"ysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first. Parameters; ----------; adata; The annotated data matrix.; resolution; A parameter value controlling the coarseness of the clustering.; Higher values lead to more clusters.; Set to `None` if overriding `partition_type`; to one that doesn’t accept a `resolution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Whether to copy `adata` or modify it inplace.; flavor; Which package's implementation to use.; **clustering_args; Any further arguments to pass to :func:`~leidenalg.find_pa",MatchSource.CODE_COMMENT,src/scanpy/tools/_leiden.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:1337,Performance,perform,perform,1337,"pp.bbknn` first. Parameters; ----------; adata; The annotated data matrix.; resolution; A parameter value controlling the coarseness of the clustering.; Higher values lead to more clusters.; Set to `None` if overriding `partition_type`; to one that doesn’t accept a `resolution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Whether to copy `adata` or modify it inplace.; flavor; Which package's implementation to use.; **clustering_args; Any further arguments to pass to :func:`~leidenalg.find_partition` (which in turn passes arguments to the `partition_type`); or :meth:`igraph.Graph.community_leiden` from",MatchSource.CODE_COMMENT,src/scanpy/tools/_leiden.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py:1211,Energy Efficiency,power,powerful,1211," proposed for single-cell; analysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first,; or explicitly passing a ``adjacency`` matrix. Parameters; ----------; adata; The annotated data matrix.; resolution; For the default flavor (``'vtraag'``) or for ```RAPIDS```, you can provide a; resolution (higher resolution means finding more and smaller clusters),; which defaults to 1.0.; See “Time as a resolution parameter” in :cite:t:`Lambiotte2014`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain ``(obs_key, list_of_categories)``.; key_added; Key under which to add the cluster labels. (default: ``'louvain'``); adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; flavor; Choose between to packages for computing the clustering. ``'vtraag'``; Much more powerful than ``'igraph'``, and the default.; ``'igraph'``; Built in ``igraph`` method.; ``'rapids'``; GPU accelerated implementation. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.tl.louvain` instead.; directed; Interpret the ``adjacency`` matrix as directed graph?; use_weights; Use weights from knn graph.; partition_type; Type of partition to use.; Only a valid argument if ``flavor`` is ``'vtraag'``.; partition_kwargs; Key word arguments to pass to partitioning,; if ``vtraag`` method is being used.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, louvain looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, louvain looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Copy adata or modify it inplace. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData",MatchSource.CODE_COMMENT,src/scanpy/tools/_louvain.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py:786,Performance,optimiz,optimization,786,"""""""\; Cluster cells into subgroups :cite:p:`Blondel2008,Levine2015,Traag2017`. Cluster cells using the Louvain algorithm :cite:p:`Blondel2008` in the implementation; of :cite:t:`Traag2017`. The Louvain algorithm has been proposed for single-cell; analysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first,; or explicitly passing a ``adjacency`` matrix. Parameters; ----------; adata; The annotated data matrix.; resolution; For the default flavor (``'vtraag'``) or for ```RAPIDS```, you can provide a; resolution (higher resolution means finding more and smaller clusters),; which defaults to 1.0.; See “Time as a resolution parameter” in :cite:t:`Lambiotte2014`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain ``(obs_key, list_of_categories)``.; key_added; Key under which to add the cluster labels. (default: ``'louvain'``); adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; flavor; Choose between to packages for computing the clustering. ``'vtraag'``; Much more powerful than ``'igraph'``, and the default.; ``'igraph'``; Built in ``igraph`` method.; ``'rapids'``; GPU accelerated implementation. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.tl.louvain` instead.; directed; Interpret the ``adjacency`` matrix as directed graph?; use_weights; Use weights from knn graph.; partition_type; Type of partition to use.; Only a valid argument if ``flavor`` is ``'vtraag'``.; partition_kwargs; Key word arguments to pass to partitioning,; if ``vtraag`` method is being used.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, louvain looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, louvain looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.;",MatchSource.CODE_COMMENT,src/scanpy/tools/_louvain.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py:2,Testability,Test,Test,2,"# Test user inputs",MatchSource.CODE_COMMENT,src/scanpy/tools/_marker_gene_overlap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py:64,Testability,test,test,64,"# Note:; # Could add an 'enrich' option here; # (fisher's exact test or hypergeometric test),; # but that would require knowledge of the size of the space from which; # the reference marker gene set was taken.; # This is at best approximately known.; # Create a pandas dataframe with the results",MatchSource.CODE_COMMENT,src/scanpy/tools/_marker_gene_overlap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py:87,Testability,test,test,87,"# Note:; # Could add an 'enrich' option here; # (fisher's exact test or hypergeometric test),; # but that would require knowledge of the size of the space from which; # the reference marker gene set was taken.; # This is at best approximately known.; # Create a pandas dataframe with the results",MatchSource.CODE_COMMENT,src/scanpy/tools/_marker_gene_overlap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:2293,Performance,perform,perform,2293,"aph` via; `init_pos='paga'` to get single-cell embeddings that are typically more; faithful to the global topology. Parameters; ----------; adata; An annotated data matrix.; groups; Key for categorical in `adata.obs`. You can pass your predefined groups; by choosing any categorical annotation of observations. Default:; The first present key of `'leiden'` or `'louvain'`.; use_rna_velocity; Use RNA velocity to orient edges in the abstracted graph and estimate; transitions. Requires that `adata.uns` contains a directed single-cell; graph with key `['velocity_graph']`. This feature might be subject; to change in the future.; model; The PAGA connectivity model.; neighbors_key; If not specified, paga looks `.uns['neighbors']` for neighbors settings; and `.obsp['connectivities']`, `.obsp['distances']` for connectivities and; distances respectively (default storage places for `pp.neighbors`).; If specified, paga looks `.uns[neighbors_key]` for neighbors settings and; `.obsp[.uns[neighbors_key]['connectivities_key']]`,; `.obsp[.uns[neighbors_key]['distances_key']]` for connectivities and distances; respectively.; copy; Copy `adata` before computation and return a copy. Otherwise, perform; computation inplace and return `None`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['connectivities']` : :class:`numpy.ndarray` (dtype `float`); The full adjacency matrix of the abstracted graph, weights correspond to; confidence in the connectivities of partitions.; `adata.uns['connectivities_tree']` : :class:`scipy.sparse.csr_matrix` (dtype `float`); The adjacency matrix of the tree-like subgraph that best explains; the topology. Notes; -----; Together with a random walk-based distance measure; (e.g. :func:`scanpy.tl.dpt`) this generates a partial coordinatization of; data useful for exploring and explaining its variation. .. currentmodule:: scanpy. See Also; --------; pl.paga; pl.paga_path; pl.paga_compare; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:253,Usability,simpl,simpler,253,"""""""\; Mapping out the coarse-grained connectivity structures of complex manifolds :cite:p:`Wolf2019`. By quantifying the connectivity of partitions (groups, clusters) of the; single-cell graph, partition-based graph abstraction (PAGA) generates a much; simpler abstracted graph (*PAGA graph*) of partitions, in which edge weights; represent confidence in the presence of connections. By thresholding this; confidence in :func:`~scanpy.pl.paga`, a much simpler representation of the; manifold data is obtained, which is nonetheless faithful to the topology of; the manifold. The confidence should be interpreted as the ratio of the actual versus the; expected value of connections under the null model of randomly connecting; partitions. We do not provide a p-value as this null model does not; precisely capture what one would consider ""connected"" in real data, hence it; strongly overestimates the expected value. See an extensive discussion of; this in :cite:t:`Wolf2019`. .. note::; Note that you can use the result of :func:`~scanpy.pl.paga` in; :func:`~scanpy.tl.umap` and :func:`~scanpy.tl.draw_graph` via; `init_pos='paga'` to get single-cell embeddings that are typically more; faithful to the global topology. Parameters; ----------; adata; An annotated data matrix.; groups; Key for categorical in `adata.obs`. You can pass your predefined groups; by choosing any categorical annotation of observations. Default:; The first present key of `'leiden'` or `'louvain'`.; use_rna_velocity; Use RNA velocity to orient edges in the abstracted graph and estimate; transitions. Requires that `adata.uns` contains a directed single-cell; graph with key `['velocity_graph']`. This feature might be subject; to change in the future.; model; The PAGA connectivity model.; neighbors_key; If not specified, paga looks `.uns['neighbors']` for neighbors settings; and `.obsp['connectivities']`, `.obsp['distances']` for connectivities and; distances respectively (default storage places for `pp.neighbors`).;",MatchSource.CODE_COMMENT,src/scanpy/tools/_paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:452,Usability,simpl,simpler,452,"""""""\; Mapping out the coarse-grained connectivity structures of complex manifolds :cite:p:`Wolf2019`. By quantifying the connectivity of partitions (groups, clusters) of the; single-cell graph, partition-based graph abstraction (PAGA) generates a much; simpler abstracted graph (*PAGA graph*) of partitions, in which edge weights; represent confidence in the presence of connections. By thresholding this; confidence in :func:`~scanpy.pl.paga`, a much simpler representation of the; manifold data is obtained, which is nonetheless faithful to the topology of; the manifold. The confidence should be interpreted as the ratio of the actual versus the; expected value of connections under the null model of randomly connecting; partitions. We do not provide a p-value as this null model does not; precisely capture what one would consider ""connected"" in real data, hence it; strongly overestimates the expected value. See an extensive discussion of; this in :cite:t:`Wolf2019`. .. note::; Note that you can use the result of :func:`~scanpy.pl.paga` in; :func:`~scanpy.tl.umap` and :func:`~scanpy.tl.draw_graph` via; `init_pos='paga'` to get single-cell embeddings that are typically more; faithful to the global topology. Parameters; ----------; adata; An annotated data matrix.; groups; Key for categorical in `adata.obs`. You can pass your predefined groups; by choosing any categorical annotation of observations. Default:; The first present key of `'leiden'` or `'louvain'`.; use_rna_velocity; Use RNA velocity to orient edges in the abstracted graph and estimate; transitions. Requires that `adata.uns` contains a directed single-cell; graph with key `['velocity_graph']`. This feature might be subject; to change in the future.; model; The PAGA connectivity model.; neighbors_key; If not specified, paga looks `.uns['neighbors']` for neighbors settings; and `.obsp['connectivities']`, `.obsp['distances']` for connectivities and; distances respectively (default storage places for `pp.neighbors`).;",MatchSource.CODE_COMMENT,src/scanpy/tools/_paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:32,Testability,test,test,32,"# "" 'paga/transitions_ttest', t-test on transitions (adata.uns)""",MatchSource.CODE_COMMENT,src/scanpy/tools/_paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:35,Usability,simpl,simply,35,"# this is the boolean version that simply counts edges in the clustered graph",MatchSource.CODE_COMMENT,src/scanpy/tools/_paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:40,Availability,error,errors,40,"# Singlet groups cause division by zero errors",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:6,Testability,log,logreg,6,"# for logreg only",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:37,Integrability,depend,depending,37,"""""""Set self.{means,vars,pts}{,_rest} depending on X.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:38,Availability,Mask,Mask,38,"# TODO: Come up with better solution. Mask unexpressed genes?; # See https://github.com/scipy/scipy/issues/10269",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:53,Availability,mask,mask,53,"# Calculate rank sums for each chunk for the current mask",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:76,Availability,mask,mask,76,"# If no reference group exists,; # ranking needs only to be done once (full mask)",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:9,Testability,log,logistic,9,"# binary logistic regression",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:3693,Integrability,depend,depending,3693," -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> # to visualize the results; >>> sc.pl.rank_genes_groups(adata); """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:326,Modifiability,layers,layers,326,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:362,Performance,perform,perform,362,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1996,Safety,predict,predictors,1996,"`'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approxima",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:52,Testability,log,logarithmized,52,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:242,Testability,test,tests,242,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:370,Testability,test,tests,370,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:906,Testability,test,test,906,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1019,Testability,log,logreg,1019,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1033,Testability,log,logistic,1033,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1308,Testability,test,test,1308,"ta.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by gr",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1769,Testability,test,test,1769,"t to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1871,Testability,Log,LogisticRegression,1871,"he default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. O",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:2705,Testability,log,logfoldchanges,2705,"r to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whe",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:2940,Testability,test,test,2940,"l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduce",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:3005,Testability,log,log,3005,"hat are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels',",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:3810,Testability,test,tests,3810," -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> # to visualize the results; >>> sc.pl.rank_genes_groups(adata); """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:22,Modifiability,variab,variable,22,"# for clarity, rename variable",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:22,Modifiability,variab,variable,22,"# for clarity, rename variable",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:33,Testability,log,log,33,"""""""\; Filters out genes based on log fold change and fraction of genes expressing the; gene within and outside the `groupby` categories. See :func:`~scanpy.tl.rank_genes_groups`. Results are stored in `adata.uns[key_added]`; (default: 'rank_genes_groups_filtered'). To preserve the original structure of adata.uns['rank_genes_groups'],; filtered genes are set to `NaN`. Parameters; ----------; adata; key; groupby; use_raw; key_added; min_in_group_fraction; min_fold_change; max_out_group_fraction; compare_abs; If `True`, compare absolute values of log fold change with `min_fold_change`. Returns; -------; Same output as :func:`scanpy.tl.rank_genes_groups` but with filtered genes names set to; `nan`. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> sc.tl.filter_rank_genes_groups(adata, min_fold_change=3); >>> # visualize results; >>> sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'); >>> # visualize results using dotplot; >>> sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'); """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:550,Testability,log,log,550,"""""""\; Filters out genes based on log fold change and fraction of genes expressing the; gene within and outside the `groupby` categories. See :func:`~scanpy.tl.rank_genes_groups`. Results are stored in `adata.uns[key_added]`; (default: 'rank_genes_groups_filtered'). To preserve the original structure of adata.uns['rank_genes_groups'],; filtered genes are set to `NaN`. Parameters; ----------; adata; key; groupby; use_raw; key_added; min_in_group_fraction; min_fold_change; max_out_group_fraction; compare_abs; If `True`, compare absolute values of log fold change with `min_fold_change`. Returns; -------; Same output as :func:`scanpy.tl.rank_genes_groups` but with filtered genes names set to; `nan`. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> sc.tl.filter_rank_genes_groups(adata, min_fold_change=3); >>> # visualize results; >>> sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'); >>> # visualize results using dotplot; >>> sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'); """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:5,Deployability,Update,Update,5,"""""""; Update parser with tool specific arguments. This overwrites was is done in utils.uns_args.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:7,Modifiability,variab,variables,7,"# init variables",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Usability,simpl,simple,2,"# simple vector auto regressive process or; # hill kinetics process simulation",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:17,Modifiability,coupling,coupling,17,"# check that the coupling matrix does not have eigenvalues; # greater than 1, which would lead to an exploding var process",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Performance,load,load,2,"# load the last simulation file",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Deployability,update,update,2,"# update file with sample ids",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:33,Modifiability,coupling,coupling,33,"# write files with adjacancy and coupling matrices",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:10,Deployability,update,update,10,"# due to 'update formulation' of model, there; # is always a diagonal dependence",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:70,Integrability,depend,dependence,70,"# due to 'update formulation' of model, there; # is always a diagonal dependence",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:8,Modifiability,coupling,coupling,8,"# write coupling via names",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:96,Modifiability,variab,variable,96,"# write simulated data; # the binary mode option in the following line is a fix for python 3; # variable names",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:10,Modifiability,coupling,coupling,10,"# set the coupling matrix, and with that the adjacency matrix",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:45,Deployability,update,update,45,"# loop over all tuples for which the boolean update; # rule returns true, these are stored in self.boolCoeff",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:62,Energy Efficiency,power,power,62,"""""""Inhibiting hill function. Is equivalent to 1-hill_a(self,x,power,threshold).; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:74,Energy Efficiency,power,power,74,"""""""Normalized inhibiting hill function. Is equivalent to 1-nhill_a(self,x,power,threshold).; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:26,Modifiability,coupling,couplings,26,"""""""Read the model and the couplings from the model file.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:7,Modifiability,coupling,couplings,7,"# read couplings via names",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:17,Modifiability,coupling,coupling,17,"""""""Construct the coupling matrix (and adjacancy matrix) from predefined models; or via sampling.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:19,Usability,feedback,feedback,19,"# # allow negative feedback; # if self.model == 10:; # plus_minus = (np.random.randint(0,2,n_sinknodes) - 0.5)*2; # self.Adj_signed[sinknodes,sinknodes] = plus_minus",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:25,Availability,avail,availnodes,25,"# settings.m(0,leafnodes,availnodes)",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Deployability,update,update,2,"# update leafnodes",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:9,Availability,avail,availnodes,9,"# update availnodes",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Deployability,update,update,2,"# update availnodes",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:15,Availability,avail,availnodes,15,"# settings.m(0,availnodes); # settings.m(0,leafnodes); # settings.m(0,self.Adj); # settings.m(0,'-')",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:38,Modifiability,variab,variables,38,"# this number includes parents (other variables); # and the variable itself, therefore its; # self.maxnpar+2 in the following line",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:60,Modifiability,variab,variable,60,"# this number includes parents (other variables); # and the variable itself, therefore its; # self.maxnpar+2 in the following line",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:40,Modifiability,coupling,coupling,40,"""""""Using the adjacency matrix, sample a coupling matrix.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:23,Modifiability,coupling,coupling,23,"# we already built the coupling matrix in set_coupl20()",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:28,Modifiability,coupling,coupling,28,"# set a lower bound for the coupling parameters; # they ought not to be smaller than 0.1; # and not be larger than 0.4",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:15,Modifiability,coupling,coupling,15,"# set sign for coupling",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:59,Modifiability,coupling,couplings,59,"""""""In model 1, we want enforce the following signs; on the couplings. Model 2 has the same couplings; but arbitrary signs.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:91,Modifiability,coupling,couplings,91,"""""""In model 1, we want enforce the following signs; on the couplings. Model 2 has the same couplings; but arbitrary signs.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:3,Deployability,Toggle,Toggle,3,"""""""Toggle switch.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:14,Deployability,toggle,toggle,14,"""""""Variant of toggle switch.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:14,Deployability,toggle,toggle,14,"""""""Variant of toggle switch.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Energy Efficiency,reduce,reduce,2,"# reduce the value of the coupling of the repressing genes; # otherwise completely unstable solutions are obtained",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:26,Modifiability,coupling,coupling,26,"# reduce the value of the coupling of the repressing genes; # otherwise completely unstable solutions are obtained",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:14,Deployability,toggle,toggle,14,"""""""Variant of toggle switch.""""""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:38,Deployability,update,updaterule,38,"""""""Determine parents based on boolean updaterule. Returns list of parents.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:47,Deployability,update,update,47,"# coefficients for hill functions from boolean update rules",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:26,Modifiability,coupling,coupling,26,"# check whether there are coupling matrix entries for each parent",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:308,Deployability,update,updated,308,"""""""\; Check whether time series branches. Parameters; ----------; X; current time series data.; Xsamples; list of previous branching samples.; restart; counts number of restart trials.; threshold; sets threshold for attractor identification. Returns; -------; check; true if branching realization; Xsamples; updated list; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:259,Modifiability,variab,variables,259,"# If the second largest element is smaller than threshold; # set check to False, i.e. at least two elements; # need to change in order to have a branching.; # If we observe all parameters of the system,; # a new attractor state must involve changes in two; # variables.",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:13,Modifiability,coupling,coupling,13,"""""""\; Sample coupling matrix. Checks that returned graphs contain no self-cycles. Parameters; ----------; dim; dimension of coupling matrix.; connectivity; fraction of connectivity, fully connected means 1.,; not-connected means 0, in the case of fully connected, one has; dim*(dim-1)/2 edges in the graph. Returns; -------; coupl; coupling matrix; adj; adjancancy matrix; adj_signed; signed adjacancy matrix; n_edges; Number of edges; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:124,Modifiability,coupling,coupling,124,"""""""\; Sample coupling matrix. Checks that returned graphs contain no self-cycles. Parameters; ----------; dim; dimension of coupling matrix.; connectivity; fraction of connectivity, fully connected means 1.,; not-connected means 0, in the case of fully connected, one has; dim*(dim-1)/2 edges in the graph. Returns; -------; coupl; coupling matrix; adj; adjancancy matrix; adj_signed; signed adjacancy matrix; n_edges; Number of edges; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:332,Modifiability,coupling,coupling,332,"""""""\; Sample coupling matrix. Checks that returned graphs contain no self-cycles. Parameters; ----------; dim; dimension of coupling matrix.; connectivity; fraction of connectivity, fully connected means 1.,; not-connected means 0, in the case of fully connected, one has; dim*(dim-1)/2 edges in the graph. Returns; -------; coupl; coupling matrix; adj; adjancancy matrix; adj_signed; signed adjacancy matrix; n_edges; Number of edges; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:52,Usability,learn,learning,52,"""""""; Simulates static data to investigate structure learning.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:18,Availability,avail,available,18,"# define a set of available functions",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:99,Integrability,depend,dependence,99,"""""""\; Simulate data given only an adjacancy matrix and a model. The model is a bivariate funtional dependence. The adjacancy matrix; needs to be acyclic. Parameters; ----------; Adj; adjacancy matrix of shape (dim,dim). Returns; -------; Data array of shape (n_samples,dim).; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,Modifiability,coupling,coupling,2,"# coupling function / model",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:263,Deployability,toggle,toggle,263,"# epilog = (' 1: 2dim, causal direction X_1 -> X_0, constraint signs\n'; # + ' 2: 2dim, causal direction X_1 -> X_0, arbitrary signs\n'; # + ' 3: 2dim, causal direction X_1 <-> X_0, arbitrary signs\n'; # + ' 4: 2dim, mix of model 2 and 3\n'; # + ' 5: 6dim double toggle switch\n'; # + ' 6: two independent evolutions without repression, sync.\n'; # + ' 7: two independent evolutions without repression, random init\n'; # + ' 8: two independent evolutions directed repression, random init\n'; # + ' 9: two independent evolutions mutual repression, random init\n'; # + ' 10: two indep. evol., diff. self-loops possible, mut. repr., rand init\n')",MatchSource.CODE_COMMENT,src/scanpy/tools/_sim.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:919,Availability,mask,mask,919,"""""""\; Calculate correlation matrix. Calculate a correlation matrix for genes strored in sample annotation; using :func:`~scanpy.tl.rank_genes_groups`. Parameters; ----------; adata; Annotated data matrix.; name_list; Takes a list of genes for which to calculate the correlation matrix; groupby; If no name list is passed, genes are selected from the; results of rank_gene_groups. Then this is the key of the sample grouping to consider.; Note that in this case also a group index has to be specified.; group; Group index for which the correlation matrix for top_ranked genes should be calculated.; Currently only int is supported, will change very soon; n_genes; For how many genes to calculate correlation matrix? If specified, cuts the name list; (in whatever order it is passed).; data; At the moment, this is only relevant for the case that name_list is drawn from rank_gene_groups results.; If specified, collects mask for the called group and then takes only those cells specified.; If 'Complete', calculate correlation using full data; If 'Group', calculate correlation within the selected group.; If 'Rest', calculate corrlation for everything except the group; method; Which kind of correlation coefficient to use. pearson; standard correlation coefficient; kendall; Kendall Tau correlation coefficient; spearman; Spearman rank correlation; annotation_key; Allows to define the name of the anndata entry where results are stored.; """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:34,Security,access,access,34,"# This line just makes group_mask access easier. Nothing else but 'all' will stand here.",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:51,Availability,mask,mask,51,"# TODO: Allow for sample weighting requires better mask access... later; # We store calculated data in dict, access it via dict to dict. Check if this is the best way.",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:56,Security,access,access,56,"# TODO: Allow for sample weighting requires better mask access... later; # We store calculated data in dict, access it via dict to dict. Check if this is the best way.",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:109,Security,access,access,109,"# TODO: Allow for sample weighting requires better mask access... later; # We store calculated data in dict, access it via dict to dict. Check if this is the best way.",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:63,Availability,mask,masks,63,"# Simple method that can be called by rank_gene_group. It uses masks that have been passed to the function and; # calculates how much has to be subsampled in order to reach a certain precision with a certain probability; # Then it subsamples for mask, mask rest; # Since convergence speed varies, we take the slower one, i.e. the variance. This might have future speed-up; # potential",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:246,Availability,mask,mask,246,"# Simple method that can be called by rank_gene_group. It uses masks that have been passed to the function and; # calculates how much has to be subsampled in order to reach a certain precision with a certain probability; # Then it subsamples for mask, mask rest; # Since convergence speed varies, we take the slower one, i.e. the variance. This might have future speed-up; # potential",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:252,Availability,mask,mask,252,"# Simple method that can be called by rank_gene_group. It uses masks that have been passed to the function and; # calculates how much has to be subsampled in order to reach a certain precision with a certain probability; # Then it subsamples for mask, mask rest; # Since convergence speed varies, we take the slower one, i.e. the variance. This might have future speed-up; # potential",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:2,Usability,Simpl,Simple,2,"# Simple method that can be called by rank_gene_group. It uses masks that have been passed to the function and; # calculates how much has to be subsampled in order to reach a certain precision with a certain probability; # Then it subsamples for mask, mask rest; # Since convergence speed varies, we take the slower one, i.e. the variance. This might have future speed-up; # potential",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:226,Energy Efficiency,adapt,adapted,226,"# This tool has the purpose to take a set of genes (possibly already pre-selected) and analyze AUC.; # Those and only those are eliminated who are dominated completely; # TODO: Potentially (But not till tomorrow), this can be adapted to only consider the AUC in the given; # TODO: optimization frame",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:226,Modifiability,adapt,adapted,226,"# This tool has the purpose to take a set of genes (possibly already pre-selected) and analyze AUC.; # Those and only those are eliminated who are dominated completely; # TODO: Potentially (But not till tomorrow), this can be adapted to only consider the AUC in the given; # TODO: optimization frame",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:281,Performance,optimiz,optimization,281,"# This tool has the purpose to take a set of genes (possibly already pre-selected) and analyze AUC.; # Those and only those are eliminated who are dominated completely; # TODO: Potentially (But not till tomorrow), this can be adapted to only consider the AUC in the given; # TODO: optimization frame",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:262,Security,access,accessible,262,"# This tool serves to; # It is not thought to be addressed directly but rather using rank_genes_group or ROC analysis or comparable; # TODO: Pass back a truncated adata object with only those genes that fullfill thresholding criterias; # This function should be accessible by both rank_genes_groups and ROC_curve analysis",MatchSource.CODE_COMMENT,src/scanpy/tools/_top_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:373,Deployability,install,install,373,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1331,Performance,optimiz,optimization,1331,"tter convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE ",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1618,Performance,optimiz,optimization,1618," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1871,Performance,optimiz,optimization,1871," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:452,Safety,detect,detected,452,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:279,Usability,learn,learn,279,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:725,Usability,learn,learning,725,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1383,Usability,learn,learning,1383,"tter convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE ",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1492,Usability,learn,learning,1492," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1669,Usability,learn,learning,1669," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1774,Usability,learn,learning,1774," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:2,Deployability,update,update,2,"# update AnnData instance",MatchSource.CODE_COMMENT,src/scanpy/tools/_tsne.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:248,Performance,optimiz,optimizes,248,"""""""\; Embed the neighborhood graph using UMAP :cite:p:`McInnes2018`. UMAP (Uniform Manifold Approximation and Projection) is a manifold learning; technique suitable for visualizing high-dimensional data. Besides tending to; be faster than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:411,Performance,optimiz,optimizes,411,"""""""\; Embed the neighborhood graph using UMAP :cite:p:`McInnes2018`. UMAP (Uniform Manifold Approximation and Projection) is a manifold learning; technique suitable for visualizing high-dimensional data. Besides tending to; be faster than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1514,Performance,optimiz,optimization,1514,"t these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If ",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1621,Performance,optimiz,optimization,1621," of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific ",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1711,Performance,optimiz,optimization,1711,"E, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automati",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1927,Performance,optimiz,optimizing,1927,"ues; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a c",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:136,Usability,learn,learning,136,"""""""\; Embed the neighborhood graph using UMAP :cite:p:`McInnes2018`. UMAP (Uniform Manifold Approximation and Projection) is a manifold learning; technique suitable for visualizing high-dimensional data. Besides tending to; be faster than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:716,Usability,learn,learn,716,"""""""\; Embed the neighborhood graph using UMAP :cite:p:`McInnes2018`. UMAP (Uniform Manifold Approximation and Projection) is a manifold learning; technique suitable for visualizing high-dimensional data. Besides tending to; be faster than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1237,Usability,learn,learn,1237," than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign ",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1589,Usability,learn,learning,1589," of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific ",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1865,Usability,simpl,simplex,1865,"ues; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a c",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1909,Usability,simpl,simplex,1909,"ues; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a c",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:2974,Usability,simpl,simplical,2974," embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a copy instead of writing to adata.; method; Chosen implementation. ``'umap'``; Umap’s simplical set embedding.; ``'rapids'``; GPU accelerated implementation. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.tl.umap` instead.; neighbors_key; If not specified, umap looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'] for connectivities; (default storage places for pp.neighbors).; If specified, umap looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_umap']` : :class:`numpy.ndarray` (dtype `float`); UMAP coordinates of data.; `adata.uns['umap']` : :class:`dict`; UMAP parameters. """"""",MatchSource.CODE_COMMENT,src/scanpy/tools/_umap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/_doctests.py:30,Integrability,depend,dependency,30,"""""""Mark function with doctest dependency.""""""",MatchSource.CODE_COMMENT,src/scanpy/_utils/_doctests.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/_doctests.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:22,Usability,learn,learn,22,"# e.g. https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html; # maybe in the future random.Generator",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:119,Safety,predict,prediction,119,"""""""Compute overlaps between groups. See ``identify_groups`` for identifying the groups. Parameters; ----------; adata; prediction; Field name of adata.obs.; reference; Field name of adata.obs.; normalization; Whether to normalize with respect to the predicted groups or the; reference groups.; threshold; Do not consider associations whose overlap is below this fraction.; max_n_names; Control how many reference names you want to be associated with per; predicted name. Set to `None`, if you want all. Returns; -------; asso_names; List of associated reference names; (`max_n_names` for each predicted name).; asso_matrix; Matrix where rows correspond to the predicted labels and columns to the; reference labels, entries are proportional to degree of association.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:250,Safety,predict,predicted,250,"""""""Compute overlaps between groups. See ``identify_groups`` for identifying the groups. Parameters; ----------; adata; prediction; Field name of adata.obs.; reference; Field name of adata.obs.; normalization; Whether to normalize with respect to the predicted groups or the; reference groups.; threshold; Do not consider associations whose overlap is below this fraction.; max_n_names; Control how many reference names you want to be associated with per; predicted name. Set to `None`, if you want all. Returns; -------; asso_names; List of associated reference names; (`max_n_names` for each predicted name).; asso_matrix; Matrix where rows correspond to the predicted labels and columns to the; reference labels, entries are proportional to degree of association.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:455,Safety,predict,predicted,455,"""""""Compute overlaps between groups. See ``identify_groups`` for identifying the groups. Parameters; ----------; adata; prediction; Field name of adata.obs.; reference; Field name of adata.obs.; normalization; Whether to normalize with respect to the predicted groups or the; reference groups.; threshold; Do not consider associations whose overlap is below this fraction.; max_n_names; Control how many reference names you want to be associated with per; predicted name. Set to `None`, if you want all. Returns; -------; asso_names; List of associated reference names; (`max_n_names` for each predicted name).; asso_matrix; Matrix where rows correspond to the predicted labels and columns to the; reference labels, entries are proportional to degree of association.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:593,Safety,predict,predicted,593,"""""""Compute overlaps between groups. See ``identify_groups`` for identifying the groups. Parameters; ----------; adata; prediction; Field name of adata.obs.; reference; Field name of adata.obs.; normalization; Whether to normalize with respect to the predicted groups or the; reference groups.; threshold; Do not consider associations whose overlap is below this fraction.; max_n_names; Control how many reference names you want to be associated with per; predicted name. Set to `None`, if you want all. Returns; -------; asso_names; List of associated reference names; (`max_n_names` for each predicted name).; asso_matrix; Matrix where rows correspond to the predicted labels and columns to the; reference labels, entries are proportional to degree of association.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:660,Safety,predict,predicted,660,"""""""Compute overlaps between groups. See ``identify_groups`` for identifying the groups. Parameters; ----------; adata; prediction; Field name of adata.obs.; reference; Field name of adata.obs.; normalization; Whether to normalize with respect to the predicted groups or the; reference groups.; threshold; Do not consider associations whose overlap is below this fraction.; max_n_names; Control how many reference names you want to be associated with per; predicted name. Set to `None`, if you want all. Returns; -------; asso_names; List of associated reference names; (`max_n_names` for each predicted name).; asso_matrix; Matrix where rows correspond to the predicted labels and columns to the; reference labels, entries are proportional to degree of association.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:32,Safety,predict,predicted,32,"# compute which fraction of the predicted group is contained in; # the ref group",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:71,Safety,predict,predicted,71,"# compute which fraction of the reference group is contained in; # the predicted group",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:9,Safety,predict,predicted,9,"""""""Which predicted label explains which reference label?. A predicted label explains the reference label which maximizes the minimum; of ``relative_overlaps_pred`` and ``relative_overlaps_ref``. Compare this with ``compute_association_matrix_of_groups``. Returns; -------; A dictionary of length ``len(np.unique(ref_labels))`` that stores for each; reference label the predicted label that best explains it. If ``return_overlaps`` is ``True``, this will in addition return the overlap; of the reference group with the predicted group; normalized with respect to; the reference group size and the predicted group size, respectively.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:60,Safety,predict,predicted,60,"""""""Which predicted label explains which reference label?. A predicted label explains the reference label which maximizes the minimum; of ``relative_overlaps_pred`` and ``relative_overlaps_ref``. Compare this with ``compute_association_matrix_of_groups``. Returns; -------; A dictionary of length ``len(np.unique(ref_labels))`` that stores for each; reference label the predicted label that best explains it. If ``return_overlaps`` is ``True``, this will in addition return the overlap; of the reference group with the predicted group; normalized with respect to; the reference group size and the predicted group size, respectively.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:369,Safety,predict,predicted,369,"""""""Which predicted label explains which reference label?. A predicted label explains the reference label which maximizes the minimum; of ``relative_overlaps_pred`` and ``relative_overlaps_ref``. Compare this with ``compute_association_matrix_of_groups``. Returns; -------; A dictionary of length ``len(np.unique(ref_labels))`` that stores for each; reference label the predicted label that best explains it. If ``return_overlaps`` is ``True``, this will in addition return the overlap; of the reference group with the predicted group; normalized with respect to; the reference group size and the predicted group size, respectively.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:518,Safety,predict,predicted,518,"""""""Which predicted label explains which reference label?. A predicted label explains the reference label which maximizes the minimum; of ``relative_overlaps_pred`` and ``relative_overlaps_ref``. Compare this with ``compute_association_matrix_of_groups``. Returns; -------; A dictionary of length ``len(np.unique(ref_labels))`` that stores for each; reference label the predicted label that best explains it. If ``return_overlaps`` is ``True``, this will in addition return the overlap; of the reference group with the predicted group; normalized with respect to; the reference group size and the predicted group size, respectively.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:596,Safety,predict,predicted,596,"""""""Which predicted label explains which reference label?. A predicted label explains the reference label which maximizes the minimum; of ``relative_overlaps_pred`` and ``relative_overlaps_ref``. Compare this with ``compute_association_matrix_of_groups``. Returns; -------; A dictionary of length ``len(np.unique(ref_labels))`` that stores for each; reference label the predicted label that best explains it. If ``return_overlaps`` is ``True``, this will in addition return the overlap; of the reference group with the predicted group; normalized with respect to; the reference group size and the predicted group size, respectively.; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:6,Deployability,Update,Update,6,"""""""\; Update old_params with new_params. If check==False, this merely adds and overwrites the content of old_params. If check==True, this only allows updating of parameters that are already; present in old_params. Parameters; ----------; old_params; new_params; check. Returns; -------; updated_params; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:2,Availability,mask,masked,2,"# masked operations on sparse produce which numpy matrices gives the same API issues handled here",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:27,Usability,simpl,simply,27,"# this sequence is defined simply by skipping rows; # is faster than sampling",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:38,Availability,down,download,38,"""""""Check if file is present otherwise download.""""""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:63,Security,access,access,63,"""""""Imports a module in a way that it’s only executed on member access""""""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:25,Security,access,accessing,25,"""""""Convenience class for accessing neighbors graph representations. Allows to access neighbors distances, connectivities and settings; dictionary in a uniform manner. Parameters; ----------. adata; AnnData object.; key; This defines where to look for neighbors dictionary,; connectivities, distances. neigh = NeighborsView(adata, key); neigh['distances']; neigh['connectivities']; neigh['params']; 'connectivities' in neigh; 'params' in neigh. is the same as. adata.obsp[adata.uns[key]['distances_key']]; adata.obsp[adata.uns[key]['connectivities_key']]; adata.uns[key]['params']; adata.uns[key]['connectivities_key'] in adata.obsp; 'params' in adata.uns[key]; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:78,Security,access,access,78,"""""""Convenience class for accessing neighbors graph representations. Allows to access neighbors distances, connectivities and settings; dictionary in a uniform manner. Parameters; ----------. adata; AnnData object.; key; This defines where to look for neighbors dictionary,; connectivities, distances. neigh = NeighborsView(adata, key); neigh['distances']; neigh['connectivities']; neigh['params']; 'connectivities' in neigh; 'params' in neigh. is the same as. adata.obsp[adata.uns[key]['distances_key']]; adata.obsp[adata.uns[key]['connectivities_key']]; adata.uns[key]['params']; adata.uns[key]['connectivities_key'] in adata.obsp; 'params' in adata.uns[key]; """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/compute/is_constant.py:98,Energy Efficiency,reduce,reduce,98,"""""""; Check whether values in array are constant. Params; ------; a; Array to check; axis; Axis to reduce over. Returns; -------; Boolean array, True values were constant. Example; -------. >>> a = np.array([[0, 1], [0, 0]]); >>> a; array([[0, 1],; [0, 0]]); >>> is_constant(a); False; >>> is_constant(a, axis=0); array([ True, False]); >>> is_constant(a, axis=1); array([False, True]); """"""",MatchSource.CODE_COMMENT,src/scanpy/_utils/compute/is_constant.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/compute/is_constant.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:56,Testability,test,test,56,"""""""; This file contains helper functions for the scanpy test suite.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_helpers/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:60,Availability,error,error,60,"# TODO: Report more context on the fields being compared on error; # TODO: Allow specifying paths to ignore on comparison; ###########################; # Representation choice; ###########################; # These functions can be used to check that functions are correctly using arugments like `layers`, `obsm`, etc.",MatchSource.CODE_COMMENT,src/testing/scanpy/_helpers/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:296,Modifiability,layers,layers,296,"# TODO: Report more context on the fields being compared on error; # TODO: Allow specifying paths to ignore on comparison; ###########################; # Representation choice; ###########################; # These functions can be used to check that functions are correctly using arugments like `layers`, `obsm`, etc.",MatchSource.CODE_COMMENT,src/testing/scanpy/_helpers/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:52,Testability,test,test,52,"""""""Constructor for anndata that uses dtype of X for test compatibility with older versions of AnnData. Once the minimum version of AnnData is 0.9, this function can be replaced with the default constructor.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_helpers/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py:96,Testability,test,tests,96,"""""""; Pytest skip marker evaluated at module import. This allows us to see the amount of skipped tests at the start of a test run.; :func:`pytest.importorskip` skips tests after they started running.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/marks.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py:120,Testability,test,test,120,"""""""; Pytest skip marker evaluated at module import. This allows us to see the amount of skipped tests at the start of a test run.; :func:`pytest.importorskip` skips tests after they started running.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/marks.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py:165,Testability,test,tests,165,"""""""; Pytest skip marker evaluated at module import. This allows us to see the amount of skipped tests at the start of a test run.; :func:`pytest.importorskip` skips tests after they started running.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/marks.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/params.py:27,Modifiability,flexible,flexible,27,"""""""Like fixtures, but more flexible""""""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/params.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/params.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:20,Modifiability,plugin,plugin,20,"""""""A private pytest plugin""""""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:119,Testability,test,tests,119,"""""""Limit number of threads used per worker when using pytest-xdist. Prevents oversubscription of the CPU when multiple tests with parallel code are; running at once.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:6,Testability,test,tests,6,"# All tests marked with `pytest.mark.internet` get skipped unless; # `--run-internet` passed",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:15,Testability,test,tests,15,"# Dask AnnData tests require anndata > 0.10",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py:54,Testability,test,tests,54,"""""""This file contains some common fixtures for use in tests. This is kept seperate from the helpers file because it relies on pytest.; """"""",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/fixtures/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py:7,Availability,error,errors,7,"# make errors visible and the rest ignored",MatchSource.CODE_COMMENT,src/testing/scanpy/_pytest/fixtures/__init__.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:56,Testability,test,tests,56,"# define this after importing scanpy but before running tests",MatchSource.CODE_COMMENT,tests/conftest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:28,Testability,log,loggers,28,"""""""Remove handlers from all loggers on session teardown. Fixes <https://github.com/scverse/scanpy/issues/1736>.; See also <https://github.com/pytest-dev/pytest/issues/5502>.; """"""",MatchSource.CODE_COMMENT,tests/conftest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:2,Testability,log,loggerDict,2,"# loggerDict can contain `logging.Placeholder`s",MatchSource.CODE_COMMENT,tests/conftest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:26,Testability,log,logging,26,"# loggerDict can contain `logging.Placeholder`s",MatchSource.CODE_COMMENT,tests/conftest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:25,Testability,log,logger,25,"""""""Allow use of scanpy’s logger with caplog""""""",MatchSource.CODE_COMMENT,tests/conftest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:112,Availability,Toler,Tolerance,112,"""""""\; Image files did not match.; RMS Value: {rms}; Expected: {expected}; Actual: {actual}; Difference: {diff}; Tolerance: {tol}; """"""",MatchSource.CODE_COMMENT,tests/conftest.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_clustering.py:75,Availability,error,error,75,"""""""Ensure that popping this as a `clustering_kwargs` and using it does not error out.""""""",MatchSource.CODE_COMMENT,tests/test_clustering.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_clustering.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:66,Performance,load,load,66,"# this test trivially checks whether mean normalisation worked; # load in data",MatchSource.CODE_COMMENT,tests/test_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:7,Testability,test,test,7,"# this test trivially checks whether mean normalisation worked; # load in data",MatchSource.CODE_COMMENT,tests/test_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:2,Testability,Test,Test,2,"# Test for fix to #1170",MatchSource.CODE_COMMENT,tests/test_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:151,Performance,load,load,151,"# this test checks wether combat can align data from several gaussians; # it checks this by computing the silhouette coefficient in a pca embedding; # load in data",MatchSource.CODE_COMMENT,tests/test_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:7,Testability,test,test,7,"# this test checks wether combat can align data from several gaussians; # it checks this by computing the silhouette coefficient in a pca embedding; # load in data",MatchSource.CODE_COMMENT,tests/test_combat.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:45,Performance,load,load,45,"""""""; Tests to make sure the example datasets load.; """"""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:5,Testability,Test,Tests,5,"""""""; Tests to make sure the example datasets load.; """"""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:23,Availability,down,downloading,23,"""""""Tests that reading/ downloading works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:3,Testability,Test,Tests,3,"""""""Tests that reading/ downloading works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:3,Testability,Test,Test,3,"""""""Test that changing the dataset dir doesn't break reading.""""""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:19,Availability,down,download,19,"""""""Test that image download works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:3,Testability,Test,Test,3,"""""""Test that image download works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:12,Availability,down,downloading,12,"# Test that downloading tissue image works",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:2,Testability,Test,Test,2,"# Test that downloading tissue image works",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:2,Testability,Test,Test,2,"# Test that tissue image exists and is a valid image file",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:2,Testability,Test,Test,2,"# Test that tissue image is a tif image file (using `file`)",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:12,Testability,test,tested,12,"# These are tested via doctest",MatchSource.CODE_COMMENT,tests/test_datasets.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:2,Testability,Test,Test,2,"# Test that density values are scaled; # Test that the highest value is in the middle for a grid layout",MatchSource.CODE_COMMENT,tests/test_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:41,Testability,Test,Test,41,"# Test that density values are scaled; # Test that the highest value is in the middle for a grid layout",MatchSource.CODE_COMMENT,tests/test_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:51,Availability,error,error,51,"# Test that sc.pl.embedding_density() runs without error",MatchSource.CODE_COMMENT,tests/test_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:2,Testability,Test,Test,2,"# Test that sc.pl.embedding_density() runs without error",MatchSource.CODE_COMMENT,tests/test_embedding_density.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:59,Modifiability,parameteriz,parameterized,59,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,tests/test_embedding_plots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:43,Security,access,access,43,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,tests/test_embedding_plots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:73,Testability,test,tests,73,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,tests/test_embedding_plots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:93,Testability,test,test,93,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,tests/test_embedding_plots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:2,Deployability,continuous,continuous,2,"# continuous",MatchSource.CODE_COMMENT,tests/test_embedding_plots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:5,Testability,Test,Tests,5,"""""""; Tests that manually passing values to sc.pl.spatial is similar to automatic extraction.; """"""",MatchSource.CODE_COMMENT,tests/test_embedding_plots.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_filter_rank_genes_groups.py:2,Testability,test,test,2,"# test compare_abs",MatchSource.CODE_COMMENT,tests/test_filter_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_filter_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:39,Modifiability,layers,layers,39,"""""""; adata.X is np.ones((2, 2)); adata.layers['double'] is sparse np.ones((2,2)) * 2 to also test sparse matrices; """"""",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:93,Testability,test,test,93,"""""""; adata.X is np.ones((2, 2)); adata.layers['double'] is sparse np.ones((2,2)) * 2 to also test sparse matrices; """"""",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:43,Testability,test,tests,43,"########################; # obs_df, var_df tests #; ########################",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test only obs",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test only var",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test handling of duplicated keys (in this case repeated gene names)",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test non unique index",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:15,Testability,test,test,15,"# get location test h5ad file in datasets",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:28,Testability,test,test,28,"""""""uses a larger dataset to test column order and content""""""",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test that columns content is correct for obs_df",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test that columns content is correct for var_df",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test only cells",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test only var columns",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,Testability,test,test,2,"# test handling of duplicated keys (in this case repeated cell names)",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:60,Availability,error,error,60,"# https://github.com/scverse/scanpy/issues/1634; # Test for error where just passing obsm_keys, but not keys, would cause error.",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:122,Availability,error,error,122,"# https://github.com/scverse/scanpy/issues/1634; # Test for error where just passing obsm_keys, but not keys, would cause error.",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:51,Testability,Test,Test,51,"# https://github.com/scverse/scanpy/issues/1634; # Test for error where just passing obsm_keys, but not keys, would cause error.",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:43,Availability,error,errors,43,"##################################; # Test errors for obs_df, var_df #; ##################################",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:38,Testability,Test,Test,38,"##################################; # Test errors for obs_df, var_df #; ##################################",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:14,Availability,error,error,14,"# This should error",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:17,Availability,error,error,17,"# This shouldn't error",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:55,Testability,test,tests,55,"##############################; # rank_genes_groups_df tests #; ##############################",MatchSource.CODE_COMMENT,tests/test_get.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:3,Testability,Test,Tests,3,"""""""Tests that, with `n_top_genes=None` the returned dataframe has the expected columns.""""""",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:31,Availability,error,error,31,"# cell_ranger flavor can raise error if many 0 genes",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:2,Integrability,depend,depending,2,"# depending on check_values, warnings should be raised for non-integer data",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:2,Availability,error,errors,2,"# errors should be raised for invalid theta values",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:23,Testability,test,tested,23,"# compute output to be tested",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:23,Availability,toler,tolerance,23,"# (still) Not equal to tolerance rtol=2e-05, atol=2e-05; # np.testing.assert_allclose(4, 3.9999, rtol=2e-05, atol=2e-05)",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:62,Testability,test,testing,62,"# (still) Not equal to tolerance rtol=2e-05, atol=2e-05; # np.testing.assert_allclose(4, 3.9999, rtol=2e-05, atol=2e-05)",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:4,Testability,test,test,4,"### test without batch",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:4,Testability,test,test,4,"### test with batch; # introduce a dummy ""technical covariate""; this is used in Seurat's SelectIntegrationFeatures",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:3,Testability,Test,Tests,3,"""""""Tests that, with `n_top_genes=n`; - `inplace` and `subset` interact correctly; - for both the `seurat` and `cell_ranger` flavors; - for dask arrays and non-dask arrays; """"""",MatchSource.CODE_COMMENT,tests/test_highly_variable_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:12,Testability,log,logfile,12,"# setting a logfile removes all handlers",MatchSource.CODE_COMMENT,tests/test_logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:12,Testability,log,logfile,12,"# setting a logfile removes all handlers",MatchSource.CODE_COMMENT,tests/test_logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:58,Availability,error,error,58,"""""""; Tests that these functions print to stdout and don't error. Checks that https://github.com/scverse/scanpy/issues/1437 is fixed.; """"""",MatchSource.CODE_COMMENT,tests/test_logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:5,Testability,Test,Tests,5,"""""""; Tests that these functions print to stdout and don't error. Checks that https://github.com/scverse/scanpy/issues/1437 is fixed.; """"""",MatchSource.CODE_COMMENT,tests/test_logging.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_marker_gene_overlap.py:2,Testability,Test,Test,2,"# Test all overlap calculations on artificial data",MatchSource.CODE_COMMENT,tests/test_marker_gene_overlap.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_marker_gene_overlap.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py:2,Testability,Test,Test,2,"# Test that series and vectors return same value",MatchSource.CODE_COMMENT,tests/test_metrics.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py:2,Testability,Test,Test,2,"# Test that results are similar for sparse and dense reps of same data",MatchSource.CODE_COMMENT,tests/test_metrics.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py:2,Testability,Test,Test,2,"# Test case with perfectly seperated groups",MatchSource.CODE_COMMENT,tests/test_metrics.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_neighbors_key_added.py:2,Testability,test,test,2,"# test functions with neighbors_key and obsp",MatchSource.CODE_COMMENT,tests/test_neighbors_key_added.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_neighbors_key_added.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:2,Testability,Test,Test,2,"# Test that layer kwarg works",MatchSource.CODE_COMMENT,tests/test_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:2,Integrability,depend,depending,2,"# depending on check_values, warnings should be raised for non-integer data",MatchSource.CODE_COMMENT,tests/test_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:20,Testability,test,test,20,"# compute output to test",MatchSource.CODE_COMMENT,tests/test_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:2,Testability,test,test,2,"# test against inplace",MatchSource.CODE_COMMENT,tests/test_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:12,Modifiability,variab,variables,12,"# number of variables in output if inplace=False",MatchSource.CODE_COMMENT,tests/test_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:31,Availability,mask,masked,31,"# check PC shape (non-hvgs are masked with 0s, so original number of genes)",MatchSource.CODE_COMMENT,tests/test_normalization.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_package_structure.py:2,Testability,Test,Test,2,"# Test if functions with `copy` follow conventions",MatchSource.CODE_COMMENT,tests/test_package_structure.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_package_structure.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_paga.py:2,Testability,Test,Tests,2,"# Tests that https://github.com/scverse/scanpy/issues/1887 is fixed",MatchSource.CODE_COMMENT,tests/test_paga.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_paga.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:43,Testability,test,test,43,"# TODO: Fix this case, maybe by increasing test data size.; # https://github.com/scverse/scanpy/issues/2744",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:15,Testability,test,test,15,"# This warning test is out of the fixture because it is a special case in the logic of the function",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:78,Testability,log,logic,78,"# This warning test is out of the fixture because it is a special case in the logic of the function",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Testability,Test,Tests,5,"""""""; Tests that n_comps behaves correctly; See https://github.com/scverse/scanpy/issues/1051; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Testability,Test,Tests,5,"""""""; Tests that implicitly centered pca on sparse arrays returns equivalent results to; explicit centering on dense arrays.; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:68,Availability,reliab,reliably,68,"# Test that changing random seed changes result; # Does not show up reliably with 32 bit computation",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:2,Testability,Test,Test,2,"# Test that changing random seed changes result; # Does not show up reliably with 32 bit computation",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:88,Testability,test,test,88,"""""""; See https://github.com/scverse/scanpy/issues/1590; But this is also a more general test; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:26,Testability,test,test,26,"# Subsetting for speed of test",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Testability,Test,Tests,5,"""""""; Tests that the n_pcs parameter also works for; representations not called ""X_pca""; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:41,Availability,error,error,41,"# We use all ARRAY_TYPES here since this error should be raised before; # PCA can realize that it got a Dask array",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:47,Availability,error,error,47,"""""""Check if use_highly_variable=True throws an error if the annotation is missing.""""""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:9,Availability,error,error,9,"""""""Check error for n_obs / mask length mismatch.""""""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:27,Availability,mask,mask,27,"""""""Check error for n_obs / mask length mismatch.""""""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:42,Availability,mask,mask,42,"""""""Test if pca result is equal when given mask as boolarray vs string""""""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:3,Testability,Test,Test,3,"""""""Test if pca result is equal when given mask as boolarray vs string""""""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:70,Availability,mask,mask,70,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:120,Availability,mask,mask,120,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:48,Modifiability,variab,variable,48,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:108,Modifiability,variab,variable,108,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Testability,Test,Test,5,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:16,Modifiability,layers,layers,16,"""""""; Tests that layers works the same way as .X; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Testability,Test,Tests,5,"""""""; Tests that layers works the same way as .X; """"""",MatchSource.CODE_COMMENT,tests/test_pca.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:93,Deployability,update,updated,93,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,Test,Test,2,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:52,Testability,test,test-name,52,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:70,Testability,test,test,70,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:102,Usability,simpl,simply,102,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test swap axes",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test heatmap numeric column():; # set as numeric column the vales for the first gene on the matrix",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test var/obs standardization and layer",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test standard_scale_obs",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test var_names as dict",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test that plot elements are well aligned; # small",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test dotplot dot_min, dot_max, color_map, and var_groups",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test layer, var standardization, smallest_dot,; # color title, size_title return_fig and dot_edge",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:7,Testability,test,testing,7,"# only testing stacked_violin, matrixplot and dotplot",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test use of layer",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:19,Testability,test,test,19,"# TODO: Generalize test to more plotting types",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:10,Availability,down,down,10,"# Cutting down on size for plotting, tracksplot and stacked_violin are slow",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Integrability,Wrap,Wrapped,2,"# Wrapped in another fixture to avoid mutation",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:32,Safety,avoid,avoid,32,"# Wrapped in another fixture to avoid mutation",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test that the 'groups' parameter sorts; # cells, such that the cells belonging to the groups are; # plotted on top. This new ordering requires that the size; # vector is also ordered (if given).",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Testability,Test,Test,3,"""""""Test scatterplot of per-obs points with no basis""""""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Testability,Test,Test,3,"""""""Test scatterplot of per-var points with no basis""""""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Testability,Test,Test,3,"""""""Test scatterplots of raw layer with no basis.""""""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test that plotting fails with a ValueError if trying to plot; # var_names only found in raw and use_raw is False",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test that plotting fails if one axis is a per-var value and the; # other is a per-obs value",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:94,Modifiability,variab,variable,94,"""""""Test that `scatter()` raises `ValueError` where appropriate. If `sc.pl.scatter()` receives variable labels that either cannot be; found or are incompatible with one another, the function should; raise a `ValueError`. This test checks that this happens as; expected.; """"""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Testability,Test,Test,3,"""""""Test that `scatter()` raises `ValueError` where appropriate. If `sc.pl.scatter()` receives variable labels that either cannot be; found or are incompatible with one another, the function should; raise a `ValueError`. This test checks that this happens as; expected.; """"""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:225,Testability,test,test,225,"""""""Test that `scatter()` raises `ValueError` where appropriate. If `sc.pl.scatter()` receives variable labels that either cannot be; found or are incompatible with one another, the function should; raise a `ValueError`. This test checks that this happens as; expected.; """"""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:29,Safety,predict,predict,29,"""""""; Test to make sure I can predict when scatter reps should be the same; """"""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:5,Testability,Test,Test,5,"""""""; Test to make sure I can predict when scatter reps should be the same; """"""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:51,Testability,Test,Tests,51,"# https://github.com/scverse/scanpy/issues/1000; # Tests that plotting functions don't make a copy from a view unless they; # actually have to",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:262,Availability,error,error,262,"# the pbmc68k was generated using rank_genes_groups with method='logreg'; # which does not generate 'logfoldchanges', although this field is; # required by `sc.get.rank_genes_groups_df`.; # After updating rank_genes_groups plots to use the latter function; # an error appears. Re-running rank_genes_groups with default method; # solves the problem.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:65,Testability,log,logreg,65,"# the pbmc68k was generated using rank_genes_groups with method='logreg'; # which does not generate 'logfoldchanges', although this field is; # required by `sc.get.rank_genes_groups_df`.; # After updating rank_genes_groups plots to use the latter function; # an error appears. Re-running rank_genes_groups with default method; # solves the problem.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:101,Testability,log,logfoldchanges,101,"# the pbmc68k was generated using rank_genes_groups with method='logreg'; # which does not generate 'logfoldchanges', although this field is; # required by `sc.get.rank_genes_groups_df`.; # After updating rank_genes_groups plots to use the latter function; # an error appears. Re-running rank_genes_groups with default method; # solves the problem.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:39,Safety,avoid,avoid,39,"# Only plotting one group at a time to avoid generating dendrogram; # TODO: Generating a dendrogram modifies the object, this should be; # optional and also maybe not modify the object.",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Testability,test,test,2,"# test category order when groupby is a list (#1735)",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:49,Availability,mask,masked,49,"""""""Check that all desired cells are coloured and masked cells gray""""""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:23,Availability,mask,mask,23,"""""""Check that the same mask given as string or bool array provides the same result""""""",MatchSource.CODE_COMMENT,tests/test_plotting.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Testability,Test,Test,2,"# Test base",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Testability,Test,Test,2,"# Test that we're equivalent for 64 bit",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Testability,Test,Test,2,"# Test whether ours is more accurate for 32 bit",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:27,Availability,error,error,27,"# This should not throw an error",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:5,Testability,Test,Test,5,"""""""; Test that it doesn't matter where the array being scaled is in the anndata object.; """"""",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:5,Testability,Test,Test,5,"""""""; Test that running sc.pp.scale on an anndata object and an array returns the same results.; """"""",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:27,Availability,error,error,27,"# These shouldn't throw an error",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Testability,Test,Tests,2,"# Tests that constant values don't change results; # (since support for constant values is implemented by us)",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:17,Availability,failure,failure,17,"# Just tests for failure for now",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:7,Testability,test,tests,7,"# Just tests for failure for now",MatchSource.CODE_COMMENT,tests/test_preprocessing.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:5,Testability,test,test,5,"# We test results for a simple generic example; # Tests are conducted for sparse and non-sparse AnnData objects.; # Due to minor changes in multiplication implementation for sparse and non-sparse objects,; # results differ (very) slightly",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:50,Testability,Test,Tests,50,"# We test results for a simple generic example; # Tests are conducted for sparse and non-sparse AnnData objects.; # Due to minor changes in multiplication implementation for sparse and non-sparse objects,; # results differ (very) slightly",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:24,Usability,simpl,simple,24,"# We test results for a simple generic example; # Tests are conducted for sparse and non-sparse AnnData objects.; # Due to minor changes in multiplication implementation for sparse and non-sparse objects,; # results differ (very) slightly",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:9,Testability,test,test,9,"# create test object",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:2,Energy Efficiency,adapt,adapt,2,"# adapt marker_genes for cluster (so as to have some form of reasonable input",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:2,Modifiability,adapt,adapt,2,"# adapt marker_genes for cluster (so as to have some form of reasonable input",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:4,Testability,test,test,4,"# t-test",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:33,Performance,load,load,33,"""""""tests the sequence log1p→save→load→rank_genes_groups""""""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:3,Testability,test,tests,3,"""""""tests the sequence log1p→save→load→rank_genes_groups""""""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:70,Availability,mask,mask,70,"""""""\; Check that no. genes in output is; 1. =n_genes when n_genes<sum(mask); 2. =sum(mask) when n_genes>sum(mask); """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:85,Availability,mask,mask,85,"""""""\; Check that no. genes in output is; 1. =n_genes when n_genes<sum(mask); 2. =sum(mask) when n_genes>sum(mask); """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:108,Availability,mask,mask,108,"""""""\; Check that no. genes in output is; 1. =n_genes when n_genes<sum(mask); 2. =sum(mask) when n_genes>sum(mask); """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:17,Availability,mask,mask,17,"""""""\; Check that mask is applied successfully to data set \; where test statistics are already available (test stats overwritten).; """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:95,Availability,avail,available,95,"""""""\; Check that mask is applied successfully to data set \; where test statistics are already available (test stats overwritten).; """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:67,Testability,test,test,67,"""""""\; Check that mask is applied successfully to data set \; where test statistics are already available (test stats overwritten).; """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:106,Testability,test,test,106,"""""""\; Check that mask is applied successfully to data set \; where test statistics are already available (test stats overwritten).; """"""",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups_logreg.py:18,Testability,log,logreg,18,"# for method in ['logreg', 't-test']:",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups_logreg.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups_logreg.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups_logreg.py:30,Testability,test,test,30,"# for method in ['logreg', 't-test']:",MatchSource.CODE_COMMENT,tests/test_rank_genes_groups_logreg.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups_logreg.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:2,Testability,Test,Test,2,"# Test that it can be written:",MatchSource.CODE_COMMENT,tests/test_read_10x.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:6,Testability,test,test,6,"# the test data are such that X is the same shape for both ""genomes"",; # but the values are different",MatchSource.CODE_COMMENT,tests/test_read_10x.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:3,Testability,Test,Test,3,"""""""Test checking that read_visium reads the right genome""""""",MatchSource.CODE_COMMENT,tests/test_read_10x.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:2,Testability,Test,Tests,2,"# Tests that gex option doesn't, say, make the function return None",MatchSource.CODE_COMMENT,tests/test_read_10x.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:2,Testability,Test,Tests,2,"# Tests the 10x probe barcode matrix is read correctly",MatchSource.CODE_COMMENT,tests/test_read_10x.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test ""data"" for 3 cells * 4 genes",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test AnnData arguments; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:28,Testability,test,test,28,"# test AnnData arguments; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test scaling with explicit zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test scaling with explicit zero_center == False",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test bare count arguments, for simplicity only with explicit copy=True; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:76,Testability,test,test,76,"# test bare count arguments, for simplicity only with explicit copy=True; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:33,Usability,simpl,simplicity,33,"# test bare count arguments, for simplicity only with explicit copy=True; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test scaling with explicit zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test scaling with explicit zero_center == False",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,Testability,test,test,2,"# test scaling with explicit zero_center == True",MatchSource.CODE_COMMENT,tests/test_scaling.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:5,Testability,test,testing,5,"# np.testing.assert_allclose(reference, adata.obs[""Test""].to_numpy())",MatchSource.CODE_COMMENT,tests/test_score_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:51,Testability,Test,Test,51,"# np.testing.assert_allclose(reference, adata.obs[""Test""].to_numpy())",MatchSource.CODE_COMMENT,tests/test_score_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:16,Testability,test,test,16,"# TODO: write a test that costs less resources and is more meaningful",MatchSource.CODE_COMMENT,tests/test_score_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:180,Deployability,patch,patched,180,"""""""; another check that _sparsemean behaves like np.nanmean!. monkeypatch the _score_genes._sparse_nanmean function to np.nanmean; and check that the result is the same as the non-patched (i.e. sparse_nanmean); function; """"""",MatchSource.CODE_COMMENT,tests/test_score_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:6,Deployability,patch,patch,6,"# now patch _sparse_nanmean by np.nanmean inside sc.tools",MatchSource.CODE_COMMENT,tests/test_score_genes.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:32,Safety,detect,detects,32,"""""""Check that scrublet runs and detects some doublets.""""""",MatchSource.CODE_COMMENT,tests/test_scrublet.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:3,Testability,Test,Test,3,"""""""Test that Scrublet run works with batched data.""""""",MatchSource.CODE_COMMENT,tests/test_scrublet.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:5,Testability,Test,Test,5,"""""""; Test that Scrublet processing is arranged correctly. Check that simulations run on raw data.; """"""",MatchSource.CODE_COMMENT,tests/test_scrublet.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:2,Energy Efficiency,Reduce,Reduce,2,"# Reduce size of input for faster test",MatchSource.CODE_COMMENT,tests/test_scrublet.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:34,Testability,test,test,34,"# Reduce size of input for faster test",MatchSource.CODE_COMMENT,tests/test_scrublet.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:5,Testability,Test,Test,5,"""""""; Test that Scrublet args are passed. Check that changes to parameters change scrublet results.; """"""",MatchSource.CODE_COMMENT,tests/test_scrublet.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:23,Deployability,integrat,integrate,23,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:107,Deployability,integrat,integrate,107,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:23,Integrability,integrat,integrate,23,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:107,Integrability,integrat,integrate,107,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:117,Integrability,wrap,wrapper,117,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:5,Testability,Test,Test,5,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:62,Testability,test,test,62,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:55,Usability,simpl,simple,55,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_harmony_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:25,Deployability,integrat,integration,25,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:113,Deployability,integrat,integrate,113,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:25,Integrability,integrat,integration,25,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:113,Integrability,integrat,integrate,113,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:123,Integrability,wrap,wrapper,123,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:5,Testability,Test,Test,5,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:66,Testability,test,test,66,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:59,Usability,simpl,simple,59,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,tests/external/test_scanorama_integrate.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py:286,Testability,test,testing,286,"# PAGA for hematopoiesis in mouse [(Paul *et al.*, 2015)](https://doi.org/10.1016/j.cell.2015.11.013); # Hematopoiesis: trace myeloid and erythroid differentiation for data of [Paul *et al.* (2015)](https://doi.org/10.1016/j.cell.2015.11.013).; #; # This is the subsampled notebook for testing.",MatchSource.CODE_COMMENT,tests/notebooks/test_paga_paul15_subsampled.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py:46,Deployability,install,installed,46,"# TODO: currently needs skip if louvain isn't installed, do major rework; # Clustering and PAGA",MatchSource.CODE_COMMENT,tests/notebooks/test_paga_paul15_subsampled.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py:8,Testability,test,test,8,"# add a test for this at some point; # data.to_csv('./write/paga_path_{}.csv'.format(descr))",MatchSource.CODE_COMMENT,tests/notebooks/test_paga_paul15_subsampled.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:558,Availability,avail,available,558,"# *First compiled on May 5, 2017. Updated August 14, 2018.*; # # Clustering 3k PBMCs following a Seurat Tutorial; #; # This started out with a demonstration that Scanpy would allow to reproduce most of Seurat's; # ([Satija *et al.*, 2015](https://doi.org/10.1038/nbt.3192)) clustering tutorial as described on; # https://satijalab.org/seurat/articles/pbmc3k_tutorial.html (July 26, 2017), which we gratefully acknowledge.; # In the meanwhile, we have added and removed several pieces.; #; # The data consists in *3k PBMCs from a Healthy Donor* and is freely available from 10x Genomics; # ([here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz); # from this [webpage](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k)).",MatchSource.CODE_COMMENT,tests/notebooks/test_pbmc3k.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:34,Deployability,Update,Updated,34,"# *First compiled on May 5, 2017. Updated August 14, 2018.*; # # Clustering 3k PBMCs following a Seurat Tutorial; #; # This started out with a demonstration that Scanpy would allow to reproduce most of Seurat's; # ([Satija *et al.*, 2015](https://doi.org/10.1038/nbt.3192)) clustering tutorial as described on; # https://satijalab.org/seurat/articles/pbmc3k_tutorial.html (July 26, 2017), which we gratefully acknowledge.; # In the meanwhile, we have added and removed several pieces.; #; # The data consists in *3k PBMCs from a Healthy Donor* and is freely available from 10x Genomics; # ([here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz); # from this [webpage](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k)).",MatchSource.CODE_COMMENT,tests/notebooks/test_pbmc3k.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:55,Testability,test,test,55,"# Finding marker genes; # Due to incosistency with our test runner vs local, these clusters need to; # be pre-annotated as the numbers for each cluster are not consistent.",MatchSource.CODE_COMMENT,tests/notebooks/test_pbmc3k.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py
https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:18,Availability,error,error,18,"# gives a strange error, probably due to jitter or something; # sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=8); # save_and_compare_images('rank_genes_groups_4')",MatchSource.CODE_COMMENT,tests/notebooks/test_pbmc3k.py,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py
