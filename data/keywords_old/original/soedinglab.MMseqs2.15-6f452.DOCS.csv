id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:3763,Availability,mask,masks,3763,"o; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and; modification follow. TERMS AND CONDITIONS. 0. Definitions. ""This License"" refers to version 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a work means to copy from or adapt all or part of the work; in a fashion requiring copyright permission, other than the making of an; exact copy. The resulting work is called a ""modified version"" of the; earlier work or a work ""based on"" the earlier work. A ""covered work"" means either the unmodified Program or a work based; on the Program. To ""propagate"" a work means to do anything with it that, without; permission, would make you directly or secondarily liable for; infringement under applicable copyright law, except executing it on a; computer or modifying a private copy. Propagation includes copying,; distribution (with or without modification), making available to the; public, and in some countries other activities as well. To ""convey"" a w",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:4626,Availability,avail,available,4626,"ion 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a work means to copy from or adapt all or part of the work; in a fashion requiring copyright permission, other than the making of an; exact copy. The resulting work is called a ""modified version"" of the; earlier work or a work ""based on"" the earlier work. A ""covered work"" means either the unmodified Program or a work based; on the Program. To ""propagate"" a work means to do anything with it that, without; permission, would make you directly or secondarily liable for; infringement under applicable copyright law, except executing it on a; computer or modifying a private copy. Propagation includes copying,; distribution (with or without modification), making available to the; public, and in some countries other activities as well. To ""convey"" a work means any kind of propagation that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and prominently visible; feature that (1) displays an appropriate copyright notice, and (2); tells the user that there is no warranty for the work (except to the; extent that warranties are provided), that licensees may convey the; work under this License, and how to view a copy of this License. If; the interface presents a list of user commands or options, such as a; menu, a prominent item in the list meets this criterion. 1. Source Code. The ""source code"" for a work means the preferred form of the work; for making modifications to it. ""Object code"" means any non-source; form of a work. A ""Sta",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:6242,Availability,avail,available,6242,"te copyright notice, and (2); tells the user that there is no warranty for the work (except to the; extent that warranties are provided), that licensees may convey the; work under this License, and how to view a copy of this License. If; the interface presents a list of user commands or options, such as a; menu, a prominent item in the list meets this criterion. 1. Source Code. The ""source code"" for a work means the preferred form of the work; for making modifications to it. ""Object code"" means any non-source; form of a work. A ""Standard Interface"" means an interface that either is an official; standard defined by a recognized standards body, or, in the case of; interfaces specified for a particular programming language, one that; is widely used among developers working in that language. The ""System Libraries"" of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work, including scripts to; control those activities. However, it does not include the work's; System Libraries, or general-purpose tools or generally available free; programs which are used unmodified in performing those activities but; which are not part of the work. For example, Corresponding Source; includes interface definition files ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:6894,Availability,avail,available,6894," of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work, including scripts to; control those activities. However, it does not include the work's; System Libraries, or general-purpose tools or generally available free; programs which are used unmodified in performing those activities but; which are not part of the work. For example, Corresponding Source; includes interface definition files associated with source files for; the work, and the source code for shared libraries and dynamically; linked subprograms that the work is specifically designed to require,; such as by intimate data communication or control flow between those; subprograms and other parts of the work. The Corresponding Source need not include anything that users; can regenerate automatically from other parts of the Corresponding; Source. The Corresponding Source for a work in source code form is that; same work. 2. Basic Permissions. All rights granted under this License are granted for the term of; copyright on the Program, and are irrevocable provided the stated; conditions are met. This License explicitly affirms your unlimited; permission to run the unmodified Program. The output from running a; covered work is covered by t",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:14317,Availability,avail,available,14317,"rk server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Source as a System Library, need not be; included in conveying the object code work. A ""User Product"" is either (1) a ""consumer product"", which means any; tangible personal property which is normally used for personal, family,; or household purposes, or (2) anything designed or sold for incorporation; into a dwelling. In determining whether a product is a consumer product,; doubtful cases shall be resolved in favor of coverage. For a particular; product received by a particular user, ""normally used"" refers to a; typical or common use of that class of product, regardless of the status; of t",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:17386,Availability,avail,available,17386,"xed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If additional permissions; apply only to part of the Program, that part may be used separately; under those permissions, but the entire Program remains governed by; this License without regard to the additional permissions. When you convey a copy of a covered work, you may at your option; remove any additional permissions from that copy, or from any part of; it. (Additional permissions may be written to require their own; removal in certain cases when you modify the work.) You may place; additional p",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:25594,Availability,avail,available,25594,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:25697,Availability,avail,available,25697,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:25824,Availability,avail,available,25824,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:26046,Availability,down,downstream,26046,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:27905,Availability,avail,available,27905,"s not include within; the scope of its coverage, prohibits the exercise of, or is; conditioned on the non-exercise of one or more of the rights that are; specifically granted under this License. You may not convey a covered; work if you are a party to an arrangement with a third party that is; in the business of distributing software, under which you make payment; to the third party based on the extent of your activity of conveying; the work, and under which the third party grants, to any of the; parties who would receive the covered work from you, a discriminatory; patent license (a) in connection with copies of the covered work; conveyed by you (or copies made from those copies), or (b) primarily; for and in connection with specific products or compilations that; contain the covered work, unless you entered into that arrangement,; or that patent license was granted, prior to 28 March 2007. Nothing in this License shall be construed as excluding or limiting; any implied license or other defenses to infringement that may; otherwise be available to you under applicable patent law. 12. No Surrender of Others' Freedom. If conditions are imposed on you (whether by court order, agreement or; otherwise) that contradict the conditions of this License, they do not; excuse you from the conditions of this License. If you cannot convey a; covered work so as to satisfy simultaneously your obligations under this; License and any other pertinent obligations, then as a consequence you may; not convey it at all. For example, if you agree to terms that obligate you; to collect a royalty for further conveying from those to whom you convey; the Program, the only way you could satisfy both those terms and this; License would be to refrain entirely from conveying the Program. 13. Use with the GNU Affero General Public License. Notwithstanding any other provision of this License, you have; permission to link or combine any covered work with a work licensed; under version 3 of the GNU Aff",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:800,Deployability,release,released,800," GNU GENERAL PUBLIC LICENSE; Version 3, 29 June 2007. Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>; Everyone is permitted to copy and distribute verbatim copies; of this license document, but changing it is not allowed. Preamble. The GNU General Public License is a free, copyleft license for; software and other kinds of works. The licenses for most software and other practical works are designed; to take away your freedom to share and change the works. By contrast,; the GNU General Public License is intended to guarantee your freedom to; share and change all versions of a program--to make sure it remains free; software for all its users. We, the Free Software Foundation, use the; GNU General Public License for most of our software; it applies also to; any other work released this way by its authors. You can apply it to; your programs, too. When we speak of free software, we are referring to freedom, not; price. Our General Public Licenses are designed to make sure that you; have the freedom to distribute copies of free software (and charge for; them if you wish), that you receive source code or can get it if you; want it, that you can change the software or use pieces of it in new; free programs, and that you know you can do these things. To protect your rights, we need to prevent others from denying you; these rights or asking you to surrender the rights. Therefore, you have; certain responsibilities if you distribute copies of the software, or if; you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must pass on to the recipients the same; freedoms that you received. You must make sure that they, too, receive; or can get the source code. And you must show them these terms so they; know their rights. Developers that use the GNU GPL protect your rights with two steps:; (1) assert copyright on the software, and (2) offer you this License; givi",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:2425,Deployability,install,install,2425,"f you distribute copies of the software, or if; you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must pass on to the recipients the same; freedoms that you received. You must make sure that they, too, receive; or can get the source code. And you must show them these terms so they; know their rights. Developers that use the GNU GPL protect your rights with two steps:; (1) assert copyright on the software, and (2) offer you this License; giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GPL clearly explains; that there is no warranty for this free software. For both users' and; authors' sake, the GPL requires that modified versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:6666,Deployability,install,install,6666,"icial; standard defined by a recognized standards body, or, in the case of; interfaces specified for a particular programming language, one that; is widely used among developers working in that language. The ""System Libraries"" of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work, including scripts to; control those activities. However, it does not include the work's; System Libraries, or general-purpose tools or generally available free; programs which are used unmodified in performing those activities but; which are not part of the work. For example, Corresponding Source; includes interface definition files associated with source files for; the work, and the source code for shared libraries and dynamically; linked subprograms that the work is specifically designed to require,; such as by intimate data communication or control flow between those; subprograms and other parts of the work. The Corresponding Source need not include anything that users; can regenerate automatically from other parts of the Corresponding; Source. The Corresponding Source for a work in source code form is that; same work. 2. Basic Permissions. All rights granted under this License are granted for the term of; copyri",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:10751,Deployability,release,released,10751," may convey verbatim copies of the Program's source code as you; receive it, in any medium, provided that you conspicuously and; appropriately publish on each copy an appropriate copyright notice;; keep intact all notices stating that this License and any; non-permissive terms added in accord with section 7 apply to the code;; keep intact all notices of the absence of any warranty; and give all; recipients a copy of this License along with the Program. You may charge any price or no price for each copy that you convey,; and you may offer support or warranty protection for a fee. 5. Conveying Modified Source Versions. You may convey a work based on the Program, or the modifications to; produce it from the Program, in the form of source code under the; terms of section 4, provided that you also meet all of these conditions:. a) The work must carry prominent notices stating that you modified; it, and giving a relevant date. b) The work must carry prominent notices stating that it is; released under this License and any conditions added under section; 7. This requirement modifies the requirement in section 4 to; ""keep intact all notices"". c) You must license the entire work, as a whole, under this; License to anyone who comes into possession of a copy. This; License will therefore apply, along with any applicable section 7; additional terms, to the whole of the work, and all its parts,; regardless of how they are packaged. This License gives no; permission to license the work in any other way, but it does not; invalidate such permission if you have separately received it. d) If the work has interactive user interfaces, each must display; Appropriate Legal Notices; however, if the Program has interactive; interfaces that do not display Appropriate Legal Notices, your; work need not make them do so. A compilation of a covered work with other separate and independent; works, which are not by their nature extensions of the covered work,; and which are not combined with it s",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:15759,Deployability,install,install,15759,"eying the object code work. A ""User Product"" is either (1) a ""consumer product"", which means any; tangible personal property which is normally used for personal, family,; or household purposes, or (2) anything designed or sold for incorporation; into a dwelling. In determining whether a product is a consumer product,; doubtful cases shall be resolved in favor of coverage. For a particular; product received by a particular user, ""normally used"" refers to a; typical or common use of that class of product, regardless of the status; of the particular user or of the way in which the particular user; actually uses, or expects or is expected to use, the product. A product; is a consumer product regardless of whether the product has substantial; commercial, industrial or non-consumer uses, unless such uses represent; the only significant mode of use of the product. ""Installation Information"" for a User Product means any methods,; procedures, authorization keys, or other information required to install; and execute modified versions of a covered work in that User Product from; a modified version of its Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Inst",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:16626,Deployability,install,install,16626,"""Installation Information"" for a User Product means any methods,; procedures, authorization keys, or other information required to install; and execute modified versions of a covered work in that User Product from; a modified version of its Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making excepti",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:16709,Deployability,install,installed,16709,"""Installation Information"" for a User Product means any methods,; procedures, authorization keys, or other information required to install; and execute modified versions of a covered work in that User Product from; a modified version of its Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making excepti",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:16865,Deployability,update,updates,16865,"s Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If addition",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:16911,Deployability,install,installed,16911,"s Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If addition",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:16997,Deployability,install,installed,16997,"s Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If addition",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:1072,Energy Efficiency,charge,charge,1072,"f.org/>; Everyone is permitted to copy and distribute verbatim copies; of this license document, but changing it is not allowed. Preamble. The GNU General Public License is a free, copyleft license for; software and other kinds of works. The licenses for most software and other practical works are designed; to take away your freedom to share and change the works. By contrast,; the GNU General Public License is intended to guarantee your freedom to; share and change all versions of a program--to make sure it remains free; software for all its users. We, the Free Software Foundation, use the; GNU General Public License for most of our software; it applies also to; any other work released this way by its authors. You can apply it to; your programs, too. When we speak of free software, we are referring to freedom, not; price. Our General Public Licenses are designed to make sure that you; have the freedom to distribute copies of free software (and charge for; them if you wish), that you receive source code or can get it if you; want it, that you can change the software or use pieces of it in new; free programs, and that you know you can do these things. To protect your rights, we need to prevent others from denying you; these rights or asking you to surrender the rights. Therefore, you have; certain responsibilities if you distribute copies of the software, or if; you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must pass on to the recipients the same; freedoms that you received. You must make sure that they, too, receive; or can get the source code. And you must show them these terms so they; know their rights. Developers that use the GNU GPL protect your rights with two steps:; (1) assert copyright on the software, and (2) offer you this License; giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GP",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:3992,Energy Efficiency,adapt,adapt,3992,"protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and; modification follow. TERMS AND CONDITIONS. 0. Definitions. ""This License"" refers to version 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a work means to copy from or adapt all or part of the work; in a fashion requiring copyright permission, other than the making of an; exact copy. The resulting work is called a ""modified version"" of the; earlier work or a work ""based on"" the earlier work. A ""covered work"" means either the unmodified Program or a work based; on the Program. To ""propagate"" a work means to do anything with it that, without; permission, would make you directly or secondarily liable for; infringement under applicable copyright law, except executing it on a; computer or modifying a private copy. Propagation includes copying,; distribution (with or without modification), making available to the; public, and in some countries other activities as well. To ""convey"" a work means any kind of propagation that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and promi",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:9325,Energy Efficiency,power,power,9325,"ou do; not control copyright. Those thus making or running the covered works; for you must do so exclusively on your behalf, under your direction; and control, on terms that prohibit them from making any copies of; your copyrighted material outside their relationship with you. Conveying under any other circumstances is permitted solely under; the conditions stated below. Sublicensing is not allowed; section 10; makes it unnecessary. 3. Protecting Users' Legal Rights From Anti-Circumvention Law. No covered work shall be deemed part of an effective technological; measure under any applicable law fulfilling obligations under article; 11 of the WIPO copyright treaty adopted on 20 December 1996, or; similar laws prohibiting or restricting circumvention of such; measures. When you convey a covered work, you waive any legal power to forbid; circumvention of technological measures to the extent such circumvention; is effected by exercising rights under this License with respect to; the covered work, and you disclaim any intention to limit operation or; modification of the work as a means of enforcing, against the work's; users, your or third parties' legal rights to forbid circumvention of; technological measures. 4. Conveying Verbatim Copies. You may convey verbatim copies of the Program's source code as you; receive it, in any medium, provided that you conspicuously and; appropriately publish on each copy an appropriate copyright notice;; keep intact all notices stating that this License and any; non-permissive terms added in accord with section 7 apply to the code;; keep intact all notices of the absence of any warranty; and give all; recipients a copy of this License along with the Program. You may charge any price or no price for each copy that you convey,; and you may offer support or warranty protection for a fee. 5. Conveying Modified Source Versions. You may convey a work based on the Program, or the modifications to; produce it from the Program, in the form of sour",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:10220,Energy Efficiency,charge,charge,10220,"en you convey a covered work, you waive any legal power to forbid; circumvention of technological measures to the extent such circumvention; is effected by exercising rights under this License with respect to; the covered work, and you disclaim any intention to limit operation or; modification of the work as a means of enforcing, against the work's; users, your or third parties' legal rights to forbid circumvention of; technological measures. 4. Conveying Verbatim Copies. You may convey verbatim copies of the Program's source code as you; receive it, in any medium, provided that you conspicuously and; appropriately publish on each copy an appropriate copyright notice;; keep intact all notices stating that this License and any; non-permissive terms added in accord with section 7 apply to the code;; keep intact all notices of the absence of any warranty; and give all; recipients a copy of this License along with the Program. You may charge any price or no price for each copy that you convey,; and you may offer support or warranty protection for a fee. 5. Conveying Modified Source Versions. You may convey a work based on the Program, or the modifications to; produce it from the Program, in the form of source code under the; terms of section 4, provided that you also meet all of these conditions:. a) The work must carry prominent notices stating that you modified; it, and giving a relevant date. b) The work must carry prominent notices stating that it is; released under this License and any conditions added under section; 7. This requirement modifies the requirement in section 4 to; ""keep intact all notices"". c) You must license the entire work, as a whole, under this; License to anyone who comes into possession of a copy. This; License will therefore apply, along with any applicable section 7; additional terms, to the whole of the work, and all its parts,; regardless of how they are packaged. This License gives no; permission to license the work in any other way, but it",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13312,Energy Efficiency,charge,charge,13312,"mpilation's users; beyond what the individual works permit. Inclusion of a covered work; in an aggregate does not cause this License to apply to the other; parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms; of sections 4 and 5, provided that you also convey the; machine-readable Corresponding Source under the terms of this License,; in one of these ways:. a) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by the; Corresponding Source fixed on a durable physical medium; customarily used for software interchange. b) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corres",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13686,Energy Efficiency,charge,charge,13686,"luding a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Sourc",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13806,Energy Efficiency,charge,charge,13806,"luding a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Sourc",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:14579,Energy Efficiency,charge,charge,14579,"commercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Source as a System Library, need not be; included in conveying the object code work. A ""User Product"" is either (1) a ""consumer product"", which means any; tangible personal property which is normally used for personal, family,; or household purposes, or (2) anything designed or sold for incorporation; into a dwelling. In determining whether a product is a consumer product,; doubtful cases shall be resolved in favor of coverage. For a particular; product received by a particular user, ""normally used"" refers to a; typical or common use of that class of product, regardless of the status; of the particular user or of the way in which the particular user; actually uses, or expects or is expected to use, the product. A product; is a consumer product regardless of whether the product has ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:23770,Energy Efficiency,charge,charge,23770,"is License. You are not responsible; for enforcing compliance by third parties with this License. An ""entity transaction"" is a transaction transferring control of an; organization, or substantially all assets of one, or subdividing an; organization, or merging organizations. If propagation of a covered; work results from an entity transaction, each party to that; transaction who receives a copy of the work also receives whatever; licenses to the work the party's predecessor in interest had or could; give under the previous paragraph, plus a right to possession of the; Corresponding Source of the work from the predecessor in interest, if; the predecessor has it or can get it with reasonable efforts. You may not impose any further restrictions on the exercise of the; rights granted or affirmed under this License. For example, you may; not impose a license fee, royalty, or other charge for exercise of; rights granted under this License, and you may not initiate litigation; (including a cross-claim or counterclaim in a lawsuit) alleging that; any patent claim is infringed by making, using, selling, offering for; sale, or importing the Program or any portion of it. 11. Patents. A ""contributor"" is a copyright holder who authorizes use under this; License of the Program or a work on which the Program is based. The; work thus licensed is called the contributor's ""contributor version"". A contributor's ""essential patent claims"" are all patent claims; owned or controlled by the contributor, whether already acquired or; hereafter acquired, that would be infringed by some manner, permitted; by this License, of making, using, or selling its contributor version,; but do not include claims that would be infringed only as a; consequence of further modification of the contributor version. For; purposes of this definition, ""control"" includes the right to grant; patent sublicenses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:25633,Energy Efficiency,charge,charge,25633,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:4928,Integrability,interface,interface,4928,"e resulting work is called a ""modified version"" of the; earlier work or a work ""based on"" the earlier work. A ""covered work"" means either the unmodified Program or a work based; on the Program. To ""propagate"" a work means to do anything with it that, without; permission, would make you directly or secondarily liable for; infringement under applicable copyright law, except executing it on a; computer or modifying a private copy. Propagation includes copying,; distribution (with or without modification), making available to the; public, and in some countries other activities as well. To ""convey"" a work means any kind of propagation that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and prominently visible; feature that (1) displays an appropriate copyright notice, and (2); tells the user that there is no warranty for the work (except to the; extent that warranties are provided), that licensees may convey the; work under this License, and how to view a copy of this License. If; the interface presents a list of user commands or options, such as a; menu, a prominent item in the list meets this criterion. 1. Source Code. The ""source code"" for a work means the preferred form of the work; for making modifications to it. ""Object code"" means any non-source; form of a work. A ""Standard Interface"" means an interface that either is an official; standard defined by a recognized standards body, or, in the case of; interfaces specified for a particular programming language, one that; is widely used among developers working in that language. The ""System Libraries"" of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serve",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:5325,Integrability,interface,interface,5325,", would make you directly or secondarily liable for; infringement under applicable copyright law, except executing it on a; computer or modifying a private copy. Propagation includes copying,; distribution (with or without modification), making available to the; public, and in some countries other activities as well. To ""convey"" a work means any kind of propagation that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and prominently visible; feature that (1) displays an appropriate copyright notice, and (2); tells the user that there is no warranty for the work (except to the; extent that warranties are provided), that licensees may convey the; work under this License, and how to view a copy of this License. If; the interface presents a list of user commands or options, such as a; menu, a prominent item in the list meets this criterion. 1. Source Code. The ""source code"" for a work means the preferred form of the work; for making modifications to it. ""Object code"" means any non-source; form of a work. A ""Standard Interface"" means an interface that either is an official; standard defined by a recognized standards body, or, in the case of; interfaces specified for a particular programming language, one that; is widely used among developers working in that language. The ""System Libraries"" of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window syste",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:5647,Integrability,interface,interface,5647,"n that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and prominently visible; feature that (1) displays an appropriate copyright notice, and (2); tells the user that there is no warranty for the work (except to the; extent that warranties are provided), that licensees may convey the; work under this License, and how to view a copy of this License. If; the interface presents a list of user commands or options, such as a; menu, a prominent item in the list meets this criterion. 1. Source Code. The ""source code"" for a work means the preferred form of the work; for making modifications to it. ""Object code"" means any non-source; form of a work. A ""Standard Interface"" means an interface that either is an official; standard defined by a recognized standards body, or, in the case of; interfaces specified for a particular programming language, one that; is widely used among developers working in that language. The ""System Libraries"" of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work,",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:5754,Integrability,interface,interfaces,5754,"n that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and prominently visible; feature that (1) displays an appropriate copyright notice, and (2); tells the user that there is no warranty for the work (except to the; extent that warranties are provided), that licensees may convey the; work under this License, and how to view a copy of this License. If; the interface presents a list of user commands or options, such as a; menu, a prominent item in the list meets this criterion. 1. Source Code. The ""source code"" for a work means the preferred form of the work; for making modifications to it. ""Object code"" means any non-source; form of a work. A ""Standard Interface"" means an interface that either is an official; standard defined by a recognized standards body, or, in the case of; interfaces specified for a particular programming language, one that; is widely used among developers working in that language. The ""System Libraries"" of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work,",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:7057,Integrability,interface,interface,7057,"a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work, including scripts to; control those activities. However, it does not include the work's; System Libraries, or general-purpose tools or generally available free; programs which are used unmodified in performing those activities but; which are not part of the work. For example, Corresponding Source; includes interface definition files associated with source files for; the work, and the source code for shared libraries and dynamically; linked subprograms that the work is specifically designed to require,; such as by intimate data communication or control flow between those; subprograms and other parts of the work. The Corresponding Source need not include anything that users; can regenerate automatically from other parts of the Corresponding; Source. The Corresponding Source for a work in source code form is that; same work. 2. Basic Permissions. All rights granted under this License are granted for the term of; copyright on the Program, and are irrevocable provided the stated; conditions are met. This License explicitly affirms your unlimited; permission to run the unmodified Program. The output from running a; covered work is covered by this License only if the output, given its; content, constitutes a covered work. This License acknowledges your; rights of fair use or other equivalent, as provided by copyright law. You may make, run and propagate covered works that you do not; convey, without conditions so long as you",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:11386,Integrability,interface,interfaces,11386," the Program, in the form of source code under the; terms of section 4, provided that you also meet all of these conditions:. a) The work must carry prominent notices stating that you modified; it, and giving a relevant date. b) The work must carry prominent notices stating that it is; released under this License and any conditions added under section; 7. This requirement modifies the requirement in section 4 to; ""keep intact all notices"". c) You must license the entire work, as a whole, under this; License to anyone who comes into possession of a copy. This; License will therefore apply, along with any applicable section 7; additional terms, to the whole of the work, and all its parts,; regardless of how they are packaged. This License gives no; permission to license the work in any other way, but it does not; invalidate such permission if you have separately received it. d) If the work has interactive user interfaces, each must display; Appropriate Legal Notices; however, if the Program has interactive; interfaces that do not display Appropriate Legal Notices, your; work need not make them do so. A compilation of a covered work with other separate and independent; works, which are not by their nature extensions of the covered work,; and which are not combined with it such as to form a larger program,; in or on a volume of a storage or distribution medium, is called an; ""aggregate"" if the compilation and its resulting copyright are not; used to limit the access or legal rights of the compilation's users; beyond what the individual works permit. Inclusion of a covered work; in an aggregate does not cause this License to apply to the other; parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms; of sections 4 and 5, provided that you also convey the; machine-readable Corresponding Source under the terms of this License,; in one of these ways:. a) Convey the object code in, or embodied in, a physical pr",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:11485,Integrability,interface,interfaces,11485," the Program, in the form of source code under the; terms of section 4, provided that you also meet all of these conditions:. a) The work must carry prominent notices stating that you modified; it, and giving a relevant date. b) The work must carry prominent notices stating that it is; released under this License and any conditions added under section; 7. This requirement modifies the requirement in section 4 to; ""keep intact all notices"". c) You must license the entire work, as a whole, under this; License to anyone who comes into possession of a copy. This; License will therefore apply, along with any applicable section 7; additional terms, to the whole of the work, and all its parts,; regardless of how they are packaged. This License gives no; permission to license the work in any other way, but it does not; invalidate such permission if you have separately received it. d) If the work has interactive user interfaces, each must display; Appropriate Legal Notices; however, if the Program has interactive; interfaces that do not display Appropriate Legal Notices, your; work need not make them do so. A compilation of a covered work with other separate and independent; works, which are not by their nature extensions of the covered work,; and which are not combined with it such as to form a larger program,; in or on a volume of a storage or distribution medium, is called an; ""aggregate"" if the compilation and its resulting copyright are not; used to limit the access or legal rights of the compilation's users; beyond what the individual works permit. Inclusion of a covered work; in an aggregate does not cause this License to apply to the other; parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms; of sections 4 and 5, provided that you also convey the; machine-readable Corresponding Source under the terms of this License,; in one of these ways:. a) Convey the object code in, or embodied in, a physical pr",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:17162,Integrability,protocol,protocols,17162,"ork under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If additional permissions; apply only to part of the Program, that part may be used separately; under those permissions, but the entire Program remains governed by; this License without regard to the additional permissions. When you convey a copy of a ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:19537,Integrability,contract,contractual,19537,"rial you; add to a covered work, you may (if authorized by the copyright holders of; that material) supplement the terms of this License with terms:. a) Disclaiming warranty or limiting liability differently from the; terms of sections 15 and 16 of this License; or. b) Requiring preservation of specified reasonable legal notices or; author attributions in that material or in the Appropriate Legal; Notices displayed by works containing it; or. c) Prohibiting misrepresentation of the origin of that material, or; requiring that modified versions of such material be marked in; reasonable ways as different from the original version; or. d) Limiting the use for publicity purposes of names of licensors or; authors of the material; or. e) Declining to grant rights under trademark law for use of some; trade names, trademarks, or service marks; or. f) Requiring indemnification of licensors and authors of that; material by anyone who conveys the material (or modified versions of; it) with contractual assumptions of liability to the recipient, for; any liability that these contractual assumptions directly impose on; those licensors and authors. All other non-permissive additional terms are considered ""further; restrictions"" within the meaning of section 10. If the Program as you; received it, or any part of it, contains a notice stating that it is; governed by this License along with a term that is a further; restriction, you may remove that term. If a license document contains; a further restriction but permits relicensing or conveying under this; License, you may add to a covered work material governed by the terms; of that license document, provided that the further restriction does; not survive such relicensing or conveying. If you add terms to a covered work in accord with this section, you; must place, in the relevant source files, a statement of the; additional terms that apply to those files, or a notice indicating; where to find the applicable terms. Additional terms, ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:19622,Integrability,contract,contractual,19622,"rial you; add to a covered work, you may (if authorized by the copyright holders of; that material) supplement the terms of this License with terms:. a) Disclaiming warranty or limiting liability differently from the; terms of sections 15 and 16 of this License; or. b) Requiring preservation of specified reasonable legal notices or; author attributions in that material or in the Appropriate Legal; Notices displayed by works containing it; or. c) Prohibiting misrepresentation of the origin of that material, or; requiring that modified versions of such material be marked in; reasonable ways as different from the original version; or. d) Limiting the use for publicity purposes of names of licensors or; authors of the material; or. e) Declining to grant rights under trademark law for use of some; trade names, trademarks, or service marks; or. f) Requiring indemnification of licensors and authors of that; material by anyone who conveys the material (or modified versions of; it) with contractual assumptions of liability to the recipient, for; any liability that these contractual assumptions directly impose on; those licensors and authors. All other non-permissive additional terms are considered ""further; restrictions"" within the meaning of section 10. If the Program as you; received it, or any part of it, contains a notice stating that it is; governed by this License along with a term that is a further; restriction, you may remove that term. If a license document contains; a further restriction but permits relicensing or conveying under this; License, you may add to a covered work material governed by the terms; of that license document, provided that the further restriction does; not survive such relicensing or conveying. If you add terms to a covered work in accord with this section, you; must place, in the relevant source files, a statement of the; additional terms that apply to those files, or a notice indicating; where to find the applicable terms. Additional terms, ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:34012,Integrability,interface,interface,34012,"dea of what it does.}; Copyright (C) {year} {name of author}. This program is free software: you can redistribute it and/or modify; it under the terms of the GNU General Public License as published by; the Free Software Foundation, either version 3 of the License, or; (at your option) any later version. This program is distributed in the hope that it will be useful,; but WITHOUT ANY WARRANTY; without even the implied warranty of; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the; GNU General Public License for more details. You should have received a copy of the GNU General Public License; along with this program. If not, see <http://www.gnu.org/licenses/>. Also add information on how to contact you by electronic and paper mail. If the program does terminal interaction, make it output a short; notice like this when it starts in an interactive mode:. {project} Copyright (C) {year} {fullname}; This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.; This is free software, and you are welcome to redistribute it; under certain conditions; type `show c' for details. The hypothetical commands `show w' and `show c' should show the appropriate; parts of the General Public License. Of course, your program's commands; might be different; for a GUI interface, you would use an ""about box"". You should also get your employer (if you work as a programmer) or school,; if any, to sign a ""copyright disclaimer"" for the program, if necessary.; For more information on this, and how to apply and follow the GNU GPL, see; <http://www.gnu.org/licenses/>. The GNU General Public License does not permit incorporating your program; into proprietary programs. If your program is a subroutine library, you; may consider it more useful to permit linking proprietary applications with; the library. If this is what you want to do, use the GNU Lesser General; Public License instead of this License. But first, please read; <http://www.gnu.org/philosophy/why-not-lgpl.html>.; ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:2945,Modifiability,extend,extend,2945," and (2) offer you this License; giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GPL clearly explains; that there is no warranty for this free software. For both users' and; authors' sake, the GPL requires that modified versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and; modification follow. TERMS AND CONDITIONS. 0. Definitions. ""This License"" refers to version 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:3992,Modifiability,adapt,adapt,3992,"protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and; modification follow. TERMS AND CONDITIONS. 0. Definitions. ""This License"" refers to version 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a work means to copy from or adapt all or part of the work; in a fashion requiring copyright permission, other than the making of an; exact copy. The resulting work is called a ""modified version"" of the; earlier work or a work ""based on"" the earlier work. A ""covered work"" means either the unmodified Program or a work based; on the Program. To ""propagate"" a work means to do anything with it that, without; permission, would make you directly or secondarily liable for; infringement under applicable copyright law, except executing it on a; computer or modifying a private copy. Propagation includes copying,; distribution (with or without modification), making available to the; public, and in some countries other activities as well. To ""convey"" a work means any kind of propagation that enables other; parties to make or receive copies. Mere interaction with a user through; a computer network, with no transfer of a copy, is not conveying. An interactive user interface displays ""Appropriate Legal Notices""; to the extent that it includes a convenient and promi",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:26016,Modifiability,extend,extend,26016,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:26737,Modifiability,extend,extended,26737,"s not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the covered; work and works based on it. A patent license is ""discriminatory"" if it does not include within; the scope of its coverage, prohibits the exercise of, or is; conditioned on the non-exercise of one or more of the rights that are; specifically granted under this License. You may not convey a covered; work if you are a party to an arrangement with a third party that is; in the business of distributing software, under which you make payment; to the third party based on the extent of your activity of conveying; the work, and under which the third party grants, to any of the; parties who would receive the covered work from you, a discriminatory; patent license (a) in connection with copies of the covered work; conveyed by you (or copies made from those copies), or (b) primarily; for and in connection wit",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:6948,Performance,perform,performing,6948," of an executable work include anything, other; than the work as a whole, that (a) is included in the normal form of; packaging a Major Component, but which is not part of that Major; Component, and (b) serves only to enable use of the work with that; Major Component, or to implement a Standard Interface for which an; implementation is available to the public in source code form. A; ""Major Component"", in this context, means a major essential component; (kernel, window system, and so on) of the specific operating system; (if any) on which the executable work runs, or a compiler used to; produce the work, or an object code interpreter used to run it. The ""Corresponding Source"" for a work in object code form means all; the source code needed to generate, install, and (for an executable; work) run the object code and to modify the work, including scripts to; control those activities. However, it does not include the work's; System Libraries, or general-purpose tools or generally available free; programs which are used unmodified in performing those activities but; which are not part of the work. For example, Corresponding Source; includes interface definition files associated with source files for; the work, and the source code for shared libraries and dynamically; linked subprograms that the work is specifically designed to require,; such as by intimate data communication or control flow between those; subprograms and other parts of the work. The Corresponding Source need not include anything that users; can regenerate automatically from other parts of the Corresponding; Source. The Corresponding Source for a work in source code form is that; same work. 2. Basic Permissions. All rights granted under this License are granted for the term of; copyright on the Program, and are irrevocable provided the stated; conditions are met. This License explicitly affirms your unlimited; permission to run the unmodified Program. The output from running a; covered work is covered by t",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13198,Performance,perform,performing,13198,"mpilation's users; beyond what the individual works permit. Inclusion of a covered work; in an aggregate does not cause this License to apply to the other; parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms; of sections 4 and 5, provided that you also convey the; machine-readable Corresponding Source under the terms of this License,; in one of these ways:. a) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by the; Corresponding Source fixed on a durable physical medium; customarily used for software interchange. b) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corres",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:3270,Safety,avoid,avoid,3270," versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and; modification follow. TERMS AND CONDITIONS. 0. Definitions. ""This License"" refers to version 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a work means to copy from or adapt all or part of the work; in a fashion requiring copyright permission, other than the making of an; exact copy. The resulting work is called a ""modified version"" of the; earlier work or a work ""based on"" the earlier work. A ""covered work"" means either t",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:32458,Safety,safe,safest,32458," WITH ANY OTHER PROGRAMS),; EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF; SUCH DAMAGES. 17. Interpretation of Sections 15 and 16. If the disclaimer of warranty and limitation of liability provided; above cannot be given local legal effect according to their terms,; reviewing courts shall apply local law that most closely approximates; an absolute waiver of all civil liability in connection with the; Program, unless a warranty or assumption of liability accompanies a; copy of the Program in return for a fee. END OF TERMS AND CONDITIONS. How to Apply These Terms to Your New Programs. If you develop a new program, and you want it to be of the greatest; possible use to the public, the best way to achieve this is to make it; free software which everyone can redistribute and change under these terms. To do so, attach the following notices to the program. It is safest; to attach them to the start of each source file to most effectively; state the exclusion of warranty; and each file should have at least; the ""copyright"" line and a pointer to where the full notice is found. {one line to give the program's name and a brief idea of what it does.}; Copyright (C) {year} {name of author}. This program is free software: you can redistribute it and/or modify; it under the terms of the GNU General Public License as published by; the Free Software Foundation, either version 3 of the License, or; (at your option) any later version. This program is distributed in the hope that it will be useful,; but WITHOUT ANY WARRANTY; without even the implied warranty of; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the; GNU General Public License for more details. You should have received a copy of the GNU General Public License; along with this program. If not, see <http://www.gnu.org/licenses/>. Also add information on how to contact you by electronic and paper mail. If the program does terminal interaction, make it output a short; notice like this when ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:2415,Security,access,access,2415,"f you distribute copies of the software, or if; you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must pass on to the recipients the same; freedoms that you received. You must make sure that they, too, receive; or can get the source code. And you must show them these terms so they; know their rights. Developers that use the GNU GPL protect your rights with two steps:; (1) assert copyright on the software, and (2) offer you this License; giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GPL clearly explains; that there is no warranty for this free software. For both users' and; authors' sake, the GPL requires that modified versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:3085,Security,threat,threatened,3085,"rs' protection, the GPL clearly explains; that there is no warranty for this free software. For both users' and; authors' sake, the GPL requires that modified versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software patents.; States should not allow patents to restrict development and use of; software on general-purpose computers, but in those that do, we wish to; avoid the special danger that patents applied to a free program could; make it effectively proprietary. To prevent this, the GPL assures that; patents cannot be used to render the program non-free. The precise terms and conditions for copying, distribution and; modification follow. TERMS AND CONDITIONS. 0. Definitions. ""This License"" refers to version 3 of the GNU General Public License. ""Copyright"" also means copyright-like laws that apply to other kinds of; works, such as semiconductor masks. ""The Program"" refers to any copyrightable work licensed under this; License. Each licensee is addressed as ""you"". ""Licensees"" and; ""recipients"" may be individuals or organizations. To ""modify"" a work means to copy from or adapt all or part of the work; in a fashion requiring copyright permission, other than the making of ",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:11944,Security,access,access,11944,"er section; 7. This requirement modifies the requirement in section 4 to; ""keep intact all notices"". c) You must license the entire work, as a whole, under this; License to anyone who comes into possession of a copy. This; License will therefore apply, along with any applicable section 7; additional terms, to the whole of the work, and all its parts,; regardless of how they are packaged. This License gives no; permission to license the work in any other way, but it does not; invalidate such permission if you have separately received it. d) If the work has interactive user interfaces, each must display; Appropriate Legal Notices; however, if the Program has interactive; interfaces that do not display Appropriate Legal Notices, your; work need not make them do so. A compilation of a covered work with other separate and independent; works, which are not by their nature extensions of the covered work,; and which are not combined with it such as to form a larger program,; in or on a volume of a storage or distribution medium, is called an; ""aggregate"" if the compilation and its resulting copyright are not; used to limit the access or legal rights of the compilation's users; beyond what the individual works permit. Inclusion of a covered work; in an aggregate does not cause this License to apply to the other; parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms; of sections 4 and 5, provided that you also convey the; machine-readable Corresponding Source under the terms of this License,; in one of these ways:. a) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by the; Corresponding Source fixed on a durable physical medium; customarily used for software interchange. b) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by a; written offer, valid for at least three year",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13243,Security,access,access,13243,"mpilation's users; beyond what the individual works permit. Inclusion of a covered work; in an aggregate does not cause this License to apply to the other; parts of the aggregate. 6. Conveying Non-Source Forms. You may convey a covered work in object code form under the terms; of sections 4 and 5, provided that you also convey the; machine-readable Corresponding Source under the terms of this License,; in one of these ways:. a) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by the; Corresponding Source fixed on a durable physical medium; customarily used for software interchange. b) Convey the object code in, or embodied in, a physical product; (including a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corres",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13637,Security,access,access,13637,"luding a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Sourc",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:13716,Security,access,access,13716,"luding a physical distribution medium), accompanied by a; written offer, valid for at least three years and valid for as; long as you offer spare parts or customer support for that product; model, to give anyone who possesses the object code either (1) a; copy of the Corresponding Source for all the software in the; product that is covered by this License, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Sourc",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:15706,Security,authoriz,authorization,15706,"eying the object code work. A ""User Product"" is either (1) a ""consumer product"", which means any; tangible personal property which is normally used for personal, family,; or household purposes, or (2) anything designed or sold for incorporation; into a dwelling. In determining whether a product is a consumer product,; doubtful cases shall be resolved in favor of coverage. For a particular; product received by a particular user, ""normally used"" refers to a; typical or common use of that class of product, regardless of the status; of the particular user or of the way in which the particular user; actually uses, or expects or is expected to use, the product. A product; is a consumer product regardless of whether the product has substantial; commercial, industrial or non-consumer uses, unless such uses represent; the only significant mode of use of the product. ""Installation Information"" for a User Product means any methods,; procedures, authorization keys, or other information required to install; and execute modified versions of a covered work in that User Product from; a modified version of its Corresponding Source. The information must; suffice to ensure that the continued functioning of the modified object; code is in no case prevented or interfered with solely because; modification has been made. If you convey an object code work under this section in, or with, or; specifically for use in, a User Product, and the conveying occurs as; part of a transaction in which the right of possession and use of the; User Product is transferred to the recipient in perpetuity or for a; fixed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Inst",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:17461,Security,password,password,17461,"xed term (regardless of how the transaction is characterized), the; Corresponding Source conveyed under this section must be accompanied; by the Installation Information. But this requirement does not apply; if neither you nor any third party retains the ability to install; modified object code on the User Product (for example, the work has; been installed in ROM). The requirement to provide Installation Information does not include a; requirement to continue to provide support service, warranty, or updates; for a work that has been modified or installed by the recipient, or for; the User Product in which it has been modified or installed. Access to a; network may be denied when the modification itself materially and; adversely affects the operation of the network or violates the rules and; protocols for communication across the network. Corresponding Source conveyed, and Installation Information provided,; in accord with this section must be in a format that is publicly; documented (and with an implementation available to the public in; source code form), and must require no special password or key for; unpacking, reading or copying. 7. Additional Terms. ""Additional permissions"" are terms that supplement the terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If additional permissions; apply only to part of the Program, that part may be used separately; under those permissions, but the entire Program remains governed by; this License without regard to the additional permissions. When you convey a copy of a covered work, you may at your option; remove any additional permissions from that copy, or from any part of; it. (Additional permissions may be written to require their own; removal in certain cases when you modify the work.) You may place; additional p",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:18589,Security,authoriz,authorized,18589,"e terms of this; License by making exceptions from one or more of its conditions.; Additional permissions that are applicable to the entire Program shall; be treated as though they were included in this License, to the extent; that they are valid under applicable law. If additional permissions; apply only to part of the Program, that part may be used separately; under those permissions, but the entire Program remains governed by; this License without regard to the additional permissions. When you convey a copy of a covered work, you may at your option; remove any additional permissions from that copy, or from any part of; it. (Additional permissions may be written to require their own; removal in certain cases when you modify the work.) You may place; additional permissions on material, added by you to a covered work,; for which you have or can give appropriate copyright permission. Notwithstanding any other provision of this License, for material you; add to a covered work, you may (if authorized by the copyright holders of; that material) supplement the terms of this License with terms:. a) Disclaiming warranty or limiting liability differently from the; terms of sections 15 and 16 of this License; or. b) Requiring preservation of specified reasonable legal notices or; author attributions in that material or in the Appropriate Legal; Notices displayed by works containing it; or. c) Prohibiting misrepresentation of the origin of that material, or; requiring that modified versions of such material be marked in; reasonable ways as different from the original version; or. d) Limiting the use for publicity purposes of names of licensors or; authors of the material; or. e) Declining to grant rights under trademark law for use of some; trade names, trademarks, or service marks; or. f) Requiring indemnification of licensors and authors of that; material by anyone who conveys the material (or modified versions of; it) with contractual assumptions of liability to the recipie",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:24115,Security,authoriz,authorizes,24115,"ing organizations. If propagation of a covered; work results from an entity transaction, each party to that; transaction who receives a copy of the work also receives whatever; licenses to the work the party's predecessor in interest had or could; give under the previous paragraph, plus a right to possession of the; Corresponding Source of the work from the predecessor in interest, if; the predecessor has it or can get it with reasonable efforts. You may not impose any further restrictions on the exercise of the; rights granted or affirmed under this License. For example, you may; not impose a license fee, royalty, or other charge for exercise of; rights granted under this License, and you may not initiate litigation; (including a cross-claim or counterclaim in a lawsuit) alleging that; any patent claim is infringed by making, using, selling, offering for; sale, or importing the Program or any portion of it. 11. Patents. A ""contributor"" is a copyright holder who authorizes use under this; License of the Program or a work on which the Program is based. The; work thus licensed is called the contributor's ""contributor version"". A contributor's ""essential patent claims"" are all patent claims; owned or controlled by the contributor, whether already acquired or; hereafter acquired, that would be infringed by some manner, permitted; by this License, of making, using, or selling its contributor version,; but do not include claims that would be infringed only as a; consequence of further modification of the contributor version. For; purposes of this definition, ""control"" includes the right to grant; patent sublicenses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""pat",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:25739,Security,access,accessible,25739,"ses in a manner consistent with the requirements of; this License. Each contributor grants you a non-exclusive, worldwide, royalty-free; patent license under the contributor's essential patent claims, to; make, use, sell, offer for sale, import and otherwise run, modify and; propagate the contents of its contributor version. In the following three paragraphs, a ""patent license"" is any express; agreement or commitment, however denominated, not to enforce a patent; (such as an express permission to practice a patent or covenant not to; sue for patent infringement). To ""grant"" such a patent license to a; party means to make such an agreement or commitment not to enforce a; patent against the party. If you convey a covered work, knowingly relying on a patent license,; and the Corresponding Source of the work is not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the c",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:26594,Security,authoriz,authorizing,26594,"s not available for anyone; to copy, free of charge and under the terms of this License, through a; publicly available network server or other readily accessible means,; then you must either (1) cause the Corresponding Source to be so; available, or (2) arrange to deprive yourself of the benefit of the; patent license for this particular work, or (3) arrange, in a manner; consistent with the requirements of this License, to extend the patent; license to downstream recipients. ""Knowingly relying"" means you have; actual knowledge that, but for the patent license, your conveying the; covered work in a country, or your recipient's use of the covered work; in a country, would infringe one or more identifiable patents in that; country that you have reason to believe are valid. If, pursuant to or in connection with a single transaction or; arrangement, you convey, or propagate by procuring conveyance of, a; covered work, and grant a patent license to some of the parties; receiving the covered work authorizing them to use, propagate, modify; or convey a specific copy of the covered work, then the patent license; you grant is automatically extended to all recipients of the covered; work and works based on it. A patent license is ""discriminatory"" if it does not include within; the scope of its coverage, prohibits the exercise of, or is; conditioned on the non-exercise of one or more of the rights that are; specifically granted under this License. You may not convey a covered; work if you are a party to an arrangement with a third party that is; in the business of distributing software, under which you make payment; to the third party based on the extent of your activity of conveying; the work, and under which the third party grants, to any of the; parties who would receive the covered work from you, a discriminatory; patent license (a) in connection with copies of the covered work; conveyed by you (or copies made from those copies), or (b) primarily; for and in connection wit",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:30189,Security,authoriz,authorizes,30189,"ncerning interaction through a network will apply to the; combination as such. 14. Revised Versions of this License. The Free Software Foundation may publish revised and/or new versions of; the GNU General Public License from time to time. Such new versions will; be similar in spirit to the present version, but may differ in detail to; address new problems or concerns. Each version is given a distinguishing version number. If the; Program specifies that a certain numbered version of the GNU General; Public License ""or any later version"" applies to it, you have the; option of following the terms and conditions either of that numbered; version or of any later version published by the Free Software; Foundation. If the Program does not specify a version number of the; GNU General Public License, you may choose any version ever published; by the Free Software Foundation. If the Program specifies that a proxy can decide which future; versions of the GNU General Public License can be used, that proxy's; public statement of acceptance of a version permanently authorizes you; to choose that version for the Program. Later license versions may give you additional or different; permissions. However, no additional obligations are imposed on any; author or copyright holder as a result of your choosing to follow a; later version. 15. Disclaimer of Warranty. THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY; APPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT; HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM ""AS IS"" WITHOUT WARRANTY; OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,; THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM; IS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF; ALL NECESSARY SERVICING, REPAIR OR CORRECTION. 16. Limitation of Liability. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREE",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:1931,Testability,assert,assert,1931," Public Licenses are designed to make sure that you; have the freedom to distribute copies of free software (and charge for; them if you wish), that you receive source code or can get it if you; want it, that you can change the software or use pieces of it in new; free programs, and that you know you can do these things. To protect your rights, we need to prevent others from denying you; these rights or asking you to surrender the rights. Therefore, you have; certain responsibilities if you distribute copies of the software, or if; you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must pass on to the recipients the same; freedoms that you received. You must make sure that they, too, receive; or can get the source code. And you must show them these terms so they; know their rights. Developers that use the GNU GPL protect your rights with two steps:; (1) assert copyright on the software, and (2) offer you this License; giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GPL clearly explains; that there is no warranty for this free software. For both users' and; authors' sake, the GPL requires that modified versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this pro",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:2116,Usability,clear,clearly,2116,"urce code or can get it if you; want it, that you can change the software or use pieces of it in new; free programs, and that you know you can do these things. To protect your rights, we need to prevent others from denying you; these rights or asking you to surrender the rights. Therefore, you have; certain responsibilities if you distribute copies of the software, or if; you modify it: responsibilities to respect the freedom of others. For example, if you distribute copies of such a program, whether; gratis or for a fee, you must pass on to the recipients the same; freedoms that you received. You must make sure that they, too, receive; or can get the source code. And you must show them these terms so they; know their rights. Developers that use the GNU GPL protect your rights with two steps:; (1) assert copyright on the software, and (2) offer you this License; giving you legal permission to copy, distribute and/or modify it. For the developers' and authors' protection, the GPL clearly explains; that there is no warranty for this free software. For both users' and; authors' sake, the GPL requires that modified versions be marked as; changed, so that their problems will not be attributed erroneously to; authors of previous versions. Some devices are designed to deny users access to install or run; modified versions of the software inside them, although the manufacturer; can do so. This is fundamentally incompatible with the aim of; protecting users' freedom to change the software. The systematic; pattern of such abuse occurs in the area of products for individuals to; use, which is precisely where it is most unacceptable. Therefore, we; have designed this version of the GPL to prohibit the practice for those; products. If such problems arise substantially in other domains, we; stand ready to extend this provision to those domains in future versions; of the GPL, as needed to protect the freedom of users. Finally, every program is threatened constantly by software pate",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md:14126,Usability,clear,clear,14126,"se, on a durable physical; medium customarily used for software interchange, for a price no; more than your reasonable cost of physically performing this; conveying of source, or (2) access to copy the; Corresponding Source from a network server at no charge. c) Convey individual copies of the object code with a copy of the; written offer to provide the Corresponding Source. This; alternative is allowed only occasionally and noncommercially, and; only if you received the object code with such an offer, in accord; with subsection 6b. d) Convey the object code by offering access from a designated; place (gratis or for a charge), and offer equivalent access to the; Corresponding Source in the same way through the same place at no; further charge. You need not require recipients to copy the; Corresponding Source along with the object code. If the place to; copy the object code is a network server, the Corresponding Source; may be on a different server (operated by you or a third party); that supports equivalent copying facilities, provided you maintain; clear directions next to the object code saying where to find the; Corresponding Source. Regardless of what server hosts the; Corresponding Source, you remain obligated to ensure that it is; available for as long as needed to satisfy these requirements. e) Convey the object code using peer-to-peer transmission, provided; you inform other peers where the object code and Corresponding; Source of the work are being offered to the general public at no; charge under subsection 6d. A separable portion of the object code, whose source code is excluded; from the Corresponding Source as a System Library, need not be; included in conveying the object code work. A ""User Product"" is either (1) a ""consumer product"", which means any; tangible personal property which is normally used for personal, family,; or household purposes, or (2) anything designed or sold for incorporation; into a dwelling. In determining whether a product is a co",MatchSource.DOCS,LICENSE.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/LICENSE.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:1766,Availability,down,downloads,1766,"Nature Biotechnology, doi: 10.1038/nbt.3988 (2017)](https://www.nature.com/articles/nbt.3988). [Steinegger M and Soeding J. Clustering huge protein sequence sets in linear time. Nature Communications, doi: 10.1038/s41467-018-04964-5 (2018)](https://www.nature.com/articles/s41467-018-04964-5). [Mirdita M, Steinegger M and Soeding J. MMseqs2 desktop and local web server app for fast, interactive sequence searches. Bioinformatics, doi: 10.1093/bioinformatics/bty1057 (2019)](https://academic.oup.com/bioinformatics/article/35/16/2856/5280135). [Mirdita M, Steinegger M, Breitwieser F, Soding J, Levy Karin E: Fast and sensitive taxonomic assignment to metagenomic contigs. Bioinformatics, doi: 10.1093/bioinformatics/btab184 (2021)](https://doi.org/10.1093/bioinformatics/btab184). [![BioConda Install](https://img.shields.io/conda/dn/bioconda/mmseqs2.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/mmseqs2) [![Github All Releases](https://img.shields.io/github/downloads/soedinglab/mmseqs2/total.svg)](https://github.com/soedinglab/mmseqs2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://biocontainers.pro/#/tools/mmseqs2) [![Build Status](https://dev.azure.com/themartinsteinegger/mmseqs2/_apis/build/status/soedinglab.MMseqs2?branchName=master)](https://dev.azure.com/themartinsteinegger/mmseqs2/_build/latest?definitionId=2&branchName=master) <a href=""https://chat.mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tut",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:2563,Availability,avail,available,2563,"[BioConda Install](https://img.shields.io/conda/dn/bioconda/mmseqs2.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/mmseqs2) [![Github All Releases](https://img.shields.io/github/downloads/soedinglab/mmseqs2/total.svg)](https://github.com/soedinglab/mmseqs2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://biocontainers.pro/#/tools/mmseqs2) [![Build Status](https://dev.azure.com/themartinsteinegger/mmseqs2/_apis/build/status/soedinglab.MMseqs2?branchName=master)](https://dev.azure.com/themartinsteinegger/mmseqs2/_build/latest?definitionId=2&branchName=master) <a href=""https://chat.mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install d",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3261,Availability,down,downloading,3261,".mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction s",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:4628,Availability,avail,available,4628,"AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction set (check by executing `cat /proc/cpuinfo | grep sse4_1` on Linux or `sysctl -a | grep machdep.cpu.features | grep SSE4.1` on MacOS). The AVX2 version is faster than SSE4.1, check if AVX2 is supported by executing `cat /proc/cpuinfo | grep avx2` on Linux and `sysctl -a | grep machdep.cpu.leaf7_features | grep AVX2` on MacOS). A SSE2 version is also available for very old systems. MMseqs2 also works on ARM64 systems and on PPC64LE systems with POWER8 ISA or newer. We provide static binaries for all supported platforms at [mmseqs.com/latest](https://mmseqs.com/latest). MMseqs2 comes with a bash command and parameter auto completion, which can be activated by adding the following lines to your $HOME/.bash_profile:. <pre>; if [ -f /<b>Path to MMseqs2</b>/util/bash-completion.sh ]; then; source /<b>Path to MMseqs2</b>/util/bash-completion.sh; fi; </pre>; ; ## Getting started; We provide `easy` workflows to cluster, search and assign taxonomy. These `easy` workflows are a shorthand to deal directly with FASTA/FASTQ files as input and output. MMseqs2 provides many modules to transform, filter, execute external programs and search. However, these modules use the MMseqs2 database formats, instead of the FASTA/FASTQ format. For maximum flexibility, we recommend using MMseqs2 workflows and modules directly. Please read more about this in the [d",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:5767,Availability,avail,available,5767,"wer. We provide static binaries for all supported platforms at [mmseqs.com/latest](https://mmseqs.com/latest). MMseqs2 comes with a bash command and parameter auto completion, which can be activated by adding the following lines to your $HOME/.bash_profile:. <pre>; if [ -f /<b>Path to MMseqs2</b>/util/bash-completion.sh ]; then; source /<b>Path to MMseqs2</b>/util/bash-completion.sh; fi; </pre>; ; ## Getting started; We provide `easy` workflows to cluster, search and assign taxonomy. These `easy` workflows are a shorthand to deal directly with FASTA/FASTQ files as input and output. MMseqs2 provides many modules to transform, filter, execute external programs and search. However, these modules use the MMseqs2 database formats, instead of the FASTA/FASTQ format. For maximum flexibility, we recommend using MMseqs2 workflows and modules directly. Please read more about this in the [documentation](https://github.com/soedinglab/mmseqs2/wiki). ### Cluster. For clustering, MMseqs2 `easy-cluster` and `easy-linclust` are available. `easy-cluster` by default clusters the entries of a FASTA/FASTQ file using a cascaded clustering algorithm.; ; mmseqs easy-cluster examples/DB.fasta clusterRes tmp --min-seq-id 0.5 -c 0.8 --cov-mode 1; ; `easy-linclust` clusters the entries of a FASTA/FASTQ file. The runtime scales linearly with input size. This mode is recommended for huge datasets.; ; mmseqs easy-linclust examples/DB.fasta clusterRes tmp; ; Read more about the [clustering format](https://github.com/soedinglab/mmseqs2/wiki#clustering-format) in our user guide.; ; Please adjust the [clustering criteria](https://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta exa",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:7094,Availability,down,download,7094,"ust examples/DB.fasta clusterRes tmp; ; Read more about the [clustering format](https://github.com/soedinglab/mmseqs2/wiki#clustering-format) in our user guide.; ; Please adjust the [clustering criteria](https://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` retur",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:7280,Availability,down,downloading-databases,7280,"tering-format) in our user guide.; ; Please adjust the [clustering criteria](https://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output co",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:7321,Availability,down,download,7321,"tps://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output columns](https://github.com/soedinglab/mmseqs2/wiki#custom-alignment-format-with-c",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:9387,Availability,down,downloads,9387,"mat-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does-mmseqs2-compute-the-sequence-identity) the identity in default. To output real sequence identity use `--alignment-mode 3` or `-a`. ### Taxonomy; The `easy-taxonomy` workflow can be used to assign sequences taxonomical labels. It performs a search against a sequence database with taxonomy information (seqTaxDb), chooses the most representative sets of aligned target sequences according to different strategies (according to `--lca-mode`) and computes the lowest common ancestor among those. mmseqs createdb examples/DB.fasta targetDB; mmseqs createtaxdb targetDB tmp; mmseqs createindex targetDB tmp; mmseqs easy-taxonomy examples/QUERY.fasta targetDB alnRes tmp. By default, `createtaxdb` assigns a Uniprot accession to a taxonomical identifier to every sequence and downloads the NCBI taxonomy. We also support [BLAST](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-from-an-existing-blast-database), [SILVA](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-for-silva) or [custom taxonomical](https://github.com/soedinglab/MMseqs2/wiki#manually-annotate-a-sequence-database-with-taxonomic-information) databases. Many common taxonomic reference databases can be easily downloaded and set up by the [`databases` workflow](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases). Read more about the [taxonomy format](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-format) and the [classification](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) in our user guide. ### Supported search modes. MMseqs2 provides many additional search modes:; * Iterative sequences-profile searches ",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:9887,Availability,down,downloaded,9887,"with taxonomy information (seqTaxDb), chooses the most representative sets of aligned target sequences according to different strategies (according to `--lca-mode`) and computes the lowest common ancestor among those. mmseqs createdb examples/DB.fasta targetDB; mmseqs createtaxdb targetDB tmp; mmseqs createindex targetDB tmp; mmseqs easy-taxonomy examples/QUERY.fasta targetDB alnRes tmp. By default, `createtaxdb` assigns a Uniprot accession to a taxonomical identifier to every sequence and downloads the NCBI taxonomy. We also support [BLAST](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-from-an-existing-blast-database), [SILVA](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-for-silva) or [custom taxonomical](https://github.com/soedinglab/MMseqs2/wiki#manually-annotate-a-sequence-database-with-taxonomic-information) databases. Many common taxonomic reference databases can be easily downloaded and set up by the [`databases` workflow](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases). Read more about the [taxonomy format](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-format) and the [classification](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) in our user guide. ### Supported search modes. MMseqs2 provides many additional search modes:; * Iterative sequences-profile searches (like PSI-BLAST) with the `--num-iterations` parameter; * [Translated searches](https://github.com/soedinglab/MMseqs2/wiki#translated-sequence-searching) of nucleotides against proteins (blastx), proteins against nucleotides (tblastn) or nucleotide against nucleotide (tblastx); * [Iterative increasing sensitivity searches](https://github.com/soedinglab/MMseqs2/wiki#how-to-find-the-best-hit-the-fastest-way) to find only the best hits faster; * [Taxonomic assignment](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmse",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:9982,Availability,down,downloading-databases,9982,"arget sequences according to different strategies (according to `--lca-mode`) and computes the lowest common ancestor among those. mmseqs createdb examples/DB.fasta targetDB; mmseqs createtaxdb targetDB tmp; mmseqs createindex targetDB tmp; mmseqs easy-taxonomy examples/QUERY.fasta targetDB alnRes tmp. By default, `createtaxdb` assigns a Uniprot accession to a taxonomical identifier to every sequence and downloads the NCBI taxonomy. We also support [BLAST](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-from-an-existing-blast-database), [SILVA](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-for-silva) or [custom taxonomical](https://github.com/soedinglab/MMseqs2/wiki#manually-annotate-a-sequence-database-with-taxonomic-information) databases. Many common taxonomic reference databases can be easily downloaded and set up by the [`databases` workflow](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases). Read more about the [taxonomy format](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-format) and the [classification](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) in our user guide. ### Supported search modes. MMseqs2 provides many additional search modes:; * Iterative sequences-profile searches (like PSI-BLAST) with the `--num-iterations` parameter; * [Translated searches](https://github.com/soedinglab/MMseqs2/wiki#translated-sequence-searching) of nucleotides against proteins (blastx), proteins against nucleotides (tblastn) or nucleotide against nucleotide (tblastx); * [Iterative increasing sensitivity searches](https://github.com/soedinglab/MMseqs2/wiki#how-to-find-the-best-hit-the-fastest-way) to find only the best hits faster; * [Taxonomic assignment](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) using 2bLCA or LCA; * Fast ungapped alignment searches to find [very simila",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:11904,Availability,avail,available,11904,"lignment searches to find [very similar sequence matches](https://github.com/soedinglab/MMseqs2/wiki#mapping-very-similar-sequences-using-mmseqs-map); * Very fast and sensitive searches against [profile databases such as the PFAM](https://github.com/soedinglab/MMseqs2/wiki#how-to-create-a-target-profile-database-from-pfam); * [Reciprocal best hits search](https://github.com/soedinglab/MMseqs2/wiki#reciprocal-best-hit-using-mmseqs-rbh); * [Web search API and user interface](https://github.com/soedinglab/MMseqs2-App). Many modes can also be combined. You can, for example, do a translated nucleotide against protein profile search. ### Memory requirements; MMseqs2 minimum memory requirements for `cluster` or `linclust` is 1 byte per sequence residue, `search` needs 1 byte per target residue. Sequence databases can be compressed using the `--compress` flag, DNA sequences can be reduced by a factor of `~3.5` and proteins by `~1.7`.; ; MMseqs2 checks the available system memory and automatically divides the target database in parts that fit into memory. Splitting the database will increase the runtime slightly. It is possible to control the memory usage using `--split-memory-limit`. ### How to run MMseqs2 on multiple servers using MPI; MMseqs2 can run on multiple cores and servers using OpenMP and Message Passing Interface (MPI).; MPI assigns database splits to each compute node, which are then computed with multiple cores (OpenMP). Make sure that MMseqs2 was compiled with MPI by using the `-DHAVE_MPI=1` flag (`cmake -DHAVE_MPI=1 -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=. ..`). Our precompiled static version of MMseqs2 cannot use MPI. The version string of MMseqs2 will have a `-MPI` suffix, if it was built successfully with MPI support. To search with multiple servers, call the `search` or `cluster` workflow with the MPI command exported in the RUNNER environment variable. The databases and temporary folder have to be shared between all nodes (e.g. through NFS):. R",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:1845,Deployability,release,releases,1845,"es/nbt.3988). [Steinegger M and Soeding J. Clustering huge protein sequence sets in linear time. Nature Communications, doi: 10.1038/s41467-018-04964-5 (2018)](https://www.nature.com/articles/s41467-018-04964-5). [Mirdita M, Steinegger M and Soeding J. MMseqs2 desktop and local web server app for fast, interactive sequence searches. Bioinformatics, doi: 10.1093/bioinformatics/bty1057 (2019)](https://academic.oup.com/bioinformatics/article/35/16/2856/5280135). [Mirdita M, Steinegger M, Breitwieser F, Soding J, Levy Karin E: Fast and sensitive taxonomic assignment to metagenomic contigs. Bioinformatics, doi: 10.1093/bioinformatics/btab184 (2021)](https://doi.org/10.1093/bioinformatics/btab184). [![BioConda Install](https://img.shields.io/conda/dn/bioconda/mmseqs2.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/mmseqs2) [![Github All Releases](https://img.shields.io/github/downloads/soedinglab/mmseqs2/total.svg)](https://github.com/soedinglab/mmseqs2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://biocontainers.pro/#/tools/mmseqs2) [![Build Status](https://dev.azure.com/themartinsteinegger/mmseqs2/_apis/build/status/soedinglab.MMseqs2?branchName=master)](https://dev.azure.com/themartinsteinegger/mmseqs2/_build/latest?definitionId=2&branchName=master) <a href=""https://chat.mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3062,Deployability,update,updates,3062,"themartinsteinegger/mmseqs2/_apis/build/status/soedinglab.MMseqs2?branchName=master)](https://dev.azure.com/themartinsteinegger/mmseqs2/_build/latest?definitionId=2&branchName=master) <a href=""https://chat.mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linu",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3246,Deployability,install,installation,3246,".mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction s",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3443,Deployability,install,install,3443,"></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction set (check by executing `cat /proc/cpuinfo | grep sse4_1` on Linux or `sysctl -a | grep machdep.cpu.features | grep SSE4.1` on MacOS). The AVX2 version is faster than SSE4.1, check if AVX2 is supported by executing `cat /proc/cpuinfo | g",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3465,Deployability,install,install,3465,"></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction set (check by executing `cat /proc/cpuinfo | grep sse4_1` on Linux or `sysctl -a | grep machdep.cpu.features | grep SSE4.1` on MacOS). The AVX2 version is faster than SSE4.1, check if AVX2 is supported by executing `cat /proc/cpuinfo | g",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3484,Deployability,install,install,3484,"></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction set (check by executing `cat /proc/cpuinfo | grep sse4_1` on Linux or `sysctl -a | grep machdep.cpu.features | grep SSE4.1` on MacOS). The AVX2 version is faster than SSE4.1, check if AVX2 is supported by executing `cat /proc/cpuinfo | g",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3509,Deployability,install,install,3509,"></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction set (check by executing `cat /proc/cpuinfo | grep sse4_1` on Linux or `sysctl -a | grep machdep.cpu.features | grep SSE4.1` on MacOS). The AVX2 version is faster than SSE4.1, check if AVX2 is supported by executing `cat /proc/cpuinfo | g",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:3555,Deployability,install,install,3555,"></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-linux-sse41.tar.gz; tar xvfz mmseqs-linux-sse41.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE2 (slowest, for very old systems); wget https://mmseqs.com/latest/mmseqs-linux-sse2.tar.gz; tar xvfz mmseqs-linux-sse2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH. MMseqs2 requires an AMD or Intel 64-bit system (check with `uname -a | grep x86_64`). We recommend using a system with at least the SSE4.1 instruction set (check by executing `cat /proc/cpuinfo | grep sse4_1` on Linux or `sysctl -a | grep machdep.cpu.features | grep SSE4.1` on MacOS). The AVX2 version is faster than SSE4.1, check if AVX2 is supported by executing `cat /proc/cpuinfo | g",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:6847,Energy Efficiency,reduce,reduces,6847,"orithm.; ; mmseqs easy-cluster examples/DB.fasta clusterRes tmp --min-seq-id 0.5 -c 0.8 --cov-mode 1; ; `easy-linclust` clusters the entries of a FASTA/FASTQ file. The runtime scales linearly with input size. This mode is recommended for huge datasets.; ; mmseqs easy-linclust examples/DB.fasta clusterRes tmp; ; Read more about the [clustering format](https://github.com/soedinglab/mmseqs2/wiki#clustering-format) in our user guide.; ; Please adjust the [clustering criteria](https://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:7624,Energy Efficiency,adapt,adapted,7624,"inst either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output columns](https://github.com/soedinglab/mmseqs2/wiki#custom-alignment-format-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:11828,Energy Efficiency,reduce,reduced,11828,"Taxonomic assignment](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) using 2bLCA or LCA; * Fast ungapped alignment searches to find [very similar sequence matches](https://github.com/soedinglab/MMseqs2/wiki#mapping-very-similar-sequences-using-mmseqs-map); * Very fast and sensitive searches against [profile databases such as the PFAM](https://github.com/soedinglab/MMseqs2/wiki#how-to-create-a-target-profile-database-from-pfam); * [Reciprocal best hits search](https://github.com/soedinglab/MMseqs2/wiki#reciprocal-best-hit-using-mmseqs-rbh); * [Web search API and user interface](https://github.com/soedinglab/MMseqs2-App). Many modes can also be combined. You can, for example, do a translated nucleotide against protein profile search. ### Memory requirements; MMseqs2 minimum memory requirements for `cluster` or `linclust` is 1 byte per sequence residue, `search` needs 1 byte per target residue. Sequence databases can be compressed using the `--compress` flag, DNA sequences can be reduced by a factor of `~3.5` and proteins by `~1.7`.; ; MMseqs2 checks the available system memory and automatically divides the target database in parts that fit into memory. Splitting the database will increase the runtime slightly. It is possible to control the memory usage using `--split-memory-limit`. ### How to run MMseqs2 on multiple servers using MPI; MMseqs2 can run on multiple cores and servers using OpenMP and Message Passing Interface (MPI).; MPI assigns database splits to each compute node, which are then computed with multiple cores (OpenMP). Make sure that MMseqs2 was compiled with MPI by using the `-DHAVE_MPI=1` flag (`cmake -DHAVE_MPI=1 -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=. ..`). Our precompiled static version of MMseqs2 cannot use MPI. The version string of MMseqs2 will have a `-MPI` suffix, if it was built successfully with MPI support. To search with multiple servers, call the `search` or `cluster` workflow with the MPI c",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:11409,Integrability,interface,interface,11409,"`--num-iterations` parameter; * [Translated searches](https://github.com/soedinglab/MMseqs2/wiki#translated-sequence-searching) of nucleotides against proteins (blastx), proteins against nucleotides (tblastn) or nucleotide against nucleotide (tblastx); * [Iterative increasing sensitivity searches](https://github.com/soedinglab/MMseqs2/wiki#how-to-find-the-best-hit-the-fastest-way) to find only the best hits faster; * [Taxonomic assignment](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) using 2bLCA or LCA; * Fast ungapped alignment searches to find [very similar sequence matches](https://github.com/soedinglab/MMseqs2/wiki#mapping-very-similar-sequences-using-mmseqs-map); * Very fast and sensitive searches against [profile databases such as the PFAM](https://github.com/soedinglab/MMseqs2/wiki#how-to-create-a-target-profile-database-from-pfam); * [Reciprocal best hits search](https://github.com/soedinglab/MMseqs2/wiki#reciprocal-best-hit-using-mmseqs-rbh); * [Web search API and user interface](https://github.com/soedinglab/MMseqs2-App). Many modes can also be combined. You can, for example, do a translated nucleotide against protein profile search. ### Memory requirements; MMseqs2 minimum memory requirements for `cluster` or `linclust` is 1 byte per sequence residue, `search` needs 1 byte per target residue. Sequence databases can be compressed using the `--compress` flag, DNA sequences can be reduced by a factor of `~3.5` and proteins by `~1.7`.; ; MMseqs2 checks the available system memory and automatically divides the target database in parts that fit into memory. Splitting the database will increase the runtime slightly. It is possible to control the memory usage using `--split-memory-limit`. ### How to run MMseqs2 on multiple servers using MPI; MMseqs2 can run on multiple cores and servers using OpenMP and Message Passing Interface (MPI).; MPI assigns database splits to each compute node, which are then computed with multiple",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:7624,Modifiability,adapt,adapted,7624,"inst either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output columns](https://github.com/soedinglab/mmseqs2/wiki#custom-alignment-format-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:12840,Modifiability,variab,variable,12840,"from-pfam); * [Reciprocal best hits search](https://github.com/soedinglab/MMseqs2/wiki#reciprocal-best-hit-using-mmseqs-rbh); * [Web search API and user interface](https://github.com/soedinglab/MMseqs2-App). Many modes can also be combined. You can, for example, do a translated nucleotide against protein profile search. ### Memory requirements; MMseqs2 minimum memory requirements for `cluster` or `linclust` is 1 byte per sequence residue, `search` needs 1 byte per target residue. Sequence databases can be compressed using the `--compress` flag, DNA sequences can be reduced by a factor of `~3.5` and proteins by `~1.7`.; ; MMseqs2 checks the available system memory and automatically divides the target database in parts that fit into memory. Splitting the database will increase the runtime slightly. It is possible to control the memory usage using `--split-memory-limit`. ### How to run MMseqs2 on multiple servers using MPI; MMseqs2 can run on multiple cores and servers using OpenMP and Message Passing Interface (MPI).; MPI assigns database splits to each compute node, which are then computed with multiple cores (OpenMP). Make sure that MMseqs2 was compiled with MPI by using the `-DHAVE_MPI=1` flag (`cmake -DHAVE_MPI=1 -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=. ..`). Our precompiled static version of MMseqs2 cannot use MPI. The version string of MMseqs2 will have a `-MPI` suffix, if it was built successfully with MPI support. To search with multiple servers, call the `search` or `cluster` workflow with the MPI command exported in the RUNNER environment variable. The databases and temporary folder have to be shared between all nodes (e.g. through NFS):. RUNNER=""mpirun -pernode -np 42"" mmseqs search queryDB targetDB resultDB tmp. ## Contributors. MMseqs2 exists thanks to all the people who contribute. ; <a href=""https://github.com/soedinglab/mmseqs2/graphs/contributors"">; <img src=""https://contributors-img.firebaseapp.com/image?repo=soedinglab/mmseqs2"" />; </a>; ",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:416,Performance,scalab,scalability,416,"# MMseqs2: ultra fast and sensitive sequence search and clustering suite; MMseqs2 (Many-against-Many sequence searching) is a software suite to search and cluster huge protein and nucleotide sequence sets. MMseqs2 is open source GPL-licensed software implemented in C++ for Linux, MacOS, and (as beta version, via cygwin) Windows. The software is designed to run on multiple cores and servers and exhibits very good scalability. MMseqs2 can run 10000 times faster than BLAST. At 100 times its speed it achieves almost the same sensitivity. It can perform profile searches with the same sensitivity as PSI-BLAST at over 400 times its speed. ## Publications. [Steinegger M and Soeding J. MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. Nature Biotechnology, doi: 10.1038/nbt.3988 (2017)](https://www.nature.com/articles/nbt.3988). [Steinegger M and Soeding J. Clustering huge protein sequence sets in linear time. Nature Communications, doi: 10.1038/s41467-018-04964-5 (2018)](https://www.nature.com/articles/s41467-018-04964-5). [Mirdita M, Steinegger M and Soeding J. MMseqs2 desktop and local web server app for fast, interactive sequence searches. Bioinformatics, doi: 10.1093/bioinformatics/bty1057 (2019)](https://academic.oup.com/bioinformatics/article/35/16/2856/5280135). [Mirdita M, Steinegger M, Breitwieser F, Soding J, Levy Karin E: Fast and sensitive taxonomic assignment to metagenomic contigs. Bioinformatics, doi: 10.1093/bioinformatics/btab184 (2021)](https://doi.org/10.1093/bioinformatics/btab184). [![BioConda Install](https://img.shields.io/conda/dn/bioconda/mmseqs2.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/mmseqs2) [![Github All Releases](https://img.shields.io/github/downloads/soedinglab/mmseqs2/total.svg)](https://github.com/soedinglab/mmseqs2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://bioc",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:547,Performance,perform,perform,547,"# MMseqs2: ultra fast and sensitive sequence search and clustering suite; MMseqs2 (Many-against-Many sequence searching) is a software suite to search and cluster huge protein and nucleotide sequence sets. MMseqs2 is open source GPL-licensed software implemented in C++ for Linux, MacOS, and (as beta version, via cygwin) Windows. The software is designed to run on multiple cores and servers and exhibits very good scalability. MMseqs2 can run 10000 times faster than BLAST. At 100 times its speed it achieves almost the same sensitivity. It can perform profile searches with the same sensitivity as PSI-BLAST at over 400 times its speed. ## Publications. [Steinegger M and Soeding J. MMseqs2 enables sensitive protein sequence searching for the analysis of massive data sets. Nature Biotechnology, doi: 10.1038/nbt.3988 (2017)](https://www.nature.com/articles/nbt.3988). [Steinegger M and Soeding J. Clustering huge protein sequence sets in linear time. Nature Communications, doi: 10.1038/s41467-018-04964-5 (2018)](https://www.nature.com/articles/s41467-018-04964-5). [Mirdita M, Steinegger M and Soeding J. MMseqs2 desktop and local web server app for fast, interactive sequence searches. Bioinformatics, doi: 10.1093/bioinformatics/bty1057 (2019)](https://academic.oup.com/bioinformatics/article/35/16/2856/5280135). [Mirdita M, Steinegger M, Breitwieser F, Soding J, Levy Karin E: Fast and sensitive taxonomic assignment to metagenomic contigs. Bioinformatics, doi: 10.1093/bioinformatics/btab184 (2021)](https://doi.org/10.1093/bioinformatics/btab184). [![BioConda Install](https://img.shields.io/conda/dn/bioconda/mmseqs2.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/mmseqs2) [![Github All Releases](https://img.shields.io/github/downloads/soedinglab/mmseqs2/total.svg)](https://github.com/soedinglab/mmseqs2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://bioc",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:8846,Performance,perform,performs,8846,"nglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output columns](https://github.com/soedinglab/mmseqs2/wiki#custom-alignment-format-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does-mmseqs2-compute-the-sequence-identity) the identity in default. To output real sequence identity use `--alignment-mode 3` or `-a`. ### Taxonomy; The `easy-taxonomy` workflow can be used to assign sequences taxonomical labels. It performs a search against a sequence database with taxonomy information (seqTaxDb), chooses the most representative sets of aligned target sequences according to different strategies (according to `--lca-mode`) and computes the lowest common ancestor among those. mmseqs createdb examples/DB.fasta targetDB; mmseqs createtaxdb targetDB tmp; mmseqs createindex targetDB tmp; mmseqs easy-taxonomy examples/QUERY.fasta targetDB alnRes tmp. By default, `createtaxdb` assigns a Uniprot accession to a taxonomical identifier to every sequence and downloads the NCBI taxonomy. We also support [BLAST](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-from-an-existing-blast-database), [SILVA](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-for-silva) or [custom taxonomical](https://github.com/soedinglab/MMseqs2/wiki#manually-annotate-a-sequence-database-with-taxonomic-information) databases. Many common taxonomic reference databases can be easily downloaded and set up by the [`databases` workflow](https://github.com/soedinglab/mmseqs2",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:8175,Security,access,accession,8175,"the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output columns](https://github.com/soedinglab/mmseqs2/wiki#custom-alignment-format-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does-mmseqs2-compute-the-sequence-identity) the identity in default. To output real sequence identity use `--alignment-mode 3` or `-a`. ### Taxonomy; The `easy-taxonomy` workflow can be used to assign sequences taxonomical labels. It performs a search against a sequence database with taxonomy information (seqTaxDb), chooses the most representative sets of aligned target sequences according to different strategies (according to `--lca-mode`) and computes the lowest common ancestor among those. mmseqs createdb examples/DB.fasta targetDB; mmseqs createtax",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:9327,Security,access,accession,9327,"mat-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does-mmseqs2-compute-the-sequence-identity) the identity in default. To output real sequence identity use `--alignment-mode 3` or `-a`. ### Taxonomy; The `easy-taxonomy` workflow can be used to assign sequences taxonomical labels. It performs a search against a sequence database with taxonomy information (seqTaxDb), chooses the most representative sets of aligned target sequences according to different strategies (according to `--lca-mode`) and computes the lowest common ancestor among those. mmseqs createdb examples/DB.fasta targetDB; mmseqs createtaxdb targetDB tmp; mmseqs createindex targetDB tmp; mmseqs easy-taxonomy examples/QUERY.fasta targetDB alnRes tmp. By default, `createtaxdb` assigns a Uniprot accession to a taxonomical identifier to every sequence and downloads the NCBI taxonomy. We also support [BLAST](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-from-an-existing-blast-database), [SILVA](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-for-silva) or [custom taxonomical](https://github.com/soedinglab/MMseqs2/wiki#manually-annotate-a-sequence-database-with-taxonomic-information) databases. Many common taxonomic reference databases can be easily downloaded and set up by the [`databases` workflow](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases). Read more about the [taxonomy format](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-format) and the [classification](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) in our user guide. ### Supported search modes. MMseqs2 provides many additional search modes:; * Iterative sequences-profile searches ",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:2554,Usability,guid,guide,2554,"[BioConda Install](https://img.shields.io/conda/dn/bioconda/mmseqs2.svg?style=flag&label=BioConda%20install)](https://anaconda.org/bioconda/mmseqs2) [![Github All Releases](https://img.shields.io/github/downloads/soedinglab/mmseqs2/total.svg)](https://github.com/soedinglab/mmseqs2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://biocontainers.pro/#/tools/mmseqs2) [![Build Status](https://dev.azure.com/themartinsteinegger/mmseqs2/_apis/build/status/soedinglab.MMseqs2?branchName=master)](https://dev.azure.com/themartinsteinegger/mmseqs2/_build/latest?definitionId=2&branchName=master) <a href=""https://chat.mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install d",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:2844,Usability,learn,learn,2844,"2/releases/latest) [![Biocontainer Pulls](https://img.shields.io/endpoint?url=https%3A%2F%2Fmmseqs.com%2Fbiocontainer.php%3Fcontainer%3Dmmseqs2)](https://biocontainers.pro/#/tools/mmseqs2) [![Build Status](https://dev.azure.com/themartinsteinegger/mmseqs2/_apis/build/status/soedinglab.MMseqs2?branchName=master)](https://dev.azure.com/themartinsteinegger/mmseqs2/_build/latest?definitionId=2&branchName=master) <a href=""https://chat.mmseqs.com/""><img src=""https://chat.mmseqs.com/api/v1/shield.svg?type=online&name=chat&icon=false"" /></a>. <p align=""center""><img src=""https://raw.githubusercontent.com/soedinglab/mmseqs2/master/.github/mmseqs2_logo.png"" height=""256"" /></p>. ## Documentation; The MMseqs2 user guide is available in our [GitHub Wiki](https://github.com/soedinglab/mmseqs2/wiki) or as a [PDF file](https://mmseqs.com/latest/userguide.pdf) (Thanks to [pandoc](https://github.com/jgm/pandoc)!). The wiki also contains [tutorials](https://github.com/soedinglab/MMseqs2/wiki/Tutorials) to learn how to use MMseqs2 with real data. For questions please open an issue on [GitHub](https://github.com/soedinglab/MMseqs2/issues) or ask in our [chat](https://chat.mmseqs.com). ; Keep posted about MMseqs2/Linclust updates by following Martin on [Twitter](https://twitter.com/thesteinegger). ## Installation; MMseqs2 can be used by [compiling from source](https://github.com/soedinglab/MMseqs2/wiki#installation), downloading a statically compiled binary, using [Homebrew](https://github.com/Homebrew/brew), [conda](https://github.com/conda/conda) or [Docker](https://github.com/moby/moby).; ; # install by brew; brew install mmseqs2; # install via conda; conda install -c conda-forge -c bioconda mmseqs2; # install docker; docker pull ghcr.io/soedinglab/mmseqs2; # static build with AVX2 (fastest); wget https://mmseqs.com/latest/mmseqs-linux-avx2.tar.gz; tar xvfz mmseqs-linux-avx2.tar.gz; export PATH=$(pwd)/mmseqs/bin/:$PATH; # static build with SSE4.1; wget https://mmseqs.com/latest/mmseqs-",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:6305,Usability,guid,guide,6305,"rectly with FASTA/FASTQ files as input and output. MMseqs2 provides many modules to transform, filter, execute external programs and search. However, these modules use the MMseqs2 database formats, instead of the FASTA/FASTQ format. For maximum flexibility, we recommend using MMseqs2 workflows and modules directly. Please read more about this in the [documentation](https://github.com/soedinglab/mmseqs2/wiki). ### Cluster. For clustering, MMseqs2 `easy-cluster` and `easy-linclust` are available. `easy-cluster` by default clusters the entries of a FASTA/FASTQ file using a cascaded clustering algorithm.; ; mmseqs easy-cluster examples/DB.fasta clusterRes tmp --min-seq-id 0.5 -c 0.8 --cov-mode 1; ; `easy-linclust` clusters the entries of a FASTA/FASTQ file. The runtime scales linearly with input size. This mode is recommended for huge datasets.; ; mmseqs easy-linclust examples/DB.fasta clusterRes tmp; ; Read more about the [clustering format](https://github.com/soedinglab/mmseqs2/wiki#clustering-format) in our user guide.; ; Please adjust the [clustering criteria](https://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:6522,Usability,guid,guide,6522,"format. For maximum flexibility, we recommend using MMseqs2 workflows and modules directly. Please read more about this in the [documentation](https://github.com/soedinglab/mmseqs2/wiki). ### Cluster. For clustering, MMseqs2 `easy-cluster` and `easy-linclust` are available. `easy-cluster` by default clusters the entries of a FASTA/FASTQ file using a cascaded clustering algorithm.; ; mmseqs easy-cluster examples/DB.fasta clusterRes tmp --min-seq-id 0.5 -c 0.8 --cov-mode 1; ; `easy-linclust` clusters the entries of a FASTA/FASTQ file. The runtime scales linearly with input size. This mode is recommended for huge datasets.; ; mmseqs easy-linclust examples/DB.fasta clusterRes tmp; ; Read more about the [clustering format](https://github.com/soedinglab/mmseqs2/wiki#clustering-format) in our user guide.; ; Please adjust the [clustering criteria](https://github.com/soedinglab/MMseqs2/wiki#clustering-criteria) and check if temporary directory provides enough free space. For disk space requirements, see the user guide. ### Search; ; The `easy-search` workflow searches directly with a FASTA/FASTQ files against either another FASTA/FASTQ file or an already existing MMseqs2 database.; ; mmseqs easy-search examples/QUERY.fasta examples/DB.fasta alnRes.m8 tmp; ; It is also possible to pre-compute the index for the target database. This reduces overhead when searching repeatedly against the same database. mmseqs createdb examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:7910,Usability,guid,guide,7910," examples/DB.fasta targetDB; mmseqs createindex targetDB tmp; mmseqs easy-search examples/QUERY.fasta targetDB alnRes.m8 tmp; ; The `databases` workflow provides download and setup procedures for many public reference databases, such as the Uniref, NR, NT, PFAM and many more (see [Downloading databases](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases)). For example, to download and search against a database containing the Swiss-Prot reference proteins run: . mmseqs databases UniProtKB/Swiss-Prot swissprot tmp; mmseqs easy-search examples/QUERY.fasta swissprot alnRes.m8 tmp; ; The speed and sensitivity of the `search` can be adjusted with `-s` parameter and should be adapted based on your use case (see [setting sensitivity -s parameter](https://github.com/soedinglab/mmseqs2/wiki#set-sensitivity--s-parameter)). A very fast search would use a sensitivity of `-s 1.0`, while a very sensitive search would use a sensitivity of up to `-s 7.0`. A detailed guide how to speed up searches is [here](https://github.com/soedinglab/MMseqs2/wiki#how-to-control-the-speed-of-the-search). The output can be customized with the `--format-output` option e.g. `--format-output ""query,target,qaln,taln""` returns the query and target accession and the pairwise alignments in tab separated format. You can choose many different [output columns](https://github.com/soedinglab/mmseqs2/wiki#custom-alignment-format-with-convertalis). :exclamation: `easy-search` in default computes the sequence identity by dividing the number of identical residues by the alignment length (`numIdentical/alnLen`). However, `search` [estimates](https://github.com/soedinglab/MMseqs2/wiki#how-does-mmseqs2-compute-the-sequence-identity) the identity in default. To output real sequence identity use `--alignment-mode 3` or `-a`. ### Taxonomy; The `easy-taxonomy` workflow can be used to assign sequences taxonomical labels. It performs a search against a sequence database with taxonomy information (seqTaxDb), ch",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md:10227,Usability,guid,guide,10227,"mseqs createindex targetDB tmp; mmseqs easy-taxonomy examples/QUERY.fasta targetDB alnRes tmp. By default, `createtaxdb` assigns a Uniprot accession to a taxonomical identifier to every sequence and downloads the NCBI taxonomy. We also support [BLAST](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-from-an-existing-blast-database), [SILVA](https://github.com/soedinglab/MMseqs2/wiki#create-a-sequence-database-with-taxonomic-information-for-silva) or [custom taxonomical](https://github.com/soedinglab/MMseqs2/wiki#manually-annotate-a-sequence-database-with-taxonomic-information) databases. Many common taxonomic reference databases can be easily downloaded and set up by the [`databases` workflow](https://github.com/soedinglab/mmseqs2/wiki#downloading-databases). Read more about the [taxonomy format](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-format) and the [classification](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) in our user guide. ### Supported search modes. MMseqs2 provides many additional search modes:; * Iterative sequences-profile searches (like PSI-BLAST) with the `--num-iterations` parameter; * [Translated searches](https://github.com/soedinglab/MMseqs2/wiki#translated-sequence-searching) of nucleotides against proteins (blastx), proteins against nucleotides (tblastn) or nucleotide against nucleotide (tblastx); * [Iterative increasing sensitivity searches](https://github.com/soedinglab/MMseqs2/wiki#how-to-find-the-best-hit-the-fastest-way) to find only the best hits faster; * [Taxonomic assignment](https://github.com/soedinglab/MMseqs2/wiki#taxonomy-assignment-using-mmseqs-taxonomy) using 2bLCA or LCA; * Fast ungapped alignment searches to find [very similar sequence matches](https://github.com/soedinglab/MMseqs2/wiki#mapping-very-similar-sequences-using-mmseqs-map); * Very fast and sensitive searches against [profile databases such as the PFAM](https://github.c",MatchSource.DOCS,README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/base64/README.md:175,Testability,test,test,175,"NibbleAndAHalf; ==============. ""Nibble And A Half"" is an ANSI C library that provides fast base64 encoding and decoding, all in a single header file. Wed Apr 17 6:13p; - All test related functions moved to testbase64.h. To use, only need #include ""base64.h"":; https://github.com/superwills/NibbleAndAHalf/blob/master/NibbleAndAHalf/base64.h; ",MatchSource.DOCS,lib/base64/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/base64/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:1210,Availability,avail,available,1210,"ll as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.org/abs/1705.02257) using the BibTeX entry. ```bibtex ; @InProceedings{axtmann2017,; author =	{Michael Axtmann and; Sascha Witt and; Daniel Ferizovic and; Peter Sanders},; title =	{{In-Place Parallel Super Scalar Samplesort (IPSSSSo)}},",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:402,Energy Efficiency,efficient,efficient,402,"# In-place Parallel Super Scalar Samplesort (IPS⁴o). This is the implementation of the algorithm presented in the [eponymous paper](https://arxiv.org/abs/1705.02257),; which contains an in-depth description of its inner workings, as well as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.o",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:267,Performance,perform,performance,267,"# In-place Parallel Super Scalar Samplesort (IPS⁴o). This is the implementation of the algorithm presented in the [eponymous paper](https://arxiv.org/abs/1705.02257),; which contains an in-depth description of its inner workings, as well as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.o",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:396,Performance,cache,cache-efficient,396,"# In-place Parallel Super Scalar Samplesort (IPS⁴o). This is the implementation of the algorithm presented in the [eponymous paper](https://arxiv.org/abs/1705.02257),; which contains an in-depth description of its inner workings, as well as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.o",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:447,Performance,perform,performs,447,"# In-place Parallel Super Scalar Samplesort (IPS⁴o). This is the implementation of the algorithm presented in the [eponymous paper](https://arxiv.org/abs/1705.02257),; which contains an in-depth description of its inner workings, as well as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.o",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:413,Safety,avoid,avoids,413,"# In-place Parallel Super Scalar Samplesort (IPS⁴o). This is the implementation of the algorithm presented in the [eponymous paper](https://arxiv.org/abs/1705.02257),; which contains an in-depth description of its inner workings, as well as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.o",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md:465,Testability,log,log,465,"# In-place Parallel Super Scalar Samplesort (IPS⁴o). This is the implementation of the algorithm presented in the [eponymous paper](https://arxiv.org/abs/1705.02257),; which contains an in-depth description of its inner workings, as well as an extensive experimental performance evaluation.; Here's the abstract:. > We present a sorting algorithm that works in-place, executes in parallel, is; > cache-efficient, avoids branch-mispredictions, and performs work O(n log n) for; > arbitrary inputs with high probability. The main algorithmic contributions are; > new ways to make distribution-based algorithms in-place: On the practical side,; > by using coarse-grained block-based permutations, and on the theoretical side,; > we show how to eliminate the recursion stack. Extensive experiments show that; > our algorithm IPS⁴o scales well on a variety of multi-core machines. We; > outperform our closest in-place competitor by a factor of up to 3. Even as; > a sequential algorithm, we are up to 1.5 times faster than the closest; > sequential competitor, BlockQuicksort. ## Usage. ```C++; #include ""ips4o.hpp"". // sort sequentially; ips4o::sort(begin, end[, comparator]). // sort in parallel (uses OpenMP if available, std::thread otherwise); ips4o::parallel::sort(begin, end[, comparator]); ```. Make sure to compile with C++14 support. Currently, the code does not compile on Windows. For the parallel algorithm, you need to enable either OpenMP (`-fopenmp`) or C++ threads (e.g., `-pthread`).; You also need a CPU that supports 16-byte compare-and-exchange instructions.; If you get undefined references to `__atomic_fetch_add_16`, either set your CPU correctly (e.g., `-march=native`),; enable the instructions explicitly (`-mcx16`), or try linking against GCC's libatomic (`-latomic`). ## Licensing. IPS⁴o is free software provided under the BSD 2-Clause License described in the [LICENSE file](LICENSE). If you use IPS⁴o in an academic setting please cite the [eponymous paper](https://arxiv.o",MatchSource.DOCS,lib/ips4o/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ips4o/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:2921,Availability,avail,available,2921," * [ksw2_extz2_sse.c](ksw2_extz2_sse.c): global and extension with SSE intrinsics; Suzuki's; * [ksw2_extd.c](ksw2_extd.c): global and extension alignment, dual gap cost; Green's formulation; * [ksw2_extd2_sse.c](ksw2_extd2_sse.c): global and extension, dual gap cost, with SSE intrinsics; Suzuki's. Users are encouraged to copy the header file `ksw2.h` and relevant; `ksw2_*.c` file to their own source code trees. On x86 CPUs with SSE2; intrinsics, `ksw2_extz2_sse.c` is recommended in general. It supports global; alignment, alignment extension with Z-drop, score-only alignment, global-only; alignment and right-aligned CIGARs. `ksw2_gg*.c` are mostly for demonstration; and comparison purposes. They are annotated with more comments and easier to; understand than `ksw2_ext*.c`. Header file [ksw2.h](ksw2.h) contains brief; documentations. TeX file [ksw2.tex](tex/ksw2.tex) gives brief derivation. To compile the test program `ksw-test`, just type `make`. It takes the; advantage of SSE4.1 when available. To compile with SSE2 only, use `make; sse2=1` instead. If you have installed [parasail][para], use `make; parasail=prefix`, where `prefix` points to the parasail install directory (e.g.; `/usr/local`). The following shows a complete example about how to use the library.; ```c; #include <string.h>; #include <stdio.h>; #include ""ksw2.h"". void align(const char *tseq, const char *qseq, int sc_mch, int sc_mis, int gapo, int gape); {; 	int i, a = sc_mch, b = sc_mis < 0? sc_mis : -sc_mis; // a>0 and b<0; 	int8_t mat[25] = { a,b,b,b,0, b,a,b,b,0, b,b,a,b,0, b,b,b,a,0, 0,0,0,0,0 };; 	int tl = strlen(tseq), ql = strlen(qseq);; 	uint8_t *ts, *qs, c[256];; 	ksw_extz_t ez;. 	memset(&ez, 0, sizeof(ksw_extz_t));; 	memset(c, 4, 256);; 	c['A'] = c['a'] = 0; c['C'] = c['c'] = 1;; 	c['G'] = c['g'] = 2; c['T'] = c['t'] = 3; // build the encoding table; 	ts = (uint8_t*)malloc(tl);; 	qs = (uint8_t*)malloc(ql);; 	for (i = 0; i < tl; ++i) ts[i] = c[(uint8_t)tseq[i]]; // encode to 0/1/2/3; 	for (i = 0",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:2999,Deployability,install,installed,2999,"l and extension alignment, dual gap cost; Green's formulation; * [ksw2_extd2_sse.c](ksw2_extd2_sse.c): global and extension, dual gap cost, with SSE intrinsics; Suzuki's. Users are encouraged to copy the header file `ksw2.h` and relevant; `ksw2_*.c` file to their own source code trees. On x86 CPUs with SSE2; intrinsics, `ksw2_extz2_sse.c` is recommended in general. It supports global; alignment, alignment extension with Z-drop, score-only alignment, global-only; alignment and right-aligned CIGARs. `ksw2_gg*.c` are mostly for demonstration; and comparison purposes. They are annotated with more comments and easier to; understand than `ksw2_ext*.c`. Header file [ksw2.h](ksw2.h) contains brief; documentations. TeX file [ksw2.tex](tex/ksw2.tex) gives brief derivation. To compile the test program `ksw-test`, just type `make`. It takes the; advantage of SSE4.1 when available. To compile with SSE2 only, use `make; sse2=1` instead. If you have installed [parasail][para], use `make; parasail=prefix`, where `prefix` points to the parasail install directory (e.g.; `/usr/local`). The following shows a complete example about how to use the library.; ```c; #include <string.h>; #include <stdio.h>; #include ""ksw2.h"". void align(const char *tseq, const char *qseq, int sc_mch, int sc_mis, int gapo, int gape); {; 	int i, a = sc_mch, b = sc_mis < 0? sc_mis : -sc_mis; // a>0 and b<0; 	int8_t mat[25] = { a,b,b,b,0, b,a,b,b,0, b,b,a,b,0, b,b,b,a,0, 0,0,0,0,0 };; 	int tl = strlen(tseq), ql = strlen(qseq);; 	uint8_t *ts, *qs, c[256];; 	ksw_extz_t ez;. 	memset(&ez, 0, sizeof(ksw_extz_t));; 	memset(c, 4, 256);; 	c['A'] = c['a'] = 0; c['C'] = c['c'] = 1;; 	c['G'] = c['g'] = 2; c['T'] = c['t'] = 3; // build the encoding table; 	ts = (uint8_t*)malloc(tl);; 	qs = (uint8_t*)malloc(ql);; 	for (i = 0; i < tl; ++i) ts[i] = c[(uint8_t)tseq[i]]; // encode to 0/1/2/3; 	for (i = 0; i < ql; ++i) qs[i] = c[(uint8_t)qseq[i]];; 	ksw_extz(0, ql, qs, tl, ts, 5, mat, gapo, gape, -1, -1, 0, &ez);; 	for (i = 0; i <",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:3094,Deployability,install,install,3094,"l and extension alignment, dual gap cost; Green's formulation; * [ksw2_extd2_sse.c](ksw2_extd2_sse.c): global and extension, dual gap cost, with SSE intrinsics; Suzuki's. Users are encouraged to copy the header file `ksw2.h` and relevant; `ksw2_*.c` file to their own source code trees. On x86 CPUs with SSE2; intrinsics, `ksw2_extz2_sse.c` is recommended in general. It supports global; alignment, alignment extension with Z-drop, score-only alignment, global-only; alignment and right-aligned CIGARs. `ksw2_gg*.c` are mostly for demonstration; and comparison purposes. They are annotated with more comments and easier to; understand than `ksw2_ext*.c`. Header file [ksw2.h](ksw2.h) contains brief; documentations. TeX file [ksw2.tex](tex/ksw2.tex) gives brief derivation. To compile the test program `ksw-test`, just type `make`. It takes the; advantage of SSE4.1 when available. To compile with SSE2 only, use `make; sse2=1` instead. If you have installed [parasail][para], use `make; parasail=prefix`, where `prefix` points to the parasail install directory (e.g.; `/usr/local`). The following shows a complete example about how to use the library.; ```c; #include <string.h>; #include <stdio.h>; #include ""ksw2.h"". void align(const char *tseq, const char *qseq, int sc_mch, int sc_mis, int gapo, int gape); {; 	int i, a = sc_mch, b = sc_mis < 0? sc_mis : -sc_mis; // a>0 and b<0; 	int8_t mat[25] = { a,b,b,b,0, b,a,b,b,0, b,b,a,b,0, b,b,b,a,0, 0,0,0,0,0 };; 	int tl = strlen(tseq), ql = strlen(qseq);; 	uint8_t *ts, *qs, c[256];; 	ksw_extz_t ez;. 	memset(&ez, 0, sizeof(ksw_extz_t));; 	memset(c, 4, 256);; 	c['A'] = c['a'] = 0; c['C'] = c['c'] = 1;; 	c['G'] = c['g'] = 2; c['T'] = c['t'] = 3; // build the encoding table; 	ts = (uint8_t*)malloc(tl);; 	qs = (uint8_t*)malloc(ql);; 	for (i = 0; i < tl; ++i) ts[i] = c[(uint8_t)tseq[i]]; // encode to 0/1/2/3; 	for (i = 0; i < ql; ++i) qs[i] = c[(uint8_t)qseq[i]];; 	ksw_extz(0, ql, qs, tl, ts, 5, mat, gapo, gape, -1, -1, 0, &ez);; 	for (i = 0; i <",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:5833,Energy Efficiency,reduce,reduces,5833,"parasail|; | |-t ps\_nw\_diag\_32 |3.0 |N |N |SSE4|parasail|; | |-t ps\_nw\_scan\_32 |3.0 |N |N |SSE4|parasail|; | |-t extz2\_sse -sg |0.96 |N |N |SSE2|ksw2 |; | |-t extz2\_sse -sg |0.84 |N |N |SSE4|ksw2 |; | |-t extz2\_sse -s |3.0 |N |Y |SSE2|ksw2 |; | |-t extz2\_sse -s |2.7 |N |Y |SSE4|ksw2 |; |16.5k |-t gg -s |0.84 |N |N |N |ksw2 |; | |-t gg |1.6 |Y |N |N |ksw2 |; | |-t gg2 |3.3 |Y |N |N |ksw2 |; | |-t extz |2.0 |Y |Y |N |ksw2 |; | |-t extz2\_sse |0.40 |Y |Y |SSE4|ksw2 |; | |-t extz2\_sse -g |0.18 |Y |N |SSE4|ksw2 |. The standard DP formulation is about twice as fast as Suzuki's diagonal; formulation (`-tgg` vs `-tgg2`), but SSE-based diagonal formulation; is several times faster than the standard DP. If we only want to compute one; global alignment score, we can use 16-way parallelization in the entire inner; loop. For extension alignment, though, we need to keep an array of 32-bit; scores and have to use 4-way parallelization for part of the inner loop. This; significantly reduces performance (`-sg` vs `-s`). KSW2 is faster than; parasail partly because the former uses one score for all matches and another; score for all mismatches. For diagonal formulations, vectorization is more; complex given a generic scoring matrix. It is possible to further accelerate global alignment with dynamic banding as; is implemented in [edlib][edlib]. However, it is not as effective for extension; alignment. Another idea is [adaptive banding][adap-band], which might be worth; trying at some point. ## Alternative Libraries. |Library |CIGAR|Intra-seq|Affine-gap|Local |Global |Glocal |Extension|; |:---------------|:---:|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|; |[edlib][edlib] |Yes |Yes |No |Very fast|Very fast|Very fast|N/A |; |[KSW][klib] |Yes |Yes |Yes |Fast |Slow |N/A |Slow |; |KSW2 |Yes |Yes |Yes/dual |N/A |Fast |N/A |Fast |; |[libgaba][gaba] |Yes |Yes |Yes |N/A? |N/A? |N/A? |Fast |; |[libssa][ssa] |No |No? |Yes |Fast |Fast |N/A |N/A |; |[Opal][opal] |No |No ",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:6274,Energy Efficiency,adapt,adaptive,6274,"Y |Y |SSE4|ksw2 |; | |-t extz2\_sse -g |0.18 |Y |N |SSE4|ksw2 |. The standard DP formulation is about twice as fast as Suzuki's diagonal; formulation (`-tgg` vs `-tgg2`), but SSE-based diagonal formulation; is several times faster than the standard DP. If we only want to compute one; global alignment score, we can use 16-way parallelization in the entire inner; loop. For extension alignment, though, we need to keep an array of 32-bit; scores and have to use 4-way parallelization for part of the inner loop. This; significantly reduces performance (`-sg` vs `-s`). KSW2 is faster than; parasail partly because the former uses one score for all matches and another; score for all mismatches. For diagonal formulations, vectorization is more; complex given a generic scoring matrix. It is possible to further accelerate global alignment with dynamic banding as; is implemented in [edlib][edlib]. However, it is not as effective for extension; alignment. Another idea is [adaptive banding][adap-band], which might be worth; trying at some point. ## Alternative Libraries. |Library |CIGAR|Intra-seq|Affine-gap|Local |Global |Glocal |Extension|; |:---------------|:---:|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|; |[edlib][edlib] |Yes |Yes |No |Very fast|Very fast|Very fast|N/A |; |[KSW][klib] |Yes |Yes |Yes |Fast |Slow |N/A |Slow |; |KSW2 |Yes |Yes |Yes/dual |N/A |Fast |N/A |Fast |; |[libgaba][gaba] |Yes |Yes |Yes |N/A? |N/A? |N/A? |Fast |; |[libssa][ssa] |No |No? |Yes |Fast |Fast |N/A |N/A |; |[Opal][opal] |No |No |Yes |Fast |Fast |Fast |N/A |; |[Parasail][para]|No |Yes |Yes |Fast |Fast |Fast |N/A |; |[SeqAn][seqan] |Yes |Yes |Yes |Slow |Slow |Slow |N/A |; |[SSW][ssw] |Yes |Yes |Yes |Fast |N/A |N/A |N/A |; |[SWIPE][swipe] |Yes |No |Yes |Fast |N/A? |N/A? |N/A |; |[SWPS3][swps3] |No |Yes |Yes |Fast |N/A? |N/A |N/A |. [hs]: https://github.com/ocxtal; [hs-eq]: https://github.com/ocxtal/diffbench; [edlib]: https://github.com/Martinsos/edlib; [klib]: https://github.com/att",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:7612,Energy Efficiency,adapt,adaptivebandbench,7612,"rformance (`-sg` vs `-s`). KSW2 is faster than; parasail partly because the former uses one score for all matches and another; score for all mismatches. For diagonal formulations, vectorization is more; complex given a generic scoring matrix. It is possible to further accelerate global alignment with dynamic banding as; is implemented in [edlib][edlib]. However, it is not as effective for extension; alignment. Another idea is [adaptive banding][adap-band], which might be worth; trying at some point. ## Alternative Libraries. |Library |CIGAR|Intra-seq|Affine-gap|Local |Global |Glocal |Extension|; |:---------------|:---:|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|; |[edlib][edlib] |Yes |Yes |No |Very fast|Very fast|Very fast|N/A |; |[KSW][klib] |Yes |Yes |Yes |Fast |Slow |N/A |Slow |; |KSW2 |Yes |Yes |Yes/dual |N/A |Fast |N/A |Fast |; |[libgaba][gaba] |Yes |Yes |Yes |N/A? |N/A? |N/A? |Fast |; |[libssa][ssa] |No |No? |Yes |Fast |Fast |N/A |N/A |; |[Opal][opal] |No |No |Yes |Fast |Fast |Fast |N/A |; |[Parasail][para]|No |Yes |Yes |Fast |Fast |Fast |N/A |; |[SeqAn][seqan] |Yes |Yes |Yes |Slow |Slow |Slow |N/A |; |[SSW][ssw] |Yes |Yes |Yes |Fast |N/A |N/A |N/A |; |[SWIPE][swipe] |Yes |No |Yes |Fast |N/A? |N/A? |N/A |; |[SWPS3][swps3] |No |Yes |Yes |Fast |N/A? |N/A |N/A |. [hs]: https://github.com/ocxtal; [hs-eq]: https://github.com/ocxtal/diffbench; [edlib]: https://github.com/Martinsos/edlib; [klib]: https://github.com/attractivechaos/klib; [para]: https://github.com/jeffdaily/parasail; [opal]: https://github.com/Martinsos/opal; [ssw]: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library; [ssa]: https://github.com/RonnySoak/libssa; [gaba]: https://github.com/ocxtal/libgaba; [adap-band]: https://github.com/ocxtal/adaptivebandbench; [swipe]: https://github.com/torognes/swipe; [swps3]: http://lab.dessimoz.org/swps3/; [seqan]: http://seqan.de; [piece-affine]: https://www.ncbi.nlm.nih.gov/pubmed/2165832; [mm2]: https://github.com/lh3/minimap2; ",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:6274,Modifiability,adapt,adaptive,6274,"Y |Y |SSE4|ksw2 |; | |-t extz2\_sse -g |0.18 |Y |N |SSE4|ksw2 |. The standard DP formulation is about twice as fast as Suzuki's diagonal; formulation (`-tgg` vs `-tgg2`), but SSE-based diagonal formulation; is several times faster than the standard DP. If we only want to compute one; global alignment score, we can use 16-way parallelization in the entire inner; loop. For extension alignment, though, we need to keep an array of 32-bit; scores and have to use 4-way parallelization for part of the inner loop. This; significantly reduces performance (`-sg` vs `-s`). KSW2 is faster than; parasail partly because the former uses one score for all matches and another; score for all mismatches. For diagonal formulations, vectorization is more; complex given a generic scoring matrix. It is possible to further accelerate global alignment with dynamic banding as; is implemented in [edlib][edlib]. However, it is not as effective for extension; alignment. Another idea is [adaptive banding][adap-band], which might be worth; trying at some point. ## Alternative Libraries. |Library |CIGAR|Intra-seq|Affine-gap|Local |Global |Glocal |Extension|; |:---------------|:---:|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|; |[edlib][edlib] |Yes |Yes |No |Very fast|Very fast|Very fast|N/A |; |[KSW][klib] |Yes |Yes |Yes |Fast |Slow |N/A |Slow |; |KSW2 |Yes |Yes |Yes/dual |N/A |Fast |N/A |Fast |; |[libgaba][gaba] |Yes |Yes |Yes |N/A? |N/A? |N/A? |Fast |; |[libssa][ssa] |No |No? |Yes |Fast |Fast |N/A |N/A |; |[Opal][opal] |No |No |Yes |Fast |Fast |Fast |N/A |; |[Parasail][para]|No |Yes |Yes |Fast |Fast |Fast |N/A |; |[SeqAn][seqan] |Yes |Yes |Yes |Slow |Slow |Slow |N/A |; |[SSW][ssw] |Yes |Yes |Yes |Fast |N/A |N/A |N/A |; |[SWIPE][swipe] |Yes |No |Yes |Fast |N/A? |N/A? |N/A |; |[SWPS3][swps3] |No |Yes |Yes |Fast |N/A? |N/A |N/A |. [hs]: https://github.com/ocxtal; [hs-eq]: https://github.com/ocxtal/diffbench; [edlib]: https://github.com/Martinsos/edlib; [klib]: https://github.com/att",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:7612,Modifiability,adapt,adaptivebandbench,7612,"rformance (`-sg` vs `-s`). KSW2 is faster than; parasail partly because the former uses one score for all matches and another; score for all mismatches. For diagonal formulations, vectorization is more; complex given a generic scoring matrix. It is possible to further accelerate global alignment with dynamic banding as; is implemented in [edlib][edlib]. However, it is not as effective for extension; alignment. Another idea is [adaptive banding][adap-band], which might be worth; trying at some point. ## Alternative Libraries. |Library |CIGAR|Intra-seq|Affine-gap|Local |Global |Glocal |Extension|; |:---------------|:---:|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|; |[edlib][edlib] |Yes |Yes |No |Very fast|Very fast|Very fast|N/A |; |[KSW][klib] |Yes |Yes |Yes |Fast |Slow |N/A |Slow |; |KSW2 |Yes |Yes |Yes/dual |N/A |Fast |N/A |Fast |; |[libgaba][gaba] |Yes |Yes |Yes |N/A? |N/A? |N/A? |Fast |; |[libssa][ssa] |No |No? |Yes |Fast |Fast |N/A |N/A |; |[Opal][opal] |No |No |Yes |Fast |Fast |Fast |N/A |; |[Parasail][para]|No |Yes |Yes |Fast |Fast |Fast |N/A |; |[SeqAn][seqan] |Yes |Yes |Yes |Slow |Slow |Slow |N/A |; |[SSW][ssw] |Yes |Yes |Yes |Fast |N/A |N/A |N/A |; |[SWIPE][swipe] |Yes |No |Yes |Fast |N/A? |N/A? |N/A |; |[SWPS3][swps3] |No |Yes |Yes |Fast |N/A? |N/A |N/A |. [hs]: https://github.com/ocxtal; [hs-eq]: https://github.com/ocxtal/diffbench; [edlib]: https://github.com/Martinsos/edlib; [klib]: https://github.com/attractivechaos/klib; [para]: https://github.com/jeffdaily/parasail; [opal]: https://github.com/Martinsos/opal; [ssw]: https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library; [ssa]: https://github.com/RonnySoak/libssa; [gaba]: https://github.com/ocxtal/libgaba; [adap-band]: https://github.com/ocxtal/adaptivebandbench; [swipe]: https://github.com/torognes/swipe; [swps3]: http://lab.dessimoz.org/swps3/; [seqan]: http://seqan.de; [piece-affine]: https://www.ncbi.nlm.nih.gov/pubmed/2165832; [mm2]: https://github.com/lh3/minimap2; ",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:5841,Performance,perform,performance,5841,"parasail|; | |-t ps\_nw\_diag\_32 |3.0 |N |N |SSE4|parasail|; | |-t ps\_nw\_scan\_32 |3.0 |N |N |SSE4|parasail|; | |-t extz2\_sse -sg |0.96 |N |N |SSE2|ksw2 |; | |-t extz2\_sse -sg |0.84 |N |N |SSE4|ksw2 |; | |-t extz2\_sse -s |3.0 |N |Y |SSE2|ksw2 |; | |-t extz2\_sse -s |2.7 |N |Y |SSE4|ksw2 |; |16.5k |-t gg -s |0.84 |N |N |N |ksw2 |; | |-t gg |1.6 |Y |N |N |ksw2 |; | |-t gg2 |3.3 |Y |N |N |ksw2 |; | |-t extz |2.0 |Y |Y |N |ksw2 |; | |-t extz2\_sse |0.40 |Y |Y |SSE4|ksw2 |; | |-t extz2\_sse -g |0.18 |Y |N |SSE4|ksw2 |. The standard DP formulation is about twice as fast as Suzuki's diagonal; formulation (`-tgg` vs `-tgg2`), but SSE-based diagonal formulation; is several times faster than the standard DP. If we only want to compute one; global alignment score, we can use 16-way parallelization in the entire inner; loop. For extension alignment, though, we need to keep an array of 32-bit; scores and have to use 4-way parallelization for part of the inner loop. This; significantly reduces performance (`-sg` vs `-s`). KSW2 is faster than; parasail partly because the former uses one score for all matches and another; score for all mismatches. For diagonal formulations, vectorization is more; complex given a generic scoring matrix. It is possible to further accelerate global alignment with dynamic banding as; is implemented in [edlib][edlib]. However, it is not as effective for extension; alignment. Another idea is [adaptive banding][adap-band], which might be worth; trying at some point. ## Alternative Libraries. |Library |CIGAR|Intra-seq|Affine-gap|Local |Global |Glocal |Extension|; |:---------------|:---:|:-------:|:--------:|:-------:|:-------:|:-------:|:-------:|; |[edlib][edlib] |Yes |Yes |No |Very fast|Very fast|Very fast|N/A |; |[KSW][klib] |Yes |Yes |Yes |Fast |Slow |N/A |Slow |; |KSW2 |Yes |Yes |Yes/dual |N/A |Fast |N/A |Fast |; |[libgaba][gaba] |Yes |Yes |Yes |N/A? |N/A? |N/A? |Fast |; |[libssa][ssa] |No |No? |Yes |Fast |Fast |N/A |N/A |; |[Opal][opal] |No |No ",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:2839,Testability,test,test,2839,".c](ksw2_extz.c): global and extension alignment; Green's formulation; * [ksw2_extz2_sse.c](ksw2_extz2_sse.c): global and extension with SSE intrinsics; Suzuki's; * [ksw2_extd.c](ksw2_extd.c): global and extension alignment, dual gap cost; Green's formulation; * [ksw2_extd2_sse.c](ksw2_extd2_sse.c): global and extension, dual gap cost, with SSE intrinsics; Suzuki's. Users are encouraged to copy the header file `ksw2.h` and relevant; `ksw2_*.c` file to their own source code trees. On x86 CPUs with SSE2; intrinsics, `ksw2_extz2_sse.c` is recommended in general. It supports global; alignment, alignment extension with Z-drop, score-only alignment, global-only; alignment and right-aligned CIGARs. `ksw2_gg*.c` are mostly for demonstration; and comparison purposes. They are annotated with more comments and easier to; understand than `ksw2_ext*.c`. Header file [ksw2.h](ksw2.h) contains brief; documentations. TeX file [ksw2.tex](tex/ksw2.tex) gives brief derivation. To compile the test program `ksw-test`, just type `make`. It takes the; advantage of SSE4.1 when available. To compile with SSE2 only, use `make; sse2=1` instead. If you have installed [parasail][para], use `make; parasail=prefix`, where `prefix` points to the parasail install directory (e.g.; `/usr/local`). The following shows a complete example about how to use the library.; ```c; #include <string.h>; #include <stdio.h>; #include ""ksw2.h"". void align(const char *tseq, const char *qseq, int sc_mch, int sc_mis, int gapo, int gape); {; 	int i, a = sc_mch, b = sc_mis < 0? sc_mis : -sc_mis; // a>0 and b<0; 	int8_t mat[25] = { a,b,b,b,0, b,a,b,b,0, b,b,a,b,0, b,b,b,a,0, 0,0,0,0,0 };; 	int tl = strlen(tseq), ql = strlen(qseq);; 	uint8_t *ts, *qs, c[256];; 	ksw_extz_t ez;. 	memset(&ez, 0, sizeof(ksw_extz_t));; 	memset(c, 4, 256);; 	c['A'] = c['a'] = 0; c['C'] = c['c'] = 1;; 	c['G'] = c['g'] = 2; c['T'] = c['t'] = 3; // build the encoding table; 	ts = (uint8_t*)malloc(tl);; 	qs = (uint8_t*)malloc(ql);; 	for (i = 0; i < ",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:2857,Testability,test,test,2857,".c](ksw2_extz.c): global and extension alignment; Green's formulation; * [ksw2_extz2_sse.c](ksw2_extz2_sse.c): global and extension with SSE intrinsics; Suzuki's; * [ksw2_extd.c](ksw2_extd.c): global and extension alignment, dual gap cost; Green's formulation; * [ksw2_extd2_sse.c](ksw2_extd2_sse.c): global and extension, dual gap cost, with SSE intrinsics; Suzuki's. Users are encouraged to copy the header file `ksw2.h` and relevant; `ksw2_*.c` file to their own source code trees. On x86 CPUs with SSE2; intrinsics, `ksw2_extz2_sse.c` is recommended in general. It supports global; alignment, alignment extension with Z-drop, score-only alignment, global-only; alignment and right-aligned CIGARs. `ksw2_gg*.c` are mostly for demonstration; and comparison purposes. They are annotated with more comments and easier to; understand than `ksw2_ext*.c`. Header file [ksw2.h](ksw2.h) contains brief; documentations. TeX file [ksw2.tex](tex/ksw2.tex) gives brief derivation. To compile the test program `ksw-test`, just type `make`. It takes the; advantage of SSE4.1 when available. To compile with SSE2 only, use `make; sse2=1` instead. If you have installed [parasail][para], use `make; parasail=prefix`, where `prefix` points to the parasail install directory (e.g.; `/usr/local`). The following shows a complete example about how to use the library.; ```c; #include <string.h>; #include <stdio.h>; #include ""ksw2.h"". void align(const char *tseq, const char *qseq, int sc_mch, int sc_mis, int gapo, int gape); {; 	int i, a = sc_mch, b = sc_mis < 0? sc_mis : -sc_mis; // a>0 and b<0; 	int8_t mat[25] = { a,b,b,b,0, b,a,b,b,0, b,b,a,b,0, b,b,b,a,0, 0,0,0,0,0 };; 	int tl = strlen(tseq), ql = strlen(qseq);; 	uint8_t *ts, *qs, c[256];; 	ksw_extz_t ez;. 	memset(&ez, 0, sizeof(ksw_extz_t));; 	memset(c, 4, 256);; 	c['A'] = c['a'] = 0; c['C'] = c['c'] = 1;; 	c['G'] = c['g'] = 2; c['T'] = c['t'] = 3; // build the encoding table; 	ts = (uint8_t*)malloc(tl);; 	qs = (uint8_t*)malloc(ql);; 	for (i = 0; i < ",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md:4419,Testability,test,test,4419,"= sc_mis < 0? sc_mis : -sc_mis; // a>0 and b<0; 	int8_t mat[25] = { a,b,b,b,0, b,a,b,b,0, b,b,a,b,0, b,b,b,a,0, 0,0,0,0,0 };; 	int tl = strlen(tseq), ql = strlen(qseq);; 	uint8_t *ts, *qs, c[256];; 	ksw_extz_t ez;. 	memset(&ez, 0, sizeof(ksw_extz_t));; 	memset(c, 4, 256);; 	c['A'] = c['a'] = 0; c['C'] = c['c'] = 1;; 	c['G'] = c['g'] = 2; c['T'] = c['t'] = 3; // build the encoding table; 	ts = (uint8_t*)malloc(tl);; 	qs = (uint8_t*)malloc(ql);; 	for (i = 0; i < tl; ++i) ts[i] = c[(uint8_t)tseq[i]]; // encode to 0/1/2/3; 	for (i = 0; i < ql; ++i) qs[i] = c[(uint8_t)qseq[i]];; 	ksw_extz(0, ql, qs, tl, ts, 5, mat, gapo, gape, -1, -1, 0, &ez);; 	for (i = 0; i < ez.n_cigar; ++i) // print CIGAR; 		printf(""%d%c"", ez.cigar[i]>>4, ""MID""[ez.cigar[i]&0xf]);; 	putchar('\n');; 	free(ez.cigar); free(ts); free(qs);; }. int main(int argc, char *argv[]); {; 	align(""ATAGCTAGCTAGCAT"", ""AGCTAcCGCAT"", 1, -2, 2, 1);; 	return 0;; }; ```. ## Performance Analysis. The following table shows timing on two pairs of long sequences (both in the; ""test"" directory). |Data set|Command line options |Time (s)|CIGAR|Ext|SIMD|Source |; |:-------|:--------------------------------|:-------|:---:|:-:|:--:|:-------|; |50k |-t gg -s |7.3 |N |N |N |ksw2 |; | |-t gg2 -s |19.8 |N |N |N |ksw2 |; | |-t extz -s |9.2 |N |Y |N |ksw2 |; | |-t ps\_nw |9.8 |N |N |N |parasail|; | |-t ps\_nw\_striped\_sse2\_128\_32|2.9 |N |N |SSE2|parasail|; | |-t ps\_nw\_striped\_32 |2.2 |N |N |SSE4|parasail|; | |-t ps\_nw\_diag\_32 |3.0 |N |N |SSE4|parasail|; | |-t ps\_nw\_scan\_32 |3.0 |N |N |SSE4|parasail|; | |-t extz2\_sse -sg |0.96 |N |N |SSE2|ksw2 |; | |-t extz2\_sse -sg |0.84 |N |N |SSE4|ksw2 |; | |-t extz2\_sse -s |3.0 |N |Y |SSE2|ksw2 |; | |-t extz2\_sse -s |2.7 |N |Y |SSE4|ksw2 |; |16.5k |-t gg -s |0.84 |N |N |N |ksw2 |; | |-t gg |1.6 |Y |N |N |ksw2 |; | |-t gg2 |3.3 |Y |N |N |ksw2 |; | |-t extz |2.0 |Y |Y |N |ksw2 |; | |-t extz2\_sse |0.40 |Y |Y |SSE4|ksw2 |; | |-t extz2\_sse -g |0.18 |Y |N |SSE4|ksw2 |. The standard DP formul",MatchSource.DOCS,lib/ksw2/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/microtar/README.md:74,Energy Efficiency,adapt,adapted,74,# microtar; A lightweight tar library written in ANSI C. This library was adapted from the original microtar (https://github.com/rxi/microtar) ; to be read-only and support fast seeking. ## License; This library is free software; you can redistribute it and/or modify it under; the terms of the MIT license. See [LICENSE](LICENSE) for details.; ,MatchSource.DOCS,lib/microtar/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/microtar/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/microtar/README.md:74,Modifiability,adapt,adapted,74,# microtar; A lightweight tar library written in ANSI C. This library was adapted from the original microtar (https://github.com/rxi/microtar) ; to be read-only and support fast seeking. ## License; This library is free software; you can redistribute it and/or modify it under; the terms of the MIT license. See [LICENSE](LICENSE) for details.; ,MatchSource.DOCS,lib/microtar/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/microtar/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1481,Availability,error,error,1481,"the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound varia",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1584,Availability,error,error,1584,"the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound varia",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1732,Availability,error,error,1732,"e and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_comp",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1843,Availability,error,error,1843,"s and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without var",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1885,Availability,error,error,1885,"arly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1949,Availability,error,error,1949,"arly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1986,Availability,error,error,1986,"arly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1995,Availability,failure,failure,1995,"arly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2014,Availability,error,error,2014,"arly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2068,Availability,error,error,2068,"uilding. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finishe",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2160,Availability,error,error,2160,"r, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2183,Availability,error,error,2183,"r, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2236,Availability,error,error,2236,"nimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /*",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2260,Availability,error,error,2260,"nimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /*",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2419,Availability,error,error,2419,"TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2688,Availability,failure,failure,2688,". `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2762,Availability,error,error,2762,". `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2798,Availability,error,error,2798,". `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:3532,Availability,error,error,3532,"sion with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n""",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:3689,Availability,error,error,3689,"n 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; E",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:4205,Availability,error,errors,4205,"e_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; Evaluating:; sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:4581,Availability,error,error,4581,"tf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; Evaluating:; sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:8164,Availability,avail,available,8164,"ion; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constants are available:. - `pi`, `e`. ## Compile-time options. By default, TinyExpr does exponentiation from left to right. For example:. `a^b^c == (a^b)^c` and `-a^b == (-a)^b`. This is by design. It's the way that spreadsheets do it (e.g. Excel, Google Sheets). If you would rather have exponentiation work from right to left, you need to; define `TE_POW_FROM_RIGHT` when compiling `tinyexpr.c`. There is a; commented-out define near the top of that file. With this option enabled, the; behaviour is:. `a^b^c == a^(b^c)` and `-a^b == -(a^b)`. That will match how many scripting languages do it (e.g. Python, Ruby). Also, if you'd like `log` to default to the natural log instead of `log10`,; then you can define `TE_NAT_LOG`. ## Hints. - All functions/types start with the letters *te*. - To allow constant optimization, surround constant expressions in parentheses.; For example ""x+(1+5)"" will evaluate the ""(1+5)"" expression at compile time and; compile the entire expression as ""x+6"", saving a ru",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:989,Deployability,integrat,integrate,989,"](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*e",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:4396,Energy Efficiency,efficient,efficient,4396,"s 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; Evaluating:; sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x +",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6824,Energy Efficiency,power,power,6824,"the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6837,Energy Efficiency,power,power,6837,"the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6847,Energy Efficiency,power,power,6847,"the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6955,Energy Efficiency,power,power,6955,"the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:642,Integrability,depend,dependencies,642,"[![Build Status](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failur",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:989,Integrability,integrat,integrate,989,"](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*e",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:599,Modifiability,variab,variables,599,"[![Build Status](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failur",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:854,Modifiability,variab,variables,854,"[![Build Status](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failur",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:884,Modifiability,variab,variables,884,"[![Build Status](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failur",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1553,Modifiability,variab,variables,1553,"the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound varia",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2542,Modifiability,variab,variables,2542,"ariable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2567,Modifiability,variab,variable,2567,"ariable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:2846,Modifiability,variab,variables,2846,"()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (a",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:3029,Modifiability,variab,variable,3029,"d set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:3149,Modifiability,variab,variable,3149,"p(""(5+5)"", &error); /* Returns 10, error is set to 0. */; double c = te_interp(""(5+5"", &error); /* Returns NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:3269,Modifiability,variab,variables,3269,"s NaN, error is set to 4. */; ```. ## te_compile, te_eval, te_free; ```C; te_expr *te_compile(const char *expression, const te_variable *lookup, int lookup_len, int *error);; double te_eval(const te_expr *n);; void te_free(te_expr *n);; ```. Give `te_compile()` an expression with unbound variables and a list of; variable names and pointers. `te_compile()` will return a `te_expr*` which can; be evaluated later using `te_eval()`. On failure, `te_compile()` will return 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(ex",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:3718,Modifiability,variab,variables,3718,"n 0; and optionally set the passed in `*error` to the location of the parse error. You may also compile expressions without variables by passing `te_compile()`'s second; and thrid arguments as 0. Give `te_eval()` a `te_expr*` from `te_compile()`. `te_eval()` will evaluate the expression; using the current variable values. After you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; E",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:4046,Modifiability,variab,variables,4046,"r you're finished, make sure to call `te_free()`. **example usage:**. ```C; double x, y;; /* Store variable names and pointers. */; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. int err;; /* Compile the expression with variables. */; te_expr *expr = te_compile(""sqrt(x^2+y^2)"", vars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; Evaluating:; sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers t",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:4297,Modifiability,variab,variables,4297,"ars, 2, &err);. if (expr) {; x = 3; y = 4;; const double h1 = te_eval(expr); /* Returns 5. */. x = 5; y = 12;; const double h2 = te_eval(expr); /* Returns 13. */. te_free(expr);; } else {; printf(""Parse error at %d\n"", err);; }. ```. ## Longer Example. Here is a complete example that will evaluate an expression passed in from the command; line. It also does error checking and binds the variables `x` and `y` to *3* and *4*, respectively. ```C; #include ""tinyexpr.h""; #include <stdio.h>. int main(int argc, char *argv[]); {; if (argc < 2) {; printf(""Usage: example2 \""expression\""\n"");; return 0;; }. const char *expression = argv[1];; printf(""Evaluating:\n\t%s\n"", expression);. /* This shows an example where the variables; * x and y are bound at eval-time. */; double x, y;; te_variable vars[] = {{""x"", &x}, {""y"", &y}};. /* This will compile the expression and check for errors. */; int err;; te_expr *n = te_compile(expression, vars, 2, &err);. if (n) {; /* The variables can be changed here, and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; Evaluating:; sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:5713,Modifiability,variab,variables,5713,"sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes constant branches. In this example,; the compiled expression returned by `te_compile()` would become:. ![example syntax tree](doc/e2.png?raw=true). `te_eval()` will automatically load in any variables by their pointer, and then evaluate; and return the result of the expression. `te_free()` should always be called when you're done with the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6902,Modifiability,variab,variable,6902,"the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:7082,Modifiability,variab,variable,7082,"nvolves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constant",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:5701,Performance,load,load,5701,"sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes constant branches. In this example,; the compiled expression returned by `te_compile()` would become:. ![example syntax tree](doc/e2.png?raw=true). `te_eval()` will automatically load in any variables by their pointer, and then evaluate; and return the result of the expression. `te_free()` should always be called when you're done with the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6210,Performance,perform,performance,6210,"mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes constant branches. In this example,; the compiled expression returned by `te_compile()` would become:. ![example syntax tree](doc/e2.png?raw=true). `te_eval()` will automatically load in any variables by their pointer, and then evaluate; and return the result of the expression. `te_free()` should always be called when you're done with the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:8960,Performance,optimiz,optimization,8960," *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constants are available:. - `pi`, `e`. ## Compile-time options. By default, TinyExpr does exponentiation from left to right. For example:. `a^b^c == (a^b)^c` and `-a^b == (-a)^b`. This is by design. It's the way that spreadsheets do it (e.g. Excel, Google Sheets). If you would rather have exponentiation work from right to left, you need to; define `TE_POW_FROM_RIGHT` when compiling `tinyexpr.c`. There is a; commented-out define near the top of that file. With this option enabled, the; behaviour is:. `a^b^c == a^(b^c)` and `-a^b == -(a^b)`. That will match how many scripting languages do it (e.g. Python, Ruby). Also, if you'd like `log` to default to the natural log instead of `log10`,; then you can define `TE_NAT_LOG`. ## Hints. - All functions/types start with the letters *te*. - To allow constant optimization, surround constant expressions in parentheses.; For example ""x+(1+5)"" will evaluate the ""(1+5)"" expression at compile time and; compile the entire expression as ""x+6"", saving a runtime calculation. The; parentheses are important, because TinyExpr will not change the order of; evaluation. If you instead compiled ""x+1+5"" TinyExpr will insist that ""1"" is; added to ""x"" first, and ""5"" is added the result second. ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1024,Safety,safe,safe,1024,"](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*e",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:138,Testability,log,logo,138,"[![Build Status](https://travis-ci.org/codeplea/tinyexpr.svg?branch=master)](https://travis-ci.org/codeplea/tinyexpr). <img alt=""TinyExpr logo"" src=""https://codeplea.com/public/content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failur",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6257,Testability,benchmark,benchmark,6257,"mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes constant branches. In this example,; the compiled expression returned by `te_compile()` would become:. ![example syntax tree](doc/e2.png?raw=true). `te_eval()` will automatically load in any variables by their pointer, and then evaluate; and return the result of the expression. `te_free()` should always be called when you're done with the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:7840,Testability,log,log,7840,"wer>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constants are available:. - `pi`, `e`. ## Compile-time options. By default, TinyExpr does exponentiation from left to right. For example:. `a^b^c == (a^b)^c` and `-a^b == (-a)^b`. This is by design. It's the way that spreadsheets do it (e.g. Excel, Google Sheets). If you would rather have exponentiation work from right to left, you need to; define `TE_POW_FROM_RIGHT` when compiling `tinyexpr.c`. There is a; commented-out define near the top of that file. With this option enabled, the; behaviour is:. `a^b^c == a^(b^c)` and `-a^b == -(a^b)`. That will match how many scripting languages do it (e.g. Python, Ruby). Also, if you'd like `log` to default to the natural log instead of `log",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:7847,Testability,log,log,7847,"wer>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace between tokens is ignored. Valid variable names consist of a lower case letter followed by any combination; of: lower case letters *a* through *z*, the digits *0* through *9*, and; underscore. Constants can be integers, decimal numbers, or in scientific; notation (e.g. *1e3* for *1000*). A leading zero is not required (e.g. *.5*; for *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constants are available:. - `pi`, `e`. ## Compile-time options. By default, TinyExpr does exponentiation from left to right. For example:. `a^b^c == (a^b)^c` and `-a^b == (-a)^b`. This is by design. It's the way that spreadsheets do it (e.g. Excel, Google Sheets). If you would rather have exponentiation work from right to left, you need to; define `TE_POW_FROM_RIGHT` when compiling `tinyexpr.c`. There is a; commented-out define near the top of that file. With this option enabled, the; behaviour is:. `a^b^c == a^(b^c)` and `-a^b == -(a^b)`. That will match how many scripting languages do it (e.g. Python, Ruby). Also, if you'd like `log` to default to the natural log instead of `log",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:8789,Testability,log,log,8789," *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constants are available:. - `pi`, `e`. ## Compile-time options. By default, TinyExpr does exponentiation from left to right. For example:. `a^b^c == (a^b)^c` and `-a^b == (-a)^b`. This is by design. It's the way that spreadsheets do it (e.g. Excel, Google Sheets). If you would rather have exponentiation work from right to left, you need to; define `TE_POW_FROM_RIGHT` when compiling `tinyexpr.c`. There is a; commented-out define near the top of that file. With this option enabled, the; behaviour is:. `a^b^c == a^(b^c)` and `-a^b == -(a^b)`. That will match how many scripting languages do it (e.g. Python, Ruby). Also, if you'd like `log` to default to the natural log instead of `log10`,; then you can define `TE_NAT_LOG`. ## Hints. - All functions/types start with the letters *te*. - To allow constant optimization, surround constant expressions in parentheses.; For example ""x+(1+5)"" will evaluate the ""(1+5)"" expression at compile time and; compile the entire expression as ""x+6"", saving a runtime calculation. The; parentheses are important, because TinyExpr will not change the order of; evaluation. If you instead compiled ""x+1+5"" TinyExpr will insist that ""1"" is; added to ""x"" first, and ""5"" is added the result second. ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:8820,Testability,log,log,8820," *0.5*). ## Functions supported. TinyExpr supports addition (+), subtraction/negation (-), multiplication (\*),; division (/), exponentiation (^) and modulus (%) with the normal operator; precedence (the one exception being that exponentiation is evaluated; left-to-right, but this can be changed - see below). The following C math functions are also supported:. - abs (calls to *fabs*), acos, asin, atan, atan2, ceil, cos, cosh, exp, floor, ln (calls to *log*), log (calls to *log10* by default, see below), log10, pow, sin, sinh, sqrt, tan, tanh. The following functions are also built-in and provided by TinyExpr:. - fac (factorials e.g. `fac 5` == 120); - ncr (combinations e.g. `ncr(6,2)` == 15); - npr (permutations e.g. `npr(6,2)` == 30). Also, the following constants are available:. - `pi`, `e`. ## Compile-time options. By default, TinyExpr does exponentiation from left to right. For example:. `a^b^c == (a^b)^c` and `-a^b == (-a)^b`. This is by design. It's the way that spreadsheets do it (e.g. Excel, Google Sheets). If you would rather have exponentiation work from right to left, you need to; define `TE_POW_FROM_RIGHT` when compiling `tinyexpr.c`. There is a; commented-out define near the top of that file. With this option enabled, the; behaviour is:. `a^b^c == a^(b^c)` and `-a^b == -(a^b)`. That will match how many scripting languages do it (e.g. Python, Ruby). Also, if you'd like `log` to default to the natural log instead of `log10`,; then you can define `TE_NAT_LOG`. ## Hints. - All functions/types start with the letters *te*. - To allow constant optimization, surround constant expressions in parentheses.; For example ""x+(1+5)"" will evaluate the ""(1+5)"" expression at compile time and; compile the entire expression as ""x+6"", saving a runtime calculation. The; parentheses are important, because TinyExpr will not change the order of; evaluation. If you instead compiled ""x+1+5"" TinyExpr will insist that ""1"" is; added to ""x"" first, and ""5"" is added the result second. ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:1165,Usability,simpl,simply,1165,"content/tinyexpr_logo.png"" align=""right""/>. # TinyExpr. TinyExpr is a very small recursive descent parser and evaluation engine for; math expressions. It's handy when you want to add the ability to evaluation; math expressions at runtime without adding a bunch of cruft to you project. In addition to the standard math operators and precedence, TinyExpr also supports; the standard C math functions and runtime binding of variables. ## Features. - **ANSI C with no dependencies**.; - Single source file and header file.; - Simple and fast.; - Implements standard operators precedence.; - Exposes standard C math functions (sin, sqrt, ln, etc.).; - Can add custom functions and variables easily.; - Can bind variables at eval-time.; - Released under the zlib license - free for nearly any use.; - Easy to use and integrate with your code; - Thread-safe, provided that your *malloc* is. ## Building. TinyExpr is self-contained in two files: `tinyexpr.c` and `tinyexpr.h`. To use; TinyExpr, simply add those two files to your project. ## Short Example. Here is a minimal example to evaluate an expression at runtime. ```C; #include ""tinyexpr.h""; printf(""%f\n"", te_interp(""5*5"", 0)); /* Prints 25. */; ```. ## Usage. TinyExpr defines only four functions:. ```C; double te_interp(const char *expression, int *error);; te_expr *te_compile(const char *expression, const te_variable *variables, int var_count, int *error);; double te_eval(const te_expr *expr);; void te_free(te_expr *expr);; ```. ## te_interp; ```C; double te_interp(const char *expression, int *error);; ```. `te_interp()` takes an expression and immediately returns the result of it. If there; is a parse error, `te_interp()` returns NaN. If the `error` pointer argument is not 0, then `te_interp()` will set `*error` to the position; of the parse error on failure, and set `*error` to 0 on success. **example usage:**. ```C; int error;. double a = te_interp(""(5+5)"", 0); /* Returns 10. */; double b = te_interp(""(5+5)"", &error); /* Return",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:5299,Usability,simpl,simple,5299," and eval can be called as many; * times as you like. This is fairly efficient because the parsing has; * already been done. */; x = 3; y = 4;; const double r = te_eval(n); printf(""Result:\n\t%f\n"", r);; te_free(n);; } else {; /* Show the user where the error is at. */; printf(""\t%*s^\nError near here"", err-1, """");; }. return 0;; }; ```. This produces the output:. $ example2 ""sqrt(x^2+y2)""; Evaluating:; sqrt(x^2+y2); ^; Error near here. $ example2 ""sqrt(x^2+y^2)""; Evaluating:; sqrt(x^2+y^2); Result:; 5.000000. ## Binding to Custom Functions. TinyExpr can also call to custom functions implemented in C. Here is a short example:. ```C; double my_sum(double a, double b) {; /* Example C function that adds two numbers together. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes constant branches. In this example,; the compiled expression returned by `te_compile()` would become:. ![example syntax tree](doc/e2.png?raw=true). `te_eval()` will automatically load in any variables by their pointer, and then evaluate; and return the result of the expression. `te_free()` should always be called when you're done with the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | ",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md:6063,Usability,simpl,simplified,6063,"gether. */; return a + b;; }. te_variable vars[] = {; {""mysum"", my_sum, TE_FUNCTION2} /* TE_FUNCTION2 used because my_sum takes two arguments. */; };. te_expr *n = te_compile(""mysum(5, 6)"", vars, 1, 0);. ```. ## How it works. `te_compile()` uses a simple recursive descent parser to compile your; expression into a syntax tree. For example, the expression `""sin x + 1/4""`; parses as:. ![example syntax tree](doc/e1.png?raw=true). `te_compile()` also automatically prunes constant branches. In this example,; the compiled expression returned by `te_compile()` would become:. ![example syntax tree](doc/e2.png?raw=true). `te_eval()` will automatically load in any variables by their pointer, and then evaluate; and return the result of the expression. `te_free()` should always be called when you're done with the compiled expression. ## Speed. TinyExpr is pretty fast compared to C when the expression is short, when the; expression does hard calculations (e.g. exponentiation), and when some of the; work can be simplified by `te_compile()`. TinyExpr is slow compared to C when the; expression is long and involves only basic arithmetic. Here is some example performance numbers taken from the included; **benchmark.c** program:. | Expression | te_eval time | native C time | slowdown |; | :------------- |-------------:| -----:|----:|; | sqrt(a^1.5+a^2.5) | 15,641 ms | 14,478 ms | 8% slower |; | a+5 | 765 ms | 563 ms | 36% slower |; | a+(5*2) | 765 ms | 563 ms | 36% slower |; | (a+5)*2 | 1422 ms | 563 ms | 153% slower |; | (1/(a+1)+2/(a+2)+3/(a+3)) | 5,516 ms | 1,266 ms | 336% slower |. ## Grammar. TinyExpr parses the following grammar:. <list> = <expr> {"","" <expr>}; <expr> = <term> {(""+"" | ""-"") <term>}; <term> = <factor> {(""*"" | ""/"" | ""%"") <factor>}; <factor> = <power> {""^"" <power>}; <power> = {(""-"" | ""+"")} <base>; <base> = <constant>; | <variable>; | <function-0> {""("" "")""}; | <function-1> <power>; | <function-X> ""("" <expr> {"","" <expr>} "")""; | ""("" <list> "")"". In addition, whitespace bet",MatchSource.DOCS,lib/tinyexpr/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CODE_OF_CONDUCT.md:235,Availability,toler,tolerated,235,# Code of Conduct. Facebook has adopted a Code of Conduct that we expect project participants to adhere to.; Please read the [full text](https://code.fb.com/codeofconduct/); so that you can understand what actions will and will not be tolerated.; ,MatchSource.DOCS,lib/zstd/CODE_OF_CONDUCT.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CODE_OF_CONDUCT.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:261,Deployability,release,release,261,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:596,Deployability,update,update,596,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:1253,Safety,safe,safe,1253,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:1273,Security,secur,security,1273,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:549,Testability,test,tested,549,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:561,Testability,test,tests,561,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:637,Testability,test,test,637,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md:1104,Usability,clear,clear,1104,"# Contributing to Zstandard; We want to make contributing to this project as easy and transparent as; possible. ## Our Development Process; New versions are being developed in the ""dev"" branch,; or in their own feature branch.; When they are deemed ready for a release, they are merged into ""master"". As a consequences, all contributions must stage first through ""dev""; or their own feature branch. ## Pull Requests; We actively welcome your pull requests. 1. Fork the repo and create your branch from `dev`.; 2. If you've added code that should be tested, add tests.; 3. If you've changed APIs, update the documentation.; 4. Ensure the test suite passes.; 5. Make sure your code lints.; 6. If you haven't already, complete the Contributor License Agreement (""CLA""). ## Contributor License Agreement (""CLA""); In order to accept your pull request, we need you to submit a CLA. You only need; to do this once to work on any of Facebook's open source projects. Complete your CLA here: <https://code.facebook.com/cla>. ## Issues; We use GitHub issues to track public bugs. Please ensure your description is; clear and has sufficient instructions to be able to reproduce the issue. Facebook has a [bounty program](https://www.facebook.com/whitehat/) for the safe; disclosure of security bugs. In those cases, please go through the process; outlined on that page and do not file a public issue. ## Coding Style ; * 4 spaces for indentation rather than tabs. ## License; By contributing to Zstandard, you agree that your contributions will be licensed; under both the [LICENSE](LICENSE) file and the [COPYING](COPYING) file in the root directory of this source tree.; ",MatchSource.DOCS,lib/zstd/CONTRIBUTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/CONTRIBUTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:6068,Availability,avail,available,6068,"ecompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:4561,Deployability,release,releases,4561,"ase for Small Data compression. Previous charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives. The smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no ""past"" to build upon. To solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.; Training Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called ""dictionary"", which must be loaded before compression and decompression.; Using this dictionary, the compression ratio achievable on small data improves dramatically. The following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).; It consists of roughly 10K records weighing about 1KB each. Compression Ratio | Compression Speed | Decompression Speed; ------------------|-------------------|--------------------; ![Compression Ratio](doc/images/dict-cr.png ""Compression Ratio"") | ![Compression Speed](doc/images/dict-cs.png ""Compression Speed"") | ![Decompression Speed](doc/images/dict-ds.png ""Decompression Speed""). These compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previous",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:5363,Deployability,deploy,deploying,5363,", the compression ratio achievable on small data improves dramatically. The following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).; It consists of roughly 10K records weighing about 1KB each. Compression Ratio | Compression Speed | Decompression Speed; ------------------|-------------------|--------------------; ![Compression Ratio](doc/images/dict-cr.png ""Compression Ratio"") | ![Compression Speed](doc/images/dict-cs.png ""Compression Speed"") | ![Decompression Speed](doc/images/dict-ds.png ""Decompression Speed""). These compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, an",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:6104,Deployability,install,install,6104,"ecompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:6126,Deployability,install,install,6126,"ecompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:7024,Deployability,deploy,deployed,7024,"st of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard is considered safe for production environments. ### License. Zstandard is dual-licensed under [BSD](LICENSE) and [GPLv2](COPYING). ### Contributing. The ""dev"" branch is the one where all contributions are merged before reaching ""master"".; If you plan to propose a patch, please commit into the ""dev"" branch, or its own feature branch.; Direct commit to ""master"" are not permitted.; For more information, please read [CONTRIBUTING](CONTRIBUTING.md).; ",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:7061,Deployability,continuous,continuously,7061,"st of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard is considered safe for production environments. ### License. Zstandard is dual-licensed under [BSD](LICENSE) and [GPLv2](COPYING). ### Contributing. The ""dev"" branch is the one where all contributions are merged before reaching ""master"".; If you plan to propose a patch, please commit into the ""dev"" branch, or its own feature branch.; Direct commit to ""master"" are not permitted.; For more information, please read [CONTRIBUTING](CONTRIBUTING.md).; ",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:7418,Deployability,patch,patch,7418,"st of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard is considered safe for production environments. ### License. Zstandard is dual-licensed under [BSD](LICENSE) and [GPLv2](COPYING). ### Contributing. The ""dev"" branch is the one where all contributions are merged before reaching ""master"".; If you plan to propose a patch, please commit into the ""dev"" branch, or its own feature branch.; Direct commit to ""master"" are not permitted.; For more information, please read [CONTRIBUTING](CONTRIBUTING.md).; ",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:5301,Energy Efficiency,efficient,efficient,5301,"""dictionary"", which must be loaded before compression and decompression.; Using this dictionary, the compression ratio achievable on small data improves dramatically. The following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).; It consists of roughly 10K records weighing about 1KB each. Compression Ratio | Compression Speed | Decompression Speed; ------------------|-------------------|--------------------; ![Compression Ratio](doc/images/dict-cr.png ""Compression Ratio"") | ![Compression Speed](doc/images/dict-cs.png ""Compression Speed"") | ![Decompression Speed](doc/images/dict-ds.png ""Decompression Speed""). These compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:2642,Modifiability,config,configurable,2642," a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. [lzbench]: https://github.com/inikep/lzbench; [Silesia compression corpus]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/s |; | quicklz 1.5.0 -1 | 2.238 | 550 MB/s | 710 MB/s |; | lzo1x 2.09 -1 | 2.108 | 650 MB/s | 830 MB/s |; | lz4 1.8.1 | 2.101 | 750 MB/s | 3700 MB/s |; | snappy 1.1.4 | 2.091 | 530 MB/s | 1800 MB/s |; | lzf 3.6 -1 | 2.077 | 400 MB/s | 860 MB/s |. [zlib]:http://www.zlib.net/; [LZ4]: http://www.lz4.org/. Zstd can also offer stronger compression ratios at the cost of compression speed.; Speed vs Compression trade-off is configurable by small increments.; Decompression speed is preserved and remains roughly the same at all settings,; a property shared by most LZ compression algorithms, such as [zlib] or lzma. The following tests were run; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`); with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. Compression Speed vs Ratio | Decompression Speed; ---------------------------|--------------------; ![Compression Speed vs Ratio](doc/images/CSpeed2.png ""Compression Speed vs Ratio"") | ![Decompression Speed](doc/images/DSpeed3.png ""Decompression Speed""). A few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.; For a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png). ### The case for Small Data compression. Previous charts provide results applicable to typ",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:4109,Performance,tune,tune,4109,"s]. Compression Speed vs Ratio | Decompression Speed; ---------------------------|--------------------; ![Compression Speed vs Ratio](doc/images/CSpeed2.png ""Compression Speed vs Ratio"") | ![Decompression Speed](doc/images/DSpeed3.png ""Decompression Speed""). A few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.; For a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png). ### The case for Small Data compression. Previous charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives. The smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no ""past"" to build upon. To solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.; Training Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called ""dictionary"", which must be loaded before compression and decompression.; Using this dictionary, the compression ratio achievable on small data improves dramatically. The following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).; It consists of roughly 10K records weighing about 1KB each. Compression Ratio | Compression Speed | Decompression Speed; ------------------|-------------------|--------------------; ![Compression Ratio](doc/images/dict-cr.png ""Compression Ratio"") | ![Compression Speed](doc/images/dict-cs.png ""Compression Speed"") | ![Decompression Speed](doc/images/dict-ds.png ""Decompression Speed""). These compression gains are achieve",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:4330,Performance,load,loaded,4330,"ages/DSpeed3.png ""Decompression Speed""). A few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.; For a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png). ### The case for Small Data compression. Previous charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives. The smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no ""past"" to build upon. To solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.; Training Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called ""dictionary"", which must be loaded before compression and decompression.; Using this dictionary, the compression ratio achievable on small data improves dramatically. The following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).; It consists of roughly 10K records weighing about 1KB each. Compression Ratio | Compression Speed | Decompression Speed; ------------------|-------------------|--------------------; ![Compression Ratio](doc/images/dict-cr.png ""Compression Ratio"") | ![Compression Speed](doc/images/dict-cs.png ""Compression Speed"") | ![Decompression Speed](doc/images/dict-ds.png ""Decompression Speed""). These compression gains are achieved while simultaneously providing _faster_ compression and decompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:7168,Safety,safe,safe,7168,"st of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard is considered safe for production environments. ### License. Zstandard is dual-licensed under [BSD](LICENSE) and [GPLv2](COPYING). ### Contributing. The ""dev"" branch is the one where all contributions are merged before reaching ""master"".; If you plan to propose a patch, please commit into the ""dev"" branch, or its own feature branch.; Direct commit to ""master"" are not permitted.; For more information, please read [CONTRIBUTING](CONTRIBUTING.md).; ",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:1062,Testability,test,test,1062,"ebook/zstd/dev/doc/images/zstd_logo86.png"" alt=""Zstandard""></p>. __Zstandard__, or `zstd` as short version, is a fast lossless compression algorithm,; targeting real-time compression scenarios at zlib-level and better compression ratios.; It's backed by a very fast entropy stage, provided by [Huff0 and FSE library](https://github.com/Cyan4973/FiniteStateEntropy). The project is provided as an open-source dual [BSD](LICENSE) and [GPLv2](COPYING) licensed **C** library,; and a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.; Should your project require another programming language,; a list of known ports and bindings is provided on [Zstandard homepage](http://www.zstd.net/#other-languages). Development branch status : [![Build Status][travisDevBadge]][travisLink] [![Build status][AppveyorDevBadge]][AppveyorLink] [![Build status][CircleDevBadge]][CircleLink]. [travisDevBadge]: https://travis-ci.org/facebook/zstd.svg?branch=dev ""Continuous Integration test suite""; [travisLink]: https://travis-ci.org/facebook/zstd; [AppveyorDevBadge]: https://ci.appveyor.com/api/projects/status/xt38wbdxjk5mrbem/branch/dev?svg=true ""Windows test suite""; [AppveyorLink]: https://ci.appveyor.com/project/YannCollet/zstd-p0yf0; [CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield ""Short test suite""; [CircleLink]: https://circleci.com/gh/facebook/zstd. ### Benchmarks. For reference, several fast compression algorithms were tested and compared; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`),; with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. [lzbench]: https://github.com/inikep/lzbench; [Silesia compression corpus]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| --------",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:1236,Testability,test,test,1236,"ting real-time compression scenarios at zlib-level and better compression ratios.; It's backed by a very fast entropy stage, provided by [Huff0 and FSE library](https://github.com/Cyan4973/FiniteStateEntropy). The project is provided as an open-source dual [BSD](LICENSE) and [GPLv2](COPYING) licensed **C** library,; and a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.; Should your project require another programming language,; a list of known ports and bindings is provided on [Zstandard homepage](http://www.zstd.net/#other-languages). Development branch status : [![Build Status][travisDevBadge]][travisLink] [![Build status][AppveyorDevBadge]][AppveyorLink] [![Build status][CircleDevBadge]][CircleLink]. [travisDevBadge]: https://travis-ci.org/facebook/zstd.svg?branch=dev ""Continuous Integration test suite""; [travisLink]: https://travis-ci.org/facebook/zstd; [AppveyorDevBadge]: https://ci.appveyor.com/api/projects/status/xt38wbdxjk5mrbem/branch/dev?svg=true ""Windows test suite""; [AppveyorLink]: https://ci.appveyor.com/project/YannCollet/zstd-p0yf0; [CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield ""Short test suite""; [CircleLink]: https://circleci.com/gh/facebook/zstd. ### Benchmarks. For reference, several fast compression algorithms were tested and compared; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`),; with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. [lzbench]: https://github.com/inikep/lzbench; [Silesia compression corpus]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:1409,Testability,test,test,1409,"teEntropy). The project is provided as an open-source dual [BSD](LICENSE) and [GPLv2](COPYING) licensed **C** library,; and a command line utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.; Should your project require another programming language,; a list of known ports and bindings is provided on [Zstandard homepage](http://www.zstd.net/#other-languages). Development branch status : [![Build Status][travisDevBadge]][travisLink] [![Build status][AppveyorDevBadge]][AppveyorLink] [![Build status][CircleDevBadge]][CircleLink]. [travisDevBadge]: https://travis-ci.org/facebook/zstd.svg?branch=dev ""Continuous Integration test suite""; [travisLink]: https://travis-ci.org/facebook/zstd; [AppveyorDevBadge]: https://ci.appveyor.com/api/projects/status/xt38wbdxjk5mrbem/branch/dev?svg=true ""Windows test suite""; [AppveyorLink]: https://ci.appveyor.com/project/YannCollet/zstd-p0yf0; [CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield ""Short test suite""; [CircleLink]: https://circleci.com/gh/facebook/zstd. ### Benchmarks. For reference, several fast compression algorithms were tested and compared; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`),; with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. [lzbench]: https://github.com/inikep/lzbench; [Silesia compression corpus]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/s |; | quicklz 1.5.0 -1 | 2.238 | 550 MB/s | 710 MB/s |; | lzo1x 2.09 -1 | 2.108 | 650 MB/s | 830 MB/s |; | lz4 1.8.1 | 2.101 | 750 MB/s | 3700 MB/s |; | snappy 1.1.4 | 2.091 | 530 MB/s | 1800 MB/s ",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:1547,Testability,test,tested,1547,"ine utility producing and decoding `.zst`, `.gz`, `.xz` and `.lz4` files.; Should your project require another programming language,; a list of known ports and bindings is provided on [Zstandard homepage](http://www.zstd.net/#other-languages). Development branch status : [![Build Status][travisDevBadge]][travisLink] [![Build status][AppveyorDevBadge]][AppveyorLink] [![Build status][CircleDevBadge]][CircleLink]. [travisDevBadge]: https://travis-ci.org/facebook/zstd.svg?branch=dev ""Continuous Integration test suite""; [travisLink]: https://travis-ci.org/facebook/zstd; [AppveyorDevBadge]: https://ci.appveyor.com/api/projects/status/xt38wbdxjk5mrbem/branch/dev?svg=true ""Windows test suite""; [AppveyorLink]: https://ci.appveyor.com/project/YannCollet/zstd-p0yf0; [CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield ""Short test suite""; [CircleLink]: https://circleci.com/gh/facebook/zstd. ### Benchmarks. For reference, several fast compression algorithms were tested and compared; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`),; with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. [lzbench]: https://github.com/inikep/lzbench; [Silesia compression corpus]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/s |; | quicklz 1.5.0 -1 | 2.238 | 550 MB/s | 710 MB/s |; | lzo1x 2.09 -1 | 2.108 | 650 MB/s | 830 MB/s |; | lz4 1.8.1 | 2.101 | 750 MB/s | 3700 MB/s |; | snappy 1.1.4 | 2.091 | 530 MB/s | 1800 MB/s |; | lzf 3.6 -1 | 2.077 | 400 MB/s | 860 MB/s |. [zlib]:http://www.zlib.net/; [LZ4]: http://www.lz4.org/. Zstd can also offer stronger c",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:1714,Testability,benchmark,benchmark,1714,"nd bindings is provided on [Zstandard homepage](http://www.zstd.net/#other-languages). Development branch status : [![Build Status][travisDevBadge]][travisLink] [![Build status][AppveyorDevBadge]][AppveyorLink] [![Build status][CircleDevBadge]][CircleLink]. [travisDevBadge]: https://travis-ci.org/facebook/zstd.svg?branch=dev ""Continuous Integration test suite""; [travisLink]: https://travis-ci.org/facebook/zstd; [AppveyorDevBadge]: https://ci.appveyor.com/api/projects/status/xt38wbdxjk5mrbem/branch/dev?svg=true ""Windows test suite""; [AppveyorLink]: https://ci.appveyor.com/project/YannCollet/zstd-p0yf0; [CircleDevBadge]: https://circleci.com/gh/facebook/zstd/tree/dev.svg?style=shield ""Short test suite""; [CircleLink]: https://circleci.com/gh/facebook/zstd. ### Benchmarks. For reference, several fast compression algorithms were tested and compared; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`),; with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. [lzbench]: https://github.com/inikep/lzbench; [Silesia compression corpus]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/s |; | quicklz 1.5.0 -1 | 2.238 | 550 MB/s | 710 MB/s |; | lzo1x 2.09 -1 | 2.108 | 650 MB/s | 830 MB/s |; | lz4 1.8.1 | 2.101 | 750 MB/s | 3700 MB/s |; | snappy 1.1.4 | 2.091 | 530 MB/s | 1800 MB/s |; | lzf 3.6 -1 | 2.077 | 400 MB/s | 860 MB/s |. [zlib]:http://www.zlib.net/; [LZ4]: http://www.lz4.org/. Zstd can also offer stronger compression ratios at the cost of compression speed.; Speed vs Compression trade-off is configurable by small increments.; Decompression speed is preserved an",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:2848,Testability,test,tests,2848,"]: http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia; [gcc]: https://gcc.gnu.org/. | Compressor name | Ratio | Compression| Decompress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/s |; | quicklz 1.5.0 -1 | 2.238 | 550 MB/s | 710 MB/s |; | lzo1x 2.09 -1 | 2.108 | 650 MB/s | 830 MB/s |; | lz4 1.8.1 | 2.101 | 750 MB/s | 3700 MB/s |; | snappy 1.1.4 | 2.091 | 530 MB/s | 1800 MB/s |; | lzf 3.6 -1 | 2.077 | 400 MB/s | 860 MB/s |. [zlib]:http://www.zlib.net/; [LZ4]: http://www.lz4.org/. Zstd can also offer stronger compression ratios at the cost of compression speed.; Speed vs Compression trade-off is configurable by small increments.; Decompression speed is preserved and remains roughly the same at all settings,; a property shared by most LZ compression algorithms, such as [zlib] or lzma. The following tests were run; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`); with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. Compression Speed vs Ratio | Decompression Speed; ---------------------------|--------------------; ![Compression Speed vs Ratio](doc/images/CSpeed2.png ""Compression Speed vs Ratio"") | ![Decompression Speed](doc/images/DSpeed3.png ""Decompression Speed""). A few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.; For a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png). ### The case for Small Data compression. Previous charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives. The smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and re",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:3009,Testability,benchmark,benchmark,3009,"mpress.|; | --------------- | ------| -----------| ---------- |; | **zstd 1.3.4 -1** | 2.877 | 470 MB/s | 1380 MB/s |; | zlib 1.2.11 -1 | 2.743 | 110 MB/s | 400 MB/s |; | brotli 1.0.2 -0 | 2.701 | 410 MB/s | 430 MB/s |; | quicklz 1.5.0 -1 | 2.238 | 550 MB/s | 710 MB/s |; | lzo1x 2.09 -1 | 2.108 | 650 MB/s | 830 MB/s |; | lz4 1.8.1 | 2.101 | 750 MB/s | 3700 MB/s |; | snappy 1.1.4 | 2.091 | 530 MB/s | 1800 MB/s |; | lzf 3.6 -1 | 2.077 | 400 MB/s | 860 MB/s |. [zlib]:http://www.zlib.net/; [LZ4]: http://www.lz4.org/. Zstd can also offer stronger compression ratios at the cost of compression speed.; Speed vs Compression trade-off is configurable by small increments.; Decompression speed is preserved and remains roughly the same at all settings,; a property shared by most LZ compression algorithms, such as [zlib] or lzma. The following tests were run; on a server running Linux Debian (`Linux version 4.14.0-3-amd64`); with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. Compression Speed vs Ratio | Decompression Speed; ---------------------------|--------------------; ![Compression Speed vs Ratio](doc/images/CSpeed2.png ""Compression Speed vs Ratio"") | ![Decompression Speed](doc/images/DSpeed3.png ""Decompression Speed""). A few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.; For a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png). ### The case for Small Data compression. Previous charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives. The smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:6207,Testability,test,tests,6207,"ecompression speeds. Training works if there is some correlation in a family of small data samples. The more data-specific a dictionary is, the more efficient it is (there is no _universal dictionary_).; Hence, deploying one dictionary per type of data will provide the greatest benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm will gradually use previously decoded content to better compress the rest of the file. #### Dictionary compression How To:. 1) Create the dictionary. `zstd --train FullPathToTrainingSet/* -o dictionaryName`. 2) Compress with dictionary. `zstd -D dictionaryName FILE`. 3) Decompress with dictionary. `zstd -D dictionaryName --decompress FILE.zst`. ### Build instructions. #### Makefile. If your system is compatible with standard `make` (or `gmake`),; invoking `make` in root directory will generate `zstd` cli in root directory. Other available options include:; - `make install` : create and install zstd cli, library and man pages; - `make check` : create and run `zstd`, tests its behavior on local platform. #### cmake. A `cmake` project generator is provided within `build/cmake`.; It can generate Makefiles or other build scripts; to create `zstd` binary, and `libzstd` dynamic and static libraries. By default, `CMAKE_BUILD_TYPE` is set to `Release`. #### Meson. A Meson project is provided within `build/meson`. #### Visual Studio (Windows). Going into `build` directory, you will find additional possibilities:; - Projects for Visual Studio 2005, 2008 and 2010.; + VS2010 project is compatible with VS2012, VS2013, VS2015 and VS2017.; - Automated build scripts for Visual compiler by [@KrzysFR](https://github.com/KrzysFR), in `build/VS_scripts`,; which will build `zstd` cli and `libzstd` library without any need to open Visual Studio solution. ### Status. Zstandard is currently deployed within Facebook. It is used continuously to compress large amounts of data in multiple formats and use cases.; Zstandard",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md:3906,Usability,learn,learn,3906,"Linux Debian (`Linux version 4.14.0-3-amd64`); with a Core i7-6700K CPU @ 4.0GHz,; using [lzbench], an open-source in-memory benchmark by @inikep; compiled with [gcc] 7.3.0,; on the [Silesia compression corpus]. Compression Speed vs Ratio | Decompression Speed; ---------------------------|--------------------; ![Compression Speed vs Ratio](doc/images/CSpeed2.png ""Compression Speed vs Ratio"") | ![Decompression Speed](doc/images/DSpeed3.png ""Decompression Speed""). A few other algorithms can produce higher compression ratios at slower speeds, falling outside of the graph.; For a larger picture including slow modes, [click on this link](doc/images/DCspeed5.png). ### The case for Small Data compression. Previous charts provide results applicable to typical file and stream scenarios (several MB). Small data comes with different perspectives. The smaller the amount of data to compress, the more difficult it is to compress. This problem is common to all compression algorithms, and reason is, compression algorithms learn from past data how to compress future data. But at the beginning of a new data set, there is no ""past"" to build upon. To solve this situation, Zstd offers a __training mode__, which can be used to tune the algorithm for a selected type of data.; Training Zstandard is achieved by providing it with a few samples (one file per sample). The result of this training is stored in a file called ""dictionary"", which must be loaded before compression and decompression.; Using this dictionary, the compression ratio achievable on small data improves dramatically. The following example uses the `github-users` [sample set](https://github.com/facebook/zstd/releases/tag/v1.1.3), created from [github public API](https://developer.github.com/v3/users/#get-all-users).; It consists of roughly 10K records weighing about 1KB each. Compression Ratio | Compression Speed | Decompression Speed; ------------------|-------------------|--------------------; ![Compression Ratio](doc/image",MatchSource.DOCS,lib/zstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1881,Deployability,install,install,1881,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:31,Testability,test,testing,31,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:97,Testability,test,tests,97,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:136,Testability,test,tests,136,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:239,Testability,test,tests,239,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:400,Testability,test,tests,400,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:443,Testability,test,tests,443,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:467,Testability,test,tests,467,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:483,Testability,test,tests,483,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:491,Testability,test,tests,491,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:509,Testability,test,tests,509,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:530,Testability,test,tests,530,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:594,Testability,test,tests,594,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:698,Testability,test,tests,698,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:722,Testability,test,tests,722,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:807,Testability,test,tests,807,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:828,Testability,test,test-long-data,828,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:854,Testability,test,tests,854,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:862,Testability,test,tests,862,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:880,Testability,test,tests,880,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:907,Testability,test,tests,907,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:933,Testability,test,tests,933,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1039,Testability,test,tests,1039,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1061,Testability,test,testing,1061,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1110,Testability,test,tests,1110,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1198,Testability,test,tests,1198,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1344,Testability,test,tests,1344,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1361,Testability,test,test,1361,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1418,Testability,test,tests,1418,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1580,Testability,test,testing,1580,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1604,Testability,test,tests,1604,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1648,Testability,test,test,1648,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md:1861,Testability,test,test,1861,"Testing; =======. Zstandard CI testing is split up into three sections:; short, medium, and long tests. Short Tests; -----------; Short tests run on CircleCI for new commits on every branch and pull request.; They consist of the following tests:; - Compilation on all supported targets (x86, x86_64, ARM, AArch64, PowerPC, and PowerPC64); - Compilation on various versions of gcc, clang, and g++; - `tests/playTests.sh` on x86_64, without the tests on long data (CLI tests); - Small tests (`tests/legacy.c`, `tests/longmatch.c`, `tests/symbols.c`) on x64_64. Medium Tests; ------------; Medium tests run on every commit and pull request to `dev` branch, on TravisCI.; They consist of the following tests:; - The following tests run with UBsan and Asan on x86_64 and x86, as well as with; Msan on x86_64; - `tests/playTests.sh --test-long-data`; - Fuzzer tests: `tests/fuzzer.c`, `tests/zstreamtest.c`, and `tests/decodecorpus.c`; - `tests/zstreamtest.c` under Tsan (streaming mode, including multithreaded mode); - Valgrind Test (`make -C tests valgrindTest`) (testing CLI and fuzzer under valgrind); - Fuzzer tests (see above) on ARM, AArch64, PowerPC, and PowerPC64. Long Tests; ----------; Long tests run on all commits to `master` branch,; and once a day on the current version of `dev` branch,; on TravisCI.; They consist of the following tests:; - Entire test suite (including fuzzers and some other specialized tests) on:; - x86_64 and x86 with UBsan and Asan; - x86_64 with Msan; - ARM, AArch64, PowerPC, and PowerPC64; - Streaming mode fuzzer with Tsan (for the `zstdmt` testing); - ZlibWrapper tests, including under valgrind; - Versions test (ensuring `zstd` can decode files from all previous versions); - `pzstd` with asan and tsan, as well as in 32-bits mode; - Testing `zstd` with legacy mode off; - Testing `zbuff` (old streaming API); - Entire test suite and make install on macOS; ",MatchSource.DOCS,lib/zstd/TESTING.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/TESTING.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/simde/simde/README.md:284,Testability,test,test,284,"# SIMDe Without Test Cases. This repository contains only the core of; [SIMDe](https://github.com/simd-everywhere/simde).; It is generated automatically for every commit to master, and is; intended to be used as a submodule in projects which don't want to; include the (rather large) test cases. All development work happens in the main repository, please do not; file issues or create pull requests against this repository.; ",MatchSource.DOCS,lib/simde/simde/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/simde/simde/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:1348,Availability,avail,available,1348," contrib directory and will no longer be supported); - `VS2008` - Visual Studio 2008 project; - `VS2010` - Visual Studio 2010 project (which also works well with Visual Studio 2012, 2013, 2015); - `VS_scripts` - command line scripts prepared for Visual Studio compilation without IDE. #### How to compile zstd with Visual Studio. 1. Install Visual Studio e.g. VS 2015 Community Edition (it's free).; 2. Download the latest version of zstd from https://github.com/facebook/zstd/releases; 3. Decompress ZIP archive.; 4. Go to decompressed directory then to `projects` then `VS2010` and open `zstd.sln`; 5. Visual Studio will ask about converting VS2010 project to VS2015 and you should agree.; 6. Change `Debug` to `Release` and if you have 64-bit Windows change also `Win32` to `x64`.; 7. Press F7 on keyboard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A static ZSTD library compiled to `libzstd_static.lib`; - `libzstd-dll` : A dynamic ZSTD library (DLL) compiled to `libzstd.dll` with the import library `libzstd.lib`; - `fullbench-dll` : The fullbench program compiled with the import library; the executable requires ZSTD DLL. #### Using ZSTD DLL with Microsoft Visual C++ project. The header file `lib\zstd",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:3077,Availability,avail,available,3077,"oard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A static ZSTD library compiled to `libzstd_static.lib`; - `libzstd-dll` : A dynamic ZSTD library (DLL) compiled to `libzstd.dll` with the import library `libzstd.lib`; - `fullbench-dll` : The fullbench program compiled with the import library; the executable requires ZSTD DLL. #### Using ZSTD DLL with Microsoft Visual C++ project. The header file `lib\zstd.h` and the import library; `visual\VS2010\bin\$(Platform)_$(Configuration)\libzstd.lib` are required to compile; a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in Project Properties of Visual Studio IDE in the `C/C++` Property Pages on the `General` page.; 2. The import library has to be added to `Additional Dependencies` that can; be found in Project Properties in the `Linker` Property Pages on the `Input` page.; If one will provide only the name `libzstd.lib` without a full path to the library; then the directory has to be added to `Linker\General\Additional Library Directories`. The compiled executable will require ZSTD DLL which is available at; `visual\VS2010\bin\$(Platform)_$(Configuration)\libzstd.dll`. ; ",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:21,Deployability,integrat,integrated,21,"Projects for various integrated development environments (IDE); ==============================================================. #### Included projects. The following projects are included with the zstd distribution:; - `cmake` - CMake project contributed by Artyom Dymchenko; - `VS2005` - Visual Studio 2005 Project (this project has been moved to the contrib directory and will no longer be supported); - `VS2008` - Visual Studio 2008 project; - `VS2010` - Visual Studio 2010 project (which also works well with Visual Studio 2012, 2013, 2015); - `VS_scripts` - command line scripts prepared for Visual Studio compilation without IDE. #### How to compile zstd with Visual Studio. 1. Install Visual Studio e.g. VS 2015 Community Edition (it's free).; 2. Download the latest version of zstd from https://github.com/facebook/zstd/releases; 3. Decompress ZIP archive.; 4. Go to decompressed directory then to `projects` then `VS2010` and open `zstd.sln`; 5. Visual Studio will ask about converting VS2010 project to VS2015 and you should agree.; 6. Change `Debug` to `Release` and if you have 64-bit Windows change also `Win32` to `x64`.; 7. Press F7 on keyboard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A stati",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:828,Deployability,release,releases,828,"Projects for various integrated development environments (IDE); ==============================================================. #### Included projects. The following projects are included with the zstd distribution:; - `cmake` - CMake project contributed by Artyom Dymchenko; - `VS2005` - Visual Studio 2005 Project (this project has been moved to the contrib directory and will no longer be supported); - `VS2008` - Visual Studio 2008 project; - `VS2010` - Visual Studio 2010 project (which also works well with Visual Studio 2012, 2013, 2015); - `VS_scripts` - command line scripts prepared for Visual Studio compilation without IDE. #### How to compile zstd with Visual Studio. 1. Install Visual Studio e.g. VS 2015 Community Edition (it's free).; 2. Download the latest version of zstd from https://github.com/facebook/zstd/releases; 3. Decompress ZIP archive.; 4. Go to decompressed directory then to `projects` then `VS2010` and open `zstd.sln`; 5. Visual Studio will ask about converting VS2010 project to VS2015 and you should agree.; 6. Change `Debug` to `Release` and if you have 64-bit Windows change also `Win32` to `x64`.; 7. Press F7 on keyboard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A stati",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:21,Integrability,integrat,integrated,21,"Projects for various integrated development environments (IDE); ==============================================================. #### Included projects. The following projects are included with the zstd distribution:; - `cmake` - CMake project contributed by Artyom Dymchenko; - `VS2005` - Visual Studio 2005 Project (this project has been moved to the contrib directory and will no longer be supported); - `VS2008` - Visual Studio 2008 project; - `VS2010` - Visual Studio 2010 project (which also works well with Visual Studio 2012, 2013, 2015); - `VS_scripts` - command line scripts prepared for Visual Studio compilation without IDE. #### How to compile zstd with Visual Studio. 1. Install Visual Studio e.g. VS 2015 Community Edition (it's free).; 2. Download the latest version of zstd from https://github.com/facebook/zstd/releases; 3. Decompress ZIP archive.; 4. Go to decompressed directory then to `projects` then `VS2010` and open `zstd.sln`; 5. Visual Studio will ask about converting VS2010 project to VS2015 and you should agree.; 6. Change `Debug` to `Release` and if you have 64-bit Windows change also `Win32` to `x64`.; 7. Press F7 on keyboard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A stati",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:1949,Security,integrity,integrity,1949,"decompressed directory then to `projects` then `VS2010` and open `zstd.sln`; 5. Visual Studio will ask about converting VS2010 project to VS2015 and you should agree.; 6. Change `Debug` to `Release` and if you have 64-bit Windows change also `Win32` to `x64`.; 7. Press F7 on keyboard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A static ZSTD library compiled to `libzstd_static.lib`; - `libzstd-dll` : A dynamic ZSTD library (DLL) compiled to `libzstd.dll` with the import library `libzstd.lib`; - `fullbench-dll` : The fullbench program compiled with the import library; the executable requires ZSTD DLL. #### Using ZSTD DLL with Microsoft Visual C++ project. The header file `lib\zstd.h` and the import library; `visual\VS2010\bin\$(Platform)_$(Configuration)\libzstd.lib` are required to compile; a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in Project Properties of Visual Studio IDE in the `C/C++` Property Pages on the `General` page.; 2. The import library has to be added to `Additional Dependencies` that can; be found in Project Properties in the `Linker` Property Pages on the `Input` page.; If one will provide only",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md:1833,Testability,test,tests,1833,"decompressed directory then to `projects` then `VS2010` and open `zstd.sln`; 5. Visual Studio will ask about converting VS2010 project to VS2015 and you should agree.; 6. Change `Debug` to `Release` and if you have 64-bit Windows change also `Win32` to `x64`.; 7. Press F7 on keyboard or select `BUILD` from the menu bar and choose `Build Solution`.; 8. If compilation will be fine a compiled executable will be in `projects\VS2010\bin\x64\Release\zstd.exe`. #### Projects available within zstd.sln. The Visual Studio solution file `visual\VS2010\zstd.sln` contains many projects that will be compiled to the; `visual\VS2010\bin\$(Platform)_$(Configuration)` directory. For example `zstd` set to `x64` and; `Release` will be compiled to `visual\VS2010\bin\x64_Release\zstd.exe`. The solution file contains the; following projects:. - `zstd` : Command Line Utility, supporting gzip-like arguments; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform ; - `libzstd` : A static ZSTD library compiled to `libzstd_static.lib`; - `libzstd-dll` : A dynamic ZSTD library (DLL) compiled to `libzstd.dll` with the import library `libzstd.lib`; - `fullbench-dll` : The fullbench program compiled with the import library; the executable requires ZSTD DLL. #### Using ZSTD DLL with Microsoft Visual C++ project. The header file `lib\zstd.h` and the import library; `visual\VS2010\bin\$(Platform)_$(Configuration)\libzstd.lib` are required to compile; a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in Project Properties of Visual Studio IDE in the `C/C++` Property Pages on the `General` page.; 2. The import library has to be added to `Additional Dependencies` that can; be found in Project Properties in the `Linker` Property Pages on the `Input` page.; If one will provide only",MatchSource.DOCS,lib/zstd/build/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md:369,Deployability,release,release,369,"Zstandard Documentation; =======================. This directory contains material defining the Zstandard format,; as well as detailed instructions to use `zstd` library. __`zstd_manual.html`__ : Documentation of `zstd.h` API, in html format.; Click on this link: [http://zstd.net/zstd_manual.html](http://zstd.net/zstd_manual.html); to display documentation of latest release in readable format within a browser. __`zstd_compression_format.md`__ : This document defines the Zstandard compression format.; Compliant decoders must adhere to this document,; and compliant encoders must generate data that follows it. Should you look for ressources to develop your own port of Zstandard algorithm,; you may find the following ressources useful :. __`educational_decoder`__ : This directory contains an implementation of a Zstandard decoder,; compliant with the Zstandard compression format.; It can be used, for example, to better understand the format,; or as the basis for a separate implementation of Zstandard decoder. [__`decode_corpus`__](https://github.com/facebook/zstd/tree/dev/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing) :; This tool, stored in `/tests` directory, is able to generate random valid frames,; which is useful if you wish to test your decoder and verify it fully supports the specification.; ",MatchSource.DOCS,lib/zstd/doc/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md:1084,Testability,test,tests,1084,"Zstandard Documentation; =======================. This directory contains material defining the Zstandard format,; as well as detailed instructions to use `zstd` library. __`zstd_manual.html`__ : Documentation of `zstd.h` API, in html format.; Click on this link: [http://zstd.net/zstd_manual.html](http://zstd.net/zstd_manual.html); to display documentation of latest release in readable format within a browser. __`zstd_compression_format.md`__ : This document defines the Zstandard compression format.; Compliant decoders must adhere to this document,; and compliant encoders must generate data that follows it. Should you look for ressources to develop your own port of Zstandard algorithm,; you may find the following ressources useful :. __`educational_decoder`__ : This directory contains an implementation of a Zstandard decoder,; compliant with the Zstandard compression format.; It can be used, for example, to better understand the format,; or as the basis for a separate implementation of Zstandard decoder. [__`decode_corpus`__](https://github.com/facebook/zstd/tree/dev/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing) :; This tool, stored in `/tests` directory, is able to generate random valid frames,; which is useful if you wish to test your decoder and verify it fully supports the specification.; ",MatchSource.DOCS,lib/zstd/doc/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md:1151,Testability,test,testing,1151,"Zstandard Documentation; =======================. This directory contains material defining the Zstandard format,; as well as detailed instructions to use `zstd` library. __`zstd_manual.html`__ : Documentation of `zstd.h` API, in html format.; Click on this link: [http://zstd.net/zstd_manual.html](http://zstd.net/zstd_manual.html); to display documentation of latest release in readable format within a browser. __`zstd_compression_format.md`__ : This document defines the Zstandard compression format.; Compliant decoders must adhere to this document,; and compliant encoders must generate data that follows it. Should you look for ressources to develop your own port of Zstandard algorithm,; you may find the following ressources useful :. __`educational_decoder`__ : This directory contains an implementation of a Zstandard decoder,; compliant with the Zstandard compression format.; It can be used, for example, to better understand the format,; or as the basis for a separate implementation of Zstandard decoder. [__`decode_corpus`__](https://github.com/facebook/zstd/tree/dev/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing) :; This tool, stored in `/tests` directory, is able to generate random valid frames,; which is useful if you wish to test your decoder and verify it fully supports the specification.; ",MatchSource.DOCS,lib/zstd/doc/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md:1186,Testability,test,tests,1186,"Zstandard Documentation; =======================. This directory contains material defining the Zstandard format,; as well as detailed instructions to use `zstd` library. __`zstd_manual.html`__ : Documentation of `zstd.h` API, in html format.; Click on this link: [http://zstd.net/zstd_manual.html](http://zstd.net/zstd_manual.html); to display documentation of latest release in readable format within a browser. __`zstd_compression_format.md`__ : This document defines the Zstandard compression format.; Compliant decoders must adhere to this document,; and compliant encoders must generate data that follows it. Should you look for ressources to develop your own port of Zstandard algorithm,; you may find the following ressources useful :. __`educational_decoder`__ : This directory contains an implementation of a Zstandard decoder,; compliant with the Zstandard compression format.; It can be used, for example, to better understand the format,; or as the basis for a separate implementation of Zstandard decoder. [__`decode_corpus`__](https://github.com/facebook/zstd/tree/dev/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing) :; This tool, stored in `/tests` directory, is able to generate random valid frames,; which is useful if you wish to test your decoder and verify it fully supports the specification.; ",MatchSource.DOCS,lib/zstd/doc/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md:1277,Testability,test,test,1277,"Zstandard Documentation; =======================. This directory contains material defining the Zstandard format,; as well as detailed instructions to use `zstd` library. __`zstd_manual.html`__ : Documentation of `zstd.h` API, in html format.; Click on this link: [http://zstd.net/zstd_manual.html](http://zstd.net/zstd_manual.html); to display documentation of latest release in readable format within a browser. __`zstd_compression_format.md`__ : This document defines the Zstandard compression format.; Compliant decoders must adhere to this document,; and compliant encoders must generate data that follows it. Should you look for ressources to develop your own port of Zstandard algorithm,; you may find the following ressources useful :. __`educational_decoder`__ : This directory contains an implementation of a Zstandard decoder,; compliant with the Zstandard compression format.; It can be used, for example, to better understand the format,; or as the basis for a separate implementation of Zstandard decoder. [__`decode_corpus`__](https://github.com/facebook/zstd/tree/dev/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing) :; This tool, stored in `/tests` directory, is able to generate random valid frames,; which is useful if you wish to test your decoder and verify it fully supports the specification.; ",MatchSource.DOCS,lib/zstd/doc/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1959,Availability,error,error,1959,"nd other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, whi",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1985,Availability,error,error,1985,"nd other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, whi",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:2303,Availability,avail,available,2303,"ptional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, which is described by its header,; and has a guaranteed maximum content size, which depends on frame parameters.; Unlike frames, each block depends on previous blocks for proper decoding.; However, each block can be decompressed without waiting for its successor,; allowing streaming operations. Overview; ---------; - [F",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:54188,Availability,down,down,54188,"his formula:; ```; Number_of_Bits = (Weight>0) ? Max_Number_of_Bits + 1 - Weight : 0; ```; Symbols are sorted by `Weight`.; Within same `Weight`, symbols keep natural sequential order.; Symbols with a `Weight` of zero are removed.; Then, starting from lowest `Weight`, prefix codes are distributed in sequential order. __Example__ :; Let's presume the following list of weights has been decoded :. | Literal | 0 | 1 | 2 | 3 | 4 | 5 |; | -------- | --- | --- | --- | --- | --- | --- |; | `Weight` | 4 | 3 | 2 | 0 | 1 | 1 |. Sorted by weight and then natural sequential order,; it gives the following distribution :. | Literal | 3 | 4 | 5 | 2 | 1 | 0 |; | ---------------- | --- | --- | --- | --- | --- | ---- |; | `Weight` | 0 | 1 | 1 | 2 | 3 | 4 |; | `Number_of_Bits` | 0 | 4 | 4 | 3 | 2 | 1 |; | prefix codes | N/A | 0000| 0001| 001 | 01 | 1 |. ### Huffman-coded Streams. Given a Huffman decoding table,; it's possible to decode a Huffman-coded stream. Each bitstream must be read _backward_,; that is starting from the end down to the beginning.; Therefore it's necessary to know the size of each bitstream. It's also necessary to know exactly which _bit_ is the last one.; This is detected by a final bit flag :; the highest bit of latest byte is a final-bit-flag.; Consequently, a last byte of `0` is not possible.; And the final-bit-flag itself is not part of the useful bitstream.; Hence, the last byte contains between 0 and 7 useful bits. Starting from the end,; it's possible to read the bitstream in a __little-endian__ fashion,; keeping track of already used bits. Since the bitstream is encoded in reverse; order, starting from the end read symbols in forward order. For example, if the literal sequence ""0145"" was encoded using above prefix code,; it would be encoded (in reverse order) as:. |Symbol | 5 | 4 | 1 | 0 | Padding |; |--------|------|------|----|---|---------|; |Encoding|`0000`|`0001`|`01`|`1`| `00001` |. Resulting in following 2-bytes bitstream :; ```; 00010000 00001101; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:55697,Availability,fault,faulty,55697," from the end,; it's possible to read the bitstream in a __little-endian__ fashion,; keeping track of already used bits. Since the bitstream is encoded in reverse; order, starting from the end read symbols in forward order. For example, if the literal sequence ""0145"" was encoded using above prefix code,; it would be encoded (in reverse order) as:. |Symbol | 5 | 4 | 1 | 0 | Padding |; |--------|------|------|----|---|---------|; |Encoding|`0000`|`0001`|`01`|`1`| `00001` |. Resulting in following 2-bytes bitstream :; ```; 00010000 00001101; ```. Here is an alternative representation with the symbol codes separated by underscore:; ```; 0001_0000 00001_1_01; ```. Reading highest `Max_Number_of_Bits` bits,; it's possible to compare extracted value to decoding table,; determining the symbol to decode and number of bits to discard. The process continues up to reading the required number of symbols per stream.; If a bitstream is not entirely and exactly consumed,; hence reaching exactly its beginning position with _all_ bits consumed,; the decoding process is considered faulty. Dictionary Format; -----------------. Zstandard is compatible with ""raw content"" dictionaries,; free of any format restriction, except that they must be at least 8 bytes.; These dictionaries function as if they were just the `Content` part; of a formatted dictionary. But dictionaries created by `zstd --train` follow a format, described here. __Pre-requisites__ : a dictionary has a size,; defined either by a buffer limit, or a file size. | `Magic_Number` | `Dictionary_ID` | `Entropy_Tables` | `Content` |; | -------------- | --------------- | ---------------- | --------- |. __`Magic_Number`__ : 4 bytes ID, value 0xEC30A437, __little-endian__ format. __`Dictionary_ID`__ : 4 bytes, stored in __little-endian__ format.; `Dictionary_ID` can be any value, except 0 (which means no `Dictionary_ID`).; It's used by decoders to check if they use the correct dictionary. _Reserved ranges :_; If the frame is going to",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:62598,Availability,avail,available,62598," | 0 |; | 59 | 50 | 6 | 0 |; | 60 | 49 | 6 | 0 |; | 61 | 48 | 6 | 0 |; | 62 | 47 | 6 | 0 |; | 63 | 46 | 6 | 0 |. #### Offset Code:. | State | Symbol | Number_Of_Bits | Base |; | ----- | ------ | -------------- | ---- |; | 0 | 0 | 5 | 0 |; | 1 | 6 | 4 | 0 |; | 2 | 9 | 5 | 0 |; | 3 | 15 | 5 | 0 |; | 4 | 21 | 5 | 0 |; | 5 | 3 | 5 | 0 |; | 6 | 7 | 4 | 0 |; | 7 | 12 | 5 | 0 |; | 8 | 18 | 5 | 0 |; | 9 | 23 | 5 | 0 |; | 10 | 5 | 5 | 0 |; | 11 | 8 | 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman ex",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:63105,Availability,error,error,63105," 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several details, by Sean Purcell; - 0.2.2 : added predefined codes, by Johannes Rudolph; - 0.2.1 : clarify field names, by Przemyslaw Skibinski; - 0.2.0 : numerous format adjustments for zstd v0.8+; - 0.1.2 : limit Huffman tree depth to 11 bits; - 0.1.1 : reserved dictID ranges; - 0.1.0 : initial release; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:63573,Availability,error,error,63573," 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several details, by Sean Purcell; - 0.2.2 : added predefined codes, by Johannes Rudolph; - 0.2.1 : clarify field names, by Przemyslaw Skibinski; - 0.2.0 : numerous format adjustments for zstd v0.8+; - 0.1.2 : limit Huffman tree depth to 11 bits; - 0.1.1 : reserved dictID ranges; - 0.1.0 : initial release; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:7035,Deployability,continuous,continuous,7035,"-------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved_bit` |; | 2 | `Content_Checksum_flag` |; | 1-0 | `Dictionary_ID_flag` |. In this table, bit 7 is the highest bit, while bit 0 is the lowest one. __`Frame_Content_Size_flag`__. This is a 2-bits flag (`= Frame_Header_Descriptor >> 6`),; specifying if `Frame_Content_Size` (the decompressed data size); is provided within the header.; `Flag_Value` provides `FCS_Field_Size`,; which is the number of bytes used by `Frame_Content_Size`; according to the following table:. | `Flag_Value` | 0 | 1 | 2 | 3 |; | -------------- | ------ | --- | --- | --- |; |`FCS_Field_Size`| 0 or 1 | 2 | 4 | 8 |. When `Flag_Value` is `0`, `FCS_Field_Size` depends on `Single_Segment_flag` :; if `Single_Segment_flag` is set, `FCS_Field_Size` is 1.; Otherwise, `FCS_Field_Size` is 0 : `Frame_Content_Size` is not provided. __`Single_Segment_flag`__. If this flag is set,; data must be regenerated within a single continuous memory segment. In this case, `Window_Descriptor` byte is skipped,; but `Frame_Content_Size` is necessarily present.; As a consequence, the decoder must allocate a memory segment; of size equal or larger than `Frame_Content_Size`. In order to preserve the decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For broader compatibility, decoders are recommended to support; memory sizes of at least 8 MB.; This is only a recommendation,; each decoder is free to support higher or lower limits,; depending on local limitations. __`Unused_bit`__. A decoder compliant with this specification version shall not interpret this bit.; It might be used in any future version,; to signal a property which is transparent to properly decode the frame.; An encoder compliant with this specification version must set this bit to zero. __`Reserved_bit`__. This bit is reserve",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:24243,Deployability,update,updated,24243,"erleaved, in a single _bitstream_. The `Sequences_Section` starts by a header,; followed by optional probability tables for each symbol type,; followed by the bitstream. | `Sequences_Section_Header` | [`Literals_Length_Table`] | [`Offset_Table`] | [`Match_Length_Table`] | bitStream |; | -------------------------- | ------------------------- | ---------------- | ---------------------- | --------- |. To decode the `Sequences_Section`, it's required to know its size.; Its size is deduced from the size of `Literals_Section`:; `Sequences_Section_Size = Block_Size - Literals_Section_Size`. #### `Sequences_Section_Header`. Consists of 2 items:; - `Number_of_Sequences`; - Symbol compression modes. __`Number_of_Sequences`__. This is a variable size field using between 1 and 3 bytes.; Let's call its first byte `byte0`.; - `if (byte0 == 0)` : there are no sequences.; The sequence section stops there.; Decompressed content is defined entirely as Literals Section content.; The FSE tables used in `Repeat_Mode` aren't updated.; - `if (byte0 < 128)` : `Number_of_Sequences = byte0` . Uses 1 byte.; - `if (byte0 < 255)` : `Number_of_Sequences = ((byte0-128) << 8) + byte1` . Uses 2 bytes.; - `if (byte0 == 255)`: `Number_of_Sequences = byte1 + (byte2<<8) + 0x7F00` . Uses 3 bytes. __Symbol compression modes__. This is a single byte, defining the compression mode of each symbol type. |Bit number| 7-6 | 5-4 | 3-2 | 1-0 |; | -------- | ----------------------- | -------------- | -------------------- | ---------- |; |Field name| `Literals_Lengths_Mode` | `Offsets_Mode` | `Match_Lengths_Mode` | `Reserved` |. The last field, `Reserved`, must be all-zeroes. `Literals_Lengths_Mode`, `Offsets_Mode` and `Match_Lengths_Mode` define the `Compression_Mode` of; literals lengths, offsets, and match lengths symbols respectively. They follow the same enumeration :. | Value | 0 | 1 | 2 | 3 |; | ------------------ | ----------------- | ---------- | --------------------- | ------------- |; | `Compression_Mod",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:32902,Deployability,update,update,32902,"ately before the last `1`-bit for padding. After decoding the starting states, a single sequence is decoded; `Number_Of_Sequences` times.; These sequences are decoded in order from first to last.; Since the compressor writes the bitstream in the forward direction,; this means the compressor must encode the sequences starting with the last; one and ending with the first. ##### Decoding a sequence; For each of the symbol types, the FSE state can be used to determine the appropriate code.; The code then defines the `Baseline` and `Number_of_Bits` to read for each type.; See the [description of the codes] for how to determine these values. [description of the codes]: #the-codes-for-literals-lengths-match-lengths-and-offsets. Decoding starts by reading the `Number_of_Bits` required to decode `Offset`.; It then does the same for `Match_Length`, and then for `Literals_Length`.; This sequence is then used for [sequence execution](#sequence-execution). If it is not the last sequence in the block,; the next operation is to update states.; Using the rules pre-calculated in the decoding tables,; `Literals_Length_State` is updated,; followed by `Match_Length_State`,; and then `Offset_State`.; See the [FSE section](#fse) for details on how to update states from the bitstream. This operation will be repeated `Number_of_Sequences` times.; At the end, the bitstream shall be entirely consumed,; otherwise the bitstream is considered corrupted. #### Default Distributions; If `Predefined_Mode` is selected for a symbol type,; its FSE decoding table is generated from a predefined distribution table defined here.; For details on how to convert this distribution into a decoding table, see the [FSE section]. [FSE section]: #from-normalized-distribution-to-decoding-tables. ##### Literals Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short literalsLength_defaultDistribution[36] =; { 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2,",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:33001,Deployability,update,updated,33001,"Sequences` times.; These sequences are decoded in order from first to last.; Since the compressor writes the bitstream in the forward direction,; this means the compressor must encode the sequences starting with the last; one and ending with the first. ##### Decoding a sequence; For each of the symbol types, the FSE state can be used to determine the appropriate code.; The code then defines the `Baseline` and `Number_of_Bits` to read for each type.; See the [description of the codes] for how to determine these values. [description of the codes]: #the-codes-for-literals-lengths-match-lengths-and-offsets. Decoding starts by reading the `Number_of_Bits` required to decode `Offset`.; It then does the same for `Match_Length`, and then for `Literals_Length`.; This sequence is then used for [sequence execution](#sequence-execution). If it is not the last sequence in the block,; the next operation is to update states.; Using the rules pre-calculated in the decoding tables,; `Literals_Length_State` is updated,; followed by `Match_Length_State`,; and then `Offset_State`.; See the [FSE section](#fse) for details on how to update states from the bitstream. This operation will be repeated `Number_of_Sequences` times.; At the end, the bitstream shall be entirely consumed,; otherwise the bitstream is considered corrupted. #### Default Distributions; If `Predefined_Mode` is selected for a symbol type,; its FSE decoding table is generated from a predefined distribution table defined here.; For details on how to convert this distribution into a decoding table, see the [FSE section]. [FSE section]: #from-normalized-distribution-to-decoding-tables. ##### Literals Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short literalsLength_defaultDistribution[36] =; { 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1,; -1,-1,-1,-1 };; ```. ##### Match Length; The decoding table uses an accuracy log of 6 bits (64 states).",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:33122,Deployability,update,update,33122,"in the forward direction,; this means the compressor must encode the sequences starting with the last; one and ending with the first. ##### Decoding a sequence; For each of the symbol types, the FSE state can be used to determine the appropriate code.; The code then defines the `Baseline` and `Number_of_Bits` to read for each type.; See the [description of the codes] for how to determine these values. [description of the codes]: #the-codes-for-literals-lengths-match-lengths-and-offsets. Decoding starts by reading the `Number_of_Bits` required to decode `Offset`.; It then does the same for `Match_Length`, and then for `Literals_Length`.; This sequence is then used for [sequence execution](#sequence-execution). If it is not the last sequence in the block,; the next operation is to update states.; Using the rules pre-calculated in the decoding tables,; `Literals_Length_State` is updated,; followed by `Match_Length_State`,; and then `Offset_State`.; See the [FSE section](#fse) for details on how to update states from the bitstream. This operation will be repeated `Number_of_Sequences` times.; At the end, the bitstream shall be entirely consumed,; otherwise the bitstream is considered corrupted. #### Default Distributions; If `Predefined_Mode` is selected for a symbol type,; its FSE decoding table is generated from a predefined distribution table defined here.; For details on how to convert this distribution into a decoding table, see the [FSE section]. [FSE section]: #from-normalized-distribution-to-decoding-tables. ##### Literals Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short literalsLength_defaultDistribution[36] =; { 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1,; -1,-1,-1,-1 };; ```. ##### Match Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short matchLengths_defaultDistribution[53] =; { 1, 4, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:36883,Deployability,update,updates,36883,"ed_Offset1`, `Repeated_Offset2`, and `Repeated_Offset3`.; They are sorted in recency order, with `Repeated_Offset1` meaning ""most recent one"". If `offset_value == 1`, then the offset used is `Repeated_Offset1`, etc. There is an exception though, when current sequence's `literals_length = 0`.; In this case, repeated offsets are shifted by one,; so an `offset_value` of 1 means `Repeated_Offset2`,; an `offset_value` of 2 means `Repeated_Offset3`,; and an `offset_value` of 3 means `Repeated_Offset1 - 1_byte`. For the first block, the starting offset history is populated with following values :; `Repeated_Offset1`=1, `Repeated_Offset2`=4, `Repeated_Offset3`=8,; unless a dictionary is used, in which case they come from the dictionary. Then each block gets its starting offset history from the ending values of the most recent `Compressed_Block`.; Note that blocks which are not `Compressed_Block` are skipped, they do not contribute to offset history. [Offset Codes]: #offset-codes. ###### Offset updates rules. The newest offset takes the lead in offset history,; shifting others back by one rank,; up to the previous rank of the new offset _if it was present in history_. __Examples__ :. In the common case, when new offset is not part of history :; `Repeated_Offset3` = `Repeated_Offset2`; `Repeated_Offset2` = `Repeated_Offset1`; `Repeated_Offset1` = `NewOffset`. When the new offset _is_ part of history, there may be specific adjustments. When `NewOffset` == `Repeated_Offset1`, offset history remains actually unmodified. When `NewOffset` == `Repeated_Offset2`,; `Repeated_Offset1` and `Repeated_Offset2` ranks are swapped.; `Repeated_Offset3` is unmodified. When `NewOffset` == `Repeated_Offset3`,; there is actually no difference with the common case :; all offsets are shifted by one rank,; `NewOffset` (== `Repeated_Offset3`) becomes the new `Repeated_Offset1`. Also worth mentioning, the specific corner case when `offset_value` == 3,; and the literal length of the current sequence is",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:37985,Deployability,update,update,37985,"mples__ :. In the common case, when new offset is not part of history :; `Repeated_Offset3` = `Repeated_Offset2`; `Repeated_Offset2` = `Repeated_Offset1`; `Repeated_Offset1` = `NewOffset`. When the new offset _is_ part of history, there may be specific adjustments. When `NewOffset` == `Repeated_Offset1`, offset history remains actually unmodified. When `NewOffset` == `Repeated_Offset2`,; `Repeated_Offset1` and `Repeated_Offset2` ranks are swapped.; `Repeated_Offset3` is unmodified. When `NewOffset` == `Repeated_Offset3`,; there is actually no difference with the common case :; all offsets are shifted by one rank,; `NewOffset` (== `Repeated_Offset3`) becomes the new `Repeated_Offset1`. Also worth mentioning, the specific corner case when `offset_value` == 3,; and the literal length of the current sequence is zero.; In which case , `NewOffset` = `Repeated_Offset1` - 1_byte.; Here also, from an offset history update perspective, it's just a common case :; `Repeated_Offset3` = `Repeated_Offset2`; `Repeated_Offset2` = `Repeated_Offset1`; `Repeated_Offset1` = `NewOffset` ( == `Repeated_Offset1` - 1_byte ). Skippable Frames; ----------------. | `Magic_Number` | `Frame_Size` | `User_Data` |; |:--------------:|:------------:|:-----------:|; | 4 bytes | 4 bytes | n bytes |. Skippable frames allow the insertion of user-defined metadata; into a flow of concatenated frames. Skippable frames defined in this specification are compatible with [LZ4] ones. [LZ4]:http://www.lz4.org. From a compliant decoder perspective, skippable frames need just be skipped,; and their content ignored, resuming decoding after the skippable frame. It can be noted that a skippable frame; can be used to watermark a stream of concatenated frames; embedding any kind of tracking information (even just an UUID).; Users wary of such possibility should scan the stream of concatenated frames; in an attempt to detect such frame for analysis or removal. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:63285,Deployability,update,update,63285," 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several details, by Sean Purcell; - 0.2.2 : added predefined codes, by Johannes Rudolph; - 0.2.1 : clarify field names, by Przemyslaw Skibinski; - 0.2.0 : numerous format adjustments for zstd v0.8+; - 0.1.2 : limit Huffman tree depth to 11 bits; - 0.1.1 : reserved dictID ranges; - 0.1.0 : initial release; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:64027,Deployability,release,release,64027," 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several details, by Sean Purcell; - 0.2.2 : added predefined codes, by Johannes Rudolph; - 0.2.1 : clarify field names, by Przemyslaw Skibinski; - 0.2.0 : numerous format adjustments for zstd v0.8+; - 0.1.2 : limit Huffman tree depth to 11 bits; - 0.1.1 : reserved dictID ranges; - 0.1.0 : initial release; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:216,Energy Efficiency,charge,charge,216,"Zstandard Compression Format; ============================. ### Notices. Copyright (c) 2016-present Yann Collet, Facebook, Inc. Permission is granted to copy and distribute this document; for any purpose and without charge,; including translations into other languages; and incorporation into compilations,; provided that the copyright notice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version. 0.3.1 (25/10/18). Introduction; ------------. The purpose of this document is to define a lossless compressed data format,; that is independent of CPU type, operating system,; file system and character set, suitable for; file compression, pipe and streaming compression,; using the [Zstandard algorithm](http://www.zstandard.org).; The text of the specification assumes a basic background in programming; at the level of bits and other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; e",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:4765,Energy Efficiency,reduce,reduces,4765,"er frames.; The decompressed content of multiple concatenated frames is the concatenation of; each frame decompressed content. There are two frame formats defined by Zstandard:; Zstandard frames and Skippable frames.; Zstandard frames contain compressed data, while; skippable frames contain custom user metadata. ## Zstandard frames; The structure of a single Zstandard frame is following:. | `Magic_Number` | `Frame_Header` |`Data_Block`| [More data blocks] | [`Content_Checksum`] |; |:--------------:|:--------------:|:----------:| ------------------ |:--------------------:|; | 4 bytes | 2-14 bytes | n bytes | | 0-4 bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descr",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:7199,Energy Efficiency,allocate,allocate,7199," In this table, bit 7 is the highest bit, while bit 0 is the lowest one. __`Frame_Content_Size_flag`__. This is a 2-bits flag (`= Frame_Header_Descriptor >> 6`),; specifying if `Frame_Content_Size` (the decompressed data size); is provided within the header.; `Flag_Value` provides `FCS_Field_Size`,; which is the number of bytes used by `Frame_Content_Size`; according to the following table:. | `Flag_Value` | 0 | 1 | 2 | 3 |; | -------------- | ------ | --- | --- | --- |; |`FCS_Field_Size`| 0 or 1 | 2 | 4 | 8 |. When `Flag_Value` is `0`, `FCS_Field_Size` depends on `Single_Segment_flag` :; if `Single_Segment_flag` is set, `FCS_Field_Size` is 1.; Otherwise, `FCS_Field_Size` is 0 : `Frame_Content_Size` is not provided. __`Single_Segment_flag`__. If this flag is set,; data must be regenerated within a single continuous memory segment. In this case, `Window_Descriptor` byte is skipped,; but `Frame_Content_Size` is necessarily present.; As a consequence, the decoder must allocate a memory segment; of size equal or larger than `Frame_Content_Size`. In order to preserve the decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For broader compatibility, decoders are recommended to support; memory sizes of at least 8 MB.; This is only a recommendation,; each decoder is free to support higher or lower limits,; depending on local limitations. __`Unused_bit`__. A decoder compliant with this specification version shall not interpret this bit.; It might be used in any future version,; to signal a property which is transparent to properly decode the frame.; An encoder compliant with this specification version must set this bit to zero. __`Reserved_bit`__. This bit is reserved for some future feature.; Its value _must be zero_.; A decoder compliant with this specification version must ensure it is not set.; This bit may be used in a future revision,; to signal a feature that",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:8865,Energy Efficiency,allocate,allocate,8865,"s transparent to properly decode the frame.; An encoder compliant with this specification version must set this bit to zero. __`Reserved_bit`__. This bit is reserved for some future feature.; Its value _must be zero_.; A decoder compliant with this specification version must ensure it is not set.; This bit may be used in a future revision,; to signal a feature that must be interpreted to decode the frame correctly. __`Content_Checksum_flag`__. If this flag is set, a 32-bits `Content_Checksum` will be present at frame's end.; See `Content_Checksum` paragraph. __`Dictionary_ID_flag`__. This is a 2-bits flag (`= FHD & 3`),; telling if a dictionary ID is provided within the header.; It also specifies the size of this field as `DID_Field_Size`. |`Flag_Value` | 0 | 1 | 2 | 3 |; | -------------- | --- | --- | --- | --- |; |`DID_Field_Size`| 0 | 1 | 2 | 4 |. #### `Window_Descriptor`. Provides guarantees on minimum memory buffer required to decompress a frame.; This information is important for decoders to allocate enough memory. The `Window_Descriptor` byte is optional.; When `Single_Segment_flag` is set, `Window_Descriptor` is not present.; In this case, `Window_Size` is `Frame_Content_Size`,; which can be any value from 0 to 2^64-1 bytes (16 ExaBytes). | Bit numbers | 7-3 | 2-0 |; | ----------- | ---------- | ---------- |; | Field name | `Exponent` | `Mantissa` |. The minimum memory buffer size is called `Window_Size`.; It is described by the following formulas :; ```; windowLog = 10 + Exponent;; windowBase = 1 << windowLog;; windowAdd = (windowBase / 8) * Mantissa;; Window_Size = windowBase + windowAdd;; ```; The minimum `Window_Size` is 1 KB.; The maximum `Window_Size` is `(1<<41) + 7*(1<<38)` bytes, which is 3.75 TB. In general, larger `Window_Size` tend to improve compression ratio,; but at the cost of memory usage. To properly decode compressed data,; a decoder will need to allocate a buffer of at least `Window_Size` bytes. In order to preserve decoder from unreasonab",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:9758,Energy Efficiency,allocate,allocate,9758,"arantees on minimum memory buffer required to decompress a frame.; This information is important for decoders to allocate enough memory. The `Window_Descriptor` byte is optional.; When `Single_Segment_flag` is set, `Window_Descriptor` is not present.; In this case, `Window_Size` is `Frame_Content_Size`,; which can be any value from 0 to 2^64-1 bytes (16 ExaBytes). | Bit numbers | 7-3 | 2-0 |; | ----------- | ---------- | ---------- |; | Field name | `Exponent` | `Mantissa` |. The minimum memory buffer size is called `Window_Size`.; It is described by the following formulas :; ```; windowLog = 10 + Exponent;; windowBase = 1 << windowLog;; windowAdd = (windowBase / 8) * Mantissa;; Window_Size = windowBase + windowAdd;; ```; The minimum `Window_Size` is 1 KB.; The maximum `Window_Size` is `(1<<41) + 7*(1<<38)` bytes, which is 3.75 TB. In general, larger `Window_Size` tend to improve compression ratio,; but at the cost of memory usage. To properly decode compressed data,; a decoder will need to allocate a buffer of at least `Window_Size` bytes. In order to preserve decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For improved interoperability,; it's recommended for decoders to support `Window_Size` of up to 8 MB,; and it's recommended for encoders to not generate frame requiring `Window_Size` larger than 8 MB.; It's merely a recommendation though,; decoders are free to support larger or lower limits,; depending on local limitations. #### `Dictionary_ID`. This is a variable size field, which contains; the ID of the dictionary required to properly decode the frame.; `Dictionary_ID` field is optional. When it's not present,; it's up to the decoder to know which dictionary to use. `Dictionary_ID` field size is provided by `DID_Field_Size`.; `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can rep",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:10960,Energy Efficiency,efficient,efficient,10960," a compressed frame; which requests a memory size beyond decoder's authorized range. For improved interoperability,; it's recommended for decoders to support `Window_Size` of up to 8 MB,; and it's recommended for encoders to not generate frame requiring `Window_Size` larger than 8 MB.; It's merely a recommendation though,; decoders are free to support larger or lower limits,; depending on local limitations. #### `Dictionary_ID`. This is a variable size field, which contains; the ID of the dictionary required to properly decode the frame.; `Dictionary_ID` field is optional. When it's not present,; it's up to the decoder to know which dictionary to use. `Dictionary_ID` field size is provided by `DID_Field_Size`.; `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can represent an ID 0-65535.; 4 bytes can represent an ID 0-4294967295.; Format is __little-endian__. It's allowed to represent a small ID (for example `13`); with a large 4-bytes dictionary ID, even if it is less efficient. _Reserved ranges :_; Within private environments, any `Dictionary_ID` can be used. However, for frames and dictionaries distributed in public space,; `Dictionary_ID` must be attributed carefully.; Rules for public environment are not yet decided,; but the following ranges are reserved for some future registrar :; - low range : `<= 32767`; - high range : `>= (1 << 31)`. Outside of these ranges, any value of `Dictionary_ID`; which is both `>= 32768` and `< (1<<31)` can be used freely,; even in public environment. #### `Frame_Content_Size`. This is the original (uncompressed) size. This information is optional.; `Frame_Content_Size` uses a variable number of bytes, provided by `FCS_Field_Size`.; `FCS_Field_Size` is provided by the value of `Frame_Content_Size_flag`.; `FCS_Field_Size` can be equal to 0 (not present), 1, 2, 4 or 8 bytes. | `FCS_Field_Size` | Range |; | ---------------- | ---------- |; | 0 | unknown |; | 1 | 0 - 2",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:16295,Energy Efficiency,charge,charge,16295,"required by `Repeat_Mode`; for each symbol type (literals lengths, match lengths, offsets). Note that decoding tables aren't always from the previous `Compressed_Block`. - Every decoding table can come from a dictionary.; - The Huffman tree comes from the previous `Compressed_Literals_Block`. Literals Section; ----------------; All literals are regrouped in the first part of the block.; They can be decoded first, and then copied during [Sequence Execution],; or they can be decoded on the flow during [Sequence Execution]. Literals can be stored uncompressed or compressed using Huffman prefix codes.; When compressed, an optional tree description can be present,; followed by 1 or 4 streams. | `Literals_Section_Header` | [`Huffman_Tree_Description`] | [jumpTable] | Stream1 | [Stream2] | [Stream3] | [Stream4] |; | ------------------------- | ---------------------------- | ----------- | ------- | --------- | --------- | --------- |. ### `Literals_Section_Header`. Header is in charge of describing how literals are packed.; It's a byte-aligned variable-size bitfield, ranging from 1 to 5 bytes,; using __little-endian__ convention. | `Literals_Block_Type` | `Size_Format` | `Regenerated_Size` | [`Compressed_Size`] |; | --------------------- | ------------- | ------------------ | ------------------- |; | 2 bits | 1 - 2 bits | 5 - 20 bits | 0 - 18 bits |. In this representation, bits on the left are the lowest bits. __`Literals_Block_Type`__. This field uses 2 lowest bits of first byte, describing 4 different block types :. | `Literals_Block_Type` | Value |; | --------------------------- | ----- |; | `Raw_Literals_Block` | 0 |; | `RLE_Literals_Block` | 1 |; | `Compressed_Literals_Block` | 2 |; | `Treeless_Literals_Block` | 3 |. - `Raw_Literals_Block` - Literals are stored uncompressed.; - `RLE_Literals_Block` - Literals consist of a single byte value; repeated `Regenerated_Size` times.; - `Compressed_Literals_Block` - This is a standard Huffman-compressed block,; starting with a ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:19191,Energy Efficiency,efficient,efficient,19191,"ing several bytes, convention is __little-endian__. __`Size_Format` for `Raw_Literals_Block` and `RLE_Literals_Block`__ :. `Size_Format` uses 1 _or_ 2 bits.; Its value is : `Size_Format = (Literals_Section_Header[0]>>2) & 3`. - `Size_Format` == 00 or 10 : `Size_Format` uses 1 bit.; `Regenerated_Size` uses 5 bits (0-31).; `Literals_Section_Header` uses 1 byte.; `Regenerated_Size = Literals_Section_Header[0]>>3`; - `Size_Format` == 01 : `Size_Format` uses 2 bits.; `Regenerated_Size` uses 12 bits (0-4095).; `Literals_Section_Header` uses 2 bytes.; `Regenerated_Size = (Literals_Section_Header[0]>>4) + (Literals_Section_Header[1]<<4)`; - `Size_Format` == 11 : `Size_Format` uses 2 bits.; `Regenerated_Size` uses 20 bits (0-1048575).; `Literals_Section_Header` uses 3 bytes.; `Regenerated_Size = (Literals_Section_Header[0]>>4) + (Literals_Section_Header[1]<<4) + (Literals_Section_Header[2]<<12)`. Only Stream1 is present for these cases.; Note : it's allowed to represent a short value (for example `13`); using a long format, even if it's less efficient. __`Size_Format` for `Compressed_Literals_Block` and `Treeless_Literals_Block`__ :. `Size_Format` always uses 2 bits. - `Size_Format` == 00 : _A single stream_.; Both `Regenerated_Size` and `Compressed_Size` use 10 bits (0-1023).; `Literals_Section_Header` uses 3 bytes.; - `Size_Format` == 01 : 4 streams.; Both `Regenerated_Size` and `Compressed_Size` use 10 bits (0-1023).; `Literals_Section_Header` uses 3 bytes.; - `Size_Format` == 10 : 4 streams.; Both `Regenerated_Size` and `Compressed_Size` use 14 bits (0-16383).; `Literals_Section_Header` uses 4 bytes.; - `Size_Format` == 11 : 4 streams.; Both `Regenerated_Size` and `Compressed_Size` use 18 bits (0-262143).; `Literals_Section_Header` uses 5 bytes. Both `Compressed_Size` and `Regenerated_Size` fields follow __little-endian__ convention.; Note: `Compressed_Size` __includes__ the size of the Huffman Tree description; _when_ it is present. #### Raw Literals Block; The data in ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:40549,Energy Efficiency,power,power,40549,"ata`__. The `User_Data` can be anything. Data will just be skipped by the decoder. Entropy Encoding; ----------------; Two types of entropy encoding are used by the Zstandard format:; FSE, and Huffman coding.; Huffman is used to compress literals,; while FSE is used for all other symbols; (`Literals_Length_Code`, `Match_Length_Code`, offset codes); and to compress Huffman headers. FSE; ---; FSE, short for Finite State Entropy, is an entropy codec based on [ANS].; FSE encoding/decoding involves a state that is carried over between symbols,; so decoding must be done in the opposite direction as encoding.; Therefore, all FSE bitstreams are read from end to beginning.; Note that the order of the bits in the stream is not reversed,; we just read the elements in the reverse order they are written. For additional details on FSE, see [Finite State Entropy]. [Finite State Entropy]:https://github.com/Cyan4973/FiniteStateEntropy/. FSE decoding involves a decoding table which has a power of 2 size, and contain three elements:; `Symbol`, `Num_Bits`, and `Baseline`.; The `log2` of the table size is its `Accuracy_Log`.; An FSE state value represents an index in this table. To obtain the initial state value, consume `Accuracy_Log` bits from the stream as a __little-endian__ value.; The next symbol in the stream is the `Symbol` indicated in the table for that state.; To obtain the next state value,; the decoder should consume `Num_Bits` bits from the stream as a __little-endian__ value and add it to `Baseline`. [ANS]: https://en.wikipedia.org/wiki/Asymmetric_Numeral_Systems. ### FSE Table Description; To decode FSE streams, it is necessary to construct the decoding table.; The Zstandard format encodes FSE table descriptions as follows:. An FSE distribution table describes the probabilities of all symbols; from `0` to the last present one (included); on a normalized scale of `1 << Accuracy_Log` .; Note that there must be two or more symbols with nonzero probability. It's a bitstream w",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:43220,Energy Efficiency,allocate,allocated,43220,"100 + 1 == 157` (inclusive).; Therefore, it must read `log2sup(157) == 8` bits. - Value decoded : small values use 1 less bit :; __example__ :; Presuming values from 0 to 157 (inclusive) are possible,; 255-157 = 98 values are remaining in an 8-bits field.; They are used this way :; first 98 values (hence from 0 to 97) use only 7 bits,; values from 98 to 157 use 8 bits.; This is achieved through this scheme :. | Value read | Value decoded | Number of bits used |; | ---------- | ------------- | ------------------- |; | 0 - 97 | 0 - 97 | 7 |; | 98 - 127 | 98 - 127 | 8 |; | 128 - 225 | 0 - 97 | 7 |; | 226 - 255 | 128 - 157 | 8 |. Symbols probabilities are read one by one, in order. Probability is obtained from Value decoded by following formula :; `Proba = value - 1`. It means value `0` becomes negative probability `-1`.; `-1` is a special probability, which means ""less than 1"".; Its effect on distribution table is described in the [next section].; For the purpose of calculating total allocated probability points, it counts as one. [next section]:#from-normalized-distribution-to-decoding-tables. When a symbol has a __probability__ of `zero`,; it is followed by a 2-bits repeat flag.; This repeat flag tells how many probabilities of zeroes follow the current one.; It provides a number ranging from 0 to 3.; If it is a 3, another 2-bits repeat flag follows, and so on. When last symbol reaches cumulated total of `1 << Accuracy_Log`,; decoding is complete.; If the last symbol makes cumulated total go above `1 << Accuracy_Log`,; distribution is considered corrupted. Then the decoder can tell how many bytes were used in this process,; and how many symbols are present.; The bitstream consumes a round number of bytes.; Any remaining bit within the last byte is just unused. #### From normalized distribution to decoding tables. The distribution of normalized probabilities is enough; to create a unique decoding table. It follows the following build rule :. The table has a size of `T",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:44630,Energy Efficiency,allocate,allocated,44630,"umulated total of `1 << Accuracy_Log`,; decoding is complete.; If the last symbol makes cumulated total go above `1 << Accuracy_Log`,; distribution is considered corrupted. Then the decoder can tell how many bytes were used in this process,; and how many symbols are present.; The bitstream consumes a round number of bytes.; Any remaining bit within the last byte is just unused. #### From normalized distribution to decoding tables. The distribution of normalized probabilities is enough; to create a unique decoding table. It follows the following build rule :. The table has a size of `Table_Size = 1 << Accuracy_Log`.; Each cell describes the symbol decoded,; and instructions to get the next state. Symbols are scanned in their natural order for ""less than 1"" probabilities.; Symbols with this probability are being attributed a single cell,; starting from the end of the table and retreating.; These symbols define a full state reset, reading `Accuracy_Log` bits. All remaining symbols are allocated in their natural order.; Starting from symbol `0` and table position `0`,; each symbol gets allocated as many cells as its probability.; Cell allocation is spreaded, not linear :; each successor position follow this rule :. ```; position += (tableSize>>1) + (tableSize>>3) + 3;; position &= tableSize-1;; ```. A position is skipped if already occupied by a ""less than 1"" probability symbol.; `position` does not reset between symbols, it simply iterates through; each position in the table, switching to the next symbol when enough; states have been allocated to the current one. The result is a list of state values.; Each state will decode the current symbol. To get the `Number_of_Bits` and `Baseline` required for next state,; it's first necessary to sort all states in their natural order.; The lower states will need 1 more bit than higher ones.; The process is repeated for each symbol. __Example__ :; Presuming a symbol has a probability of 5.; It receives 5 state values. States are s",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:44732,Energy Efficiency,allocate,allocated,44732,"s cumulated total go above `1 << Accuracy_Log`,; distribution is considered corrupted. Then the decoder can tell how many bytes were used in this process,; and how many symbols are present.; The bitstream consumes a round number of bytes.; Any remaining bit within the last byte is just unused. #### From normalized distribution to decoding tables. The distribution of normalized probabilities is enough; to create a unique decoding table. It follows the following build rule :. The table has a size of `Table_Size = 1 << Accuracy_Log`.; Each cell describes the symbol decoded,; and instructions to get the next state. Symbols are scanned in their natural order for ""less than 1"" probabilities.; Symbols with this probability are being attributed a single cell,; starting from the end of the table and retreating.; These symbols define a full state reset, reading `Accuracy_Log` bits. All remaining symbols are allocated in their natural order.; Starting from symbol `0` and table position `0`,; each symbol gets allocated as many cells as its probability.; Cell allocation is spreaded, not linear :; each successor position follow this rule :. ```; position += (tableSize>>1) + (tableSize>>3) + 3;; position &= tableSize-1;; ```. A position is skipped if already occupied by a ""less than 1"" probability symbol.; `position` does not reset between symbols, it simply iterates through; each position in the table, switching to the next symbol when enough; states have been allocated to the current one. The result is a list of state values.; Each state will decode the current symbol. To get the `Number_of_Bits` and `Baseline` required for next state,; it's first necessary to sort all states in their natural order.; The lower states will need 1 more bit than higher ones.; The process is repeated for each symbol. __Example__ :; Presuming a symbol has a probability of 5.; It receives 5 state values. States are sorted in natural order. Next power of 2 is 8.; Space of probabilities is divided into ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:45190,Energy Efficiency,allocate,allocated,45190,"to create a unique decoding table. It follows the following build rule :. The table has a size of `Table_Size = 1 << Accuracy_Log`.; Each cell describes the symbol decoded,; and instructions to get the next state. Symbols are scanned in their natural order for ""less than 1"" probabilities.; Symbols with this probability are being attributed a single cell,; starting from the end of the table and retreating.; These symbols define a full state reset, reading `Accuracy_Log` bits. All remaining symbols are allocated in their natural order.; Starting from symbol `0` and table position `0`,; each symbol gets allocated as many cells as its probability.; Cell allocation is spreaded, not linear :; each successor position follow this rule :. ```; position += (tableSize>>1) + (tableSize>>3) + 3;; position &= tableSize-1;; ```. A position is skipped if already occupied by a ""less than 1"" probability symbol.; `position` does not reset between symbols, it simply iterates through; each position in the table, switching to the next symbol when enough; states have been allocated to the current one. The result is a list of state values.; Each state will decode the current symbol. To get the `Number_of_Bits` and `Baseline` required for next state,; it's first necessary to sort all states in their natural order.; The lower states will need 1 more bit than higher ones.; The process is repeated for each symbol. __Example__ :; Presuming a symbol has a probability of 5.; It receives 5 state values. States are sorted in natural order. Next power of 2 is 8.; Space of probabilities is divided into 8 equal parts.; Presuming the `Accuracy_Log` is 7, it defines 128 states.; Divided by 8, each share is 16 large. In order to reach 8, 8-5=3 lowest states will count ""double"",; doubling the number of shares (32 in width),; requiring one more bit in the process. Baseline is assigned starting from the higher states using fewer bits,; and proceeding naturally, then resuming at the first state,; each takes i",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:45662,Energy Efficiency,power,power,45662,"arting from symbol `0` and table position `0`,; each symbol gets allocated as many cells as its probability.; Cell allocation is spreaded, not linear :; each successor position follow this rule :. ```; position += (tableSize>>1) + (tableSize>>3) + 3;; position &= tableSize-1;; ```. A position is skipped if already occupied by a ""less than 1"" probability symbol.; `position` does not reset between symbols, it simply iterates through; each position in the table, switching to the next symbol when enough; states have been allocated to the current one. The result is a list of state values.; Each state will decode the current symbol. To get the `Number_of_Bits` and `Baseline` required for next state,; it's first necessary to sort all states in their natural order.; The lower states will need 1 more bit than higher ones.; The process is repeated for each symbol. __Example__ :; Presuming a symbol has a probability of 5.; It receives 5 state values. States are sorted in natural order. Next power of 2 is 8.; Space of probabilities is divided into 8 equal parts.; Presuming the `Accuracy_Log` is 7, it defines 128 states.; Divided by 8, each share is 16 large. In order to reach 8, 8-5=3 lowest states will count ""double"",; doubling the number of shares (32 in width),; requiring one more bit in the process. Baseline is assigned starting from the higher states using fewer bits,; and proceeding naturally, then resuming at the first state,; each takes its allocated width from Baseline. | state order | 0 | 1 | 2 | 3 | 4 |; | ---------------- | ----- | ----- | ------ | ---- | ----- |; | width | 32 | 32 | 32 | 16 | 16 |; | `Number_of_Bits` | 5 | 5 | 5 | 4 | 4 |; | range number | 2 | 4 | 6 | 0 | 1 |; | `Baseline` | 32 | 64 | 96 | 0 | 16 |; | range | 32-63 | 64-95 | 96-127 | 0-15 | 16-31 |. The next state is determined from current state; by reading the required `Number_of_Bits`, and adding the specified `Baseline`. See [Appendix A] for the results of this process applied to the default di",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:46128,Energy Efficiency,allocate,allocated,46128,"mbols, it simply iterates through; each position in the table, switching to the next symbol when enough; states have been allocated to the current one. The result is a list of state values.; Each state will decode the current symbol. To get the `Number_of_Bits` and `Baseline` required for next state,; it's first necessary to sort all states in their natural order.; The lower states will need 1 more bit than higher ones.; The process is repeated for each symbol. __Example__ :; Presuming a symbol has a probability of 5.; It receives 5 state values. States are sorted in natural order. Next power of 2 is 8.; Space of probabilities is divided into 8 equal parts.; Presuming the `Accuracy_Log` is 7, it defines 128 states.; Divided by 8, each share is 16 large. In order to reach 8, 8-5=3 lowest states will count ""double"",; doubling the number of shares (32 in width),; requiring one more bit in the process. Baseline is assigned starting from the higher states using fewer bits,; and proceeding naturally, then resuming at the first state,; each takes its allocated width from Baseline. | state order | 0 | 1 | 2 | 3 | 4 |; | ---------------- | ----- | ----- | ------ | ---- | ----- |; | width | 32 | 32 | 32 | 16 | 16 |; | `Number_of_Bits` | 5 | 5 | 5 | 4 | 4 |; | range number | 2 | 4 | 6 | 0 | 1 |; | `Baseline` | 32 | 64 | 96 | 0 | 16 |; | range | 32-63 | 64-95 | 96-127 | 0-15 | 16-31 |. The next state is determined from current state; by reading the required `Number_of_Bits`, and adding the specified `Baseline`. See [Appendix A] for the results of this process applied to the default distributions. [Appendix A]: #appendix-a---decoding-tables-for-predefined-codes. Huffman Coding; --------------; Zstandard Huffman-coded streams are read backwards,; similar to the FSE bitstreams.; Therefore, to find the start of the bitstream, it is therefore to; know the offset of the last byte of the Huffman-coded stream. After writing the last bit containing information, the compressor; writes a s",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:48727,Energy Efficiency,power,power,48727,"s symbols from an a priori known alphabet; by bit sequences (codewords), one codeword for each symbol,; in a manner such that different symbols may be represented; by bit sequences of different lengths,; but a parser can always parse an encoded string; unambiguously symbol-by-symbol. Given an alphabet with known symbol frequencies,; the Huffman algorithm allows the construction of an optimal prefix code; using the fewest bits of any possible prefix codes for that alphabet. Prefix code must not exceed a maximum code length.; More bits improve accuracy but cost more header size,; and require more memory or more complex decoding operations.; This specification limits maximum code length to 11 bits. #### Representation. All literal values from zero (included) to last present one (excluded); are represented by `Weight` with values from `0` to `Max_Number_of_Bits`.; Transformation from `Weight` to `Number_of_Bits` follows this formula :; ```; Number_of_Bits = Weight ? (Max_Number_of_Bits + 1 - Weight) : 0; ```; The last symbol's `Weight` is deduced from previously decoded ones,; by completing to the nearest power of 2.; This power of 2 gives `Max_Number_of_Bits`, the depth of the current tree.; `Max_Number_of_Bits` must be <= 11,; otherwise the representation is considered corrupted. __Example__ :; Let's presume the following Huffman tree must be described :. | literal value | 0 | 1 | 2 | 3 | 4 | 5 |; | ---------------- | --- | --- | --- | --- | --- | --- |; | `Number_of_Bits` | 1 | 2 | 3 | 0 | 4 | 4 |. The tree depth is 4, since its longest elements uses 4 bits; (longest elements are the one with smallest frequency).; Value `5` will not be listed, as it can be determined from values for 0-4,; nor will values above `5` as they are all 0.; Values from `0` to `4` will be listed using `Weight` instead of `Number_of_Bits`.; Weight formula is :; ```; Weight = Number_of_Bits ? (Max_Number_of_Bits + 1 - Number_of_Bits) : 0; ```; It gives the following series of weights :. | liter",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:48745,Energy Efficiency,power,power,48745,"it sequences of different lengths,; but a parser can always parse an encoded string; unambiguously symbol-by-symbol. Given an alphabet with known symbol frequencies,; the Huffman algorithm allows the construction of an optimal prefix code; using the fewest bits of any possible prefix codes for that alphabet. Prefix code must not exceed a maximum code length.; More bits improve accuracy but cost more header size,; and require more memory or more complex decoding operations.; This specification limits maximum code length to 11 bits. #### Representation. All literal values from zero (included) to last present one (excluded); are represented by `Weight` with values from `0` to `Max_Number_of_Bits`.; Transformation from `Weight` to `Number_of_Bits` follows this formula :; ```; Number_of_Bits = Weight ? (Max_Number_of_Bits + 1 - Weight) : 0; ```; The last symbol's `Weight` is deduced from previously decoded ones,; by completing to the nearest power of 2.; This power of 2 gives `Max_Number_of_Bits`, the depth of the current tree.; `Max_Number_of_Bits` must be <= 11,; otherwise the representation is considered corrupted. __Example__ :; Let's presume the following Huffman tree must be described :. | literal value | 0 | 1 | 2 | 3 | 4 | 5 |; | ---------------- | --- | --- | --- | --- | --- | --- |; | `Number_of_Bits` | 1 | 2 | 3 | 0 | 4 | 4 |. The tree depth is 4, since its longest elements uses 4 bits; (longest elements are the one with smallest frequency).; Value `5` will not be listed, as it can be determined from values for 0-4,; nor will values above `5` as they are all 0.; Values from `0` to `4` will be listed using `Weight` instead of `Number_of_Bits`.; Weight formula is :; ```; Weight = Number_of_Bits ? (Max_Number_of_Bits + 1 - Number_of_Bits) : 0; ```; It gives the following series of weights :. | literal value | 0 | 1 | 2 | 3 | 4 |; | ------------- | --- | --- | --- | --- | --- |; | `Weight` | 4 | 3 | 2 | 0 | 1 |. The decoder will do the inverse operation :; having ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:49964,Energy Efficiency,power,power,49964,"he following Huffman tree must be described :. | literal value | 0 | 1 | 2 | 3 | 4 | 5 |; | ---------------- | --- | --- | --- | --- | --- | --- |; | `Number_of_Bits` | 1 | 2 | 3 | 0 | 4 | 4 |. The tree depth is 4, since its longest elements uses 4 bits; (longest elements are the one with smallest frequency).; Value `5` will not be listed, as it can be determined from values for 0-4,; nor will values above `5` as they are all 0.; Values from `0` to `4` will be listed using `Weight` instead of `Number_of_Bits`.; Weight formula is :; ```; Weight = Number_of_Bits ? (Max_Number_of_Bits + 1 - Number_of_Bits) : 0; ```; It gives the following series of weights :. | literal value | 0 | 1 | 2 | 3 | 4 |; | ------------- | --- | --- | --- | --- | --- |; | `Weight` | 4 | 3 | 2 | 0 | 1 |. The decoder will do the inverse operation :; having collected weights of literal symbols from `0` to `4`,; it knows the last literal, `5`, is present with a non-zero `Weight`.; The `Weight` of `5` can be determined by advancing to the next power of 2.; The sum of `2^(Weight-1)` (excluding 0's) is :; `8 + 4 + 2 + 0 + 1 = 15`.; Nearest larger power of 2 value is 16.; Therefore, `Max_Number_of_Bits = 4` and `Weight[5] = 16-15 = 1`. #### Huffman Tree header. This is a single byte value (0-255),; which describes how the series of weights is encoded. - if `headerByte` < 128 :; the series of weights is compressed using FSE (see below).; The length of the FSE-compressed series is equal to `headerByte` (0-127). - if `headerByte` >= 128 :; + the series of weights uses a direct representation,; where each `Weight` is encoded directly as a 4 bits field (0-15).; + They are encoded forward, 2 weights to a byte,; first weight taking the top four bits and second one taking the bottom four.; * e.g. the following operations could be used to read the weights:; `Weight[0] = (Byte[0] >> 4), Weight[1] = (Byte[0] & 0xf)`, etc.; + The full representation occupies `Ceiling(Number_of_Weights/2)` bytes,; meaning it uses ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:50067,Energy Efficiency,power,power,50067,"| --- | --- |; | `Number_of_Bits` | 1 | 2 | 3 | 0 | 4 | 4 |. The tree depth is 4, since its longest elements uses 4 bits; (longest elements are the one with smallest frequency).; Value `5` will not be listed, as it can be determined from values for 0-4,; nor will values above `5` as they are all 0.; Values from `0` to `4` will be listed using `Weight` instead of `Number_of_Bits`.; Weight formula is :; ```; Weight = Number_of_Bits ? (Max_Number_of_Bits + 1 - Number_of_Bits) : 0; ```; It gives the following series of weights :. | literal value | 0 | 1 | 2 | 3 | 4 |; | ------------- | --- | --- | --- | --- | --- |; | `Weight` | 4 | 3 | 2 | 0 | 1 |. The decoder will do the inverse operation :; having collected weights of literal symbols from `0` to `4`,; it knows the last literal, `5`, is present with a non-zero `Weight`.; The `Weight` of `5` can be determined by advancing to the next power of 2.; The sum of `2^(Weight-1)` (excluding 0's) is :; `8 + 4 + 2 + 0 + 1 = 15`.; Nearest larger power of 2 value is 16.; Therefore, `Max_Number_of_Bits = 4` and `Weight[5] = 16-15 = 1`. #### Huffman Tree header. This is a single byte value (0-255),; which describes how the series of weights is encoded. - if `headerByte` < 128 :; the series of weights is compressed using FSE (see below).; The length of the FSE-compressed series is equal to `headerByte` (0-127). - if `headerByte` >= 128 :; + the series of weights uses a direct representation,; where each `Weight` is encoded directly as a 4 bits field (0-15).; + They are encoded forward, 2 weights to a byte,; first weight taking the top four bits and second one taking the bottom four.; * e.g. the following operations could be used to read the weights:; `Weight[0] = (Byte[0] >> 4), Weight[1] = (Byte[0] & 0xf)`, etc.; + The full representation occupies `Ceiling(Number_of_Weights/2)` bytes,; meaning it uses only full bytes even if `Number_of_Weights` is odd.; + `Number_of_Weights = headerByte - 127`.; * Note that maximum `Number_of_Weight",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1991,Integrability,message,message,1991,"nd other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, whi",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:3027,Integrability,depend,depends,3027,"ciated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, which is described by its header,; and has a guaranteed maximum content size, which depends on frame parameters.; Unlike frames, each block depends on previous blocks for proper decoding.; However, each block can be decompressed without waiting for its successor,; allowing streaming operations. Overview; ---------; - [Frames](#frames); - [Zstandard frames](#zstandard-frames); - [Blocks](#blocks); - [Literals Section](#literals-section); - [Sequences Section](#sequences-section); - [Sequence Execution](#sequence-execution); - [Skippable frames](#skippable-frames); - [Entropy Encoding](#entropy-encoding); - [FSE](#fse); - [Huffman Coding](#huffman-coding); - [Dictionary Format](#dictionary-format). Frames; ------; Zstandard compressed data is made of one or more __frames__.; Each frame is independent and can be decompressed independently of other frames.; The decompressed content of multiple concatenated frames is the concatenation of; each frame decompressed content. There are two frame formats defined by Zstandard:; Zsta",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:3083,Integrability,depend,depends,3083,"nters of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, which is described by its header,; and has a guaranteed maximum content size, which depends on frame parameters.; Unlike frames, each block depends on previous blocks for proper decoding.; However, each block can be decompressed without waiting for its successor,; allowing streaming operations. Overview; ---------; - [Frames](#frames); - [Zstandard frames](#zstandard-frames); - [Blocks](#blocks); - [Literals Section](#literals-section); - [Sequences Section](#sequences-section); - [Sequence Execution](#sequence-execution); - [Skippable frames](#skippable-frames); - [Entropy Encoding](#entropy-encoding); - [FSE](#fse); - [Huffman Coding](#huffman-coding); - [Dictionary Format](#dictionary-format). Frames; ------; Zstandard compressed data is made of one or more __frames__.; Each frame is independent and can be decompressed independently of other frames.; The decompressed content of multiple concatenated frames is the concatenation of; each frame decompressed content. There are two frame formats defined by Zstandard:; Zstandard frames and Skippable frames.; Zstandard frames contain compressed data, while; skippable frames contain cust",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:5445,Integrability,depend,depending,5445," bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descriptor`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved_bit` |; | 2 | `Content_Checksum_flag` |; | 1-0 | `Dictionary_ID_flag` |. In this table, bit 7 is the highest bit, while bit 0 is the lowest one. __`Frame_Content_Size_flag`__. This is a 2-bits flag (`= Frame_Header_Descriptor >> 6`),; specifying if `Frame_Content_Size` (",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:6779,Integrability,depend,depends,6779,"r`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved_bit` |; | 2 | `Content_Checksum_flag` |; | 1-0 | `Dictionary_ID_flag` |. In this table, bit 7 is the highest bit, while bit 0 is the lowest one. __`Frame_Content_Size_flag`__. This is a 2-bits flag (`= Frame_Header_Descriptor >> 6`),; specifying if `Frame_Content_Size` (the decompressed data size); is provided within the header.; `Flag_Value` provides `FCS_Field_Size`,; which is the number of bytes used by `Frame_Content_Size`; according to the following table:. | `Flag_Value` | 0 | 1 | 2 | 3 |; | -------------- | ------ | --- | --- | --- |; |`FCS_Field_Size`| 0 or 1 | 2 | 4 | 8 |. When `Flag_Value` is `0`, `FCS_Field_Size` depends on `Single_Segment_flag` :; if `Single_Segment_flag` is set, `FCS_Field_Size` is 1.; Otherwise, `FCS_Field_Size` is 0 : `Frame_Content_Size` is not provided. __`Single_Segment_flag`__. If this flag is set,; data must be regenerated within a single continuous memory segment. In this case, `Window_Descriptor` byte is skipped,; but `Frame_Content_Size` is necessarily present.; As a consequence, the decoder must allocate a memory segment; of size equal or larger than `Frame_Content_Size`. In order to preserve the decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For broader compatibility, decoders are recommended to support; memory sizes of at least 8 MB.; This is only a recommendation,; each decoder is free to support higher or lower limits,; depending on local limitations. __`Unused_bit`__. A decoder compliant with this specification version shall not interpret this bit.; It might be used in ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:7650,Integrability,depend,depending,7650,"g_Value` | 0 | 1 | 2 | 3 |; | -------------- | ------ | --- | --- | --- |; |`FCS_Field_Size`| 0 or 1 | 2 | 4 | 8 |. When `Flag_Value` is `0`, `FCS_Field_Size` depends on `Single_Segment_flag` :; if `Single_Segment_flag` is set, `FCS_Field_Size` is 1.; Otherwise, `FCS_Field_Size` is 0 : `Frame_Content_Size` is not provided. __`Single_Segment_flag`__. If this flag is set,; data must be regenerated within a single continuous memory segment. In this case, `Window_Descriptor` byte is skipped,; but `Frame_Content_Size` is necessarily present.; As a consequence, the decoder must allocate a memory segment; of size equal or larger than `Frame_Content_Size`. In order to preserve the decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For broader compatibility, decoders are recommended to support; memory sizes of at least 8 MB.; This is only a recommendation,; each decoder is free to support higher or lower limits,; depending on local limitations. __`Unused_bit`__. A decoder compliant with this specification version shall not interpret this bit.; It might be used in any future version,; to signal a property which is transparent to properly decode the frame.; An encoder compliant with this specification version must set this bit to zero. __`Reserved_bit`__. This bit is reserved for some future feature.; Its value _must be zero_.; A decoder compliant with this specification version must ensure it is not set.; This bit may be used in a future revision,; to signal a feature that must be interpreted to decode the frame correctly. __`Content_Checksum_flag`__. If this flag is set, a 32-bits `Content_Checksum` will be present at frame's end.; See `Content_Checksum` paragraph. __`Dictionary_ID_flag`__. This is a 2-bits flag (`= FHD & 3`),; telling if a dictionary ID is provided within the header.; It also specifies the size of this field as `DID_Field_Size`. |`Flag_Value` | 0 ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:10006,Integrability,interoperab,interoperability,10006,"^64-1 bytes (16 ExaBytes). | Bit numbers | 7-3 | 2-0 |; | ----------- | ---------- | ---------- |; | Field name | `Exponent` | `Mantissa` |. The minimum memory buffer size is called `Window_Size`.; It is described by the following formulas :; ```; windowLog = 10 + Exponent;; windowBase = 1 << windowLog;; windowAdd = (windowBase / 8) * Mantissa;; Window_Size = windowBase + windowAdd;; ```; The minimum `Window_Size` is 1 KB.; The maximum `Window_Size` is `(1<<41) + 7*(1<<38)` bytes, which is 3.75 TB. In general, larger `Window_Size` tend to improve compression ratio,; but at the cost of memory usage. To properly decode compressed data,; a decoder will need to allocate a buffer of at least `Window_Size` bytes. In order to preserve decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For improved interoperability,; it's recommended for decoders to support `Window_Size` of up to 8 MB,; and it's recommended for encoders to not generate frame requiring `Window_Size` larger than 8 MB.; It's merely a recommendation though,; decoders are free to support larger or lower limits,; depending on local limitations. #### `Dictionary_ID`. This is a variable size field, which contains; the ID of the dictionary required to properly decode the frame.; `Dictionary_ID` field is optional. When it's not present,; it's up to the decoder to know which dictionary to use. `Dictionary_ID` field size is provided by `DID_Field_Size`.; `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can represent an ID 0-65535.; 4 bytes can represent an ID 0-4294967295.; Format is __little-endian__. It's allowed to represent a small ID (for example `13`); with a large 4-bytes dictionary ID, even if it is less efficient. _Reserved ranges :_; Within private environments, any `Dictionary_ID` can be used. However, for frames and dictionaries di",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:10287,Integrability,depend,depending,10287,"fer size is called `Window_Size`.; It is described by the following formulas :; ```; windowLog = 10 + Exponent;; windowBase = 1 << windowLog;; windowAdd = (windowBase / 8) * Mantissa;; Window_Size = windowBase + windowAdd;; ```; The minimum `Window_Size` is 1 KB.; The maximum `Window_Size` is `(1<<41) + 7*(1<<38)` bytes, which is 3.75 TB. In general, larger `Window_Size` tend to improve compression ratio,; but at the cost of memory usage. To properly decode compressed data,; a decoder will need to allocate a buffer of at least `Window_Size` bytes. In order to preserve decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For improved interoperability,; it's recommended for decoders to support `Window_Size` of up to 8 MB,; and it's recommended for encoders to not generate frame requiring `Window_Size` larger than 8 MB.; It's merely a recommendation though,; decoders are free to support larger or lower limits,; depending on local limitations. #### `Dictionary_ID`. This is a variable size field, which contains; the ID of the dictionary required to properly decode the frame.; `Dictionary_ID` field is optional. When it's not present,; it's up to the decoder to know which dictionary to use. `Dictionary_ID` field size is provided by `DID_Field_Size`.; `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can represent an ID 0-65535.; 4 bytes can represent an ID 0-4294967295.; Format is __little-endian__. It's allowed to represent a small ID (for example `13`); with a large 4-bytes dictionary ID, even if it is less efficient. _Reserved ranges :_; Within private environments, any `Dictionary_ID` can be used. However, for frames and dictionaries distributed in public space,; `Dictionary_ID` must be attributed carefully.; Rules for public environment are not yet decided,; but the following ranges are reserved",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:42006,Integrability,depend,depends,42006,"ts from the stream as a __little-endian__ value and add it to `Baseline`. [ANS]: https://en.wikipedia.org/wiki/Asymmetric_Numeral_Systems. ### FSE Table Description; To decode FSE streams, it is necessary to construct the decoding table.; The Zstandard format encodes FSE table descriptions as follows:. An FSE distribution table describes the probabilities of all symbols; from `0` to the last present one (included); on a normalized scale of `1 << Accuracy_Log` .; Note that there must be two or more symbols with nonzero probability. It's a bitstream which is read forward, in __little-endian__ fashion.; It's not necessary to know bitstream exact size,; it will be discovered and reported by the decoding process. The bitstream starts by reporting on which scale it operates.; Let's `low4Bits` designate the lowest 4 bits of the first byte :; `Accuracy_Log = low4bits + 5`. Then follows each symbol value, from `0` to last present one.; The number of bits used by each field is variable.; It depends on :. - Remaining probabilities + 1 :; __example__ :; Presuming an `Accuracy_Log` of 8,; and presuming 100 probabilities points have already been distributed,; the decoder may read any value from `0` to `256 - 100 + 1 == 157` (inclusive).; Therefore, it must read `log2sup(157) == 8` bits. - Value decoded : small values use 1 less bit :; __example__ :; Presuming values from 0 to 157 (inclusive) are possible,; 255-157 = 98 values are remaining in an 8-bits field.; They are used this way :; first 98 values (hence from 0 to 97) use only 7 bits,; values from 98 to 157 use 8 bits.; This is achieved through this scheme :. | Value read | Value decoded | Number of bits used |; | ---------- | ------------- | ------------------- |; | 0 - 97 | 0 - 97 | 7 |; | 98 - 127 | 98 - 127 | 8 |; | 128 - 225 | 0 - 97 | 7 |; | 226 - 255 | 128 - 157 | 8 |. Symbols probabilities are read one by one, in order. Probability is obtained from Value decoded by following formula :; `Proba = value - 1`. It means va",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:2287,Modifiability,portab,portable,2287,"ptional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells the decoder how to decompress it. A frame encapsulates one or multiple __blocks__.; Each block contains arbitrary content, which is described by its header,; and has a guaranteed maximum content size, which depends on frame parameters.; Unlike frames, each block depends on previous blocks for proper decoding.; However, each block can be decompressed without waiting for its successor,; allowing streaming operations. Overview; ---------; - [F",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:5383,Modifiability,variab,variable,5383," bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descriptor`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved_bit` |; | 2 | `Content_Checksum_flag` |; | 1-0 | `Dictionary_ID_flag` |. In this table, bit 7 is the highest bit, while bit 0 is the lowest one. __`Frame_Content_Size_flag`__. This is a 2-bits flag (`= Frame_Header_Descriptor >> 6`),; specifying if `Frame_Content_Size` (",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:10351,Modifiability,variab,variable,10351,";; windowAdd = (windowBase / 8) * Mantissa;; Window_Size = windowBase + windowAdd;; ```; The minimum `Window_Size` is 1 KB.; The maximum `Window_Size` is `(1<<41) + 7*(1<<38)` bytes, which is 3.75 TB. In general, larger `Window_Size` tend to improve compression ratio,; but at the cost of memory usage. To properly decode compressed data,; a decoder will need to allocate a buffer of at least `Window_Size` bytes. In order to preserve decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For improved interoperability,; it's recommended for decoders to support `Window_Size` of up to 8 MB,; and it's recommended for encoders to not generate frame requiring `Window_Size` larger than 8 MB.; It's merely a recommendation though,; decoders are free to support larger or lower limits,; depending on local limitations. #### `Dictionary_ID`. This is a variable size field, which contains; the ID of the dictionary required to properly decode the frame.; `Dictionary_ID` field is optional. When it's not present,; it's up to the decoder to know which dictionary to use. `Dictionary_ID` field size is provided by `DID_Field_Size`.; `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can represent an ID 0-65535.; 4 bytes can represent an ID 0-4294967295.; Format is __little-endian__. It's allowed to represent a small ID (for example `13`); with a large 4-bytes dictionary ID, even if it is less efficient. _Reserved ranges :_; Within private environments, any `Dictionary_ID` can be used. However, for frames and dictionaries distributed in public space,; `Dictionary_ID` must be attributed carefully.; Rules for public environment are not yet decided,; but the following ranges are reserved for some future registrar :; - low range : `<= 32767`; - high range : `>= (1 << 31)`. Outside of these ranges, any value of `Dictionary_ID`",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:11616,Modifiability,variab,variable,11616," `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can represent an ID 0-65535.; 4 bytes can represent an ID 0-4294967295.; Format is __little-endian__. It's allowed to represent a small ID (for example `13`); with a large 4-bytes dictionary ID, even if it is less efficient. _Reserved ranges :_; Within private environments, any `Dictionary_ID` can be used. However, for frames and dictionaries distributed in public space,; `Dictionary_ID` must be attributed carefully.; Rules for public environment are not yet decided,; but the following ranges are reserved for some future registrar :; - low range : `<= 32767`; - high range : `>= (1 << 31)`. Outside of these ranges, any value of `Dictionary_ID`; which is both `>= 32768` and `< (1<<31)` can be used freely,; even in public environment. #### `Frame_Content_Size`. This is the original (uncompressed) size. This information is optional.; `Frame_Content_Size` uses a variable number of bytes, provided by `FCS_Field_Size`.; `FCS_Field_Size` is provided by the value of `Frame_Content_Size_flag`.; `FCS_Field_Size` can be equal to 0 (not present), 1, 2, 4 or 8 bytes. | `FCS_Field_Size` | Range |; | ---------------- | ---------- |; | 0 | unknown |; | 1 | 0 - 255 |; | 2 | 256 - 65791|; | 4 | 0 - 2^32-1 |; | 8 | 0 - 2^64-1 |. `Frame_Content_Size` format is __little-endian__.; When `FCS_Field_Size` is 1, 4 or 8 bytes, the value is read directly.; When `FCS_Field_Size` is 2, _the offset of 256 is added_.; It's allowed to represent a small size (for example `18`) using any compatible variant. Blocks; -------. After `Magic_Number` and `Frame_Header`, there are some number of blocks.; Each frame must have at least one block,; but there is no upper limit on the number of blocks per frame. The structure of a block is as follows:. | `Block_Header` | `Block_Content` |; |:--------------:|:---------------:|; | 3 bytes | n bytes |. `Block_Header` uses 3 bytes, written using __lit",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:16362,Modifiability,variab,variable-size,16362,"fsets). Note that decoding tables aren't always from the previous `Compressed_Block`. - Every decoding table can come from a dictionary.; - The Huffman tree comes from the previous `Compressed_Literals_Block`. Literals Section; ----------------; All literals are regrouped in the first part of the block.; They can be decoded first, and then copied during [Sequence Execution],; or they can be decoded on the flow during [Sequence Execution]. Literals can be stored uncompressed or compressed using Huffman prefix codes.; When compressed, an optional tree description can be present,; followed by 1 or 4 streams. | `Literals_Section_Header` | [`Huffman_Tree_Description`] | [jumpTable] | Stream1 | [Stream2] | [Stream3] | [Stream4] |; | ------------------------- | ---------------------------- | ----------- | ------- | --------- | --------- | --------- |. ### `Literals_Section_Header`. Header is in charge of describing how literals are packed.; It's a byte-aligned variable-size bitfield, ranging from 1 to 5 bytes,; using __little-endian__ convention. | `Literals_Block_Type` | `Size_Format` | `Regenerated_Size` | [`Compressed_Size`] |; | --------------------- | ------------- | ------------------ | ------------------- |; | 2 bits | 1 - 2 bits | 5 - 20 bits | 0 - 18 bits |. In this representation, bits on the left are the lowest bits. __`Literals_Block_Type`__. This field uses 2 lowest bits of first byte, describing 4 different block types :. | `Literals_Block_Type` | Value |; | --------------------------- | ----- |; | `Raw_Literals_Block` | 0 |; | `RLE_Literals_Block` | 1 |; | `Compressed_Literals_Block` | 2 |; | `Treeless_Literals_Block` | 3 |. - `Raw_Literals_Block` - Literals are stored uncompressed.; - `RLE_Literals_Block` - Literals consist of a single byte value; repeated `Regenerated_Size` times.; - `Compressed_Literals_Block` - This is a standard Huffman-compressed block,; starting with a Huffman tree description.; See details below.; - `Treeless_Literals_Block` - This is",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:23960,Modifiability,variab,variable,23960,"scribed in more detail in [Sequence Execution](#sequence-execution). The `Sequences_Section` regroup all symbols required to decode commands.; There are 3 symbol types : literals lengths, offsets and match lengths.; They are encoded together, interleaved, in a single _bitstream_. The `Sequences_Section` starts by a header,; followed by optional probability tables for each symbol type,; followed by the bitstream. | `Sequences_Section_Header` | [`Literals_Length_Table`] | [`Offset_Table`] | [`Match_Length_Table`] | bitStream |; | -------------------------- | ------------------------- | ---------------- | ---------------------- | --------- |. To decode the `Sequences_Section`, it's required to know its size.; Its size is deduced from the size of `Literals_Section`:; `Sequences_Section_Size = Block_Size - Literals_Section_Size`. #### `Sequences_Section_Header`. Consists of 2 items:; - `Number_of_Sequences`; - Symbol compression modes. __`Number_of_Sequences`__. This is a variable size field using between 1 and 3 bytes.; Let's call its first byte `byte0`.; - `if (byte0 == 0)` : there are no sequences.; The sequence section stops there.; Decompressed content is defined entirely as Literals Section content.; The FSE tables used in `Repeat_Mode` aren't updated.; - `if (byte0 < 128)` : `Number_of_Sequences = byte0` . Uses 1 byte.; - `if (byte0 < 255)` : `Number_of_Sequences = ((byte0-128) << 8) + byte1` . Uses 2 bytes.; - `if (byte0 == 255)`: `Number_of_Sequences = byte1 + (byte2<<8) + 0x7F00` . Uses 3 bytes. __Symbol compression modes__. This is a single byte, defining the compression mode of each symbol type. |Bit number| 7-6 | 5-4 | 3-2 | 1-0 |; | -------- | ----------------------- | -------------- | -------------------- | ---------- |; |Field name| `Literals_Lengths_Mode` | `Offsets_Mode` | `Match_Lengths_Mode` | `Reserved` |. The last field, `Reserved`, must be all-zeroes. `Literals_Lengths_Mode`, `Offsets_Mode` and `Match_Lengths_Mode` define the `Compression_Mode` of; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:41992,Modifiability,variab,variable,41992,"ecoder should consume `Num_Bits` bits from the stream as a __little-endian__ value and add it to `Baseline`. [ANS]: https://en.wikipedia.org/wiki/Asymmetric_Numeral_Systems. ### FSE Table Description; To decode FSE streams, it is necessary to construct the decoding table.; The Zstandard format encodes FSE table descriptions as follows:. An FSE distribution table describes the probabilities of all symbols; from `0` to the last present one (included); on a normalized scale of `1 << Accuracy_Log` .; Note that there must be two or more symbols with nonzero probability. It's a bitstream which is read forward, in __little-endian__ fashion.; It's not necessary to know bitstream exact size,; it will be discovered and reported by the decoding process. The bitstream starts by reporting on which scale it operates.; Let's `low4Bits` designate the lowest 4 bits of the first byte :; `Accuracy_Log = low4bits + 5`. Then follows each symbol value, from `0` to last present one.; The number of bits used by each field is variable.; It depends on :. - Remaining probabilities + 1 :; __example__ :; Presuming an `Accuracy_Log` of 8,; and presuming 100 probabilities points have already been distributed,; the decoder may read any value from `0` to `256 - 100 + 1 == 157` (inclusive).; Therefore, it must read `log2sup(157) == 8` bits. - Value decoded : small values use 1 less bit :; __example__ :; Presuming values from 0 to 157 (inclusive) are possible,; 255-157 = 98 values are remaining in an 8-bits field.; They are used this way :; first 98 values (hence from 0 to 97) use only 7 bits,; values from 98 to 157 use 8 bits.; This is achieved through this scheme :. | Value read | Value decoded | Number of bits used |; | ---------- | ------------- | ------------------- |; | 0 - 97 | 0 - 97 | 7 |; | 98 - 127 | 98 - 127 | 8 |; | 128 - 225 | 0 - 97 | 7 |; | 226 - 255 | 128 - 157 | 8 |. Symbols probabilities are read one by one, in order. Probability is obtained from Value decoded by following formula ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:58294,Performance,load,loaded,58294,"epeat distribution mode for sequence decoding.; It's finally followed by 3 offset values, populating recent offsets (instead of using `{1,4,8}`),; stored in order, 4-bytes __little-endian__ each, for a total of 12 bytes.; Each recent offset must have a value < dictionary size. __`Content`__ : The rest of the dictionary is its content.; The content act as a ""past"" in front of data to compress or decompress,; so it can be referenced in sequence commands.; As long as the amount of data decoded from this frame is less than or; equal to `Window_Size`, sequence commands may specify offsets longer; than the total length of decoded output so far to reference back to the; dictionary, even parts of the dictionary with offsets larger than `Window_Size`. ; After the total output has surpassed `Window_Size` however,; this is no longer allowed and the dictionary is no longer accessible. [compressed blocks]: #the-format-of-compressed_block. If a dictionary is provided by an external source,; it should be loaded with great care, its content considered untrusted. Appendix A - Decoding tables for predefined codes; -------------------------------------------------. This appendix contains FSE decoding tables; for the predefined literal length, match length, and offset codes.; The tables have been constructed using the algorithm as given above in chapter; ""from normalized distribution to decoding tables"".; The tables here can be used as examples; to crosscheck that an implementation build its decoding tables correctly. #### Literal Length Code:. | State | Symbol | Number_Of_Bits | Base |; | ----- | ------ | -------------- | ---- |; | 0 | 0 | 4 | 0 |; | 1 | 0 | 4 | 16 |; | 2 | 1 | 5 | 32 |; | 3 | 3 | 5 | 0 |; | 4 | 4 | 5 | 0 |; | 5 | 6 | 5 | 0 |; | 6 | 7 | 5 | 0 |; | 7 | 9 | 5 | 0 |; | 8 | 10 | 5 | 0 |; | 9 | 12 | 5 | 0 |; | 10 | 14 | 6 | 0 |; | 11 | 16 | 5 | 0 |; | 12 | 18 | 5 | 0 |; | 13 | 19 | 5 | 0 |; | 14 | 21 | 5 | 0 |; | 15 | 22 | 5 | 0 |; | 16 | 24 | 5 | 0 |; | 17 | 25 | 5 | 32 |;",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1329,Safety,detect,detection,1329,"tice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version. 0.3.1 (25/10/18). Introduction; ------------. The purpose of this document is to define a lossless compressed data format,; that is independent of CPU type, operating system,; file system and character set, suitable for; file compression, pipe and streaming compression,; using the [Zstandard algorithm](http://www.zstandard.org).; The text of the specification assumes a basic background in programming; at the level of bits and other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/f",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:4603,Safety,avoid,avoids,4603,"y-format). Frames; ------; Zstandard compressed data is made of one or more __frames__.; Each frame is independent and can be decompressed independently of other frames.; The decompressed content of multiple concatenated frames is the concatenation of; each frame decompressed content. There are two frame formats defined by Zstandard:; Zstandard frames and Skippable frames.; Zstandard frames contain compressed data, while; skippable frames contain custom user metadata. ## Zstandard frames; The structure of a single Zstandard frame is following:. | `Magic_Number` | `Frame_Header` |`Data_Block`| [More data blocks] | [`Content_Checksum`] |; |:--------------:|:--------------:|:----------:| ------------------ |:--------------------:|; | 4 bytes | 2-14 bytes | n bytes | | 0-4 bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ---------",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:38962,Safety,detect,detect,38962,"set1` - 1_byte.; Here also, from an offset history update perspective, it's just a common case :; `Repeated_Offset3` = `Repeated_Offset2`; `Repeated_Offset2` = `Repeated_Offset1`; `Repeated_Offset1` = `NewOffset` ( == `Repeated_Offset1` - 1_byte ). Skippable Frames; ----------------. | `Magic_Number` | `Frame_Size` | `User_Data` |; |:--------------:|:------------:|:-----------:|; | 4 bytes | 4 bytes | n bytes |. Skippable frames allow the insertion of user-defined metadata; into a flow of concatenated frames. Skippable frames defined in this specification are compatible with [LZ4] ones. [LZ4]:http://www.lz4.org. From a compliant decoder perspective, skippable frames need just be skipped,; and their content ignored, resuming decoding after the skippable frame. It can be noted that a skippable frame; can be used to watermark a stream of concatenated frames; embedding any kind of tracking information (even just an UUID).; Users wary of such possibility should scan the stream of concatenated frames; in an attempt to detect such frame for analysis or removal. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0x184D2A5?, which means any value from 0x184D2A50 to 0x184D2A5F.; All 16 values are valid to identify a skippable frame.; This specification doesn't detail any specific tagging for skippable frames. __`Frame_Size`__. This is the size, in bytes, of the following `User_Data`; (without including the magic number nor the size field itself).; This field is represented using 4 Bytes, __little-endian__ format, unsigned 32-bits.; This means `User_Data` can’t be bigger than (2^32-1) bytes. __`User_Data`__. The `User_Data` can be anything. Data will just be skipped by the decoder. Entropy Encoding; ----------------; Two types of entropy encoding are used by the Zstandard format:; FSE, and Huffman coding.; Huffman is used to compress literals,; while FSE is used for all other symbols; (`Literals_Length_Code`, `Match_Length_Code`, offset codes); and to compress Huff",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:54347,Safety,detect,detected,54347,"e removed.; Then, starting from lowest `Weight`, prefix codes are distributed in sequential order. __Example__ :; Let's presume the following list of weights has been decoded :. | Literal | 0 | 1 | 2 | 3 | 4 | 5 |; | -------- | --- | --- | --- | --- | --- | --- |; | `Weight` | 4 | 3 | 2 | 0 | 1 | 1 |. Sorted by weight and then natural sequential order,; it gives the following distribution :. | Literal | 3 | 4 | 5 | 2 | 1 | 0 |; | ---------------- | --- | --- | --- | --- | --- | ---- |; | `Weight` | 0 | 1 | 1 | 2 | 3 | 4 |; | `Number_of_Bits` | 0 | 4 | 4 | 3 | 2 | 1 |; | prefix codes | N/A | 0000| 0001| 001 | 01 | 1 |. ### Huffman-coded Streams. Given a Huffman decoding table,; it's possible to decode a Huffman-coded stream. Each bitstream must be read _backward_,; that is starting from the end down to the beginning.; Therefore it's necessary to know the size of each bitstream. It's also necessary to know exactly which _bit_ is the last one.; This is detected by a final bit flag :; the highest bit of latest byte is a final-bit-flag.; Consequently, a last byte of `0` is not possible.; And the final-bit-flag itself is not part of the useful bitstream.; Hence, the last byte contains between 0 and 7 useful bits. Starting from the end,; it's possible to read the bitstream in a __little-endian__ fashion,; keeping track of already used bits. Since the bitstream is encoded in reverse; order, starting from the end read symbols in forward order. For example, if the literal sequence ""0145"" was encoded using above prefix code,; it would be encoded (in reverse order) as:. |Symbol | 5 | 4 | 1 | 0 | Padding |; |--------|------|------|----|---|---------|; |Encoding|`0000`|`0001`|`01`|`1`| `00001` |. Resulting in following 2-bytes bitstream :; ```; 00010000 00001101; ```. Here is an alternative representation with the symbol codes separated by underscore:; ```; 0001_0000 00001_1_01; ```. Reading highest `Max_Number_of_Bits` bits,; it's possible to compare extracted value to decoding t",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1283,Security,checksum,checksum,1283," languages; and incorporation into compilations,; provided that the copyright notice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version. 0.3.1 (25/10/18). Introduction; ------------. The purpose of this document is to define a lossless compressed data format,; that is independent of CPU type, operating system,; file system and character set, suitable for; file compression, pipe and streaming compression,; using the [Zstandard algorithm](http://www.zstandard.org).; The text of the specification assumes a basic background in programming; at the level of bits and other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1439,Security,access,access,1439,"deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version. 0.3.1 (25/10/18). Introduction; ------------. The purpose of this document is to define a lossless compressed data format,; that is independent of CPU type, operating system,; file system and character set, suitable for; file compression, pipe and streaming compression,; using the [Zstandard algorithm](http://www.zstandard.org).; The text of the specification assumes a basic background in programming; at the level of bits and other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square bracke",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:1840,Security,checksum,checksum,1840,"](http://www.zstandard.org).; The text of the specification assumes a basic background in programming; at the level of bits and other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; explaining which parameter is unsupported. This specification is intended for use by implementers of software; to compress data into Zstandard format and/or decompress data from Zstandard format.; The Zstandard format is supported by an open source reference implementation,; written in portable C, and available at : https://github.com/facebook/zstd . ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`. ### Definitions; Content compressed by Zstandard is transformed into a Zstandard __frame__.; Multiple frames can be appended into a single file or stream.; A frame is completely independent, has a defined beginning and end,; and a set of parameters which tells ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:5051,Security,checksum,checksum,5051,"able frames contain custom user metadata. ## Zstandard frames; The structure of a single Zstandard frame is following:. | `Magic_Number` | `Frame_Header` |`Data_Block`| [More data blocks] | [`Content_Checksum`] |; |:--------------:|:--------------:|:----------:| ------------------ |:--------------------:|; | 4 bytes | 2-14 bytes | n bytes | | 0-4 bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descriptor`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_f",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:5122,Security,checksum,checksum,5122,"of a single Zstandard frame is following:. | `Magic_Number` | `Frame_Header` |`Data_Block`| [More data blocks] | [`Content_Checksum`] |; |:--------------:|:--------------:|:----------:| ------------------ |:--------------------:|; | 4 bytes | 2-14 bytes | n bytes | | 0-4 bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descriptor`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:5158,Security,hash,hash,5158,"of a single Zstandard frame is following:. | `Magic_Number` | `Frame_Header` |`Data_Block`| [More data blocks] | [`Content_Checksum`] |; |:--------------:|:--------------:|:----------:| ------------------ |:--------------------:|; | 4 bytes | 2-14 bytes | n bytes | | 0-4 bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descriptor`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:5289,Security,checksum,checksum,5289,"|:--------------:|:----------:| ------------------ |:--------------------:|; | 4 bytes | 2-14 bytes | n bytes | | 0-4 bytes |. __`Magic_Number`__. 4 Bytes, __little-endian__ format.; Value : 0xFD2FB528; Note: This value was selected to be less probable to find at the beginning of some random file.; It avoids trivial patterns (0x00, 0xFF, repeated bytes, increasing bytes, etc.),; contains byte values outside of ASCII range,; and doesn't map into UTF8 space.; It reduces the chances that a text file represent this value by accident. __`Frame_Header`__. 2 to 14 Bytes, detailed in [`Frame_Header`](#frame_header). __`Data_Block`__. Detailed in [`Blocks`](#blocks).; That’s where compressed data is stored. __`Content_Checksum`__. An optional 32-bit checksum, only present if `Content_Checksum_flag` is set.; The content checksum is the result; of [xxh64() hash function](http://www.xxhash.org); digesting the original (decoded) data as input, and a seed of zero.; The low 4 bytes of the checksum are stored in __little-endian__ format. ### `Frame_Header`. The `Frame_Header` has a variable size, with a minimum of 2 bytes,; and up to 14 bytes depending on optional parameters.; The structure of `Frame_Header` is following:. | `Frame_Header_Descriptor` | [`Window_Descriptor`] | [`Dictionary_ID`] | [`Frame_Content_Size`] |; | ------------------------- | --------------------- | ----------------- | ---------------------- |; | 1 byte | 0-1 byte | 0-4 bytes | 0-8 bytes |. #### `Frame_Header_Descriptor`. The first header's byte is called the `Frame_Header_Descriptor`.; It describes which other fields are present.; Decoding this byte is enough to tell the size of `Frame_Header`. | Bit number | Field name |; | ---------- | ---------- |; | 7-6 | `Frame_Content_Size_flag` |; | 5 | `Single_Segment_flag` |; | 4 | `Unused_bit` |; | 3 | `Reserved_bit` |; | 2 | `Content_Checksum_flag` |; | 1-0 | `Dictionary_ID_flag` |. In this table, bit 7 is the highest bit, while bit 0 is the lowest one. __`Frame_",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:7447,Security,authoriz,authorized,7447,"or >> 6`),; specifying if `Frame_Content_Size` (the decompressed data size); is provided within the header.; `Flag_Value` provides `FCS_Field_Size`,; which is the number of bytes used by `Frame_Content_Size`; according to the following table:. | `Flag_Value` | 0 | 1 | 2 | 3 |; | -------------- | ------ | --- | --- | --- |; |`FCS_Field_Size`| 0 or 1 | 2 | 4 | 8 |. When `Flag_Value` is `0`, `FCS_Field_Size` depends on `Single_Segment_flag` :; if `Single_Segment_flag` is set, `FCS_Field_Size` is 1.; Otherwise, `FCS_Field_Size` is 0 : `Frame_Content_Size` is not provided. __`Single_Segment_flag`__. If this flag is set,; data must be regenerated within a single continuous memory segment. In this case, `Window_Descriptor` byte is skipped,; but `Frame_Content_Size` is necessarily present.; As a consequence, the decoder must allocate a memory segment; of size equal or larger than `Frame_Content_Size`. In order to preserve the decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For broader compatibility, decoders are recommended to support; memory sizes of at least 8 MB.; This is only a recommendation,; each decoder is free to support higher or lower limits,; depending on local limitations. __`Unused_bit`__. A decoder compliant with this specification version shall not interpret this bit.; It might be used in any future version,; to signal a property which is transparent to properly decode the frame.; An encoder compliant with this specification version must set this bit to zero. __`Reserved_bit`__. This bit is reserved for some future feature.; Its value _must be zero_.; A decoder compliant with this specification version must ensure it is not set.; This bit may be used in a future revision,; to signal a feature that must be interpreted to decode the frame correctly. __`Content_Checksum_flag`__. If this flag is set, a 32-bits `Content_Checksum` will be present at f",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:9975,Security,authoriz,authorized,9975,"_Descriptor` byte is optional.; When `Single_Segment_flag` is set, `Window_Descriptor` is not present.; In this case, `Window_Size` is `Frame_Content_Size`,; which can be any value from 0 to 2^64-1 bytes (16 ExaBytes). | Bit numbers | 7-3 | 2-0 |; | ----------- | ---------- | ---------- |; | Field name | `Exponent` | `Mantissa` |. The minimum memory buffer size is called `Window_Size`.; It is described by the following formulas :; ```; windowLog = 10 + Exponent;; windowBase = 1 << windowLog;; windowAdd = (windowBase / 8) * Mantissa;; Window_Size = windowBase + windowAdd;; ```; The minimum `Window_Size` is 1 KB.; The maximum `Window_Size` is `(1<<41) + 7*(1<<38)` bytes, which is 3.75 TB. In general, larger `Window_Size` tend to improve compression ratio,; but at the cost of memory usage. To properly decode compressed data,; a decoder will need to allocate a buffer of at least `Window_Size` bytes. In order to preserve decoder from unreasonable memory requirements,; a decoder is allowed to reject a compressed frame; which requests a memory size beyond decoder's authorized range. For improved interoperability,; it's recommended for decoders to support `Window_Size` of up to 8 MB,; and it's recommended for encoders to not generate frame requiring `Window_Size` larger than 8 MB.; It's merely a recommendation though,; decoders are free to support larger or lower limits,; depending on local limitations. #### `Dictionary_ID`. This is a variable size field, which contains; the ID of the dictionary required to properly decode the frame.; `Dictionary_ID` field is optional. When it's not present,; it's up to the decoder to know which dictionary to use. `Dictionary_ID` field size is provided by `DID_Field_Size`.; `DID_Field_Size` is directly derived from value of `Dictionary_ID_flag`.; 1 byte can represent an ID 0-255.; 2 bytes can represent an ID 0-65535.; 4 bytes can represent an ID 0-4294967295.; Format is __little-endian__. It's allowed to represent a small ID (for example `1",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:58163,Security,access,accessible,58163," :; Huffman tables for literals, FSE table for offsets,; FSE table for match lengths, and FSE table for literals lengths.; These tables populate the Repeat Stats literals mode and; Repeat distribution mode for sequence decoding.; It's finally followed by 3 offset values, populating recent offsets (instead of using `{1,4,8}`),; stored in order, 4-bytes __little-endian__ each, for a total of 12 bytes.; Each recent offset must have a value < dictionary size. __`Content`__ : The rest of the dictionary is its content.; The content act as a ""past"" in front of data to compress or decompress,; so it can be referenced in sequence commands.; As long as the amount of data decoded from this frame is less than or; equal to `Window_Size`, sequence commands may specify offsets longer; than the total length of decoded output so far to reference back to the; dictionary, even parts of the dictionary with offsets larger than `Window_Size`. ; After the total output has surpassed `Window_Size` however,; this is no longer allowed and the dictionary is no longer accessible. [compressed blocks]: #the-format-of-compressed_block. If a dictionary is provided by an external source,; it should be loaded with great care, its content considered untrusted. Appendix A - Decoding tables for predefined codes; -------------------------------------------------. This appendix contains FSE decoding tables; for the predefined literal length, match length, and offset codes.; The tables have been constructed using the algorithm as given above in chapter; ""from normalized distribution to decoding tables"".; The tables here can be used as examples; to crosscheck that an implementation build its decoding tables correctly. #### Literal Length Code:. | State | Symbol | Number_Of_Bits | Base |; | ----- | ------ | -------------- | ---- |; | 0 | 0 | 4 | 0 |; | 1 | 0 | 4 | 16 |; | 2 | 1 | 5 | 32 |; | 3 | 3 | 5 | 0 |; | 4 | 4 | 5 | 0 |; | 5 | 6 | 5 | 0 |; | 6 | 7 | 5 | 0 |; | 7 | 9 | 5 | 0 |; | 8 | 10 | 5 | 0 |; | 9 | ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:25852,Testability,log,log,25852,"ls_Lengths_Mode`, `Offsets_Mode` and `Match_Lengths_Mode` define the `Compression_Mode` of; literals lengths, offsets, and match lengths symbols respectively. They follow the same enumeration :. | Value | 0 | 1 | 2 | 3 |; | ------------------ | ----------------- | ---------- | --------------------- | ------------- |; | `Compression_Mode` | `Predefined_Mode` | `RLE_Mode` | `FSE_Compressed_Mode` | `Repeat_Mode` |. - `Predefined_Mode` : A predefined FSE distribution table is used, defined in; [default distributions](#default-distributions).; No distribution table will be present.; - `RLE_Mode` : The table description consists of a single byte, which contains the symbol's value.; This symbol will be used for all sequences.; - `FSE_Compressed_Mode` : standard FSE compression.; A distribution table will be present.; The format of this distribution table is described in [FSE Table Description](#fse-table-description).; Note that the maximum allowed accuracy log for literals length and match length tables is 9,; and the maximum accuracy log for the offsets table is 8.; `FSE_Compressed_Mode` must not be used when only one symbol is present,; `RLE_Mode` should be used instead (although any other mode will work).; - `Repeat_Mode` : The table used in the previous `Compressed_Block` with `Number_of_Sequences > 0` will be used again,; or if this is the first block, table in the dictionary will be used.; Note that this includes `RLE_mode`, so if `Repeat_Mode` follows `RLE_Mode`, the same symbol will be repeated.; It also includes `Predefined_Mode`, in which case `Repeat_Mode` will have same outcome as `Predefined_Mode`.; No distribution table will be present.; If this mode is used without any previous sequence table in the frame; (nor [dictionary](#dictionary-format)) to repeat, this should be treated as corruption. #### The codes for literals lengths, match lengths, and offsets. Each symbol is a _code_ in its own context,; which specifies `Baseline` and `Number_of_Bits` to add.; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:25932,Testability,log,log,25932,"ls_Lengths_Mode`, `Offsets_Mode` and `Match_Lengths_Mode` define the `Compression_Mode` of; literals lengths, offsets, and match lengths symbols respectively. They follow the same enumeration :. | Value | 0 | 1 | 2 | 3 |; | ------------------ | ----------------- | ---------- | --------------------- | ------------- |; | `Compression_Mode` | `Predefined_Mode` | `RLE_Mode` | `FSE_Compressed_Mode` | `Repeat_Mode` |. - `Predefined_Mode` : A predefined FSE distribution table is used, defined in; [default distributions](#default-distributions).; No distribution table will be present.; - `RLE_Mode` : The table description consists of a single byte, which contains the symbol's value.; This symbol will be used for all sequences.; - `FSE_Compressed_Mode` : standard FSE compression.; A distribution table will be present.; The format of this distribution table is described in [FSE Table Description](#fse-table-description).; Note that the maximum allowed accuracy log for literals length and match length tables is 9,; and the maximum accuracy log for the offsets table is 8.; `FSE_Compressed_Mode` must not be used when only one symbol is present,; `RLE_Mode` should be used instead (although any other mode will work).; - `Repeat_Mode` : The table used in the previous `Compressed_Block` with `Number_of_Sequences > 0` will be used again,; or if this is the first block, table in the dictionary will be used.; Note that this includes `RLE_mode`, so if `Repeat_Mode` follows `RLE_Mode`, the same symbol will be repeated.; It also includes `Predefined_Mode`, in which case `Repeat_Mode` will have same outcome as `Predefined_Mode`.; No distribution table will be present.; If this mode is used without any previous sequence table in the frame; (nor [dictionary](#dictionary-format)) to repeat, this should be treated as corruption. #### The codes for literals lengths, match lengths, and offsets. Each symbol is a _code_ in its own context,; which specifies `Baseline` and `Number_of_Bits` to add.; ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:33709,Testability,log,log,33709,"es the same for `Match_Length`, and then for `Literals_Length`.; This sequence is then used for [sequence execution](#sequence-execution). If it is not the last sequence in the block,; the next operation is to update states.; Using the rules pre-calculated in the decoding tables,; `Literals_Length_State` is updated,; followed by `Match_Length_State`,; and then `Offset_State`.; See the [FSE section](#fse) for details on how to update states from the bitstream. This operation will be repeated `Number_of_Sequences` times.; At the end, the bitstream shall be entirely consumed,; otherwise the bitstream is considered corrupted. #### Default Distributions; If `Predefined_Mode` is selected for a symbol type,; its FSE decoding table is generated from a predefined distribution table defined here.; For details on how to convert this distribution into a decoding table, see the [FSE section]. [FSE section]: #from-normalized-distribution-to-decoding-tables. ##### Literals Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short literalsLength_defaultDistribution[36] =; { 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1,; -1,-1,-1,-1 };; ```. ##### Match Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short matchLengths_defaultDistribution[53] =; { 1, 4, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,-1,-1,; -1,-1,-1,-1,-1 };; ```. ##### Offset Codes; The decoding table uses an accuracy log of 5 bits (32 states),; and supports a maximum `N` value of 28, allowing offset values up to 536,870,908 . If any sequence in the compressed block requires a larger offset than this,; it's not possible to use the default distribution to represent it.; ```; short offsetCodes_defaultDistribution[29] =; { 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1,-1,-1,-1,-1,-1 };; ```. Sequence Exec",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:33967,Testability,log,log,33967," the decoding tables,; `Literals_Length_State` is updated,; followed by `Match_Length_State`,; and then `Offset_State`.; See the [FSE section](#fse) for details on how to update states from the bitstream. This operation will be repeated `Number_of_Sequences` times.; At the end, the bitstream shall be entirely consumed,; otherwise the bitstream is considered corrupted. #### Default Distributions; If `Predefined_Mode` is selected for a symbol type,; its FSE decoding table is generated from a predefined distribution table defined here.; For details on how to convert this distribution into a decoding table, see the [FSE section]. [FSE section]: #from-normalized-distribution-to-decoding-tables. ##### Literals Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short literalsLength_defaultDistribution[36] =; { 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1,; -1,-1,-1,-1 };; ```. ##### Match Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short matchLengths_defaultDistribution[53] =; { 1, 4, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,-1,-1,; -1,-1,-1,-1,-1 };; ```. ##### Offset Codes; The decoding table uses an accuracy log of 5 bits (32 states),; and supports a maximum `N` value of 28, allowing offset values up to 536,870,908 . If any sequence in the compressed block requires a larger offset than this,; it's not possible to use the default distribution to represent it.; ```; short offsetCodes_defaultDistribution[29] =; { 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1,-1,-1,-1,-1,-1 };; ```. Sequence Execution; ------------------; Once literals and sequences have been decoded,; they are combined to produce the decoded content of a block. Each sequence consists of a tuple of (`literals_length`, `offset_value`, `match_length`),; decoded as described in the [Sequ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:34275,Testability,log,log,34275,"onsidered corrupted. #### Default Distributions; If `Predefined_Mode` is selected for a symbol type,; its FSE decoding table is generated from a predefined distribution table defined here.; For details on how to convert this distribution into a decoding table, see the [FSE section]. [FSE section]: #from-normalized-distribution-to-decoding-tables. ##### Literals Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short literalsLength_defaultDistribution[36] =; { 4, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1,; 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1,; -1,-1,-1,-1 };; ```. ##### Match Length; The decoding table uses an accuracy log of 6 bits (64 states).; ```; short matchLengths_defaultDistribution[53] =; { 1, 4, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,-1,-1,; -1,-1,-1,-1,-1 };; ```. ##### Offset Codes; The decoding table uses an accuracy log of 5 bits (32 states),; and supports a maximum `N` value of 28, allowing offset values up to 536,870,908 . If any sequence in the compressed block requires a larger offset than this,; it's not possible to use the default distribution to represent it.; ```; short offsetCodes_defaultDistribution[29] =; { 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,; 1, 1, 1, 1, 1, 1, 1, 1,-1,-1,-1,-1,-1 };; ```. Sequence Execution; ------------------; Once literals and sequences have been decoded,; they are combined to produce the decoded content of a block. Each sequence consists of a tuple of (`literals_length`, `offset_value`, `match_length`),; decoded as described in the [Sequences Section](#sequences-section).; To execute a sequence, first copy `literals_length` bytes; from the decoded literals to the output. Then `match_length` bytes are copied from previous decoded data.; The offset to copy from is determined by `offset_value`:; if `offset_value > 3`, then the offset is `offset_value - 3`.; If `offset_value` is from ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:52179,Testability,log,log,52179,"esentation.; * Since the last non-zero `Weight` is _not_ encoded,; this scheme is compatible with alphabet sizes of up to 129 symbols,; hence including literal symbol 128.; * If any literal symbol > 128 has a non-zero `Weight`,; direct representation is not possible.; In such case, it's necessary to use FSE compression. #### Finite State Entropy (FSE) compression of Huffman weights. In this case, the series of Huffman weights is compressed using FSE compression.; It's a single bitstream with 2 interleaved states,; sharing a single distribution table. To decode an FSE bitstream, it is necessary to know its compressed size.; Compressed size is provided by `headerByte`.; It's also necessary to know its _maximum possible_ decompressed size,; which is `255`, since literal values span from `0` to `255`,; and last symbol's `Weight` is not represented. An FSE bitstream starts by a header, describing probabilities distribution.; It will create a Decoding Table.; For a list of Huffman weights, the maximum accuracy log is 6 bits.; For more description see the [FSE header description](#fse-table-description). The Huffman header compression uses 2 states,; which share the same FSE distribution table.; The first state (`State1`) encodes the even indexed symbols,; and the second (`State2`) encodes the odd indexed symbols.; `State1` is initialized first, and then `State2`, and they take turns; decoding a single symbol and updating their state.; For more details on these FSE operations, see the [FSE section](#fse). The number of symbols to decode is determined; by tracking bitStream overflow condition:; If updating state after decoding a symbol would require more bits than; remain in the stream, it is assumed that extra bits are 0. Then,; symbols for each of the final states are decoded and the process is complete. #### Conversion from weights to Huffman prefix codes. All present symbols shall now have a `Weight` value.; It is possible to transform weights into `Number_of_Bits`, usi",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:62780,Testability,test,tested,62780," | Number_Of_Bits | Base |; | ----- | ------ | -------------- | ---- |; | 0 | 0 | 5 | 0 |; | 1 | 6 | 4 | 0 |; | 2 | 9 | 5 | 0 |; | 3 | 15 | 5 | 0 |; | 4 | 21 | 5 | 0 |; | 5 | 3 | 5 | 0 |; | 6 | 7 | 4 | 0 |; | 7 | 12 | 5 | 0 |; | 8 | 18 | 5 | 0 |; | 9 | 23 | 5 | 0 |; | 10 | 5 | 5 | 0 |; | 11 | 8 | 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several de",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:62893,Testability,test,tests,62893,"6 | 7 | 4 | 0 |; | 7 | 12 | 5 | 0 |; | 8 | 18 | 5 | 0 |; | 9 | 23 | 5 | 0 |; | 10 | 5 | 5 | 0 |; | 11 | 8 | 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several details, by Sean Purcell; - 0.2.2 : added predefined codes, by Johannes Rudolph; - 0.2.1 : clarify field names, by Przemyslaw Skibinski; - 0.2.0 : numerous format adjustments for zstd v0.8+; - ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:62960,Testability,test,testing,62960,"6 | 7 | 4 | 0 |; | 7 | 12 | 5 | 0 |; | 8 | 18 | 5 | 0 |; | 9 | 23 | 5 | 0 |; | 10 | 5 | 5 | 0 |; | 11 | 8 | 4 | 0 |; | 12 | 14 | 5 | 0 |; | 13 | 20 | 5 | 0 |; | 14 | 2 | 5 | 0 |; | 15 | 7 | 4 | 16 |; | 16 | 11 | 5 | 0 |; | 17 | 17 | 5 | 0 |; | 18 | 22 | 5 | 0 |; | 19 | 4 | 5 | 0 |; | 20 | 8 | 4 | 16 |; | 21 | 13 | 5 | 0 |; | 22 | 19 | 5 | 0 |; | 23 | 1 | 5 | 0 |; | 24 | 6 | 4 | 16 |; | 25 | 10 | 5 | 0 |; | 26 | 16 | 5 | 0 |; | 27 | 28 | 5 | 0 |; | 28 | 27 | 5 | 0 |; | 29 | 26 | 5 | 0 |; | 30 | 25 | 5 | 0 |; | 31 | 24 | 5 | 0 |. Appendix B - Resources for implementers; -------------------------------------------------. An open source reference implementation is available on :; https://github.com/facebook/zstd. The project contains a frame generator, called [decodeCorpus],; which can be used by any 3rd-party implementation; to verify that a tested decoder is compliant with the specification. [decodeCorpus]: https://github.com/facebook/zstd/tree/v1.3.4/tests#decodecorpus---tool-to-generate-zstandard-frames-for-decoder-testing. `decodeCorpus` generates random valid frames.; A compliant decoder should be able to decode them all,; or at least provide a meaningful error code explaining for which reason it cannot; (memory limit restrictions for example). Version changes; ---------------; - 0.3.1 : minor clarification regarding offset history update rules; - 0.3.0 : minor edits to match RFC8478; - 0.2.9 : clarifications for huffman weights direct representation, by Ulrich Kunitz; - 0.2.8 : clarifications for IETF RFC discuss; - 0.2.7 : clarifications from IETF RFC review, by Vijay Gurbani and Nick Terrell; - 0.2.6 : fixed an error in huffman example, by Ulrich Kunitz; - 0.2.5 : minor typos and clarifications; - 0.2.4 : section restructuring, by Sean Purcell; - 0.2.3 : clarified several details, by Sean Purcell; - 0.2.2 : added predefined codes, by Johannes Rudolph; - 0.2.1 : clarify field names, by Przemyslaw Skibinski; - 0.2.0 : numerous format adjustments for zstd v0.8+; - ",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:444,Usability,clear,clearly,444,"Zstandard Compression Format; ============================. ### Notices. Copyright (c) 2016-present Yann Collet, Facebook, Inc. Permission is granted to copy and distribute this document; for any purpose and without charge,; including translations into other languages; and incorporation into compilations,; provided that the copyright notice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version. 0.3.1 (25/10/18). Introduction; ------------. The purpose of this document is to define a lossless compressed data format,; that is independent of CPU type, operating system,; file system and character set, suitable for; file compression, pipe and streaming compression,; using the [Zstandard algorithm](http://www.zstandard.org).; The text of the specification assumes a basic background in programming; at the level of bits and other primitive data representations. The data can be produced or consumed,; even for an arbitrarily long sequentially presented input data stream,; using only an a priori bounded amount of intermediate storage,; and hence can be used in data communications.; The format uses the Zstandard compression method,; and optional [xxHash-64 checksum method](http://www.xxhash.org),; for detection of data corruption. The data format defined by this specification; does not attempt to allow random access to compressed data. Unless otherwise indicated below,; a compliant compressor must produce data sets; that conform to the specifications presented here.; It doesn’t need to support all options though. A compliant decompressor must be able to decompress; at least one working set of parameters; that conforms to the specifications presented here.; It may also ignore informative fields, such as checksum.; Whenever it does not support a parameter defined in the compressed stream,; it must produce a non-ambiguous error code and associated error message; e",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md:45078,Usability,simpl,simply,45078,"to create a unique decoding table. It follows the following build rule :. The table has a size of `Table_Size = 1 << Accuracy_Log`.; Each cell describes the symbol decoded,; and instructions to get the next state. Symbols are scanned in their natural order for ""less than 1"" probabilities.; Symbols with this probability are being attributed a single cell,; starting from the end of the table and retreating.; These symbols define a full state reset, reading `Accuracy_Log` bits. All remaining symbols are allocated in their natural order.; Starting from symbol `0` and table position `0`,; each symbol gets allocated as many cells as its probability.; Cell allocation is spreaded, not linear :; each successor position follow this rule :. ```; position += (tableSize>>1) + (tableSize>>3) + 3;; position &= tableSize-1;; ```. A position is skipped if already occupied by a ""less than 1"" probability symbol.; `position` does not reset between symbols, it simply iterates through; each position in the table, switching to the next symbol when enough; states have been allocated to the current one. The result is a list of state values.; Each state will decode the current symbol. To get the `Number_of_Bits` and `Baseline` required for next state,; it's first necessary to sort all states in their natural order.; The lower states will need 1 more bit than higher ones.; The process is repeated for each symbol. __Example__ :; Presuming a symbol has a probability of 5.; It receives 5 state values. States are sorted in natural order. Next power of 2 is 8.; Space of probabilities is divided into 8 equal parts.; Presuming the `Accuracy_Log` is 7, it defines 128 states.; Divided by 8, each share is 16 large. In order to reach 8, 8-5=3 lowest states will count ""double"",; doubling the number of shares (32 in width),; requiring one more bit in the process. Baseline is assigned starting from the higher states using fewer bits,; and proceeding naturally, then resuming at the first state,; each takes i",MatchSource.DOCS,lib/zstd/doc/zstd_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/examples/README.md:286,Usability,simpl,simple,286,"Zstandard library : usage examples; ==================================. - [Simple compression](simple_compression.c) :; Compress a single file.; Introduces usage of : `ZSTD_compress()`. - [Simple decompression](simple_decompression.c) :; Decompress a single file.; Only compatible with simple compression.; Result remains in memory.; Introduces usage of : `ZSTD_decompress()`. - [Streaming memory usage](streaming_memory_usage.c) :; Provides amount of memory used by streaming context; Introduces usage of : `ZSTD_sizeof_CStream()`. - [Streaming compression](streaming_compression.c) :; Compress a single file.; Introduces usage of : `ZSTD_compressStream()`. - [Multiple Streaming compression](multiple_streaming_compression.c) :; Compress multiple files in a single command line.; Introduces memory usage preservation technique,; reducing impact of malloc()/free() and memset() by re-using existing resources. - [Streaming decompression](streaming_decompression.c) :; Decompress a single file compressed by zstd.; Compatible with both simple and streaming compression.; Result is sent to stdout.; Introduces usage of : `ZSTD_decompressStream()`. - [Dictionary compression](dictionary_compression.c) :; Compress multiple files using the same dictionary.; Introduces usage of : `ZSTD_createCDict()` and `ZSTD_compress_usingCDict()`. - [Dictionary decompression](dictionary_decompression.c) :; Decompress multiple files using the same dictionary.; Result remains in memory.; Introduces usage of : `ZSTD_createDDict()` and `ZSTD_decompress_usingDDict()`; ",MatchSource.DOCS,lib/zstd/examples/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/examples/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/examples/README.md:1036,Usability,simpl,simple,1036,"Zstandard library : usage examples; ==================================. - [Simple compression](simple_compression.c) :; Compress a single file.; Introduces usage of : `ZSTD_compress()`. - [Simple decompression](simple_decompression.c) :; Decompress a single file.; Only compatible with simple compression.; Result remains in memory.; Introduces usage of : `ZSTD_decompress()`. - [Streaming memory usage](streaming_memory_usage.c) :; Provides amount of memory used by streaming context; Introduces usage of : `ZSTD_sizeof_CStream()`. - [Streaming compression](streaming_compression.c) :; Compress a single file.; Introduces usage of : `ZSTD_compressStream()`. - [Multiple Streaming compression](multiple_streaming_compression.c) :; Compress multiple files in a single command line.; Introduces memory usage preservation technique,; reducing impact of malloc()/free() and memset() by re-using existing resources. - [Streaming decompression](streaming_decompression.c) :; Decompress a single file compressed by zstd.; Compatible with both simple and streaming compression.; Result is sent to stdout.; Introduces usage of : `ZSTD_decompressStream()`. - [Dictionary compression](dictionary_compression.c) :; Compress multiple files using the same dictionary.; Introduces usage of : `ZSTD_createCDict()` and `ZSTD_compress_usingCDict()`. - [Dictionary decompression](dictionary_decompression.c) :; Decompress multiple files using the same dictionary.; Result remains in memory.; Introduces usage of : `ZSTD_createDDict()` and `ZSTD_decompress_usingDDict()`; ",MatchSource.DOCS,lib/zstd/examples/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/examples/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:960,Availability,error,error,960,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:4840,Availability,avail,available,4840,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:404,Deployability,install,install,404,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:520,Deployability,install,install,520,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:531,Deployability,install,install,531,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:5343,Deployability,install,install,5343,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:5507,Deployability,install,install,5507,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:1646,Integrability,depend,depend,1646,"m directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifying a number limits versions supported to that version onward.; For example, `ZSTD_LEGACY_SUPPORT=2` means : ""support legacy formats >= v0.2.0"".; `ZSTD_LEGACY_SUPPORT=3` means : ""support legacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are comp",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:1820,Integrability,depend,depends,1820,"exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifying a number limits versions supported to that version onward.; For example, `ZSTD_LEGACY_SUPPORT=2` means : ""support legacy formats >= v0.2.0"".; `ZSTD_LEGACY_SUPPORT=3` means : ""support legacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are compatible with v1+ specification.; `ZSTD_LEGACY_SUPPORT=0` also means ""do __not__ support legacy formats"".; Once enabled, this capability is transparently triggered within decompression functions.; It's also possible to invoke directly legacy API, as exposed in `lib/legacy/z",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:1972,Integrability,depend,depends,1972,"ATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifying a number limits versions supported to that version onward.; For example, `ZSTD_LEGACY_SUPPORT=2` means : ""support legacy formats >= v0.2.0"".; `ZSTD_LEGACY_SUPPORT=3` means : ""support legacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are compatible with v1+ specification.; `ZSTD_LEGACY_SUPPORT=0` also means ""do __not__ support legacy formats"".; Once enabled, this capability is transparently triggered within decompression functions.; It's also possible to invoke directly legacy API, as exposed in `lib/legacy/zstd_legacy.h`.; Each version also provides an additional dedicated set of advanced API.; For example, advanced API for version `v0.4` is exposed in `l",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:3302,Integrability,depend,dependencies,3302,"egacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are compatible with v1+ specification.; `ZSTD_LEGACY_SUPPORT=0` also means ""do __not__ support legacy formats"".; Once enabled, this capability is transparently triggered within decompression functions.; It's also possible to invoke directly legacy API, as exposed in `lib/legacy/zstd_legacy.h`.; Each version also provides an additional dedicated set of advanced API.; For example, advanced API for version `v0.4` is exposed in `lib/legacy/zstd_v04.h` .; Note : `lib/legacy` only supports _decoding_ legacy formats.; - Similarly, you can define `ZSTD_LIB_COMPRESSION, ZSTD_LIB_DECOMPRESSION`, `ZSTD_LIB_DICTBUILDER`,; and `ZSTD_LIB_DEPRECATED` as 0 to forgo compilation of the corresponding features. This will; also disable compilation of all dependencies (eg. `ZSTD_LIB_COMPRESSION=0` will also disable; dictBuilder). #### Multithreading support. Multithreading is disabled by default when building with `make`.; Enabling multithreading requires 2 conditions :; - set macro `ZSTD_MULTITHREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzst",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:386,Modifiability,variab,variables,386,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:423,Modifiability,variab,variables,423,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:5484,Modifiability,config,config,5484,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:750,Security,expose,exposed,750,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:837,Security,expose,exposed,837,"Zstandard library files; ================================. The __lib__ directory is split into several sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:1074,Security,access,access,1074,"l sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifyi",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:1112,Security,expose,exposed,1112,"l sub-directories,; in order to make it easier to select or exclude features. #### Building. `Makefile` script is provided, supporting all standard [Makefile conventions](https://www.gnu.org/prep/standards/html_node/Makefile-Conventions.html#Makefile-Conventions),; including commands variables, staged install, directory variables and standard targets.; - `make` : generates both static and dynamic libraries; - `make install` : install libraries in default system directories. `libzstd` default scope includes compression, decompression, dictionary building,; and decoding support for legacy formats >= v0.5.0. #### API. Zstandard's stable API is exposed within [lib/zstd.h](zstd.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifyi",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:1769,Security,expose,exposed,1769,"std.h). #### Advanced API. Optional advanced features are exposed via :. - `lib/common/zstd_errors.h` : translates `size_t` function results; into an `ZSTD_ErrorCode`, for accurate error handling.; - `ZSTD_STATIC_LINKING_ONLY` : if this macro is defined _before_ including `zstd.h`,; it unlocks access to advanced experimental API,; exposed in second part of `zstd.h`.; These APIs are not ""stable"", their definition may change in the future.; As a consequence, it shall ___never be used with dynamic library___ !; Only static linking is allowed. #### Modular build. It's possible to compile only a limited set of features. - Directory `lib/common` is always required, for all variants.; - Compression source code lies in `lib/compress`; - Decompression source code lies in `lib/decompress`; - It's possible to include only `compress` or only `decompress`, they don't depend on each other.; - `lib/dictBuilder` : makes it possible to generate dictionaries from a set of samples.; The API is exposed in `lib/dictBuilder/zdict.h`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifying a number limits versions supported to that version onward.; For example, `ZSTD_LEGACY_SUPPORT=2` means : ""support legacy formats >= v0.2.0"".; `ZSTD_LEGACY_SUPPORT=3` means : ""support legacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are compatible with v1+ specification.; `ZSTD_LEGACY_SUPPORT=0` also means ""do __not__ support legacy formats"".; Once enabled, this capability is transparently triggered within decompression functions.; It's also possible ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:2814,Security,expose,exposed,2814,"`.; This module depends on both `lib/common` and `lib/compress` .; - `lib/legacy` : source code to decompress legacy zstd formats, starting from `v0.1.0`.; This module depends on `lib/common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifying a number limits versions supported to that version onward.; For example, `ZSTD_LEGACY_SUPPORT=2` means : ""support legacy formats >= v0.2.0"".; `ZSTD_LEGACY_SUPPORT=3` means : ""support legacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are compatible with v1+ specification.; `ZSTD_LEGACY_SUPPORT=0` also means ""do __not__ support legacy formats"".; Once enabled, this capability is transparently triggered within decompression functions.; It's also possible to invoke directly legacy API, as exposed in `lib/legacy/zstd_legacy.h`.; Each version also provides an additional dedicated set of advanced API.; For example, advanced API for version `v0.4` is exposed in `lib/legacy/zstd_v04.h` .; Note : `lib/legacy` only supports _decoding_ legacy formats.; - Similarly, you can define `ZSTD_LIB_COMPRESSION, ZSTD_LIB_DECOMPRESSION`, `ZSTD_LIB_DICTBUILDER`,; and `ZSTD_LIB_DEPRECATED` as 0 to forgo compilation of the corresponding features. This will; also disable compilation of all dependencies (eg. `ZSTD_LIB_COMPRESSION=0` will also disable; dictBuilder). #### Multithreading support. Multithreading is disabled by default when building with `make`.; Enabling multithreading requires 2 conditions :; - set macro `ZSTD_MULTITHREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:2975,Security,expose,exposed,2975,"common` and `lib/decompress`.; To enable this feature, define `ZSTD_LEGACY_SUPPORT` during compilation.; Specifying a number limits versions supported to that version onward.; For example, `ZSTD_LEGACY_SUPPORT=2` means : ""support legacy formats >= v0.2.0"".; `ZSTD_LEGACY_SUPPORT=3` means : ""support legacy formats >= v0.3.0"", and so on.; Currently, the default library setting is `ZST_LEGACY_SUPPORT=5`.; It can be changed at build by any other value.; Note that any number >= 8 translates into ""do __not__ support legacy formats"",; since all versions of `zstd` >= v0.8 are compatible with v1+ specification.; `ZSTD_LEGACY_SUPPORT=0` also means ""do __not__ support legacy formats"".; Once enabled, this capability is transparently triggered within decompression functions.; It's also possible to invoke directly legacy API, as exposed in `lib/legacy/zstd_legacy.h`.; Each version also provides an additional dedicated set of advanced API.; For example, advanced API for version `v0.4` is exposed in `lib/legacy/zstd_v04.h` .; Note : `lib/legacy` only supports _decoding_ legacy formats.; - Similarly, you can define `ZSTD_LIB_COMPRESSION, ZSTD_LIB_DECOMPRESSION`, `ZSTD_LIB_DICTBUILDER`,; and `ZSTD_LIB_DEPRECATED` as 0 to forgo compilation of the corresponding features. This will; also disable compilation of all dependencies (eg. `ZSTD_LIB_COMPRESSION=0` will also disable; dictBuilder). #### Multithreading support. Multithreading is disabled by default when building with `make`.; Enabling multithreading requires 2 conditions :; - set macro `ZSTD_MULTITHREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.co",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:3893,Security,expose,exposed,3893,"dvanced API.; For example, advanced API for version `v0.4` is exposed in `lib/legacy/zstd_v04.h` .; Note : `lib/legacy` only supports _decoding_ legacy formats.; - Similarly, you can define `ZSTD_LIB_COMPRESSION, ZSTD_LIB_DECOMPRESSION`, `ZSTD_LIB_DICTBUILDER`,; and `ZSTD_LIB_DEPRECATED` as 0 to forgo compilation of the corresponding features. This will; also disable compilation of all dependencies (eg. `ZSTD_LIB_COMPRESSION=0` will also disable; dictBuilder). #### Multithreading support. Multithreading is disabled by default when building with `make`.; Enabling multithreading requires 2 conditions :; - set macro `ZSTD_MULTITHREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:5165,Security,expose,exposed,5165,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:4634,Testability,test,test-dll,4634,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:4740,Testability,test,test-dll,4740,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md:4754,Testability,test,test-dll,4754,"THREAD`; - on POSIX systems : compile with pthread (`-pthread` compilation flag for `gcc`). Both conditions are automatically triggered by invoking `make lib-mt` target.; Note that, when linking a POSIX program with a multithreaded version of `libzstd`,; it's necessary to trigger `-pthread` flag during link stage. Multithreading capabilities are exposed; via [advanced API `ZSTD_compress_generic()` defined in `lib/zstd.h`](https://github.com/facebook/zstd/blob/dev/lib/zstd.h#L919).; This API is still considered experimental,; but is expected to become ""stable"" at some point in the future. #### Windows : using MinGW+MSYS to create DLL. DLL can be created using MinGW+MSYS with the `make libzstd` command.; This command creates `dll\libzstd.dll` and the import library `dll\libzstd.lib`.; The import library is only required with Visual C++.; The header file `zstd.h` and the dynamic library `dll\libzstd.dll` are required to; compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude/ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### Deprecated API. Obsolete API on their way out are stored in directory `lib/deprecated`.; At this stage, it contains older streaming prototypes, in `lib/deprecated/zbuff.h`.; These prototypes will be removed in some future version.; Consider migrating code towards supported streaming API exposed in `zstd.h`. #### Miscellaneous. The other files are not source code. There are :. - `LICENSE` : contains the BSD license text; - `Makefile` : `make` script to build and install zstd library (static and dynamic); - `BUCK` : support for `buck` build system (https://buckbuild.com/); - `libzstd.pc.in` : for `pkg-config` (used in `make install`); - `README.md` : this file; ",MatchSource.DOCS,lib/zstd/lib/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:4229,Availability,degraded,degraded,4229,"le : `make zstd HAVE_LZMA=0`; It's also possible to force compilation with lzma support, using `HAVE_LZMA=1`.; In which case, linking stage will fail if `lzma` library cannot be found.; This is useful to prevent silent feature disabling. - __HAVE_LZ4__ : `zstd` can compress and decompress files in `.lz4` formats.; This is ordered through commands `--format=lz4`.; Alternatively, symlinks named `lz4`, or `unlz4` will mimic intended behavior.; `.lz4` support is automatically enabled when `lz4` library is detected at build time.; It's possible to disable `.lz4` support, by setting `HAVE_LZ4=0` .; Example : `make zstd HAVE_LZ4=0`; It's also possible to force compilation with lz4 support, using `HAVE_LZ4=1`.; In which case, linking stage will fail if `lz4` library cannot be found.; This is useful to prevent silent feature disabling. - __BACKTRACE__ : `zstd` can display a stack backtrace when execution; generates a runtime exception. By default, this feature may be; degraded/disabled on some platforms unless additional compiler directives are; applied. When triaging a runtime issue, enabling this feature can provide; more context to determine the location of the fault.; Example : `make zstd BACKTRACE=1`. #### Aggregation of parameters; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` forma",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:4429,Availability,fault,fault,4429,"case, linking stage will fail if `lzma` library cannot be found.; This is useful to prevent silent feature disabling. - __HAVE_LZ4__ : `zstd` can compress and decompress files in `.lz4` formats.; This is ordered through commands `--format=lz4`.; Alternatively, symlinks named `lz4`, or `unlz4` will mimic intended behavior.; `.lz4` support is automatically enabled when `lz4` library is detected at build time.; It's possible to disable `.lz4` support, by setting `HAVE_LZ4=0` .; Example : `make zstd HAVE_LZ4=0`; It's also possible to force compilation with lz4 support, using `HAVE_LZ4=1`.; In which case, linking stage will fail if `lz4` library cannot be found.; This is useful to prevent silent feature disabling. - __BACKTRACE__ : `zstd` can display a stack backtrace when execution; generates a runtime exception. By default, this feature may be; degraded/disabled on some platforms unless additional compiler directives are; applied. When triaging a runtime issue, enabling this feature can provide; more context to determine the location of the fault.; Example : `make zstd BACKTRACE=1`. #### Aggregation of parameters; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:4805,Availability,avail,available,4805,"le to disable `.lz4` support, by setting `HAVE_LZ4=0` .; Example : `make zstd HAVE_LZ4=0`; It's also possible to force compilation with lz4 support, using `HAVE_LZ4=1`.; In which case, linking stage will fail if `lz4` library cannot be found.; This is useful to prevent silent feature disabling. - __BACKTRACE__ : `zstd` can display a stack backtrace when execution; generates a runtime exception. By default, this feature may be; degraded/disabled on some platforms unless additional compiler directives are; applied. When triaging a runtime issue, enabling this feature can provide; more context to determine the location of the fault.; Example : `make zstd BACKTRACE=1`. #### Aggregation of parameters; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and ",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:5158,Availability,error,error,5158,"cktrace when execution; generates a runtime exception. By default, this feature may be; degraded/disabled on some platforms unless additional compiler directives are; applied. When triaging a runtime issue, enabling this feature can provide; more context to determine the location of the fault.; Example : `make zstd BACKTRACE=1`. #### Aggregation of parameters; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected wi",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:5355,Availability,error,error,5355,"e issue, enabling this feature can provide; more context to determine the location of the fault.; Example : `make zstd BACKTRACE=1`. #### Aggregation of parameters; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected with the `-o` option (default name is `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:5560,Availability,error,error,5560,"i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected with the `-o` option (default name is `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no uni",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:5700,Availability,error,error,5700,"the name of the symlink has a specific value, it triggers an associated behavior.; - `zstdmt` : compress using all cores available on local system.; - `zcat` : will decompress and output target file using any of the supported formats. `gzcat` and `zstdcat` are also equivalent.; - `gzip` : if zlib support is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected with the `-o` option (default name is `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effect",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:8560,Availability,error,errors,8560,"; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file); -f : overwrite output without prompting and (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force write to standard output, even if it is the console; -l : print information about zstd compressed files; --ultra : enable levels beyond 19, up to 22 (requires more memory); --long : enable long distance matching (requires more memory); --no-dictID : don't write dictID into header (dictionary compression); --[no-]check : integrity check (default: enabled); -r : operate recursively on directories; --format=gzip : compress files to the .gz format; --format=xz : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dic",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:6572,Deployability,deploy,deploying,6572,"will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected with the `-o` option (default name is `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface; CLI includes in-memory compression benchmark module for zstd.; The benchmark is conducted using given filenames. The files are read into memory and joined together.; It makes benchmark more precise as it eliminates I/O overhead.; Multiple filenames can be supplied, as multiple parameters, with wildcards,; or names of directories can be used as parameters with `-r` option. The benchmark measures ratio, compressed size, compression and ",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:10647,Integrability,depend,dependent,10647," with selectivity (default: 9); -o file : `file` is dictionary name (default: dictionary); --maxdict=# : limit dictionary to specified size (default: 112640); --dictID=# : force dictionary ID to specified value (default: random). Benchmark arguments :; -b# : benchmark file(s), using # compression level (default: 3); -e# : test all compression levels from -bX to # (default: 1); -i# : minimum evaluation time in seconds (default: 3s); -B# : cut file into independent blocks of size # (default: no block); --priority=rt : set process priority to real-time; ```. #### Long distance matching mode; The long distance matching mode, enabled with `--long`, is designed to improve; the compression ratio for files with long matches at a large distance (up to the; maximum window size, `128 MiB`) while still maintaining compression speed. Enabling this mode sets the window size to `128 MiB` and thus increases the memory; usage for both the compressor and decompressor. Performance in terms of speed is; dependent on long matches being found. Compression speed may degrade if few long; matches are found. Decompression speed usually improves when there are many long; distance matches. Below are graphs comparing the compression speed, compression ratio, and; decompression speed with and without long distance matching on an ideal use; case: a tar of four versions of clang (versions `3.4.1`, `3.4.2`, `3.5.0`,; `3.5.1`) with a total size of `244889600 B`. This is an ideal use case as there; are many long distance matches within the maximum window size of `128 MiB` (each; version is less than `128 MiB`). Compression Speed vs Ratio | Decompression Speed; ---------------------------|---------------------; ![Compression Speed vs Ratio](https://raw.githubusercontent.com/facebook/zstd/v1.3.3/doc/images/ldmCspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](https://raw.githubusercontent.com/facebook/zstd/v1.3.3/doc/images/ldmDspeed.png ""Decompression Speed""). | Method | Compression rati",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:805,Modifiability,variab,variables,805,"Command Line Interface for Zstandard library; ============================================. Command Line Interface (CLI) can be created using the `make` command without any additional parameters.; There are however other Makefile targets that create different variations of CLI:; - `zstd` : default CLI supporting gzip-like arguments; includes dictionary builder, benchmark, and support for decompression of legacy zstd formats; - `zstd_nolegacy` : Same as `zstd` but without support for legacy zstd formats; - `zstd-small` : CLI optimized for minimal size; no dictionary builder, no benchmark, and no support for legacy zstd formats; - `zstd-compress` : version of CLI which can only compress into zstd format; - `zstd-decompress` : version of CLI which can only decompress zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legac",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:878,Modifiability,variab,variables,878,"Command Line Interface for Zstandard library; ============================================. Command Line Interface (CLI) can be created using the `make` command without any additional parameters.; There are however other Makefile targets that create different variations of CLI:; - `zstd` : default CLI supporting gzip-like arguments; includes dictionary builder, benchmark, and support for decompression of legacy zstd formats; - `zstd_nolegacy` : Same as `zstd` but without support for legacy zstd formats; - `zstd-small` : CLI optimized for minimal size; no dictionary builder, no benchmark, and no support for legacy zstd formats; - `zstd-compress` : version of CLI which can only compress into zstd format; - `zstd-decompress` : version of CLI which can only decompress zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legac",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:1795,Modifiability,variab,variable,1795,"s zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legacy format.; if `ZSTD_LEGACY_SUPPORT >= 8`, it's the same as `0`, since there is no legacy format after `7`.; Note : `zstd` only supports decoding older formats, and cannot generate any legacy format. - __HAVE_ZLIB__ : `zstd` can compress and decompress files in `.gz` format.; This is ordered through command `--format=gzip`.; Alternatively, symlinks named `gzip` or `gunzip` will mimic intended behavior.; `.gz` support is automatically enabled when `zlib` library is detected at build time.; It's possible to disable `.gz` support, by setting `HAVE_ZLIB=0`.; Example : `make zstd HAVE_ZLIB=0`; It's also possible to force compilation with zlib support, `using HAVE_ZLIB=1`.; In which case, linking stage will fail if `zlib` library cannot be found.; This is useful to prev",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:530,Performance,optimiz,optimized,530,"Command Line Interface for Zstandard library; ============================================. Command Line Interface (CLI) can be created using the `make` command without any additional parameters.; There are however other Makefile targets that create different variations of CLI:; - `zstd` : default CLI supporting gzip-like arguments; includes dictionary builder, benchmark, and support for decompression of legacy zstd formats; - `zstd_nolegacy` : Same as `zstd` but without support for legacy zstd formats; - `zstd-small` : CLI optimized for minimal size; no dictionary builder, no benchmark, and no support for legacy zstd formats; - `zstd-compress` : version of CLI which can only compress into zstd format; - `zstd-decompress` : version of CLI which can only decompress zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legac",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:5998,Performance,tune,tune,5998," is enabled, will mimic `gzip` by compressing file using `.gz` format, removing source file by default (use `--keep` to preserve). If zlib is not supported, triggers an error.; - `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected with the `-o` option (default name is `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compres",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:6207,Performance,load,loaded,6207,"- `xz` : if lzma support is enabled, will mimic `xz` by compressing file using `.xz` format, removing source file by default (use `--keep` to preserve). If xz is not supported, triggers an error.; - `lzma` : if lzma support is enabled, will mimic `lzma` by compressing file using `.lzma` format, removing source file by default (use `--keep` to preserve). If lzma is not supported, triggers an error.; - `lz4` : if lz4 support is enabled, will mimic `lz4` by compressing file using `.lz4` format. If lz4 is not supported, triggers an error.; - `unzstd` and `unlz4` will decompress any of the supported format.; - `ungz`, `unxz` and `unlzma` will do the same, and will also remove source file by default (use `--keep` to preserve). #### Dictionary builder in Command Line Interface; Zstd offers a training mode, which can be used to tune the algorithm for a selected; type of data, by providing it with a few samples. The result of the training is stored; in a file selected with the `-o` option (default name is `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface;",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:969,Safety,detect,detected,969,"Command Line Interface for Zstandard library; ============================================. Command Line Interface (CLI) can be created using the `make` command without any additional parameters.; There are however other Makefile targets that create different variations of CLI:; - `zstd` : default CLI supporting gzip-like arguments; includes dictionary builder, benchmark, and support for decompression of legacy zstd formats; - `zstd_nolegacy` : Same as `zstd` but without support for legacy zstd formats; - `zstd-small` : CLI optimized for minimal size; no dictionary builder, no benchmark, and no support for legacy zstd formats; - `zstd-compress` : version of CLI which can only compress into zstd format; - `zstd-decompress` : version of CLI which can only decompress zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legac",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:2469,Safety,detect,detected,2469,"ions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legacy format.; if `ZSTD_LEGACY_SUPPORT >= 8`, it's the same as `0`, since there is no legacy format after `7`.; Note : `zstd` only supports decoding older formats, and cannot generate any legacy format. - __HAVE_ZLIB__ : `zstd` can compress and decompress files in `.gz` format.; This is ordered through command `--format=gzip`.; Alternatively, symlinks named `gzip` or `gunzip` will mimic intended behavior.; `.gz` support is automatically enabled when `zlib` library is detected at build time.; It's possible to disable `.gz` support, by setting `HAVE_ZLIB=0`.; Example : `make zstd HAVE_ZLIB=0`; It's also possible to force compilation with zlib support, `using HAVE_ZLIB=1`.; In which case, linking stage will fail if `zlib` library cannot be found.; This is useful to prevent silent feature disabling. - __HAVE_LZMA__ : `zstd` can compress and decompress files in `.xz` and `.lzma` formats.; This is ordered through commands `--format=xz` and `--format=lzma` respectively.; Alternatively, symlinks named `xz`, `unxz`, `lzma`, or `unlzma` will mimic intended behavior.; `.xz` and `.lzma` support is automatically enabled when `lzma` library is detected at build time.; It's possible to disable `.xz` and `.lzma` support, by setting `HAVE_LZMA=0` .; Example : `make zstd HAVE_LZMA=0`; It's also possible to force compilation with lzma support, using `HAVE_LZMA=1`.; In which case, linking stage will fail if `lzma` library cannot be found.; This is us",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:3145,Safety,detect,detected,3145,"ly supports decoding older formats, and cannot generate any legacy format. - __HAVE_ZLIB__ : `zstd` can compress and decompress files in `.gz` format.; This is ordered through command `--format=gzip`.; Alternatively, symlinks named `gzip` or `gunzip` will mimic intended behavior.; `.gz` support is automatically enabled when `zlib` library is detected at build time.; It's possible to disable `.gz` support, by setting `HAVE_ZLIB=0`.; Example : `make zstd HAVE_ZLIB=0`; It's also possible to force compilation with zlib support, `using HAVE_ZLIB=1`.; In which case, linking stage will fail if `zlib` library cannot be found.; This is useful to prevent silent feature disabling. - __HAVE_LZMA__ : `zstd` can compress and decompress files in `.xz` and `.lzma` formats.; This is ordered through commands `--format=xz` and `--format=lzma` respectively.; Alternatively, symlinks named `xz`, `unxz`, `lzma`, or `unlzma` will mimic intended behavior.; `.xz` and `.lzma` support is automatically enabled when `lzma` library is detected at build time.; It's possible to disable `.xz` and `.lzma` support, by setting `HAVE_LZMA=0` .; Example : `make zstd HAVE_LZMA=0`; It's also possible to force compilation with lzma support, using `HAVE_LZMA=1`.; In which case, linking stage will fail if `lzma` library cannot be found.; This is useful to prevent silent feature disabling. - __HAVE_LZ4__ : `zstd` can compress and decompress files in `.lz4` formats.; This is ordered through commands `--format=lz4`.; Alternatively, symlinks named `lz4`, or `unlz4` will mimic intended behavior.; `.lz4` support is automatically enabled when `lz4` library is detected at build time.; It's possible to disable `.lz4` support, by setting `HAVE_LZ4=0` .; Example : `make zstd HAVE_LZ4=0`; It's also possible to force compilation with lz4 support, using `HAVE_LZ4=1`.; In which case, linking stage will fail if `lz4` library cannot be found.; This is useful to prevent silent feature disabling. - __BACKTRACE__ : `zstd` can dis",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:3762,Safety,detect,detected,3762," found.; This is useful to prevent silent feature disabling. - __HAVE_LZMA__ : `zstd` can compress and decompress files in `.xz` and `.lzma` formats.; This is ordered through commands `--format=xz` and `--format=lzma` respectively.; Alternatively, symlinks named `xz`, `unxz`, `lzma`, or `unlzma` will mimic intended behavior.; `.xz` and `.lzma` support is automatically enabled when `lzma` library is detected at build time.; It's possible to disable `.xz` and `.lzma` support, by setting `HAVE_LZMA=0` .; Example : `make zstd HAVE_LZMA=0`; It's also possible to force compilation with lzma support, using `HAVE_LZMA=1`.; In which case, linking stage will fail if `lzma` library cannot be found.; This is useful to prevent silent feature disabling. - __HAVE_LZ4__ : `zstd` can compress and decompress files in `.lz4` formats.; This is ordered through commands `--format=lz4`.; Alternatively, symlinks named `lz4`, or `unlz4` will mimic intended behavior.; `.lz4` support is automatically enabled when `lz4` library is detected at build time.; It's possible to disable `.lz4` support, by setting `HAVE_LZ4=0` .; Example : `make zstd HAVE_LZ4=0`; It's also possible to force compilation with lz4 support, using `HAVE_LZ4=1`.; In which case, linking stage will fail if `lz4` library cannot be found.; This is useful to prevent silent feature disabling. - __BACKTRACE__ : `zstd` can display a stack backtrace when execution; generates a runtime exception. By default, this feature may be; degraded/disabled on some platforms unless additional compiler directives are; applied. When triaging a runtime issue, enabling this feature can provide; more context to determine the location of the fault.; Example : `make zstd BACKTRACE=1`. #### Aggregation of parameters; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined into `-b1e18i1`. #### Symlink shortcuts; It's possible to invoke `zstd` through a symlink.; When the name of the symlink has a specific value, it triggers an",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:8905,Security,integrity,integrity,8905,"; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file); -f : overwrite output without prompting and (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force write to standard output, even if it is the console; -l : print information about zstd compressed files; --ultra : enable levels beyond 19, up to 22 (requires more memory); --long : enable long distance matching (requires more memory); --no-dictID : don't write dictID into header (dictionary compression); --[no-]check : integrity check (default: enabled); -r : operate recursively on directories; --format=gzip : compress files to the .gz format; --format=xz : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dic",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:9162,Security,integrity,integrity,9162," (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force write to standard output, even if it is the console; -l : print information about zstd compressed files; --ultra : enable levels beyond 19, up to 22 (requires more memory); --long : enable long distance matching (requires more memory); --no-dictID : don't write dictID into header (dictionary compression); --[no-]check : integrity check (default: enabled); -r : operate recursively on directories; --format=gzip : compress files to the .gz format; --format=xz : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dictionary name (default: dictionary); --maxdict=# : limit dictionary to specified size (default: 112640); --dictID=# : force dictionary ID to specified value (default: random). Benchmark arguments :; -b# : benchmark file(s), using # compression level (default: 3); -e# : test all compression levels from -bX to # (default: 1); -i# : minimum evaluation time in seconds (default: 3s); -B# : cut file into independent blocks of size # (default: no block); --priority=rt : set process priority to real-time; ```. #### Long d",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:364,Testability,benchmark,benchmark,364,"Command Line Interface for Zstandard library; ============================================. Command Line Interface (CLI) can be created using the `make` command without any additional parameters.; There are however other Makefile targets that create different variations of CLI:; - `zstd` : default CLI supporting gzip-like arguments; includes dictionary builder, benchmark, and support for decompression of legacy zstd formats; - `zstd_nolegacy` : Same as `zstd` but without support for legacy zstd formats; - `zstd-small` : CLI optimized for minimal size; no dictionary builder, no benchmark, and no support for legacy zstd formats; - `zstd-compress` : version of CLI which can only compress into zstd format; - `zstd-decompress` : version of CLI which can only decompress zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legac",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:584,Testability,benchmark,benchmark,584,"Command Line Interface for Zstandard library; ============================================. Command Line Interface (CLI) can be created using the `make` command without any additional parameters.; There are however other Makefile targets that create different variations of CLI:; - `zstd` : default CLI supporting gzip-like arguments; includes dictionary builder, benchmark, and support for decompression of legacy zstd formats; - `zstd_nolegacy` : Same as `zstd` but without support for legacy zstd formats; - `zstd-small` : CLI optimized for minimal size; no dictionary builder, no benchmark, and no support for legacy zstd formats; - `zstd-compress` : version of CLI which can only compress into zstd format; - `zstd-decompress` : version of CLI which can only decompress zstd format. #### Compilation variables; `zstd` scope can be altered by modifying the following `make` variables :. - __HAVE_THREAD__ : multithreading is automatically enabled when `pthread` is detected.; It's possible to disable multithread support, by setting `HAVE_THREAD=0`.; Example : `make zstd HAVE_THREAD=0`; It's also possible to force multithread support, using `HAVE_THREAD=1`.; In which case, linking stage will fail if neither `pthread` nor `windows.h` library can be found.; This is useful to ensure this feature is not silently disabled. - __ZSTD_LEGACY_SUPPORT__ : `zstd` can decompress files compressed by older versions of `zstd`.; Starting v0.8.0, all versions of `zstd` produce frames compliant with the [specification](../doc/zstd_compression_format.md), and are therefore compatible.; But older versions (< v0.8.0) produced different, incompatible, frames.; By default, `zstd` supports decoding legacy formats >= v0.4.0 (`ZSTD_LEGACY_SUPPORT=4`).; This can be altered by modifying this compilation variable.; `ZSTD_LEGACY_SUPPORT=1` means ""support all formats >= v0.1.0"".; `ZSTD_LEGACY_SUPPORT=2` means ""support all formats >= v0.2.0"", and so on.; `ZSTD_LEGACY_SUPPORT=0` means _DO NOT_ support any legac",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:7203,Testability,benchmark,benchmark,7203," `dictionary`),; which can be loaded before compression and decompression. Using a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface; CLI includes in-memory compression benchmark module for zstd.; The benchmark is conducted using given filenames. The files are read into memory and joined together.; It makes benchmark more precise as it eliminates I/O overhead.; Multiple filenames can be supplied, as multiple parameters, with wildcards,; or names of directories can be used as parameters with `-r` option. The benchmark measures ratio, compressed size, compression and decompression speed.; One can select compression levels starting from `-b` and ending with `-e`.; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file);",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:7235,Testability,benchmark,benchmark,7235,"ing a dictionary, the compression ratio achievable on small data improves dramatically.; These compression gains are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface; CLI includes in-memory compression benchmark module for zstd.; The benchmark is conducted using given filenames. The files are read into memory and joined together.; It makes benchmark more precise as it eliminates I/O overhead.; Multiple filenames can be supplied, as multiple parameters, with wildcards,; or names of directories can be used as parameters with `-r` option. The benchmark measures ratio, compressed size, compression and decompression speed.; One can select compression levels starting from `-b` and ending with `-e`.; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file); -f : overwrite output without prompting and (de)compress links; --rm : remove",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:7343,Testability,benchmark,benchmark,7343,"ns are achieved while simultaneously providing faster compression and decompression speeds.; Dictionary work if there is some correlation in a family of small data (there is no universal dictionary).; Hence, deploying one dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface; CLI includes in-memory compression benchmark module for zstd.; The benchmark is conducted using given filenames. The files are read into memory and joined together.; It makes benchmark more precise as it eliminates I/O overhead.; Multiple filenames can be supplied, as multiple parameters, with wildcards,; or names of directories can be used as parameters with `-r` option. The benchmark measures ratio, compressed size, compression and decompression speed.; One can select compression levels starting from `-b` and ending with `-e`.; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file); -f : overwrite output without prompting and (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:7547,Testability,benchmark,benchmark,7547,"e dictionary per type of data will provide the greater benefits.; Dictionary gains are mostly effective in the first few KB. Then, the compression algorithm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface; CLI includes in-memory compression benchmark module for zstd.; The benchmark is conducted using given filenames. The files are read into memory and joined together.; It makes benchmark more precise as it eliminates I/O overhead.; Multiple filenames can be supplied, as multiple parameters, with wildcards,; or names of directories can be used as parameters with `-r` option. The benchmark measures ratio, compressed size, compression and decompression speed.; One can select compression levels starting from `-b` and ending with `-e`.; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file); -f : overwrite output without prompting and (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force w",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:7761,Testability,test,tested,7761,"hm; will rely more and more on previously decoded content to compress the rest of the file. Usage of the dictionary builder and created dictionaries with CLI:. 1. Create the dictionary : `zstd --train PathToTrainingSet/* -o dictionaryName`; 2. Compress with the dictionary: `zstd FILE -D dictionaryName`; 3. Decompress with the dictionary: `zstd --decompress FILE.zst -D dictionaryName`. #### Benchmark in Command Line Interface; CLI includes in-memory compression benchmark module for zstd.; The benchmark is conducted using given filenames. The files are read into memory and joined together.; It makes benchmark more precise as it eliminates I/O overhead.; Multiple filenames can be supplied, as multiple parameters, with wildcards,; or names of directories can be used as parameters with `-r` option. The benchmark measures ratio, compressed size, compression and decompression speed.; One can select compression levels starting from `-b` and ending with `-e`.; The `-i` parameter selects minimal time used for each of tested levels. #### Usage of Command Line Interface; The full list of options can be obtained with `-h` or `-H` parameter:; ```; Usage :; zstd [args] [FILE(s)] [-o file]. FILE : a filename; with no FILE, or when FILE is - , read standard input; Arguments :; -# : # compression level (1-19, default: 3); -d : decompression; -D file: use `file` as Dictionary; -o file: result stored into `file` (only if 1 input file); -f : overwrite output without prompting and (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force write to standard output, even if it is the console; -l : print information about zstd compressed files; --ultra : enable levels beyond 19, up to 22 (requir",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:9134,Testability,test,test,9134," (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force write to standard output, even if it is the console; -l : print information about zstd compressed files; --ultra : enable levels beyond 19, up to 22 (requires more memory); --long : enable long distance matching (requires more memory); --no-dictID : don't write dictID into header (dictionary compression); --[no-]check : integrity check (default: enabled); -r : operate recursively on directories; --format=gzip : compress files to the .gz format; --format=xz : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dictionary name (default: dictionary); --maxdict=# : limit dictionary to specified size (default: 112640); --dictID=# : force dictionary ID to specified value (default: random). Benchmark arguments :; -b# : benchmark file(s), using # compression level (default: 3); -e# : test all compression levels from -bX to # (default: 1); -i# : minimum evaluation time in seconds (default: 3s); -B# : cut file into independent blocks of size # (default: no block); --priority=rt : set process priority to real-time; ```. #### Long d",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:9141,Testability,test,test,9141," (de)compress links; --rm : remove source file(s) after successful de/compression; -k : preserve source file(s) (default); -h/-H : display help/long help and exit. Advanced arguments :; -V : display Version number and exit; -v : verbose mode; specify multiple times to increase verbosity; -q : suppress warnings; specify twice to suppress errors too; -c : force write to standard output, even if it is the console; -l : print information about zstd compressed files; --ultra : enable levels beyond 19, up to 22 (requires more memory); --long : enable long distance matching (requires more memory); --no-dictID : don't write dictID into header (dictionary compression); --[no-]check : integrity check (default: enabled); -r : operate recursively on directories; --format=gzip : compress files to the .gz format; --format=xz : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dictionary name (default: dictionary); --maxdict=# : limit dictionary to specified size (default: 112640); --dictID=# : force dictionary ID to specified value (default: random). Benchmark arguments :; -b# : benchmark file(s), using # compression level (default: 3); -e# : test all compression levels from -bX to # (default: 1); -i# : minimum evaluation time in seconds (default: 3s); -B# : cut file into independent blocks of size # (default: no block); --priority=rt : set process priority to real-time; ```. #### Long d",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:9907,Testability,benchmark,benchmark,9907," : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dictionary name (default: dictionary); --maxdict=# : limit dictionary to specified size (default: 112640); --dictID=# : force dictionary ID to specified value (default: random). Benchmark arguments :; -b# : benchmark file(s), using # compression level (default: 3); -e# : test all compression levels from -bX to # (default: 1); -i# : minimum evaluation time in seconds (default: 3s); -B# : cut file into independent blocks of size # (default: no block); --priority=rt : set process priority to real-time; ```. #### Long distance matching mode; The long distance matching mode, enabled with `--long`, is designed to improve; the compression ratio for files with long matches at a large distance (up to the; maximum window size, `128 MiB`) while still maintaining compression speed. Enabling this mode sets the window size to `128 MiB` and thus increases the memory; usage for both the compressor and decompressor. Performance in terms of speed is; dependent on long matches being found. Compression speed may degrade if few long; matches are found. Decompression speed usually improves when there are many long; distance matches. Below are graphs comparing the compression speed, compression ratio, and; decompression speed with and without long distance matching on an ideal use; case: a tar of four versions of clang (versions `3.4.1`, `3.4.2",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md:9972,Testability,test,test,9972," : compress files to the .xz format; --format=lzma : compress files to the .lzma format; --test : test compressed file integrity; --[no-]sparse : sparse mode (default: disabled); -M# : Set a memory usage limit for decompression; -- : All arguments after ""--"" are treated as files. Dictionary builder :; --train ## : create a dictionary from a training set of files; --train-cover[=k=#,d=#,steps=#,split=#] : use the cover algorithm with optional args; --train-fastcover[=k=#,d=#,f=#,steps=#,split=#,accel=#] : use the fastcover algorithm with optional args; --train-legacy[=s=#] : use the legacy algorithm with selectivity (default: 9); -o file : `file` is dictionary name (default: dictionary); --maxdict=# : limit dictionary to specified size (default: 112640); --dictID=# : force dictionary ID to specified value (default: random). Benchmark arguments :; -b# : benchmark file(s), using # compression level (default: 3); -e# : test all compression levels from -bX to # (default: 1); -i# : minimum evaluation time in seconds (default: 3s); -B# : cut file into independent blocks of size # (default: no block); --priority=rt : set process priority to real-time; ```. #### Long distance matching mode; The long distance matching mode, enabled with `--long`, is designed to improve; the compression ratio for files with long matches at a large distance (up to the; maximum window size, `128 MiB`) while still maintaining compression speed. Enabling this mode sets the window size to `128 MiB` and thus increases the memory; usage for both the compressor and decompressor. Performance in terms of speed is; dependent on long matches being found. Compression speed may degrade if few long; matches are found. Decompression speed usually improves when there are many long; distance matches. Below are graphs comparing the compression speed, compression ratio, and; decompression speed with and without long distance matching on an ideal use; case: a tar of four versions of clang (versions `3.4.1`, `3.4.2",MatchSource.DOCS,lib/zstd/programs/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:1321,Availability,error,error,1321,"to `zstd -d`. `zstdcat` is equivalent to `zstd -dcf`. DESCRIPTION; -----------; `zstd` is a fast lossless compression algorithm and data compression tool,; with command line syntax similar to `gzip (1)` and `xz (1)`.; It is based on the **LZ77** family, with further FSE & huff0 entropy stages.; `zstd` offers highly configurable compression speed,; with fast modes at > 200 MB/s per core,; and strong modes nearing lzma compression ratios.; It also features a very fast decoder, with speeds > 500 MB/s per core. `zstd` command line syntax is generally similar to gzip,; but features the following differences :. - Source files are preserved by default.; It's possible to remove them automatically by using the `--rm` command.; - When compressing a single file, `zstd` displays progress notifications; and result summary by default.; Use `-q` to turn them off.; - `zstd` does not accept input from console,; but it properly accepts `stdin` when it's not the console.; - `zstd` displays a short help page when command line is an error.; Use `-q` to turn it off. `zstd` compresses or decompresses each _file_ according to the selected; operation mode.; If no _files_ are given or _file_ is `-`, `zstd` reads from standard input; and writes the processed data to standard output.; `zstd` will refuse to write compressed data to standard output; if it is a terminal : it will display an error message and skip the _file_.; Similarly, `zstd` will refuse to read compressed data from standard input; if it is a terminal. Unless `--stdout` or `-o` is specified, _files_ are written to a new file; whose name is derived from the source _file_ name:. * When compressing, the suffix `.zst` is appended to the source filename to; get the target filename.; * When decompressing, the `.zst` suffix is removed from the source filename to; get the target filename. ### Concatenation with .zst files; It is possible to concatenate `.zst` files as is.; `zstd` will decompress such files as if they were a single `.zst",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:1676,Availability,error,error,1676,"d,; with fast modes at > 200 MB/s per core,; and strong modes nearing lzma compression ratios.; It also features a very fast decoder, with speeds > 500 MB/s per core. `zstd` command line syntax is generally similar to gzip,; but features the following differences :. - Source files are preserved by default.; It's possible to remove them automatically by using the `--rm` command.; - When compressing a single file, `zstd` displays progress notifications; and result summary by default.; Use `-q` to turn them off.; - `zstd` does not accept input from console,; but it properly accepts `stdin` when it's not the console.; - `zstd` displays a short help page when command line is an error.; Use `-q` to turn it off. `zstd` compresses or decompresses each _file_ according to the selected; operation mode.; If no _files_ are given or _file_ is `-`, `zstd` reads from standard input; and writes the processed data to standard output.; `zstd` will refuse to write compressed data to standard output; if it is a terminal : it will display an error message and skip the _file_.; Similarly, `zstd` will refuse to read compressed data from standard input; if it is a terminal. Unless `--stdout` or `-o` is specified, _files_ are written to a new file; whose name is derived from the source _file_ name:. * When compressing, the suffix `.zst` is appended to the source filename to; get the target filename.; * When decompressing, the `.zst` suffix is removed from the source filename to; get the target filename. ### Concatenation with .zst files; It is possible to concatenate `.zst` files as is.; `zstd` will decompress such files as if they were a single `.zst` file. OPTIONS; -------. ### Integer suffixes and special values; In most places where an integer argument is expected,; an optional suffix is supported to easily indicate large integers.; There must be no space between the integer and the suffix. * `KiB`:; Multiply the integer by 1,024 (2\^10).; `Ki`, `K`, and `KB` are accepted as synonyms for",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:3707,Availability,avail,available,3707,"\^20).; `Mi`, `M`, and `MB` are accepted as synonyms for `MiB`. ### Operation mode; If multiple operation mode options are given,; the last one takes effect. * `-z`, `--compress`:; Compress.; This is the default operation mode when no operation mode option is specified; and no other operation mode is implied from the command name; (for example, `unzstd` implies `--decompress`).; * `-d`, `--decompress`, `--uncompress`:; Decompress.; * `-t`, `--test`:; Test the integrity of compressed _files_.; This option is equivalent to `--decompress --stdout` except that the; decompressed data is discarded instead of being written to standard output.; No files are created or removed.; * `-b#`:; Benchmark file(s) using compression level #; * `--train FILEs`:; Use FILEs as a training set to create a dictionary.; The training set should contain a lot of small files (> 100).; * `-l`, `--list`:; Display information related to a zstd compressed file, such as size, ratio, and checksum.; Some of these fields may not be available.; This command can be augmented with the `-v` modifier. ### Operation modifiers. * `-#`:; `#` compression level \[1-19] (default: 3); * `--fast[=#]`:; switch to ultra-fast compression levels.; If `=#` is not present, it defaults to `1`.; The higher the value, the faster the compression speed,; at the cost of some compression ratio.; This setting overwrites compression level if one was set previously.; Similarly, if a compression level is set after `--fast`, it overrides it.; * `--ultra`:; unlocks high compression levels 20+ (maximum 22), using a lot more memory.; Note that decompression will also require more memory when using these levels.; * `--long[=#]`:; enables long distance matching with `#` `windowLog`, if not `#` is not; present it defaults to `27`.; This increases the window size (`windowLog`) and memory usage for both the; compressor and decompressor.; This setting is designed to improve the compression ratio for files with; long matches at a large dista",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5438,Availability,avail,available,5438," is not; present it defaults to `27`.; This increases the window size (`windowLog`) and memory usage for both the; compressor and decompressor.; This setting is designed to improve the compression ratio for files with; long matches at a large distance. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:8059,Availability,avail,available,8059," _INPUT-FILE_); * `-f`, `--force`:; overwrite output without prompting, and (de)compress symbolic links; * `-c`, `--stdout`:; force write to standard output, even if it is the console; * `--[no-]sparse`:; enable / disable sparse FS support,; to make files with many zeroes smaller on disk.; Creating sparse files may save disk space and speed up decompression by; reducing the amount of disk I/O.; default: enabled when output is into a file,; and disabled when output is stdout.; This setting overrides default and can force sparse mode over stdout.; * `--rm`:; remove source file(s) after successful compression or decompression; * `-k`, `--keep`:; keep source file(s) after successful compression or decompression.; This is the default behavior.; * `-r`:; operate recursively on dictionaries; * `--format=FORMAT`:; compress and decompress in other formats. If compiled with; support, zstd can compress to or decompress from other compression algorithm; formats. Possibly available options are `zstd`, `gzip`, `xz`, `lzma`, and `lz4`.; If no such format is provided, `zstd` is the default.; * `-h`/`-H`, `--help`:; display help/long help and exit; * `-V`, `--version`:; display version number and exit.; Advanced : `-vV` also displays supported formats.; `-vvV` also displays POSIX support.; * `-v`:; verbose mode; * `-q`, `--quiet`:; suppress warnings, interactivity, and notifications.; specify twice to suppress errors too.; * `-C`, `--[no-]check`:; add integrity check computed from uncompressed data (default: enabled); * `--`:; All arguments after `--` are treated as files. DICTIONARY BUILDER; ------------------; `zstd` offers _dictionary_ compression,; which greatly improves efficiency on small files and messages.; It's possible to train `zstd` with a set of samples,; the result of which is saved into a file called a `dictionary`.; Then during compression and decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:8502,Availability,error,errors,8502,"nabled when output is into a file,; and disabled when output is stdout.; This setting overrides default and can force sparse mode over stdout.; * `--rm`:; remove source file(s) after successful compression or decompression; * `-k`, `--keep`:; keep source file(s) after successful compression or decompression.; This is the default behavior.; * `-r`:; operate recursively on dictionaries; * `--format=FORMAT`:; compress and decompress in other formats. If compiled with; support, zstd can compress to or decompress from other compression algorithm; formats. Possibly available options are `zstd`, `gzip`, `xz`, `lzma`, and `lz4`.; If no such format is provided, `zstd` is the default.; * `-h`/`-H`, `--help`:; display help/long help and exit; * `-V`, `--version`:; display version number and exit.; Advanced : `-vV` also displays supported formats.; `-vvV` also displays POSIX support.; * `-v`:; verbose mode; * `-q`, `--quiet`:; suppress warnings, interactivity, and notifications.; specify twice to suppress errors too.; * `-C`, `--[no-]check`:; add integrity check computed from uncompressed data (default: enabled); * `--`:; All arguments after `--` are treated as files. DICTIONARY BUILDER; ------------------; `zstd` offers _dictionary_ compression,; which greatly improves efficiency on small files and messages.; It's possible to train `zstd` with a set of samples,; the result of which is saved into a file called a `dictionary`.; Then during compression and decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to the sample set will be greatly improved. * `--train FILEs`:; Use FILEs as training set to create a dictionary.; The training set should contain a lot of small files (> 100),; and weight typically 100x the target dictionary size; (for example, 10 MB for a 100 KB dictionary). Supports multithreading if `zstd` is compiled with threading support.; Additional parameters can be specified with `--train-fastcover`",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:14357,Availability,avail,available,14357,"B#`, `--block-size=#`:; cut file(s) into independent blocks of size # (default: no block); * `--priority=rt`:; set process priority to real-time. **Output Format:** CompressionLevel#Filename : IntputSize -> OutputSize (CompressionRatio), CompressionSpeed, DecompressionSpeed. **Methodology:** For both compression and decompression speed, the entire input is compressed/decompressed in-memory to measure speed. A run lasts at least 1 sec, so when files are small, they are compressed/decompressed several times per run, in order to improve measurement accuracy. ADVANCED COMPRESSION OPTIONS; ----------------------------; ### --zstd[=options]:; `zstd` provides 22 predefined compression levels.; The selected or default predefined compression level can be changed with; advanced compression options.; The _options_ are provided as a comma-separated list.; You may specify only the options you want to change and the rest will be; taken from the selected or default compression level.; The list of available _options_:. - `strategy`=_strat_, `strat`=_strat_:; Specify a strategy used by a match finder. There are 8 strategies numbered from 1 to 8, from faster to stronger:; 1=ZSTD\_fast, 2=ZSTD\_dfast, 3=ZSTD\_greedy, 4=ZSTD\_lazy,; 5=ZSTD\_lazy2, 6=ZSTD\_btlazy2, 7=ZSTD\_btopt, 8=ZSTD\_btultra. - `windowLog`=_wlog_, `wlog`=_wlog_:; Specify the maximum number of bits for a match distance. The higher number of increases the chance to find a match which usually; improves compression ratio.; It also increases memory requirements for the compressor and decompressor.; The minimum _wlog_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15687,Availability,down,down,15687,"umber of bits for a match distance. The higher number of increases the chance to find a match which usually; improves compression ratio.; It also increases memory requirements for the compressor and decompressor.; The minimum _wlog_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on selected strategy. For ZSTD\_btopt and ZSTD\_btultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compressio",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:17224,Availability,avail,available,17224,"cify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on selected strategy. For ZSTD\_btopt and ZSTD\_btultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compression ratio; but decreases compression speed. For ZSTD\_fast, it triggers ultra-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compression speed; but decreases compression ratio. For all other strategies, this field has no impact. The minimum _tlen_ is 0 and the maximum is 999. - `overlapLog`=_ovlog_, `ovlog`=_ovlog_:; Determine `overlapSize`, amount of data reloaded from previous job.; This parameter is only available when multithreading is enabled.; Reloading more data improves compression ratio, but decreases speed. The minimum _ovlog_ is 0, and the maximum is 9.; 0 means ""no overlap"", hence completely independent jobs.; 9 means ""full overlap"", meaning up to `windowSize` is reloaded from previous job.; Reducing _ovlog_ by 1 reduces the amount of reload by a factor 2.; Default _ovlog_ is 6, which means ""reload `windowSize / 8`"".; Exception : the maximum compression level (22) has a default _ovlog_ of 9. - `ldmHashLog`=_ldmhlog_, `ldmhlog`=_ldmhlog_:; Specify the maximum size for a hash table used for long distance matching. This option is ignored unless long distance matching is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long d",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:19462,Availability,avail,available,19462,"hing is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). - `ldmHashEveryLog`=_ldmhevery_, `ldmhevery`=_ldmhevery_:; Specify the frequency of inserting entries into the long distance matching; hash table. This option is ignored unless long distance matching is enabled. Larger values will improve compression speed. Deviating far from the; default value will likely result in a decrease in compression ratio. The default value is `wlog - ldmhlog`. ### Example; The following parameters sets advanced compression options to something; similar to predefined level 19 for files bigger than 256 KB:. `--zstd`=wlog=23,clog=23,hlog=22,slog=6,slen=3,tlen=48,strat=6. ### -B#:; Select the size of each compression job.; This parameter is available only when multi-threading is enabled.; Default value is `4 * windowSize`, which means it varies depending on compression level.; `-B#` makes it possible to select a custom value.; Note that job size must respect a minimum value which is enforced transparently.; This minimum is either 1 MB, or `overlapSize`, whichever is largest. BUGS; ----; Report bugs at: https://github.com/facebook/zstd/issues. AUTHOR; ------; Yann Collet; ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5600,Energy Efficiency,adapt,adapt,5600,"tio for files with; long matches at a large distance. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5648,Energy Efficiency,adapt,adapt,5648,"tio for files with; long matches at a large distance. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5720,Energy Efficiency,adapt,adaptation,5720," than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:6079,Energy Efficiency,adapt,adaptation,6079," `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compression).; The decoder will have to rely on implicit knowledge about which dictionary to use,; it won't be able to check if it's correct.; * `-o file`:; save result into `file` (only possible with a single",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:6172,Energy Efficiency,adapt,adapt,6172,"n, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compression).; The decoder will have to rely on implicit knowledge about which dictionary to use,; it won't be able to check if it's correct.; * `-o file`:; save result into `file` (only possible with a single _INPUT-FILE_); * `-f`, `--force`:; overwrite output without prompting, and (de)compress symbolic links; * `-",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:12587,Energy Efficiency,reduce,reduces,12587,"s multithreading if `zstd` is compiled with threading support. Examples:. `zstd --train-cover FILEs`. `zstd --train-cover=k=50,d=8 FILEs`. `zstd --train-cover=d=8,steps=500 FILEs`. `zstd --train-cover=k=50 FILEs`. `zstd --train-cover=k=50,split=60 FILEs`. * `--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]`:; Same as cover but with extra parameters _f_ and _accel_ and different default value of split; If _split_ is not specified, then it tries _split_ = 75.; If _f_ is not specified, then it tries _f_ = 20.; Requires that 0 < _f_ < 32.; If _accel_ is not specified, then it tries _accel_ = 1.; Requires that 0 < _accel_ <= 10.; Requires that _d_ = 6 or _d_ = 8. _f_ is log of size of array that keeps track of frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, in seconds (default: 3s), benchmark mode only; * `-B#`, `--block-size=#`:; cut file(s) into independent blocks of size # (default: no block); * `--priority=rt`:; set process priority to real-time. **Output Format:** CompressionLevel#Filename : IntputSize -> OutputSize (CompressionRati",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:17548,Energy Efficiency,reduce,reduces,17548,"tultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compression ratio; but decreases compression speed. For ZSTD\_fast, it triggers ultra-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compression speed; but decreases compression ratio. For all other strategies, this field has no impact. The minimum _tlen_ is 0 and the maximum is 999. - `overlapLog`=_ovlog_, `ovlog`=_ovlog_:; Determine `overlapSize`, amount of data reloaded from previous job.; This parameter is only available when multithreading is enabled.; Reloading more data improves compression ratio, but decreases speed. The minimum _ovlog_ is 0, and the maximum is 9.; 0 means ""no overlap"", hence completely independent jobs.; 9 means ""full overlap"", meaning up to `windowSize` is reloaded from previous job.; Reducing _ovlog_ by 1 reduces the amount of reload by a factor 2.; Default _ovlog_ is 6, which means ""reload `windowSize / 8`"".; Exception : the maximum compression level (22) has a default _ovlog_ of 9. - `ldmHashLog`=_ldmhlog_, `ldmhlog`=_ldmhlog_:; Specify the maximum size for a hash table used for long distance matching. This option is ignored unless long distance matching is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for lo",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:1682,Integrability,message,message,1682,"d,; with fast modes at > 200 MB/s per core,; and strong modes nearing lzma compression ratios.; It also features a very fast decoder, with speeds > 500 MB/s per core. `zstd` command line syntax is generally similar to gzip,; but features the following differences :. - Source files are preserved by default.; It's possible to remove them automatically by using the `--rm` command.; - When compressing a single file, `zstd` displays progress notifications; and result summary by default.; Use `-q` to turn them off.; - `zstd` does not accept input from console,; but it properly accepts `stdin` when it's not the console.; - `zstd` displays a short help page when command line is an error.; Use `-q` to turn it off. `zstd` compresses or decompresses each _file_ according to the selected; operation mode.; If no _files_ are given or _file_ is `-`, `zstd` reads from standard input; and writes the processed data to standard output.; `zstd` will refuse to write compressed data to standard output; if it is a terminal : it will display an error message and skip the _file_.; Similarly, `zstd` will refuse to read compressed data from standard input; if it is a terminal. Unless `--stdout` or `-o` is specified, _files_ are written to a new file; whose name is derived from the source _file_ name:. * When compressing, the suffix `.zst` is appended to the source filename to; get the target filename.; * When decompressing, the `.zst` suffix is removed from the source filename to; get the target filename. ### Concatenation with .zst files; It is possible to concatenate `.zst` files as is.; `zstd` will decompress such files as if they were a single `.zst` file. OPTIONS; -------. ### Integer suffixes and special values; In most places where an integer argument is expected,; an optional suffix is supported to easily indicate large integers.; There must be no space between the integer and the suffix. * `KiB`:; Multiply the integer by 1,024 (2\^10).; `Ki`, `K`, and `KB` are accepted as synonyms for",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:6305,Integrability,synchroniz,synchronize,6305,"; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compression).; The decoder will have to rely on implicit knowledge about which dictionary to use,; it won't be able to check if it's correct.; * `-o file`:; save result into `file` (only possible with a single _INPUT-FILE_); * `-f`, `--force`:; overwrite output without prompting, and (de)compress symbolic links; * `-c`, `--stdout`:; force write to standard output, even if it is the console; * `--[no-]sparse`:; enable / disable sparse FS support",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:6674,Integrability,synchroniz,synchronization,6674,"ly adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compression).; The decoder will have to rely on implicit knowledge about which dictionary to use,; it won't be able to check if it's correct.; * `-o file`:; save result into `file` (only possible with a single _INPUT-FILE_); * `-f`, `--force`:; overwrite output without prompting, and (de)compress symbolic links; * `-c`, `--stdout`:; force write to standard output, even if it is the console; * `--[no-]sparse`:; enable / disable sparse FS support,; to make files with many zeroes smaller on disk.; Creating sparse files may save disk space and speed up decompression by; reducing the amount of disk I/O.; default: enabled when output is into a file,; and disabled when output is stdout.; This setting overrides default and can force sparse mode over stdout.; * `--rm`",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:8802,Integrability,message,messages,8802,"p source file(s) after successful compression or decompression.; This is the default behavior.; * `-r`:; operate recursively on dictionaries; * `--format=FORMAT`:; compress and decompress in other formats. If compiled with; support, zstd can compress to or decompress from other compression algorithm; formats. Possibly available options are `zstd`, `gzip`, `xz`, `lzma`, and `lz4`.; If no such format is provided, `zstd` is the default.; * `-h`/`-H`, `--help`:; display help/long help and exit; * `-V`, `--version`:; display version number and exit.; Advanced : `-vV` also displays supported formats.; `-vvV` also displays POSIX support.; * `-v`:; verbose mode; * `-q`, `--quiet`:; suppress warnings, interactivity, and notifications.; specify twice to suppress errors too.; * `-C`, `--[no-]check`:; add integrity check computed from uncompressed data (default: enabled); * `--`:; All arguments after `--` are treated as files. DICTIONARY BUILDER; ------------------; `zstd` offers _dictionary_ compression,; which greatly improves efficiency on small files and messages.; It's possible to train `zstd` with a set of samples,; the result of which is saved into a file called a `dictionary`.; Then during compression and decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to the sample set will be greatly improved. * `--train FILEs`:; Use FILEs as training set to create a dictionary.; The training set should contain a lot of small files (> 100),; and weight typically 100x the target dictionary size; (for example, 10 MB for a 100 KB dictionary). Supports multithreading if `zstd` is compiled with threading support.; Additional parameters can be specified with `--train-fastcover`.; The legacy dictionary builder can be accessed with `--train-legacy`.; The cover dictionary builder can be accessed with `--train-cover`.; Equivalent to `--train-fastcover=d=8,steps=4`.; * `-o file`:; Dictionary saved into `file` (default name",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:16498,Integrability,depend,depending,16498,"g_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on selected strategy. For ZSTD\_btopt and ZSTD\_btultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compression ratio; but decreases compression speed. For ZSTD\_fast, it triggers ultra-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compression speed; but decreases compression ratio. For all other strategies, this field has no impact. The minimum _tlen_ is 0 and the maximum is 999. - `overlapLog`=_ovlog_, `ovlog`=_ovlog_:; Determine `overlapSize`, amount of data reloaded from previous job.; This parameter is only available when multithreading is enabled.; Reloading more data improves compression ratio, but decreases speed. The minimum _ovlog_ is 0, and the maximum is 9.; 0 means ""no overlap"", hence completely independent jobs.; 9 means ""full overlap"", meaning up t",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:19568,Integrability,depend,depending,19568,"hing is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). - `ldmHashEveryLog`=_ldmhevery_, `ldmhevery`=_ldmhevery_:; Specify the frequency of inserting entries into the long distance matching; hash table. This option is ignored unless long distance matching is enabled. Larger values will improve compression speed. Deviating far from the; default value will likely result in a decrease in compression ratio. The default value is `wlog - ldmhlog`. ### Example; The following parameters sets advanced compression options to something; similar to predefined level 19 for files bigger than 256 KB:. `--zstd`=wlog=23,clog=23,hlog=22,slog=6,slen=3,tlen=48,strat=6. ### -B#:; Select the size of each compression job.; This parameter is available only when multi-threading is enabled.; Default value is `4 * windowSize`, which means it varies depending on compression level.; `-B#` makes it possible to select a custom value.; Note that job size must respect a minimum value which is enforced transparently.; This minimum is either 1 MB, or `overlapSize`, whichever is largest. BUGS; ----; Report bugs at: https://github.com/facebook/zstd/issues. AUTHOR; ------; Yann Collet; ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:610,Modifiability,config,configurable,610,"zstd(1) -- zstd, zstdmt, unzstd, zstdcat - Compress or decompress .zst files; ============================================================================. SYNOPSIS; --------. `zstd` [*OPTIONS*] [-|_INPUT-FILE_] [-o _OUTPUT-FILE_]. `zstdmt` is equivalent to `zstd -T0`. `unzstd` is equivalent to `zstd -d`. `zstdcat` is equivalent to `zstd -dcf`. DESCRIPTION; -----------; `zstd` is a fast lossless compression algorithm and data compression tool,; with command line syntax similar to `gzip (1)` and `xz (1)`.; It is based on the **LZ77** family, with further FSE & huff0 entropy stages.; `zstd` offers highly configurable compression speed,; with fast modes at > 200 MB/s per core,; and strong modes nearing lzma compression ratios.; It also features a very fast decoder, with speeds > 500 MB/s per core. `zstd` command line syntax is generally similar to gzip,; but features the following differences :. - Source files are preserved by default.; It's possible to remove them automatically by using the `--rm` command.; - When compressing a single file, `zstd` displays progress notifications; and result summary by default.; Use `-q` to turn them off.; - `zstd` does not accept input from console,; but it properly accepts `stdin` when it's not the console.; - `zstd` displays a short help page when command line is an error.; Use `-q` to turn it off. `zstd` compresses or decompresses each _file_ according to the selected; operation mode.; If no _files_ are given or _file_ is `-`, `zstd` reads from standard input; and writes the processed data to standard output.; `zstd` will refuse to write compressed data to standard output; if it is a terminal : it will display an error message and skip the _file_.; Similarly, `zstd` will refuse to read compressed data from standard input; if it is a terminal. Unless `--stdout` or `-o` is specified, _files_ are written to a new file; whose name is derived from the source _file_ name:. * When compressing, the suffix `.zst` is appended to the source fi",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5600,Modifiability,adapt,adapt,5600,"tio for files with; long matches at a large distance. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5648,Modifiability,adapt,adapt,5648,"tio for files with; long matches at a large distance. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5720,Modifiability,adapt,adaptation,5720," than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:6079,Modifiability,adapt,adaptation,6079," `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compression).; The decoder will have to rely on implicit knowledge about which dictionary to use,; it won't be able to check if it's correct.; * `-o file`:; save result into `file` (only possible with a single",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:6172,Modifiability,adapt,adapt,6172,"n, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compression).; The decoder will have to rely on implicit knowledge about which dictionary to use,; it won't be able to check if it's correct.; * `-o file`:; save result into `file` (only possible with a single _INPUT-FILE_); * `-f`, `--force`:; overwrite output without prompting, and (de)compress symbolic links; * `-",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:5885,Performance,multi-thread,multi-threading,5885,"ng threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with `--single-thread`.; It sets window size to 8 MB by default (can be changed manually, see `wlog`).; Due to the chaotic nature of dynamic adaptation, compressed result is not reproducible.; _note_ : at the time of this writing, `--adapt` can remain stuck at low speed; when combined with multiple worker threads (>=2).; * `--rsyncable` :; `zstd` will periodically synchronize the compression state to make the; compressed file more rsync-friendly. There is a negligible impact to; compression ratio, and the faster compression levels will see a small; compression speed hit.; This feature does not work with `--single-thread`. You probably don't want; to use it with long range mode, since it will decrease the effectiveness of; the synchronization points, but your milage may vary.; * `-D file`:; use `file` as Dictionary to compress or decompress FILE(s); * `--no-dictID`:; do not store dictionary ID within frame header (dictionary compres",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:9922,Performance,tune,tuned,9922," decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to the sample set will be greatly improved. * `--train FILEs`:; Use FILEs as training set to create a dictionary.; The training set should contain a lot of small files (> 100),; and weight typically 100x the target dictionary size; (for example, 10 MB for a 100 KB dictionary). Supports multithreading if `zstd` is compiled with threading support.; Additional parameters can be specified with `--train-fastcover`.; The legacy dictionary builder can be accessed with `--train-legacy`.; The cover dictionary builder can be accessed with `--train-cover`.; Equivalent to `--train-fastcover=d=8,steps=4`.; * `-o file`:; Dictionary saved into `file` (default name: dictionary).; * `--maxdict=#`:; Limit dictionary to specified size (default: 112640).; * `-#`:; Use `#` compression level during training (optional).; Will generate statistics more tuned for selected compression level,; resulting in a _small_ compression ratio improvement for this level.; * `-B#`:; Split input files in blocks of size # (default: no split); * `--dictID=#`:; A dictionary ID is a locally unique ID that a decoder can use to verify it is; using the right dictionary.; By default, zstd will create a 4-bytes random number ID.; It's possible to give a precise number instead.; Short numbers have an advantage : an ID < 256 will only need 1 byte in the; compressed frame header, and an ID < 65536 will only need 2 bytes.; This compares favorably to 4 bytes default.; However, it's up to the dictionary manager to not assign twice the same ID to; 2 different dictionaries.; * `--train-cover[=k#,d=#,steps=#,split=#]`:; Select parameters for the default dictionary builder algorithm named cover.; If _d_ is not specified, then it tries _d_ = 6 and _d_ = 8.; If _k_ is not specified, then it tries _steps_ values in the range [50, 2000].; If _steps_ is not specified, then the default value of 40 is used.; If",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:19482,Performance,multi-thread,multi-threading,19482,"hing is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). - `ldmHashEveryLog`=_ldmhevery_, `ldmhevery`=_ldmhevery_:; Specify the frequency of inserting entries into the long distance matching; hash table. This option is ignored unless long distance matching is enabled. Larger values will improve compression speed. Deviating far from the; default value will likely result in a decrease in compression ratio. The default value is `wlog - ldmhlog`. ### Example; The following parameters sets advanced compression options to something; similar to predefined level 19 for files bigger than 256 KB:. `--zstd`=wlog=23,clog=23,hlog=22,slog=6,slen=3,tlen=48,strat=6. ### -B#:; Select the size of each compression job.; This parameter is available only when multi-threading is enabled.; Default value is `4 * windowSize`, which means it varies depending on compression level.; `-B#` makes it possible to select a custom value.; Note that job size must respect a minimum value which is enforced transparently.; This minimum is either 1 MB, or `overlapSize`, whichever is largest. BUGS; ----; Report bugs at: https://github.com/facebook/zstd/issues. AUTHOR; ------; Yann Collet; ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:4932,Safety,detect,detect,4932,"ts to `1`.; The higher the value, the faster the compression speed,; at the cost of some compression ratio.; This setting overwrites compression level if one was set previously.; Similarly, if a compression level is set after `--fast`, it overrides it.; * `--ultra`:; unlocks high compression levels 20+ (maximum 22), using a lot more memory.; Note that decompression will also require more memory when using these levels.; * `--long[=#]`:; enables long distance matching with `#` `windowLog`, if not `#` is not; present it defaults to `27`.; This increases the window size (`windowLog`) and memory usage for both the; compressor and decompressor.; This setting is designed to improve the compression ratio for files with; long matches at a large distance. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor.; * `-T#`, `--threads=#`:; Compress using `#` working threads (default: 1).; If `#` is 0, attempt to detect and use the number of physical CPU cores.; In all cases, the nb of threads is capped to ZSTDMT_NBTHREADS_MAX==200.; This modifier does nothing if `zstd` is compiled without multithread support.; * `--single-thread`:; Does not spawn a thread for compression, use a single thread for both I/O and compression.; In this mode, compression is serialized with I/O, which is slightly slower.; (This is different from `-T1`, which spawns 1 compression thread in parallel of I/O).; This mode is the only one available when multithread support is disabled.; Single-thread mode features lower memory usage.; Final compressed result is slightly different from `-T1`.; * `--adapt[=min=#,max=#]` :; `zstd` will dynamically adapt compression level to perceived I/O conditions.; Compression level adaptation can be observed live by using command `-v`.; Adaptation can be constrained between supplied `min` and `max` levels.; The feature works when combined with multi-threading and `--long` mode.; It does not work with ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:11427,Safety,safe,safe,11427,"mpressed frame header, and an ID < 65536 will only need 2 bytes.; This compares favorably to 4 bytes default.; However, it's up to the dictionary manager to not assign twice the same ID to; 2 different dictionaries.; * `--train-cover[=k#,d=#,steps=#,split=#]`:; Select parameters for the default dictionary builder algorithm named cover.; If _d_ is not specified, then it tries _d_ = 6 and _d_ = 8.; If _k_ is not specified, then it tries _steps_ values in the range [50, 2000].; If _steps_ is not specified, then the default value of 40 is used.; If _split_ is not specified or split <= 0, then the default value of 100 is used.; Requires that _d_ <= _k_. Selects segments of size _k_ with highest score to put in the dictionary.; The score of a segment is computed by the sum of the frequencies of all the; subsegments of size _d_.; Generally _d_ should be in the range [6, 8], occasionally up to 16, but the; algorithm will run faster with d <= _8_.; Good values for _k_ vary widely based on the input data, but a safe range is; [2 * _d_, 2000].; If _split_ is 100, all input samples are used for both training and testing; to find optimal _d_ and _k_ to build dictionary.; Supports multithreading if `zstd` is compiled with threading support. Examples:. `zstd --train-cover FILEs`. `zstd --train-cover=k=50,d=8 FILEs`. `zstd --train-cover=d=8,steps=500 FILEs`. `zstd --train-cover=k=50 FILEs`. `zstd --train-cover=k=50,split=60 FILEs`. * `--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]`:; Same as cover but with extra parameters _f_ and _accel_ and different default value of split; If _split_ is not specified, then it tries _split_ = 75.; If _f_ is not specified, then it tries _f_ = 20.; Requires that 0 < _f_ < 32.; If _accel_ is not specified, then it tries _accel_ = 1.; Requires that 0 < _accel_ <= 10.; Requires that _d_ = 6 or _d_ = 8. _f_ is log of size of array that keeps track of frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:3159,Security,integrity,integrity,3159," with .zst files; It is possible to concatenate `.zst` files as is.; `zstd` will decompress such files as if they were a single `.zst` file. OPTIONS; -------. ### Integer suffixes and special values; In most places where an integer argument is expected,; an optional suffix is supported to easily indicate large integers.; There must be no space between the integer and the suffix. * `KiB`:; Multiply the integer by 1,024 (2\^10).; `Ki`, `K`, and `KB` are accepted as synonyms for `KiB`.; * `MiB`:; Multiply the integer by 1,048,576 (2\^20).; `Mi`, `M`, and `MB` are accepted as synonyms for `MiB`. ### Operation mode; If multiple operation mode options are given,; the last one takes effect. * `-z`, `--compress`:; Compress.; This is the default operation mode when no operation mode option is specified; and no other operation mode is implied from the command name; (for example, `unzstd` implies `--decompress`).; * `-d`, `--decompress`, `--uncompress`:; Decompress.; * `-t`, `--test`:; Test the integrity of compressed _files_.; This option is equivalent to `--decompress --stdout` except that the; decompressed data is discarded instead of being written to standard output.; No files are created or removed.; * `-b#`:; Benchmark file(s) using compression level #; * `--train FILEs`:; Use FILEs as a training set to create a dictionary.; The training set should contain a lot of small files (> 100).; * `-l`, `--list`:; Display information related to a zstd compressed file, such as size, ratio, and checksum.; Some of these fields may not be available.; This command can be augmented with the `-v` modifier. ### Operation modifiers. * `-#`:; `#` compression level \[1-19] (default: 3); * `--fast[=#]`:; switch to ultra-fast compression levels.; If `=#` is not present, it defaults to `1`.; The higher the value, the faster the compression speed,; at the cost of some compression ratio.; This setting overwrites compression level if one was set previously.; Similarly, if a compression level is s",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:3664,Security,checksum,checksum,3664,"cepted as synonyms for `KiB`.; * `MiB`:; Multiply the integer by 1,048,576 (2\^20).; `Mi`, `M`, and `MB` are accepted as synonyms for `MiB`. ### Operation mode; If multiple operation mode options are given,; the last one takes effect. * `-z`, `--compress`:; Compress.; This is the default operation mode when no operation mode option is specified; and no other operation mode is implied from the command name; (for example, `unzstd` implies `--decompress`).; * `-d`, `--decompress`, `--uncompress`:; Decompress.; * `-t`, `--test`:; Test the integrity of compressed _files_.; This option is equivalent to `--decompress --stdout` except that the; decompressed data is discarded instead of being written to standard output.; No files are created or removed.; * `-b#`:; Benchmark file(s) using compression level #; * `--train FILEs`:; Use FILEs as a training set to create a dictionary.; The training set should contain a lot of small files (> 100).; * `-l`, `--list`:; Display information related to a zstd compressed file, such as size, ratio, and checksum.; Some of these fields may not be available.; This command can be augmented with the `-v` modifier. ### Operation modifiers. * `-#`:; `#` compression level \[1-19] (default: 3); * `--fast[=#]`:; switch to ultra-fast compression levels.; If `=#` is not present, it defaults to `1`.; The higher the value, the faster the compression speed,; at the cost of some compression ratio.; This setting overwrites compression level if one was set previously.; Similarly, if a compression level is set after `--fast`, it overrides it.; * `--ultra`:; unlocks high compression levels 20+ (maximum 22), using a lot more memory.; Note that decompression will also require more memory when using these levels.; * `--long[=#]`:; enables long distance matching with `#` `windowLog`, if not `#` is not; present it defaults to `27`.; This increases the window size (`windowLog`) and memory usage for both the; compressor and decompressor.; This setting is designed t",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:8544,Security,integrity,integrity,8544,"efault and can force sparse mode over stdout.; * `--rm`:; remove source file(s) after successful compression or decompression; * `-k`, `--keep`:; keep source file(s) after successful compression or decompression.; This is the default behavior.; * `-r`:; operate recursively on dictionaries; * `--format=FORMAT`:; compress and decompress in other formats. If compiled with; support, zstd can compress to or decompress from other compression algorithm; formats. Possibly available options are `zstd`, `gzip`, `xz`, `lzma`, and `lz4`.; If no such format is provided, `zstd` is the default.; * `-h`/`-H`, `--help`:; display help/long help and exit; * `-V`, `--version`:; display version number and exit.; Advanced : `-vV` also displays supported formats.; `-vvV` also displays POSIX support.; * `-v`:; verbose mode; * `-q`, `--quiet`:; suppress warnings, interactivity, and notifications.; specify twice to suppress errors too.; * `-C`, `--[no-]check`:; add integrity check computed from uncompressed data (default: enabled); * `--`:; All arguments after `--` are treated as files. DICTIONARY BUILDER; ------------------; `zstd` offers _dictionary_ compression,; which greatly improves efficiency on small files and messages.; It's possible to train `zstd` with a set of samples,; the result of which is saved into a file called a `dictionary`.; Then during compression and decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to the sample set will be greatly improved. * `--train FILEs`:; Use FILEs as training set to create a dictionary.; The training set should contain a lot of small files (> 100),; and weight typically 100x the target dictionary size; (for example, 10 MB for a 100 KB dictionary). Supports multithreading if `zstd` is compiled with threading support.; Additional parameters can be specified with `--train-fastcover`.; The legacy dictionary builder can be accessed with `--train-legacy`.; The cover dictionary bu",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:9534,Security,access,accessed,9534,"]check`:; add integrity check computed from uncompressed data (default: enabled); * `--`:; All arguments after `--` are treated as files. DICTIONARY BUILDER; ------------------; `zstd` offers _dictionary_ compression,; which greatly improves efficiency on small files and messages.; It's possible to train `zstd` with a set of samples,; the result of which is saved into a file called a `dictionary`.; Then during compression and decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to the sample set will be greatly improved. * `--train FILEs`:; Use FILEs as training set to create a dictionary.; The training set should contain a lot of small files (> 100),; and weight typically 100x the target dictionary size; (for example, 10 MB for a 100 KB dictionary). Supports multithreading if `zstd` is compiled with threading support.; Additional parameters can be specified with `--train-fastcover`.; The legacy dictionary builder can be accessed with `--train-legacy`.; The cover dictionary builder can be accessed with `--train-cover`.; Equivalent to `--train-fastcover=d=8,steps=4`.; * `-o file`:; Dictionary saved into `file` (default name: dictionary).; * `--maxdict=#`:; Limit dictionary to specified size (default: 112640).; * `-#`:; Use `#` compression level during training (optional).; Will generate statistics more tuned for selected compression level,; resulting in a _small_ compression ratio improvement for this level.; * `-B#`:; Split input files in blocks of size # (default: no split); * `--dictID=#`:; A dictionary ID is a locally unique ID that a decoder can use to verify it is; using the right dictionary.; By default, zstd will create a 4-bytes random number ID.; It's possible to give a precise number instead.; Short numbers have an advantage : an ID < 256 will only need 1 byte in the; compressed frame header, and an ID < 65536 will only need 2 bytes.; This compares favorably to 4 bytes default.; However, ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:9603,Security,access,accessed,9603,"t: enabled); * `--`:; All arguments after `--` are treated as files. DICTIONARY BUILDER; ------------------; `zstd` offers _dictionary_ compression,; which greatly improves efficiency on small files and messages.; It's possible to train `zstd` with a set of samples,; the result of which is saved into a file called a `dictionary`.; Then during compression and decompression, reference the same dictionary,; using command `-D dictionaryFileName`.; Compression of small files similar to the sample set will be greatly improved. * `--train FILEs`:; Use FILEs as training set to create a dictionary.; The training set should contain a lot of small files (> 100),; and weight typically 100x the target dictionary size; (for example, 10 MB for a 100 KB dictionary). Supports multithreading if `zstd` is compiled with threading support.; Additional parameters can be specified with `--train-fastcover`.; The legacy dictionary builder can be accessed with `--train-legacy`.; The cover dictionary builder can be accessed with `--train-cover`.; Equivalent to `--train-fastcover=d=8,steps=4`.; * `-o file`:; Dictionary saved into `file` (default name: dictionary).; * `--maxdict=#`:; Limit dictionary to specified size (default: 112640).; * `-#`:; Use `#` compression level during training (optional).; Will generate statistics more tuned for selected compression level,; resulting in a _small_ compression ratio improvement for this level.; * `-B#`:; Split input files in blocks of size # (default: no split); * `--dictID=#`:; A dictionary ID is a locally unique ID that a decoder can use to verify it is; using the right dictionary.; By default, zstd will create a 4-bytes random number ID.; It's possible to give a precise number instead.; Short numbers have an advantage : an ID < 256 will only need 1 byte in the; compressed frame header, and an ID < 65536 will only need 2 bytes.; This compares favorably to 4 bytes default.; However, it's up to the dictionary manager to not assign twice the same ID to;",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:12372,Security,hash,hashed,12372,"ary widely based on the input data, but a safe range is; [2 * _d_, 2000].; If _split_ is 100, all input samples are used for both training and testing; to find optimal _d_ and _k_ to build dictionary.; Supports multithreading if `zstd` is compiled with threading support. Examples:. `zstd --train-cover FILEs`. `zstd --train-cover=k=50,d=8 FILEs`. `zstd --train-cover=d=8,steps=500 FILEs`. `zstd --train-cover=k=50 FILEs`. `zstd --train-cover=k=50,split=60 FILEs`. * `--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]`:; Same as cover but with extra parameters _f_ and _accel_ and different default value of split; If _split_ is not specified, then it tries _split_ = 75.; If _f_ is not specified, then it tries _f_ = 20.; Requires that 0 < _f_ < 32.; If _accel_ is not specified, then it tries _accel_ = 1.; Requires that 0 < _accel_ <= 10.; Requires that _d_ = 6 or _d_ = 8. _f_ is log of size of array that keeps track of frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, in seconds (default: 3s), benchmark mode only; * `-B#`, `--block-size=#`:; c",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:12468,Security,hash,hashed,12468,"ples are used for both training and testing; to find optimal _d_ and _k_ to build dictionary.; Supports multithreading if `zstd` is compiled with threading support. Examples:. `zstd --train-cover FILEs`. `zstd --train-cover=k=50,d=8 FILEs`. `zstd --train-cover=d=8,steps=500 FILEs`. `zstd --train-cover=k=50 FILEs`. `zstd --train-cover=k=50,split=60 FILEs`. * `--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]`:; Same as cover but with extra parameters _f_ and _accel_ and different default value of split; If _split_ is not specified, then it tries _split_ = 75.; If _f_ is not specified, then it tries _f_ = 20.; Requires that 0 < _f_ < 32.; If _accel_ is not specified, then it tries _accel_ = 1.; Requires that 0 < _accel_ <= 10.; Requires that _d_ = 6 or _d_ = 8. _f_ is log of size of array that keeps track of frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, in seconds (default: 3s), benchmark mode only; * `-B#`, `--block-size=#`:; cut file(s) into independent blocks of size # (default: no block); * `--priority=rt`:; set process priority ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15185,Security,hash,hashLog,15185,"pecify only the options you want to change and the rest will be; taken from the selected or default compression level.; The list of available _options_:. - `strategy`=_strat_, `strat`=_strat_:; Specify a strategy used by a match finder. There are 8 strategies numbered from 1 to 8, from faster to stronger:; 1=ZSTD\_fast, 2=ZSTD\_dfast, 3=ZSTD\_greedy, 4=ZSTD\_lazy,; 5=ZSTD\_lazy2, 6=ZSTD\_btlazy2, 7=ZSTD\_btopt, 8=ZSTD\_btultra. - `windowLog`=_wlog_, `wlog`=_wlog_:; Specify the maximum number of bits for a match distance. The higher number of increases the chance to find a match which usually; improves compression ratio.; It also increases memory requirements for the compressor and decompressor.; The minimum _wlog_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15259,Security,hash,hash,15259,"pecify only the options you want to change and the rest will be; taken from the selected or default compression level.; The list of available _options_:. - `strategy`=_strat_, `strat`=_strat_:; Specify a strategy used by a match finder. There are 8 strategies numbered from 1 to 8, from faster to stronger:; 1=ZSTD\_fast, 2=ZSTD\_dfast, 3=ZSTD\_greedy, 4=ZSTD\_lazy,; 5=ZSTD\_lazy2, 6=ZSTD\_btlazy2, 7=ZSTD\_btopt, 8=ZSTD\_btultra. - `windowLog`=_wlog_, `wlog`=_wlog_:; Specify the maximum number of bits for a match distance. The higher number of increases the chance to find a match which usually; improves compression ratio.; It also increases memory requirements for the compressor and decompressor.; The minimum _wlog_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15278,Security,hash,hash,15278,"ion level.; The list of available _options_:. - `strategy`=_strat_, `strat`=_strat_:; Specify a strategy used by a match finder. There are 8 strategies numbered from 1 to 8, from faster to stronger:; 1=ZSTD\_fast, 2=ZSTD\_dfast, 3=ZSTD\_greedy, 4=ZSTD\_lazy,; 5=ZSTD\_lazy2, 6=ZSTD\_btlazy2, 7=ZSTD\_btopt, 8=ZSTD\_btultra. - `windowLog`=_wlog_, `wlog`=_wlog_:; Specify the maximum number of bits for a match distance. The higher number of increases the chance to find a match which usually; improves compression ratio.; It also increases memory requirements for the compressor and decompressor.; The minimum _wlog_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease co",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15540,Security,hash,hash,15540,"ster to stronger:; 1=ZSTD\_fast, 2=ZSTD\_dfast, 3=ZSTD\_greedy, 4=ZSTD\_lazy,; 5=ZSTD\_lazy2, 6=ZSTD\_btlazy2, 7=ZSTD\_btopt, 8=ZSTD\_btultra. - `windowLog`=_wlog_, `wlog`=_wlog_:; Specify the maximum number of bits for a match distance. The higher number of increases the chance to find a match which usually; improves compression ratio.; It also increases memory requirements for the compressor and decompressor.; The minimum _wlog_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on sele",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15960,Security,hash,hash,15960,"og_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on selected strategy. For ZSTD\_btopt and ZSTD\_btultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compression ratio; but decreases compression speed. For ZSTD\_fast, it triggers ultra-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compres",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:16281,Security,hash,hash,16281,"umber of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on selected strategy. For ZSTD\_btopt and ZSTD\_btultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compression ratio; but decreases compression speed. For ZSTD\_fast, it triggers ultra-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compression speed; but decreases compression ratio. For all other strategies, this field has no impact. The minimum _tlen_ is 0 and the maximum is 999. - `overlapLog`=_ovlog_, `ovlog`=_ovlog_:; Determine `overlapSize`, amount of data reloaded from previous job.; This parameter is only available when m",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:17809,Security,hash,hash,17809,"a-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compression speed; but decreases compression ratio. For all other strategies, this field has no impact. The minimum _tlen_ is 0 and the maximum is 999. - `overlapLog`=_ovlog_, `ovlog`=_ovlog_:; Determine `overlapSize`, amount of data reloaded from previous job.; This parameter is only available when multithreading is enabled.; Reloading more data improves compression ratio, but decreases speed. The minimum _ovlog_ is 0, and the maximum is 9.; 0 means ""no overlap"", hence completely independent jobs.; 9 means ""full overlap"", meaning up to `windowSize` is reloaded from previous job.; Reducing _ovlog_ by 1 reduces the amount of reload by a factor 2.; Default _ovlog_ is 6, which means ""reload `windowSize / 8`"".; Exception : the maximum compression level (22) has a default _ovlog_ of 9. - `ldmHashLog`=_ldmhlog_, `ldmhlog`=_ldmhlog_:; Specify the maximum size for a hash table used for long distance matching. This option is ignored unless long distance matching is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). -",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:17925,Security,hash,hash,17925,"o. For all other strategies, this field has no impact. The minimum _tlen_ is 0 and the maximum is 999. - `overlapLog`=_ovlog_, `ovlog`=_ovlog_:; Determine `overlapSize`, amount of data reloaded from previous job.; This parameter is only available when multithreading is enabled.; Reloading more data improves compression ratio, but decreases speed. The minimum _ovlog_ is 0, and the maximum is 9.; 0 means ""no overlap"", hence completely independent jobs.; 9 means ""full overlap"", meaning up to `windowSize` is reloaded from previous job.; Reducing _ovlog_ by 1 reduces the amount of reload by a factor 2.; Default _ovlog_ is 6, which means ""reload `windowSize / 8`"".; Exception : the maximum compression level (22) has a default _ovlog_ of 9. - `ldmHashLog`=_ldmhlog_, `ldmhlog`=_ldmhlog_:; Specify the maximum size for a hash table used for long distance matching. This option is ignored unless long distance matching is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). - `ldmHashEveryLog`=_ldmhevery_, `ldmhevery`=_ldmhevery_:; Specify the frequency of inserting entries into the long distance matching; hash table. This option is ignored unless long distance matchi",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:18536,Security,hash,hash,18536," previous job.; Reducing _ovlog_ by 1 reduces the amount of reload by a factor 2.; Default _ovlog_ is 6, which means ""reload `windowSize / 8`"".; Exception : the maximum compression level (22) has a default _ovlog_ of 9. - `ldmHashLog`=_ldmhlog_, `ldmhlog`=_ldmhlog_:; Specify the maximum size for a hash table used for long distance matching. This option is ignored unless long distance matching is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). - `ldmHashEveryLog`=_ldmhevery_, `ldmhevery`=_ldmhevery_:; Specify the frequency of inserting entries into the long distance matching; hash table. This option is ignored unless long distance matching is enabled. Larger values will improve compression speed. Deviating far from the; default value will likely result in a decrease in compression ratio. The default value is `wlog - ldmhlog`. ### Example; The following parameters sets advanced compression options to something; similar to predefined level 19 for files bigger than 256 KB:. `--zstd`=wlog=23,clog=23,hlog=22,slog=6,slen=3,tlen=48,strat=6. ### -B#:; Select the size of each compression job.; This parameter is available only when multi-threading is enabled.; ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:18925,Security,hash,hash,18925,"on is ignored unless long distance matching is enabled. Bigger hash tables usually improve compression ratio at the expense of more; memory during compression and a decrease in compression speed. The minimum _ldmhlog_ is 6 and the maximum is 26 (default: 20). - `ldmSearchLength`=_ldmslen_, `ldmslen`=_ldmslen_:; Specify the minimum searched length of a match for long distance matching. This option is ignored unless long distance matching is enabled. Larger/very small values usually decrease compression ratio. The minimum _ldmslen_ is 4 and the maximum is 4096 (default: 64). - `ldmBucketSizeLog`=_ldmblog_, `ldmblog`=_ldmblog_:; Specify the size of each bucket for the hash table used for long distance; matching. This option is ignored unless long distance matching is enabled. Larger bucket sizes improve collision resolution but decrease compression; speed. The minimum _ldmblog_ is 0 and the maximum is 8 (default: 3). - `ldmHashEveryLog`=_ldmhevery_, `ldmhevery`=_ldmhevery_:; Specify the frequency of inserting entries into the long distance matching; hash table. This option is ignored unless long distance matching is enabled. Larger values will improve compression speed. Deviating far from the; default value will likely result in a decrease in compression ratio. The default value is `wlog - ldmhlog`. ### Example; The following parameters sets advanced compression options to something; similar to predefined level 19 for files bigger than 256 KB:. `--zstd`=wlog=23,clog=23,hlog=22,slog=6,slen=3,tlen=48,strat=6. ### -B#:; Select the size of each compression job.; This parameter is available only when multi-threading is enabled.; Default value is `4 * windowSize`, which means it varies depending on compression level.; `-B#` makes it possible to select a custom value.; Note that job size must respect a minimum value which is enforced transparently.; This minimum is either 1 MB, or `overlapSize`, whichever is largest. BUGS; ----; Report bugs at: https://github.com/facebook/zstd",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:3142,Testability,test,test,3142," with .zst files; It is possible to concatenate `.zst` files as is.; `zstd` will decompress such files as if they were a single `.zst` file. OPTIONS; -------. ### Integer suffixes and special values; In most places where an integer argument is expected,; an optional suffix is supported to easily indicate large integers.; There must be no space between the integer and the suffix. * `KiB`:; Multiply the integer by 1,024 (2\^10).; `Ki`, `K`, and `KB` are accepted as synonyms for `KiB`.; * `MiB`:; Multiply the integer by 1,048,576 (2\^20).; `Mi`, `M`, and `MB` are accepted as synonyms for `MiB`. ### Operation mode; If multiple operation mode options are given,; the last one takes effect. * `-z`, `--compress`:; Compress.; This is the default operation mode when no operation mode option is specified; and no other operation mode is implied from the command name; (for example, `unzstd` implies `--decompress`).; * `-d`, `--decompress`, `--uncompress`:; Decompress.; * `-t`, `--test`:; Test the integrity of compressed _files_.; This option is equivalent to `--decompress --stdout` except that the; decompressed data is discarded instead of being written to standard output.; No files are created or removed.; * `-b#`:; Benchmark file(s) using compression level #; * `--train FILEs`:; Use FILEs as a training set to create a dictionary.; The training set should contain a lot of small files (> 100).; * `-l`, `--list`:; Display information related to a zstd compressed file, such as size, ratio, and checksum.; Some of these fields may not be available.; This command can be augmented with the `-v` modifier. ### Operation modifiers. * `-#`:; `#` compression level \[1-19] (default: 3); * `--fast[=#]`:; switch to ultra-fast compression levels.; If `=#` is not present, it defaults to `1`.; The higher the value, the faster the compression speed,; at the cost of some compression ratio.; This setting overwrites compression level if one was set previously.; Similarly, if a compression level is s",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:11528,Testability,test,testing,11528,"However, it's up to the dictionary manager to not assign twice the same ID to; 2 different dictionaries.; * `--train-cover[=k#,d=#,steps=#,split=#]`:; Select parameters for the default dictionary builder algorithm named cover.; If _d_ is not specified, then it tries _d_ = 6 and _d_ = 8.; If _k_ is not specified, then it tries _steps_ values in the range [50, 2000].; If _steps_ is not specified, then the default value of 40 is used.; If _split_ is not specified or split <= 0, then the default value of 100 is used.; Requires that _d_ <= _k_. Selects segments of size _k_ with highest score to put in the dictionary.; The score of a segment is computed by the sum of the frequencies of all the; subsegments of size _d_.; Generally _d_ should be in the range [6, 8], occasionally up to 16, but the; algorithm will run faster with d <= _8_.; Good values for _k_ vary widely based on the input data, but a safe range is; [2 * _d_, 2000].; If _split_ is 100, all input samples are used for both training and testing; to find optimal _d_ and _k_ to build dictionary.; Supports multithreading if `zstd` is compiled with threading support. Examples:. `zstd --train-cover FILEs`. `zstd --train-cover=k=50,d=8 FILEs`. `zstd --train-cover=d=8,steps=500 FILEs`. `zstd --train-cover=k=50 FILEs`. `zstd --train-cover=k=50,split=60 FILEs`. * `--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]`:; Same as cover but with extra parameters _f_ and _accel_ and different default value of split; If _split_ is not specified, then it tries _split_ = 75.; If _f_ is not specified, then it tries _f_ = 20.; Requires that 0 < _f_ < 32.; If _accel_ is not specified, then it tries _accel_ = 1.; Requires that 0 < _accel_ <= 10.; Requires that _d_ = 6 or _d_ = 8. _f_ is log of size of array that keeps track of frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as t",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:12274,Testability,log,log,12274,"16, but the; algorithm will run faster with d <= _8_.; Good values for _k_ vary widely based on the input data, but a safe range is; [2 * _d_, 2000].; If _split_ is 100, all input samples are used for both training and testing; to find optimal _d_ and _k_ to build dictionary.; Supports multithreading if `zstd` is compiled with threading support. Examples:. `zstd --train-cover FILEs`. `zstd --train-cover=k=50,d=8 FILEs`. `zstd --train-cover=d=8,steps=500 FILEs`. `zstd --train-cover=k=50 FILEs`. `zstd --train-cover=k=50,split=60 FILEs`. * `--train-fastcover[=k#,d=#,f=#,steps=#,split=#,accel=#]`:; Same as cover but with extra parameters _f_ and _accel_ and different default value of split; If _split_ is not specified, then it tries _split_ = 75.; If _f_ is not specified, then it tries _f_ = 20.; Requires that 0 < _f_ < 32.; If _accel_ is not specified, then it tries _accel_ = 1.; Requires that 0 < _accel_ <= 10.; Requires that _d_ = 6 or _d_ = 8. _f_ is log of size of array that keeps track of frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:13133,Testability,benchmark,benchmark,13133,"f frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, in seconds (default: 3s), benchmark mode only; * `-B#`, `--block-size=#`:; cut file(s) into independent blocks of size # (default: no block); * `--priority=rt`:; set process priority to real-time. **Output Format:** CompressionLevel#Filename : IntputSize -> OutputSize (CompressionRatio), CompressionSpeed, DecompressionSpeed. **Methodology:** For both compression and decompression speed, the entire input is compressed/decompressed in-memory to measure speed. A run lasts at least 1 sec, so when files are small, they are compressed/decompressed several times per run, in order to improve measurement accuracy. ADVANCED COMPRESSION OPTIONS; ----------------------------; ### --zstd[=options]:; `zstd` provides 22 predefined compression levels.; The selected or default predefined compression level can be changed with; advanced compression options.; The _options_ are provided as a comma-separated list.; You may specify only the options you want to change and the rest will be; taken from the selected ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:13188,Testability,benchmark,benchmark,13188,"f frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, in seconds (default: 3s), benchmark mode only; * `-B#`, `--block-size=#`:; cut file(s) into independent blocks of size # (default: no block); * `--priority=rt`:; set process priority to real-time. **Output Format:** CompressionLevel#Filename : IntputSize -> OutputSize (CompressionRatio), CompressionSpeed, DecompressionSpeed. **Methodology:** For both compression and decompression speed, the entire input is compressed/decompressed in-memory to measure speed. A run lasts at least 1 sec, so when files are small, they are compressed/decompressed several times per run, in order to improve measurement accuracy. ADVANCED COMPRESSION OPTIONS; ----------------------------; ### --zstd[=options]:; `zstd` provides 22 predefined compression levels.; The selected or default predefined compression level can be changed with; advanced compression options.; The _options_ are provided as a comma-separated list.; You may specify only the options you want to change and the rest will be; taken from the selected ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:13335,Testability,benchmark,benchmark,13335,"f frequency of subsegments of size _d_.; The subsegment is hashed to an index in the range [0,2^_f_ - 1].; It is possible that 2 different subsegments are hashed to the same index, and they are considered as the same subsegment when computing frequency.; Using a higher _f_ reduces collision but takes longer. Examples:. `zstd --train-fastcover FILEs`. `zstd --train-fastcover=d=8,f=15,accel=2 FILEs`. * `--train-legacy[=selectivity=#]`:; Use legacy dictionary builder algorithm with the given dictionary; _selectivity_ (default: 9).; The smaller the _selectivity_ value, the denser the dictionary,; improving its efficiency but reducing its possible maximum size.; `--train-legacy=s=#` is also accepted. Examples:. `zstd --train-legacy FILEs`. `zstd --train-legacy=selectivity=8 FILEs`. BENCHMARK; ---------. * `-b#`:; benchmark file(s) using compression level #; * `-e#`:; benchmark file(s) using multiple compression levels, from `-b#` to `-e#` (inclusive); * `-i#`:; minimum evaluation time, in seconds (default: 3s), benchmark mode only; * `-B#`, `--block-size=#`:; cut file(s) into independent blocks of size # (default: no block); * `--priority=rt`:; set process priority to real-time. **Output Format:** CompressionLevel#Filename : IntputSize -> OutputSize (CompressionRatio), CompressionSpeed, DecompressionSpeed. **Methodology:** For both compression and decompression speed, the entire input is compressed/decompressed in-memory to measure speed. A run lasts at least 1 sec, so when files are small, they are compressed/decompressed several times per run, in order to improve measurement accuracy. ADVANCED COMPRESSION OPTIONS; ----------------------------; ### --zstd[=options]:; `zstd` provides 22 predefined compression levels.; The selected or default predefined compression level can be changed with; advanced compression options.; The _options_ are provided as a comma-separated list.; You may specify only the options you want to change and the rest will be; taken from the selected ",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md:15995,Testability,log,logarithmic,15995,"og_ is 10 (1 KiB) and the maximum is 30 (1 GiB) on 32-bit; platforms and 31 (2 GiB) on 64-bit platforms. Note: If `windowLog` is set to larger than 27, `--long=windowLog` or; `--memory=windowSize` needs to be passed to the decompressor. - `hashLog`=_hlog_, `hlog`=_hlog_:; Specify the maximum number of bits for a hash table. Bigger hash tables cause less collisions which usually makes compression; faster, but requires more memory during compression. The minimum _hlog_ is 6 (64 B) and the maximum is 26 (128 MiB). - `chainLog`=_clog_, `clog`=_clog_:; Specify the maximum number of bits for a hash chain or a binary tree. Higher numbers of bits increases the chance to find a match which usually; improves compression ratio.; It also slows down compression speed and increases memory requirements for; compression.; This option is ignored for the ZSTD_fast strategy. The minimum _clog_ is 6 (64 B) and the maximum is 28 (256 MiB). - `searchLog`=_slog_, `slog`=_slog_:; Specify the maximum number of searches in a hash chain or a binary tree; using logarithmic scale. More searches increases the chance to find a match which usually increases; compression ratio but decreases compression speed. The minimum _slog_ is 1 and the maximum is 26. - `searchLength`=_slen_, `slen`=_slen_:; Specify the minimum searched length of a match in a hash table. Larger search lengths usually decrease compression ratio but improve; decompression speed. The minimum _slen_ is 3 and the maximum is 7. - `targetLen`=_tlen_, `tlen`=_tlen_:; The impact of this field vary depending on selected strategy. For ZSTD\_btopt and ZSTD\_btultra, it specifies the minimum match length; that causes match finder to stop searching for better matches.; A larger `targetLen` usually improves compression ratio; but decreases compression speed. For ZSTD\_fast, it triggers ultra-fast mode when > 0.; The value represents the amount of data skipped between match sampling.; Impact is reversed : a larger `targetLen` increases compres",MatchSource.DOCS,lib/zstd/programs/zstd.1.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/programs/zstd.1.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2520,Availability,avail,available,2520,"default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2597,Availability,avail,available,2597,"default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:6373,Availability,avail,available,6373," : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRatio= (accepts decimals); : determines value of gains in speed vs gains in ratio; when determining overall winner (default 5 (1% ratio = 5% speed)).; tries= : Maximum number of random restarts on a single strategy before switching (Default 5); Higher values will make optimizer run longer, more chances to find better solution.; memLog : Limits the log of the size of each memotable (1 per strategy). Will use hash tables when state space is larger than max size. ; Setting memLog = 0 turns off memoization ; --display= : specifiy which parameters are included in the output; can use all --zstd parameter names and 'cParams' as a shorthand for all parameters used in ZSTD_compressionParameters ; (Default: display all params available); -P# : generated sample compressibility (when no file is provided); -t# : Caps runtime of operation in seconds (default : 99999 seconds (about 27 hours )) ; -v : Prints Benchmarking output; -D : Next argument dictionary file; -s : Benchmark all files separately; -q : Quiet, repeat for more quiet; -q Prints parameters + results whenever a new best is found; -qq Only prints parameters whenever a new best is found, prints final parameters + results; -qqq Only print final parameters + results; -qqqq Only prints final parameter set in the form --zstd=; -v : Verbose, cancels quiet, repeat for more volume; -v Prints all candidate parameters and results. ```; Any inputs afterwards are treated as files to benchmark.; ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1093,Deployability,release,released,1093,"=========. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - T",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:959,Integrability,interoperab,interoperability,959,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1157,Integrability,interoperab,interoperability,1157,"ts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2715,Integrability,message,message,2715," for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,;",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2797,Integrability,message,message,2797,"speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfil",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3161,Integrability,message,message,3161,"of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generat",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3181,Integrability,message,message,3181,"of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generat",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3218,Integrability,message,message,3218,"of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generat",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1415,Performance,perform,performs,1415,"std-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1701,Performance,perform,performed,1701,"ng API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2356,Performance,perform,performed,2356,"fference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send e",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2383,Performance,load,load,2383,"fference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send e",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3342,Performance,load,load,3342,"of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generat",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4347,Performance,optimiz,optimizing,4347,"maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked wi",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4856,Performance,optimiz,optimize,4856,"erate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRa",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4908,Performance,optimiz,optimize,4908,"timizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRatio= (accepts decimals); : determines value of gains in speed vs gains in ratio; when determining overall winner (default 5 (1% ratio = 5% speed)).; tries= : Maximum number of random restarts on a single strategy before switching (Default 5); Higher values will make optimizer run longer, more chances to find better solution.; memLog : Limits the log of the size of each memotable (1 per strategy). Will use hash tables when state space is larger than max size. ; Setting memLog = 0 turns off memoization ; --display= : specifiy which parameters are included in the output; can use all --zstd parameter names and 'cParams' as a shorthand for all parameters used in ZSTD_compressionParameters ; (Defau",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:5916,Performance,optimiz,optimizer,5916," sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRatio= (accepts decimals); : determines value of gains in speed vs gains in ratio; when determining overall winner (default 5 (1% ratio = 5% speed)).; tries= : Maximum number of random restarts on a single strategy before switching (Default 5); Higher values will make optimizer run longer, more chances to find better solution.; memLog : Limits the log of the size of each memotable (1 per strategy). Will use hash tables when state space is larger than max size. ; Setting memLog = 0 turns off memoization ; --display= : specifiy which parameters are included in the output; can use all --zstd parameter names and 'cParams' as a shorthand for all parameters used in ZSTD_compressionParameters ; (Default: display all params available); -P# : generated sample compressibility (when no file is provided); -t# : Caps runtime of operation in seconds (default : 99999 seconds (about 27 hours )) ; -v : Prints Benchmarking output; -D : Next argument dictionary file; -s : Benchmark all files separately; -q : Quiet, repeat for more quiet; -q Prints parameters + results whenever a new best is found; -qq Only prints parameters whenever a new best is found, prints final parameters + results; -qqq Only print final parameters + results; -qqqq O",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:352,Security,integrity,integrity,352,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:672,Security,integrity,integrity,672,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3671,Security,checksum,checksums,3671,"ssage:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3954,Security,checksum,checksum,3954,"arameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given pa",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4605,Security,hash,hashLog,4605,"erate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRa",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:6058,Security,hash,hash,6058,"ng constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRatio= (accepts decimals); : determines value of gains in speed vs gains in ratio; when determining overall winner (default 5 (1% ratio = 5% speed)).; tries= : Maximum number of random restarts on a single strategy before switching (Default 5); Higher values will make optimizer run longer, more chances to find better solution.; memLog : Limits the log of the size of each memotable (1 per strategy). Will use hash tables when state space is larger than max size. ; Setting memLog = 0 turns off memoization ; --display= : specifiy which parameters are included in the output; can use all --zstd parameter names and 'cParams' as a shorthand for all parameters used in ZSTD_compressionParameters ; (Default: display all params available); -P# : generated sample compressibility (when no file is provided); -t# : Caps runtime of operation in seconds (default : 99999 seconds (about 27 hours )) ; -v : Prints Benchmarking output; -D : Next argument dictionary file; -s : Benchmark all files separately; -q : Quiet, repeat for more quiet; -q Prints parameters + results whenever a new best is found; -qq Only prints parameters whenever a new best is found, prints final parameters + results; -qqq Only print final parameters + results; -qqqq Only prints final parameter set in the form --zstd=; -v : Verbose, cancels quiet, repeat for more volume; -v Prints all candidate parameters and results. ```; Any inputs afterwards are treated as",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:35,Testability,test,testing,35,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:236,Testability,test,tests,236,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:409,Testability,test,tester,409,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:429,Testability,test,test-zstd-speed,429,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:462,Testability,test,testing,462,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:512,Testability,test,test-zstd-versions,512,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:551,Testability,test,test,551,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:708,Testability,test,test,708,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:768,Testability,test,test,768,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:910,Testability,test,test-zstd-versions,910,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:946,Testability,test,testing,946,"Programs and scripts for automated testing of Zstandard; =======================================================. This directory contains the following programs and scripts:; - `datagen` : Synthetic and parametrable data generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` th",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1214,Testability,test,test-zstd-speed,1214,"ta generator, for tests; - `fullbench` : Precisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs r",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1247,Testability,test,testing,1247,"ecisely measure speed for each zstd inner functions; - `fuzzer` : Test tool, to check zstd integrity on target platform; - `paramgrill` : parameter tester for zstd; - `test-zstd-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1432,Testability,benchmark,benchmark,1432,"std-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1474,Testability,test,testFileNames,1474,"std-speed.py` : script for testing zstd speed difference between commits; - `test-zstd-versions.py` : compatibility test between zstd versions stored on Github (v0.1+); - `zbufftest` : Test tool to check ZBUFF (a buffered streaming API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1672,Testability,benchmark,benchmark,1672,"ng API) integrity; - `zstreamtest` : Fuzzer test tool for zstd streaming API; - `legacy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1738,Testability,benchmark,benchmark,1738,"acy` : Test tool to test decoding of legacy zstd frames; - `decodecorpus` : Tool to generate valid Zstandard frames, for verifying decoder implementations. #### `test-zstd-versions.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:1923,Testability,benchmark,benchmark,1923,"s.py` - script for testing zstd interoperability between versions. This script creates `versionsTest` directory to which zstd repository is cloned.; Then all tagged (released) versions of zstd are compiled.; In the following step interoperability between zstd versions is checked. #### `test-zstd-speed.py` - script for testing zstd speed difference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py te",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2339,Testability,benchmark,benchmark,2339,"fference between commits. This script creates `speedTest` directory to which zstd repository is cloned.; Then it compiles all branches of zstd and performs a speed benchmark for a given list of files (the `testFileNames` parameter).; After `sleepTime` (an optional parameter, default 300 seconds) seconds the script checks repository for new commits.; If a new commit is found it is compiled and a speed benchmark for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send e",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2660,Testability,test,test,2660," for this commit is performed.; The results of the speed benchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,;",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2732,Testability,test,test-zstd-speed,2732,"enchmark are compared to the previous results.; If compression or decompression speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct un",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2806,Testability,test,tested,2806,"speed for one of zstd levels is lower than `lowerLimit` (an optional parameter, default 0.98) the speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfil",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2907,Testability,test,test-zstd-speed,2907,"he speed benchmark is restarted.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:2926,Testability,test,testFileNames,2926,"started.; If second results are also lower than `lowerLimit` the warning e-mail is send to recipients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,;",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3013,Testability,test,testFileNames,3013,"pients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comp",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3053,Testability,benchmark,benchmark,3053,"pients from the list (the `emails` parameter). Additional remarks:; - To be sure that speed results are accurate the script should be run on a ""stable"" target system with no other jobs running in parallel; - Using the script with virtual machines can lead to large variations of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comp",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3364,Testability,test,testing,3364,"of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generat",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3425,Testability,test,testing,3425,"of speed results; - The speed benchmark is not performed until computers' load average is lower than `maxLoadAvg` (an optional parameter, default 0.75); - The script sends e-mails using `mutt`; if `mutt` is not available it sends e-mails without attachments using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generat",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3575,Testability,test,testing,3575,"nts using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example c",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3614,Testability,test,test,3614,"nts using `mail`; if both are not available it only prints a warning. The example usage with two test files, one e-mail address, and with an additional message:; ```; ./test-zstd-speed.py ""silesia.tar calgary.tar"" ""email@gmail.com"" --message ""tested on my laptop"" --sleepTime 60; ``` . To run the script in background please use:; ```; nohup ./test-zstd-speed.py testFileNames emails &; ```. The full list of parameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example c",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:3917,Testability,test,testfiles,3917,"arameters:; ```; positional arguments:; testFileNames file names list for speed benchmark; emails list of e-mail addresses to send warnings. optional arguments:; -h, --help show this help message and exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given pa",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4164,Testability,test,test,4164,"exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cM",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4529,Testability,benchmark,benchmarks,4529,"erate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRa",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:5997,Testability,log,log,5997,"s to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRatio= (accepts decimals); : determines value of gains in speed vs gains in ratio; when determining overall winner (default 5 (1% ratio = 5% speed)).; tries= : Maximum number of random restarts on a single strategy before switching (Default 5); Higher values will make optimizer run longer, more chances to find better solution.; memLog : Limits the log of the size of each memotable (1 per strategy). Will use hash tables when state space is larger than max size. ; Setting memLog = 0 turns off memoization ; --display= : specifiy which parameters are included in the output; can use all --zstd parameter names and 'cParams' as a shorthand for all parameters used in ZSTD_compressionParameters ; (Default: display all params available); -P# : generated sample compressibility (when no file is provided); -t# : Caps runtime of operation in seconds (default : 99999 seconds (about 27 hours )) ; -v : Prints Benchmarking output; -D : Next argument dictionary file; -s : Benchmark all files separately; -q : Quiet, repeat for more quiet; -q Prints parameters + results whenever a new best is found; -qq Only prints parameters whenever a new best is found, prints final parameters + results; -qqq Only print final parameters + results; -qqqq Only prints final parameter set in the form --zstd=; -v : Verbose, cancels quiet, repeat for more volume; -v Prints all candida",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:7090,Testability,benchmark,benchmark,7090," : Minimum compression speed; dSpeed= : Minimum decompression speed; cMem= : Maximum compression memory; lvl= : Searches for solutions which are strictly better than that compression lvl in ratio and cSpeed, ; stc= : When invoked with lvl=, represents percentage slack in ratio/cSpeed allowed for a solution to be considered (Default 100%); : In normal operation, represents percentage slack in choosing viable starting strategy selection in choosing the default parameters; (Lower value will begin with stronger strategies) (Default 90%); speedRatio= (accepts decimals); : determines value of gains in speed vs gains in ratio; when determining overall winner (default 5 (1% ratio = 5% speed)).; tries= : Maximum number of random restarts on a single strategy before switching (Default 5); Higher values will make optimizer run longer, more chances to find better solution.; memLog : Limits the log of the size of each memotable (1 per strategy). Will use hash tables when state space is larger than max size. ; Setting memLog = 0 turns off memoization ; --display= : specifiy which parameters are included in the output; can use all --zstd parameter names and 'cParams' as a shorthand for all parameters used in ZSTD_compressionParameters ; (Default: display all params available); -P# : generated sample compressibility (when no file is provided); -t# : Caps runtime of operation in seconds (default : 99999 seconds (about 27 hours )) ; -v : Prints Benchmarking output; -D : Next argument dictionary file; -s : Benchmark all files separately; -q : Quiet, repeat for more quiet; -q Prints parameters + results whenever a new best is found; -qq Only prints parameters whenever a new best is found, prints final parameters + results; -qqq Only print final parameters + results; -qqqq Only prints final parameter set in the form --zstd=; -v : Verbose, cancels quiet, repeat for more volume; -v Prints all candidate parameters and results. ```; Any inputs afterwards are treated as files to benchmark.; ",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md:4246,Usability,simpl,simple,4246,"exit; --message MESSAGE attach an additional message to e-mail; --lowerLimit LOWERLIMIT; send email if speed is lower than given limit; --maxLoadAvg MAXLOADAVG; maximum load average to start testing; --lastCLevel LASTCLEVEL; last compression level for testing; --sleepTime SLEEPTIME; frequency of repository checking in seconds; ```. #### `decodecorpus` - tool to generate Zstandard frames for decoder testing; Command line tool to generate test .zst files. This tool will generate .zst files with checksums,; as well as optionally output the corresponding correct uncompressed data for; extra verfication. Example:; ```; ./decodecorpus -ptestfiles -otestfiles -n10000 -s5; ```; will generate 10,000 sample .zst files using a seed of 5 in the `testfiles` directory,; with the zstd checksum field set,; as well as the 10,000 original files for more detailed comparison of decompression results. ```; ./decodecorpus -t -T1mn; ```; will choose a random seed, and for 1 minute,; generate random test frames and ensure that the; zstd library correctly decompresses them in both simple and streaming modes. #### `paramgrill` - tool for generating compression table parameters and optimizing parameters on file given constraints. Full list of arguments; ```; -T# : set level 1 speed objective; -B# : cut input into blocks of size # (default : single block); -S : benchmarks a single run (example command: -Sl3w10h12); w# - windowLog; h# - hashLog; c# - chainLog; s# - searchLog; l# - searchLength; t# - targetLength; S# - strategy; L# - level; --zstd= : Single run, parameter selection syntax same as zstdcli with more parameters; (Added forceAttachDictionary / fadt) ; When invoked with --optimize, this represents the sample to exceed. ; --optimize= : find parameters to maximize compression ratio given parameters; Can use all --zstd= commands to constrain the type of solution found in addition to the following constraints; cSpeed= : Minimum compression speed; dSpeed= : Minimum decompression speed; cM",MatchSource.DOCS,lib/zstd/tests/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:5772,Availability,down,downloaded,5772," before `deflate()` or `deflateSetDictionary()`. The function is only helpful when data is compressed in blocks. There will be no change in case of `deflateInit()` or `deflateReset()` immediately followed by `deflate(strm, Z_FINISH)`; as this case is automatically detected. #### Reusing contexts. The ordinary zlib compression of two files/streams allocates two contexts:; - for the 1st file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`; - for the 2nd file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`. The speed of compression can be improved with reusing a single context with following steps:; - initialize the context with `deflateInit`; - for the 1st file call `deflate`, `...`, `deflate`; - for the 2nd file call `deflateReset`, `deflate`, `...`, `deflate`; - free the context with `deflateEnd`. To check the difference we made experiments using `zwrapbench -ri6b6` with zstd and zlib compression (both at level 6).; The input data was decompressed git repository downloaded from https://github.com/git/git/archive/master.zip which contains 2979 files.; The table below shows that reusing contexts has a minor influence on zlib but it gives improvement for zstd.; In our example (the last 2 lines) it gives 4% better compression speed and 5% better decompression speed. | Compression type | Compression | Decompress.| Compr. size | Ratio |; | ------------------------------------------------- | ------------| -----------| ----------- | ----- |; | zlib 1.2.8 | 30.51 MB/s | 219.3 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 not reusing a context | 30.22 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper and reusing a context | 30.40 MB/s | 218.9 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper not reusing a context | 30.28 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zstd 1.1.0 using ZSTD_CCtx | 68.35 MB/s | 430.9 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 using ZSTD_CStream | 66.63 MB/s | 422.3 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 wi",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:7092,Availability,error,error,7092,"/git/git/archive/master.zip which contains 2979 files.; The table below shows that reusing contexts has a minor influence on zlib but it gives improvement for zstd.; In our example (the last 2 lines) it gives 4% better compression speed and 5% better decompression speed. | Compression type | Compression | Decompress.| Compr. size | Ratio |; | ------------------------------------------------- | ------------| -----------| ----------- | ----- |; | zlib 1.2.8 | 30.51 MB/s | 219.3 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 not reusing a context | 30.22 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper and reusing a context | 30.40 MB/s | 218.9 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper not reusing a context | 30.28 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zstd 1.1.0 using ZSTD_CCtx | 68.35 MB/s | 430.9 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 using ZSTD_CStream | 66.63 MB/s | 422.3 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 with zlibWrapper and reusing a context | 54.01 MB/s | 403.2 MB/s | 6763482 | 3.488 |; | zstd 1.1.0 with zlibWrapper not reusing a context | 51.59 MB/s | 383.7 MB/s | 6763482 | 3.488 |. #### Compatibility issues; After enabling zstd compression not all native zlib functions are supported. When calling unsupported methods they put error message into `strm->msg` and return Z_STREAM_ERROR. Supported methods:; - deflateInit; - deflate (with exception of Z_FULL_FLUSH, Z_BLOCK, and Z_TREES); - deflateSetDictionary; - deflateEnd; - deflateReset; - deflateBound; - inflateInit; - inflate; - inflateSetDictionary; - inflateReset; - inflateReset2; - compress; - compress2; - compressBound; - uncompress; - gzip file access functions. Ignored methods (they do nothing):; - deflateParams. Unsupported methods:; - deflateCopy; - deflateTune; - deflatePending; - deflatePrime; - deflateSetHeader; - inflateGetDictionary; - inflateCopy; - inflateSync; - inflatePrime; - inflateMark; - inflateGetHeader; - inflateBackInit; - inflateBack; - inflateBackEnd; ",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:5112,Energy Efficiency,allocate,allocates,5112,"reaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on smaller data. ; The zstd wrapper provides the `ZWRAP_setPledgedSrcSize()` function that allows to change a pledged source size for a given compression stream.; The function will change zstd compression parameters what may improve compression speed and/or ratio.; It should be called just after `deflateInit()`or `deflateReset()` and before `deflate()` or `deflateSetDictionary()`. The function is only helpful when data is compressed in blocks. There will be no change in case of `deflateInit()` or `deflateReset()` immediately followed by `deflate(strm, Z_FINISH)`; as this case is automatically detected. #### Reusing contexts. The ordinary zlib compression of two files/streams allocates two contexts:; - for the 1st file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`; - for the 2nd file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`. The speed of compression can be improved with reusing a single context with following steps:; - initialize the context with `deflateInit`; - for the 1st file call `deflate`, `...`, `deflate`; - for the 2nd file call `deflateReset`, `deflate`, `...`, `deflate`; - free the context with `deflateEnd`. To check the difference we made experiments using `zwrapbench -ri6b6` with zstd and zlib compression (both at level 6).; The input data was decompressed git repository downloaded from https://github.com/git/git/archive/master.zip which contains 2979 files.; The table below shows that reusing contexts has a minor influence on zlib but it gives improvement for zstd.; In our example (the last 2 lines) it gives 4% better compression speed and 5% better decompression speed. | Compression type | Compression | Decompress.|",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:10,Integrability,wrap,wrapper,10,"Zstandard wrapper for zlib; ================================. The main objective of creating a zstd wrapper for [zlib](http://zlib.net/) is to allow a quick and smooth transition to zstd for projects already using zlib. #### Required files. To build the zstd wrapper for zlib the following files are required:; - zlib.h; - a static or dynamic zlib library; - zlibWrapper/zstd_zlibwrapper.h; - zlibWrapper/zstd_zlibwrapper.c; - zlibWrapper/gz*.c files (gzclose.c, gzlib.c, gzread.c, gzwrite.c); - zlibWrapper/gz*.h files (gzcompatibility.h, gzguts.h); - a static or dynamic zstd library. The first two files are required by all projects using zlib and they are not included with the zstd distribution.; The further files are supplied with the zstd distribution. #### Embedding the zstd wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have tak",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:100,Integrability,wrap,wrapper,100,"Zstandard wrapper for zlib; ================================. The main objective of creating a zstd wrapper for [zlib](http://zlib.net/) is to allow a quick and smooth transition to zstd for projects already using zlib. #### Required files. To build the zstd wrapper for zlib the following files are required:; - zlib.h; - a static or dynamic zlib library; - zlibWrapper/zstd_zlibwrapper.h; - zlibWrapper/zstd_zlibwrapper.c; - zlibWrapper/gz*.c files (gzclose.c, gzlib.c, gzread.c, gzwrite.c); - zlibWrapper/gz*.h files (gzcompatibility.h, gzguts.h); - a static or dynamic zstd library. The first two files are required by all projects using zlib and they are not included with the zstd distribution.; The further files are supplied with the zstd distribution. #### Embedding the zstd wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have tak",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:259,Integrability,wrap,wrapper,259,"Zstandard wrapper for zlib; ================================. The main objective of creating a zstd wrapper for [zlib](http://zlib.net/) is to allow a quick and smooth transition to zstd for projects already using zlib. #### Required files. To build the zstd wrapper for zlib the following files are required:; - zlib.h; - a static or dynamic zlib library; - zlibWrapper/zstd_zlibwrapper.h; - zlibWrapper/zstd_zlibwrapper.c; - zlibWrapper/gz*.c files (gzclose.c, gzlib.c, gzread.c, gzwrite.c); - zlibWrapper/gz*.h files (gzcompatibility.h, gzguts.h); - a static or dynamic zstd library. The first two files are required by all projects using zlib and they are not included with the zstd distribution.; The further files are supplied with the zstd distribution. #### Embedding the zstd wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have tak",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:785,Integrability,wrap,wrapper,785,"Zstandard wrapper for zlib; ================================. The main objective of creating a zstd wrapper for [zlib](http://zlib.net/) is to allow a quick and smooth transition to zstd for projects already using zlib. #### Required files. To build the zstd wrapper for zlib the following files are required:; - zlib.h; - a static or dynamic zlib library; - zlibWrapper/zstd_zlibwrapper.h; - zlibWrapper/zstd_zlibwrapper.c; - zlibWrapper/gz*.c files (gzclose.c, gzlib.c, gzread.c, gzwrite.c); - zlibWrapper/gz*.h files (gzcompatibility.h, gzguts.h); - a static or dynamic zstd library. The first two files are required by all projects using zlib and they are not included with the zstd distribution.; The further files are supplied with the zstd distribution. #### Embedding the zstd wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have tak",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:924,Integrability,wrap,wrapper,924,"Zstandard wrapper for zlib; ================================. The main objective of creating a zstd wrapper for [zlib](http://zlib.net/) is to allow a quick and smooth transition to zstd for projects already using zlib. #### Required files. To build the zstd wrapper for zlib the following files are required:; - zlib.h; - a static or dynamic zlib library; - zlibWrapper/zstd_zlibwrapper.h; - zlibWrapper/zstd_zlibwrapper.c; - zlibWrapper/gz*.c files (gzclose.c, gzlib.c, gzread.c, gzwrite.c); - zlibWrapper/gz*.h files (gzcompatibility.h, gzguts.h); - a static or dynamic zstd library. The first two files are required by all projects using zlib and they are not included with the zstd distribution.; The further files are supplied with the zstd distribution. #### Embedding the zstd wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have tak",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:1331,Integrability,wrap,wrapper,1331,"ry; - zlibWrapper/zstd_zlibwrapper.h; - zlibWrapper/zstd_zlibwrapper.c; - zlibWrapper/gz*.c files (gzclose.c, gzlib.c, gzread.c, gzwrite.c); - zlibWrapper/gz*.h files (gzcompatibility.h, gzguts.h); - a static or dynamic zstd library. The first two files are required by all projects using zlib and they are not included with the zstd distribution.; The further files are supplied with the zstd distribution. #### Embedding the zstd wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have take the file `test/example.c` from [the zlib library distribution](http://zlib.net/) and copied it to [zlibWrapper/examples/example.c](examples/example.c).; After compilation and execution it shows the following results: ; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:3239,Integrability,wrap,wrapper,3239,"``; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; after inflateSync(): hello, hello!; inflate with dictionary: hello, hello!; ```; Then we have changed `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`, compiled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` which use currently unsupported features.; After running it shows the following results:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to co",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:3372,Integrability,wrap,wrapper,3372,"ello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; after inflateSync(): hello, hello!; inflate with dictionary: hello, hello!; ```; Then we have changed `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`, compiled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` which use currently unsupported features.; After running it shows the following results:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compress",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:4456,Integrability,wrap,wrapper,4456,"processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on smaller data. ; The zstd wrapper provides the `ZWRAP_setPledgedSrcSize()` function that allows to change a pledged source size for a given compression stream.; The function will change zstd compression parameters what may improve compression speed and/or ratio.; It should be called just after `deflateInit()`or `deflateReset()` and before `deflate()` or `deflateSetDictionary()`. The function is only helpful when data is compressed in blocks. There will be no change in case of `deflateInit()` or `deflateReset()` immediately followed by `deflate(strm, Z_FINISH)`; as this case is automatically detected. #### Reusing contexts. The ordinary zlib compression of two files/streams allocates two contexts:; - for the 1st file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`; - for the 2nd file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`. The speed of compression can be improved with reusing a single context with following steps:; - initialize the context with `deflateInit`; - for the 1st file call `deflate`, `...`, `deflate`; - for the 2nd file c",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:7098,Integrability,message,message,7098,"/git/git/archive/master.zip which contains 2979 files.; The table below shows that reusing contexts has a minor influence on zlib but it gives improvement for zstd.; In our example (the last 2 lines) it gives 4% better compression speed and 5% better decompression speed. | Compression type | Compression | Decompress.| Compr. size | Ratio |; | ------------------------------------------------- | ------------| -----------| ----------- | ----- |; | zlib 1.2.8 | 30.51 MB/s | 219.3 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 not reusing a context | 30.22 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper and reusing a context | 30.40 MB/s | 218.9 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper not reusing a context | 30.28 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zstd 1.1.0 using ZSTD_CCtx | 68.35 MB/s | 430.9 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 using ZSTD_CStream | 66.63 MB/s | 422.3 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 with zlibWrapper and reusing a context | 54.01 MB/s | 403.2 MB/s | 6763482 | 3.488 |; | zstd 1.1.0 with zlibWrapper not reusing a context | 51.59 MB/s | 383.7 MB/s | 6763482 | 3.488 |. #### Compatibility issues; After enabling zstd compression not all native zlib functions are supported. When calling unsupported methods they put error message into `strm->msg` and return Z_STREAM_ERROR. Supported methods:; - deflateInit; - deflate (with exception of Z_FULL_FLUSH, Z_BLOCK, and Z_TREES); - deflateSetDictionary; - deflateEnd; - deflateReset; - deflateBound; - inflateInit; - inflate; - inflateSetDictionary; - inflateReset; - inflateReset2; - compress; - compress2; - compressBound; - uncompress; - gzip file access functions. Ignored methods (they do nothing):; - deflateParams. Unsupported methods:; - deflateCopy; - deflateTune; - deflatePending; - deflatePrime; - deflateSetHeader; - inflateGetDictionary; - inflateCopy; - inflateSync; - inflatePrime; - inflateMark; - inflateGetHeader; - inflateBackInit; - inflateBack; - inflateBackEnd; ",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:3215,Performance,perform,performace,3215,"``; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; after inflateSync(): hello, hello!; inflate with dictionary: hello, hello!; ```; Then we have changed `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`, compiled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` which use currently unsupported features.; After running it shows the following results:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to co",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:1792,Safety,detect,detected,1792,"wrapper within your project. Let's assume that your project that uses zlib is compiled with:; ```gcc project.o -lz```. To compile the zstd wrapper with your project you have to do the following:; - change all references with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have take the file `test/example.c` from [the zlib library distribution](http://zlib.net/) and copied it to [zlibWrapper/examples/example.c](examples/example.c).; After compilation and execution it shows the following results: ; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; after inflateSync(): hello, hello!; inflate with dictionary: hello, hello!; ```; Then we have changed `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`, compiled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` ",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:5028,Safety,detect,detected,5028," smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on smaller data. ; The zstd wrapper provides the `ZWRAP_setPledgedSrcSize()` function that allows to change a pledged source size for a given compression stream.; The function will change zstd compression parameters what may improve compression speed and/or ratio.; It should be called just after `deflateInit()`or `deflateReset()` and before `deflate()` or `deflateSetDictionary()`. The function is only helpful when data is compressed in blocks. There will be no change in case of `deflateInit()` or `deflateReset()` immediately followed by `deflate(strm, Z_FINISH)`; as this case is automatically detected. #### Reusing contexts. The ordinary zlib compression of two files/streams allocates two contexts:; - for the 1st file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`; - for the 2nd file calls `deflateInit`, `deflate`, `...`, `deflate`, `defalateEnd`. The speed of compression can be improved with reusing a single context with following steps:; - initialize the context with `deflateInit`; - for the 1st file call `deflate`, `...`, `deflate`; - for the 2nd file call `deflateReset`, `deflate`, `...`, `deflate`; - free the context with `deflateEnd`. To check the difference we made experiments using `zwrapbench -ri6b6` with zstd and zlib compression (both at level 6).; The input data was decompressed git repository downloaded from https://github.com/git/git/archive/master.zip which contains 2979 files.; The table below shows that reusing contexts has a minor influence on zlib but it gives improve",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:7472,Security,access,access,7472,"/git/git/archive/master.zip which contains 2979 files.; The table below shows that reusing contexts has a minor influence on zlib but it gives improvement for zstd.; In our example (the last 2 lines) it gives 4% better compression speed and 5% better decompression speed. | Compression type | Compression | Decompress.| Compr. size | Ratio |; | ------------------------------------------------- | ------------| -----------| ----------- | ----- |; | zlib 1.2.8 | 30.51 MB/s | 219.3 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 not reusing a context | 30.22 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper and reusing a context | 30.40 MB/s | 218.9 MB/s | 6819783 | 3.459 |; | zlib 1.2.8 with zlibWrapper not reusing a context | 30.28 MB/s | 218.1 MB/s | 6819783 | 3.459 |; | zstd 1.1.0 using ZSTD_CCtx | 68.35 MB/s | 430.9 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 using ZSTD_CStream | 66.63 MB/s | 422.3 MB/s | 6868521 | 3.435 |; | zstd 1.1.0 with zlibWrapper and reusing a context | 54.01 MB/s | 403.2 MB/s | 6763482 | 3.488 |; | zstd 1.1.0 with zlibWrapper not reusing a context | 51.59 MB/s | 383.7 MB/s | 6763482 | 3.488 |. #### Compatibility issues; After enabling zstd compression not all native zlib functions are supported. When calling unsupported methods they put error message into `strm->msg` and return Z_STREAM_ERROR. Supported methods:; - deflateInit; - deflate (with exception of Z_FULL_FLUSH, Z_BLOCK, and Z_TREES); - deflateSetDictionary; - deflateEnd; - deflateReset; - deflateBound; - inflateInit; - inflate; - inflateSetDictionary; - inflateReset; - inflateReset2; - compress; - compress2; - compressBound; - uncompress; - gzip file access functions. Ignored methods (they do nothing):; - deflateParams. Unsupported methods:; - deflateCopy; - deflateTune; - deflatePending; - deflatePrime; - deflateSetHeader; - inflateGetDictionary; - inflateCopy; - inflateSync; - inflatePrime; - inflateMark; - inflateGetHeader; - inflateBackInit; - inflateBack; - inflateBackEnd; ",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:2013,Testability,test,test,2013,"nces with `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`; - compile your project with `zstd_zlibwrapper.c`, `gz*.c` and a static or dynamic zstd library. The linking should be changed to:; ```gcc project.o zstd_zlibwrapper.o gz*.c -lz -lzstd```. #### Enabling zstd compression within your project. After embedding the zstd wrapper within your project the zstd library is turned off by default.; Your project should work as before with zlib. There are two options to enable zstd compression:; - compilation with `-DZWRAP_USE_ZSTD=1` (or using `#define ZWRAP_USE_ZSTD 1` before `#include ""zstd_zlibwrapper.h""`); - using the `void ZWRAP_useZSTDcompression(int turn_on)` function (declared in `#include ""zstd_zlibwrapper.h""`). During decompression zlib and zstd streams are automatically detected and decompressed using a proper library.; This behavior can be changed using `ZWRAP_setDecompressionType(ZWRAP_FORCE_ZLIB)` what will make zlib decompression slightly faster. #### Example; We have take the file `test/example.c` from [the zlib library distribution](http://zlib.net/) and copied it to [zlibWrapper/examples/example.c](examples/example.c).; After compilation and execution it shows the following results: ; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; after inflateSync(): hello, hello!; inflate with dictionary: hello, hello!; ```; Then we have changed `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`, compiled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` which use currently unsupported features.; After running it shows the following results:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after ",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:3386,Testability,benchmark,benchmark,3386,": hello, hello!; inflate with dictionary: hello, hello!; ```; Then we have changed `#include ""zlib.h""` to `#include ""zstd_zlibwrapper.h""`, compiled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` which use currently unsupported features.; After running it shows the following results:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:3551,Testability,benchmark,benchmark,3551,"iled the [example.c](examples/example.c) file; with `-DZWRAP_USE_ZSTD=1` and linked with additional `zstd_zlibwrapper.o gz*.c -lzstd`.; We were forced to turn off the following functions: `test_flush`, `test_sync` which use currently unsupported features.; After running it shows the following results:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on smaller data. ; The zstd wrapper provides the `ZWRAP_setPledgedSrcSize()` function that allows to change a pledged source size for a given co",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:3891,Testability,test,tested,3891,"ults:; ```; zlib version 1.2.8 = 0x1280, compile flags = 0x65; uncompress(): hello, hello!; gzread(): hello, hello!; gzgets() after gzseek: hello!; inflate(): hello, hello!; large_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on smaller data. ; The zstd wrapper provides the `ZWRAP_setPledgedSrcSize()` function that allows to change a pledged source size for a given compression stream.; The function will change zstd compression parameters what may improve compression speed and/or ratio.; It should be called just after `deflateInit()`or `deflateReset()` and before `deflate()` or `deflateSetDictionary()`. The function is only helpful when data is compressed in b",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md:4005,Testability,benchmark,benchmark,4005,"_inflate(): OK; inflate with dictionary: hello, hello!; ```; The script used for compilation can be found at [zlibWrapper/Makefile](Makefile). #### The measurement of performace of Zstandard wrapper for zlib. The zstd distribution contains a tool called `zwrapbench` which can measure speed and ratio of zlib, zstd, and the wrapper.; The benchmark is conducted using given filenames or synthetic data if filenames are not provided.; The files are read into memory and processed independently.; It makes benchmark more precise as it eliminates I/O overhead. ; Many filenames can be supplied as multiple parameters, parameters with wildcards or names of directories can be used as parameters with the -r option.; One can select compression levels starting from `-b` and ending with `-e`. The `-i` parameter selects minimal time used for each of tested levels.; With `-B` option bigger files can be divided into smaller, independently compressed blocks. ; The benchmark tool can be compiled with `make zwrapbench` using [zlibWrapper/Makefile](Makefile). #### Improving speed of streaming compression. During streaming compression the compressor never knows how big is data to compress.; Zstandard compression can be improved by providing size of source data to the compressor. By default streaming compressor assumes that data is bigger than 256 KB but it can hurt compression speed on smaller data. ; The zstd wrapper provides the `ZWRAP_setPledgedSrcSize()` function that allows to change a pledged source size for a given compression stream.; The function will change zstd compression parameters what may improve compression speed and/or ratio.; It should be called just after `deflateInit()`or `deflateReset()` and before `deflate()` or `deflateSetDictionary()`. The function is only helpful when data is compressed in blocks. There will be no change in case of `deflateInit()` or `deflateReset()` immediately followed by `deflate(strm, Z_FINISH)`; as this case is automatically detected. #### Reusi",MatchSource.DOCS,lib/zstd/zlibWrapper/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/zlibWrapper/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:615,Deployability,release,release,615,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:731,Deployability,install,install,731,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:744,Deployability,install,install,744,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:776,Deployability,install,install,776,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:841,Deployability,install,install,841,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:487,Integrability,depend,depending,487,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:858,Modifiability,config,configure,858,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:902,Modifiability,config,configure,902,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:104,Performance,optimiz,optimize,104,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:269,Testability,test,tests,269,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:652,Testability,test,tests,652,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:965,Testability,test,testing,965,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md:171,Usability,simpl,simple,171,"Meson build system for zstandard; ================================. Meson is a build system designed to optimize programmer productivity.; It aims to do this by providing simple, out-of-the-box support for; modern software development tools and practices, such as unit tests,; coverage reports, Valgrind, CCache and the like. This Meson build system is provided with no guarantee and maintained; by Dima Krasner <dima@dimakrasner.com>. It outputs one `libzstd`, either shared or static, depending on; `default_library` option. ## How to build. `cd` to this meson directory (`build/meson`). ```sh; meson --buildtype=release -D with-contrib=true -D with-tests=true -D with-contrib=true builddir; cd builddir; ninja # to build; ninja install # to install; ```. You might want to install it in staging directory:. ```sh; DESTDIR=./staging ninja install; ```. To configure build options, use:. ```sh; meson configure; ```. See [man meson(1)](https://manpages.debian.org/testing/meson/meson.1.en.html).; ",MatchSource.DOCS,lib/zstd/build/meson/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:796,Availability,avail,available,796,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:113,Deployability,pipeline,pipelines,113,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:372,Deployability,pipeline,pipeline,372,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:842,Deployability,install,installation,842,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:872,Deployability,install,install,872,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:904,Deployability,install,install,904,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1407,Deployability,pipeline,pipeline,1407," may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:2883,Deployability,pipeline,pipeline,2883,"lso be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:14,Energy Efficiency,adapt,adapt,14,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:172,Energy Efficiency,adapt,adapting,172,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:630,Energy Efficiency,adapt,adapt,630,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:699,Energy Efficiency,adapt,adapt,699,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:714,Energy Efficiency,adapt,adaptive-compression,714,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:944,Energy Efficiency,adapt,adaptive,944,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1006,Energy Efficiency,adapt,adaptive,1006,"ary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compres",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1069,Energy Efficiency,adapt,adaptive,1069,"e across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (i",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1168,Energy Efficiency,adapt,adaptive,1168,"or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1313,Energy Efficiency,adapt,adaptive,1313,"pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1443,Energy Efficiency,adapt,adaptive,1443,"d be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other i",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1584,Energy Efficiency,adapt,adaptive,1584,"change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ###",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1704,Energy Efficiency,adapt,adaptive,1704,"ol, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial t",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3311,Energy Efficiency,adapt,adaptive,3311,"level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has ov",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3627,Energy Efficiency,adapt,adaptive,3627,"s; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4227,Energy Efficiency,adapt,adaptive,4227," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4294,Energy Efficiency,adapt,adaptive,4294," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4701,Energy Efficiency,adapt,adaptive,4701," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:14,Modifiability,adapt,adapt,14,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:172,Modifiability,adapt,adapting,172,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:630,Modifiability,adapt,adapt,630,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:699,Modifiability,adapt,adapt,699,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:714,Modifiability,adapt,adaptive-compression,714,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:944,Modifiability,adapt,adaptive,944,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1006,Modifiability,adapt,adaptive,1006,"ary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compres",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1069,Modifiability,adapt,adaptive,1069,"e across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (i",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1168,Modifiability,adapt,adaptive,1168,"or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1313,Modifiability,adapt,adaptive,1313,"pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1443,Modifiability,adapt,adaptive,1443,"d be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other i",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1584,Modifiability,adapt,adaptive,1584,"change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ###",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1704,Modifiability,adapt,adaptive,1704,"ol, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial t",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3311,Modifiability,adapt,adaptive,3311,"level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has ov",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3627,Modifiability,adapt,adaptive,3627,"s; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4227,Modifiability,adapt,adaptive,4227," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4294,Modifiability,adapt,adaptive,4294," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4701,Modifiability,adapt,adaptive,4701," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:59,Performance,optimiz,optimizing,59,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:70,Performance,perform,performance,70,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:347,Performance,bottleneck,bottlenecking,347,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:2819,Performance,throughput,throughput,2819,"e behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3974,Performance,perform,performed,3974," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4449,Performance,throughput,throughput,4449," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:2669,Testability,test,tests,2669,"e behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3025,Testability,test,tests,3025,"l be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup fi",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3043,Testability,test,test,3043,"l be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup fi",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3725,Testability,test,test,3725,"der to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 G",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:3963,Testability,test,tests,3963," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4110,Testability,test,test,4110," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:4777,Testability,test,test,4777," sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 1h 10m 43.076s |; | zstd-adaptive | 2.249 | 19.412 GB | 1h 06m 15.577s |. </td></tr>; </table>. The commands used for this test generally followed the form:. `cat FILE | pv -L 25m -q | COMPRESSION | pv -q > tmp.zst # impose 25 MB/s read limit`. `cat FILE | pv -q | COMPRESSION | pv -L 5m -q > tmp.zst # impose 5 MB/s write limit`. #### SSH Tests. The following tests were performed by piping a relatively large backup file (approximately 80 GB) through compression and over SSH to be stored on a server. The test data includes statistics for time and compressed size on `zstd` at several compression levels, as well as `zstd-adaptive`. The data highlights the potential advantages that `zstd-adaptive` has over using a low static compression level and the negative imapcts that using an excessively high static compression level can have on; pipe throughput. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:|; | zstd -3 | 2.212 | 32.426 GB | 1h 17m 59.756s |; | zstd -15 | 2.374 | 30.213 GB | 2h 56m 59.441s |; | zstd-adaptive | 2.315 | 30.993 GB | 1h 18m 52.860s |. The commands used for this test generally followed the form: . `cat FILE | COMPRESSION | ssh dev ""cat - > tmp.zst""`; ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:682,Usability,simpl,simply,682,"### Summary. `adapt` is a new compression tool targeted at optimizing performance across network connections and pipelines. The tool is aimed at sensing network speeds and adapting compression level based on network or pipe speeds.; In situations where the compression level does not appropriately match the network/pipe speed, compression may be bottlenecking the entire pipeline or the files may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:1381,Usability,simpl,simply,1381," may not be compressed as much as they potentially could be, therefore losing efficiency. It also becomes quite impractical to manually measure and set an optimalcompression level (which could potentially change over time). . ### Using `adapt`. In order to build and use the tool, you can simply run `make adapt` in the `adaptive-compression` directory under `contrib`. This will generate an executable available for use. Another possible method of installation is running `make install`, which will create and install the binary as the command `zstd-adaptive`. Similar to many other compression utilities, `zstd-adaptive` can be invoked by using the following format:. `zstd-adaptive [options] [file(s)]`. Supported options for the above format are described below. . `zstd-adaptive` also supports reading from `stdin` and writing to `stdout`, which is potentially more useful. By default, if no files are given, `zstd-adaptive` reads from and writes to standard I/O. Therefore, you can simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:2378,Usability,progress bar,progress bar,2378,"an simply insert it within a pipeline like so:. `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. ",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md:2425,Usability,progress bar,progress bar,2425," `cat FILE | zstd-adaptive | ssh ""cat - > tmp.zst""`. If a file is provided, it is also possible to force writing to stdout using the `-c` flag like so:. `zstd-adaptive -c FILE | ssh ""cat - > tmp.zst""`. Several options described below can be used to control the behavior of `zstd-adaptive`. More specifically, using the `-l#` and `-u#` flags will will set upper and lower bounds so that the compression level will always be within that range. The `-i#` flag can also be used to change the initial compression level. If an initial compression level is not provided, the initial compression level will be chosen such that it is within the appropriate range (it becomes equal to the lower bound). . ### Options; `-oFILE` : write output to `FILE`. `-i#` : provide initial compression level (must within the appropriate bounds). `-h` : display help/information. `-f` : force the compression level to stay constant. `-c` : force write to `stdout`. `-p` : hide progress bar. `-q` : quiet mode -- do not show progress bar or other information. `-l#` : set a lower bound on the compression level (default is 1). `-u#` : set an upper bound on the compression level (default is 22); ### Benchmarking / Test results; #### Artificial Tests; These artificial tests were run by using the `pv` command line utility in order to limit pipe speeds (25 MB/s read and 5 MB/s write limits were chosen to mimic severe throughput constraints). A 40 GB backup file was sent through a pipeline, compressed, and written out to a file. Compression time, size, and ratio were computed. Data for `zstd -15` was excluded from these tests because the test runs quite long. <table>; <tr><th> 25 MB/s read limit </th></tr>; <tr><td>. | Compressor Name | Ratio | Compressed Size | Compression Time |; |:----------------|------:|----------------:|-----------------:| ; | zstd -3 | 2.108 | 20.718 GB | 29m 48.530s |; | zstd-adaptive | 2.230 | 19.581 GB | 29m 48.798s |. </td><tr>; </table>. <table>; <tr><th> 5 MB/s write limit </th></tr>",MatchSource.DOCS,lib/zstd/contrib/adaptive-compression/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/adaptive-compression/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md:170,Availability,avail,available,170,; ## Requirement. The `Dockerfile` script requires a version of `docker` >= 17.05. ## Installing docker. The officiel docker install docs use a ppa with a modern version available:; https://docs.docker.com/install/linux/docker-ce/ubuntu/. ## How to run. `docker build -t zstd .`. ## test. ```; echo foo | docker run -i --rm zstd | docker run -i --rm zstd zstdcat; foo; ```; ,MatchSource.DOCS,lib/zstd/contrib/docker/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md:294,Availability,echo,echo,294,; ## Requirement. The `Dockerfile` script requires a version of `docker` >= 17.05. ## Installing docker. The officiel docker install docs use a ppa with a modern version available:; https://docs.docker.com/install/linux/docker-ce/ubuntu/. ## How to run. `docker build -t zstd .`. ## test. ```; echo foo | docker run -i --rm zstd | docker run -i --rm zstd zstdcat; foo; ```; ,MatchSource.DOCS,lib/zstd/contrib/docker/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md:125,Deployability,install,install,125,; ## Requirement. The `Dockerfile` script requires a version of `docker` >= 17.05. ## Installing docker. The officiel docker install docs use a ppa with a modern version available:; https://docs.docker.com/install/linux/docker-ce/ubuntu/. ## How to run. `docker build -t zstd .`. ## test. ```; echo foo | docker run -i --rm zstd | docker run -i --rm zstd zstdcat; foo; ```; ,MatchSource.DOCS,lib/zstd/contrib/docker/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md:206,Deployability,install,install,206,; ## Requirement. The `Dockerfile` script requires a version of `docker` >= 17.05. ## Installing docker. The officiel docker install docs use a ppa with a modern version available:; https://docs.docker.com/install/linux/docker-ce/ubuntu/. ## How to run. `docker build -t zstd .`. ## test. ```; echo foo | docker run -i --rm zstd | docker run -i --rm zstd zstdcat; foo; ```; ,MatchSource.DOCS,lib/zstd/contrib/docker/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md:283,Testability,test,test,283,; ## Requirement. The `Dockerfile` script requires a version of `docker` >= 17.05. ## Installing docker. The officiel docker install docs use a ppa with a modern version available:; https://docs.docker.com/install/linux/docker-ce/ubuntu/. ## How to run. `docker build -t zstd .`. ## test. ```; echo foo | docker run -i --rm zstd | docker run -i --rm zstd zstdcat; foo; ```; ,MatchSource.DOCS,lib/zstd/contrib/docker/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/docker/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/gen_html/README.md:746,Safety,detect,detected,746,gen_html - a program for automatic generation of zstd manual ; ============================================================. #### Introduction. This simple C++ program generates a single-page HTML manual from `zstd.h`. The format of recognized comment blocks is following:; - comments of type `/*!` mean: this is a function declaration; switch comments with declarations; - comments of type `/**` and `/*-` mean: this is a comment; use a `<H2>` header for the first line; - comments of type `/*=` and `/**=` mean: use a `<H3>` header and show also all functions until first empty line; - comments of type `/*X` where `X` is different from above-mentioned are ignored. Moreover:; - `ZSTDLIB_API` is removed to improve readability; - `typedef` are detected and included even if uncommented; - comments of type `/**<` and `/*!<` are detected and only function declaration is highlighted (bold). #### Usage. The program requires 3 parameters:; ```; gen_html [zstd_version] [input_file] [output_html]; ```. To compile program and generate zstd manual we have used: ; ```; make; ./gen_html.exe 1.1.1 ../../lib/zstd.h zstd_manual.html; ```; ,MatchSource.DOCS,lib/zstd/contrib/gen_html/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/gen_html/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/gen_html/README.md:830,Safety,detect,detected,830,gen_html - a program for automatic generation of zstd manual ; ============================================================. #### Introduction. This simple C++ program generates a single-page HTML manual from `zstd.h`. The format of recognized comment blocks is following:; - comments of type `/*!` mean: this is a function declaration; switch comments with declarations; - comments of type `/**` and `/*-` mean: this is a comment; use a `<H2>` header for the first line; - comments of type `/*=` and `/**=` mean: use a `<H3>` header and show also all functions until first empty line; - comments of type `/*X` where `X` is different from above-mentioned are ignored. Moreover:; - `ZSTDLIB_API` is removed to improve readability; - `typedef` are detected and included even if uncommented; - comments of type `/**<` and `/*!<` are detected and only function declaration is highlighted (bold). #### Usage. The program requires 3 parameters:; ```; gen_html [zstd_version] [input_file] [output_html]; ```. To compile program and generate zstd manual we have used: ; ```; make; ./gen_html.exe 1.1.1 ../../lib/zstd.h zstd_manual.html; ```; ,MatchSource.DOCS,lib/zstd/contrib/gen_html/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/gen_html/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/gen_html/README.md:149,Usability,simpl,simple,149,gen_html - a program for automatic generation of zstd manual ; ============================================================. #### Introduction. This simple C++ program generates a single-page HTML manual from `zstd.h`. The format of recognized comment blocks is following:; - comments of type `/*!` mean: this is a function declaration; switch comments with declarations; - comments of type `/**` and `/*-` mean: this is a comment; use a `<H2>` header for the first line; - comments of type `/*=` and `/**=` mean: use a `<H3>` header and show also all functions until first empty line; - comments of type `/*X` where `X` is different from above-mentioned are ignored. Moreover:; - `ZSTDLIB_API` is removed to improve readability; - `typedef` are detected and included even if uncommented; - comments of type `/**<` and `/*!<` are detected and only function declaration is highlighted (bold). #### Usage. The program requires 3 parameters:; ```; gen_html [zstd_version] [input_file] [output_html]; ```. To compile program and generate zstd manual we have used: ; ```; make; ./gen_html.exe 1.1.1 ../../lib/zstd.h zstd_manual.html; ```; ,MatchSource.DOCS,lib/zstd/contrib/gen_html/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/gen_html/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:279,Performance,latency,latency,279,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:294,Performance,cache,cache,294,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:352,Performance,perform,performance,352,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:507,Performance,load,load,507,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:57,Testability,benchmark,benchmark,57,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:67,Testability,test,test,67,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md:721,Testability,benchmark,benchmark,721,"largeNbDicts; =====================. `largeNbDicts` is a benchmark test tool; dedicated to the specific scenario of; dictionary decompression using a very large number of dictionaries.; When dictionaries are constantly changing, they are always ""cold"",; suffering from increased latency due to cache misses. The tool is created in a bid to investigate performance for this scenario,; and experiment mitigation techniques. Command line :; ```; largeNbDicts [Options] filename(s). Options :; -r : recursively load all files in subdirectories (default: off); -B# : split input into blocks of size # (default: no split); -# : use compression level # (default: 3); -D # : use # as a dictionary (default: create one); -i# : nb benchmark rounds (default: 6); --nbDicts=# : set nb of dictionaries to # (default: one per block); -h : help (this text); ```; ",MatchSource.DOCS,lib/zstd/contrib/largeNbDicts/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/largeNbDicts/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:141,Deployability,patch,patch,141,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:165,Deployability,patch,patch,165,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:177,Deployability,patch,patches,177,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:265,Deployability,patch,patch,265,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:438,Deployability,patch,patch,438,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:897,Deployability,patch,patch,897,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1367,Deployability,patch,patch,1367,".c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1554,Deployability,patch,patch,1554,"line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1670,Deployability,patch,patch,1670,"XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:2107,Deployability,patch,patch,2107,"be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is locat",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3065,Deployability,patch,patch,3065,"rom the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3194,Deployability,patch,patch,3194,"dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3496,Deployability,patch,patch,3496,"e output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | lz4 | 2.12 | 94 MB/s | 218 MB/s |; | xz | 3.43 | 5.5 MB/s | 35 MB/s |; | xz 256 KB | 3.53 | 5.4 MB/s | 40 MB/s |; | zstd 1 | 2.71 | 96 MB/s | 210 MB/s |; | zstd 5 | 2.93 | 69 MB/s | 198 MB/s |; | zstd 10 | 3.01 | 41 MB/s | 225 MB/s |; | zstd 15 | 3.",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:936,Integrability,depend,depends,936,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1081,Performance,load,loaded,1081,"ash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kern",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:386,Testability,test,test,386,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:424,Testability,test,tests,424,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:459,Testability,mock,mocking,459,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:490,Testability,test,tested,490,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:501,Testability,test,tests,501,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:598,Testability,test,tests,598,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:665,Testability,test,test,665,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:755,Testability,benchmark,benchmarked,755,"# Linux Kernel Patch. There are four pieces, the `xxhash` kernel module, the `zstd_compress` and `zstd_decompress` kernel modules, the BtrFS patch, and the SquashFS patch.; The patches are based off of the linux kernel master branch. ## xxHash kernel module. * The patch is located in `xxhash.diff`.; * The header is in `include/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel C",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1321,Testability,test,test,1321,"e/linux/xxhash.h`.; * The source is in `lib/xxhash.c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decom",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1353,Testability,test,tests,1353,".c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1388,Testability,mock,mocking,1388,".c`.; * `test/XXHashUserLandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1469,Testability,test,test,1469," the kernel headers.; I tested the tests by commenting a line of of each branch in `xxhash.c` one line at a time, and made sure the tests failed.; It can be run with the following commands:; ```; cd test && make googletest && make XXHashUserLandTest && ./XXHashUserLandTest; ```; * I also benchmarked the `xxhash` module against upstream xxHash, and made sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing th",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:1811,Testability,test,testing,1811,"sure that they ran at the same speed. ## Zstd Kernel modules. * The (large) patch is located in `zstd.diff`, which depends on `xxhash.diff`.; * The header is in `include/linux/zstd.h`.; * It is split up into `zstd_compress` and `zstd_decompress`, which can be loaded independently.; * Source files are in `lib/zstd/`.; * `lib/Kconfig` and `lib/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 2",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:2130,Testability,benchmark,benchmark,2130,"b/Makefile` need to be modified by applying `lib/Kconfig.diff` and `lib/Makefile.diff` respectively.; These changes are also included in the `zstd.diff`.; * `test/UserlandTest.cpp` contains tests for the patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a s",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:2337,Testability,benchmark,benchmark,2337," patch in userland by mocking the kernel headers.; It can be run with the following commands:; ```; cd test && make googletest && make UserlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:2506,Testability,benchmark,benchmark,2506,"rlandTest && ./UserlandTest; ```. ## BtrFS. * The patch is located in `btrfs.diff`.; * Additionally `fs/btrfs/zstd.c` is provided as a source for convenience.; * The patch seems to be working, it doesn't crash the kernel, and compresses at speeds and ratios that are expected.; It could still use some more testing for fringe features, like printing options. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is copying 10 copies of the; unzipped [silesia corpus](http://mattmahoney.net/dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. Th",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3209,Testability,test,tested,3209,"dc/silesia.html) into a BtrFS; filesystem mounted with `-o compress-force={none, lzo, zlib, zstd}`.; The decompression benchmark is timing how long it takes to `tar` all 10 copies; into `/dev/null`.; The compression ratio is measured by comparing the output of `df` and `du`.; See `btrfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3519,Testability,benchmark,benchmark,3519," Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | lz4 | 2.12 | 94 MB/s | 218 MB/s |; | xz | 3.43 | 5.5 MB/s | 35 MB/s |; | xz 256 KB | 3.53 | 5.4 MB/s | 40 MB/s |; | zstd 1 | 2.71 | 96 MB/s | 210 MB/s |; | zstd 5 | 2.93 | 69 MB/s | 198 MB/s |; | zstd 10 | 3.01 | 41 MB/s | 225 MB/s |; | zstd 15 | 3.13 | 11.4 MB/s | 224 MB/s |; | zstd 16 256 KB | 3.24 | 8.1 MB/s | 210 MB/s |; ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3664,Testability,benchmark,benchmark,3664," Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | lz4 | 2.12 | 94 MB/s | 218 MB/s |; | xz | 3.43 | 5.5 MB/s | 35 MB/s |; | xz 256 KB | 3.53 | 5.4 MB/s | 40 MB/s |; | zstd 1 | 2.71 | 96 MB/s | 210 MB/s |; | zstd 5 | 2.93 | 69 MB/s | 198 MB/s |; | zstd 10 | 3.01 | 41 MB/s | 225 MB/s |; | zstd 15 | 3.13 | 11.4 MB/s | 224 MB/s |; | zstd 16 256 KB | 3.24 | 8.1 MB/s | 210 MB/s |; ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3809,Testability,benchmark,benchmarked,3809," Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | lz4 | 2.12 | 94 MB/s | 218 MB/s |; | xz | 3.43 | 5.5 MB/s | 35 MB/s |; | xz 256 KB | 3.53 | 5.4 MB/s | 40 MB/s |; | zstd 1 | 2.71 | 96 MB/s | 210 MB/s |; | zstd 5 | 2.93 | 69 MB/s | 198 MB/s |; | zstd 10 | 3.01 | 41 MB/s | 225 MB/s |; | zstd 15 | 3.13 | 11.4 MB/s | 224 MB/s |; | zstd 16 256 KB | 3.24 | 8.1 MB/s | 210 MB/s |; ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3860,Testability,benchmark,benchmark,3860," Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | lz4 | 2.12 | 94 MB/s | 218 MB/s |; | xz | 3.43 | 5.5 MB/s | 35 MB/s |; | xz 256 KB | 3.53 | 5.4 MB/s | 40 MB/s |; | zstd 1 | 2.71 | 96 MB/s | 210 MB/s |; | zstd 5 | 2.93 | 69 MB/s | 198 MB/s |; | zstd 10 | 3.01 | 41 MB/s | 225 MB/s |; | zstd 15 | 3.13 | 11.4 MB/s | 224 MB/s |; | zstd 16 256 KB | 3.24 | 8.1 MB/s | 210 MB/s |; ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md:3955,Testability,benchmark,benchmark,3955," Compression ratio | Compression speed | Decompression speed |; |-----------|-------------------|-------------------|---------------------|; | None | 0.99 | 504 MB/s | 686 MB/s |; | lzo | 1.66 | 398 MB/s | 442 MB/s |; | zlib | 2.58 | 65 MB/s | 241 MB/s |; | zstd 1 | 2.57 | 260 MB/s | 383 MB/s |; | zstd 3 | 2.71 | 174 MB/s | 408 MB/s |; | zstd 6 | 2.87 | 70 MB/s | 398 MB/s |; | zstd 9 | 2.92 | 43 MB/s | 406 MB/s |; | zstd 12 | 2.93 | 21 MB/s | 408 MB/s |; | zstd 15 | 3.01 | 11 MB/s | 354 MB/s |. ## SquashFS. * The patch is located in `squashfs.diff`; * Additionally `fs/squashfs/zstd_wrapper.c` is provided as a source for convenience.; * The patch has been tested on the master branch of the kernel. ### Benchmarks. Benchmarks run on a Ubuntu 14.04 with 2 cores and 4 GiB of RAM.; The VM is running on a Macbook Pro with a 3.1 GHz Intel Core i7 processor,; 16 GB of ram, and a SSD.; The kernel running was built from the master branch with the patch. The compression benchmark is the file tree from the SquashFS archive found in the; Ubuntu 16.10 desktop image (ubuntu-16.10-desktop-amd64.iso).; The compression benchmark uses mksquashfs with the default block size (128 KB); and various compression algorithms/compression levels.; `xz` and `zstd` are also benchmarked with 256 KB blocks.; The decompression benchmark is timing how long it takes to `tar` the file tree; into `/dev/null`.; See `squashfs-benchmark.sh` for details. | Algorithm | Compression ratio | Compression speed | Decompression speed |; |----------------|-------------------|-------------------|---------------------|; | gzip | 2.92 | 15 MB/s | 128 MB/s |; | lzo | 2.64 | 9.5 MB/s | 217 MB/s |; | lz4 | 2.12 | 94 MB/s | 218 MB/s |; | xz | 3.43 | 5.5 MB/s | 35 MB/s |; | xz 256 KB | 3.53 | 5.4 MB/s | 40 MB/s |; | zstd 1 | 2.71 | 96 MB/s | 210 MB/s |; | zstd 5 | 2.93 | 69 MB/s | 198 MB/s |; | zstd 10 | 3.01 | 41 MB/s | 225 MB/s |; | zstd 15 | 3.13 | 11.4 MB/s | 224 MB/s |; | zstd 16 256 KB | 3.24 | 8.1 MB/s | 210 MB/s |; ",MatchSource.DOCS,lib/zstd/contrib/linux-kernel/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/linux-kernel/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:2620,Deployability,install,installed,2620,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:812,Integrability,interface,interface,812,"# Parallel Zstandard (PZstandard). Parallel Zstandard is a Pigz-like tool for Zstandard.; It provides Zstandard format compatible compression and decompression that is able to utilize multiple cores.; It breaks the input up into equal sized chunks and compresses each chunk independently into a Zstandard frame.; It then concatenates the frames together to produce the final compressed output.; Pzstandard will write a 12 byte header for each frame that is a skippable frame in the Zstandard format, which tells PZstandard the size of the next compressed frame.; PZstandard supports parallel decompression of files compressed with PZstandard.; When decompressing files compressed with Zstandard, PZstandard does IO in one thread, and decompression in another. ## Usage. PZstandard supports the same command line interface as Zstandard, but also provides the `-p` option to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:1983,Testability,test,test,1983,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:2328,Testability,test,tested,2328,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:2379,Testability,test,tested,2379,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:2830,Testability,test,tests,2830,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:2858,Testability,test,tests,2858,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md:2459,Usability,simpl,simply,2459,"ion to specify the number of threads.; Dictionary mode is not currently supported. Basic usage. pzstd input-file -o output-file -p num-threads -# # Compression; pzstd -d input-file -o output-file -p num-threads # Decompression. PZstandard also supports piping and fifo pipes. cat input-file | pzstd -p num-threads -# -c > /dev/null. For more options. pzstd --help. PZstandard tries to pick a smart default number of threads if not specified (displayed in `pzstd --help`).; If this number is not suitable, during compilation you can define `PZSTD_NUM_THREADS` to the number of threads you prefer. ## Benchmarks. As a reference, PZstandard and Pigz were compared on an Intel Core i7 @ 3.1 GHz, each using 4 threads, with the [Silesia compression corpus](http://sun.aei.polsl.pl/~sdeor/index.php?page=silesia). Compression Speed vs Ratio with 4 Threads | Decompression Speed with 4 Threads; ------------------------------------------|-----------------------------------; ![Compression Speed vs Ratio](images/Cspeed.png ""Compression Speed vs Ratio"") | ![Decompression Speed](images/Dspeed.png ""Decompression Speed""). The test procedure was to run each of the following commands 2 times for each compression level, and take the minimum time. time pzstd -# -p 4 -c silesia.tar > silesia.tar.zst; time pzstd -d -p 4 -c silesia.tar.zst > /dev/null. time pigz -# -p 4 -k -c silesia.tar > silesia.tar.gz; time pigz -d -p 4 -k -c silesia.tar.gz > /dev/null. PZstandard was tested using compression levels 1-19, and Pigz was tested using compression levels 1-9.; Pigz cannot do parallel decompression, it simply does each of reading, decompression, and writing on separate threads. ## Tests. Tests require that you have [gtest](https://github.com/google/googletest) installed.; Set `GTEST_INC` and `GTEST_LIB` in `Makefile` to specify the location of the gtest headers and libraries.; Alternatively, run `make googletest`, which will clone googletest and build it.; Run `make tests && make check` to run tests.; ",MatchSource.DOCS,lib/zstd/contrib/pzstd/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/pzstd/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md:172,Energy Efficiency,charge,charge,172,"# Zstandard Seekable Format. ### Notices. Copyright (c) 2017-present Facebook, Inc. Permission is granted to copy and distribute this document; for any purpose and without charge,; including translations into other languages; and incorporation into compilations,; provided that the copyright notice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version; 0.1.0 (11/04/17). ## Introduction; This document defines a format for compressed data to be stored so that subranges of the data can be efficiently decompressed without requiring the entire document to be decompressed.; This is done by splitting up the input data into frames,; each of which are compressed independently,; and so can be decompressed independently.; Decompression then takes advantage of a provided 'seek table', which allows the decompressor to immediately jump to the desired data. This is done in a way that is compatible with the original Zstandard format by placing the seek table in a Zstandard skippable frame. ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`; - All numeric fields are little-endian unless specified otherwise. ## Format. The format consists of a number of frames (Zstandard compressed frames and skippable frames), followed by a final skippable frame at the end containing the seek table. ### Seek Table Format; The structure of the seek table frame is as follows:. |`Skippable_Magic_Number`|`Frame_Size`|`[Seek_Table_Entries]`|`Seek_Table_Footer`|; |------------------------|------------|----------------------|-------------------|; | 4 bytes | 4 bytes | 8-12 bytes each | 9 bytes |. __`Skippable_Magic_Number`__. Value : 0x184D2A5E.; This is for compatibility with [Zstandard skippable frames].; Since it is legal for other Zsta",MatchSource.DOCS,lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md:610,Energy Efficiency,efficient,efficiently,610,"# Zstandard Seekable Format. ### Notices. Copyright (c) 2017-present Facebook, Inc. Permission is granted to copy and distribute this document; for any purpose and without charge,; including translations into other languages; and incorporation into compilations,; provided that the copyright notice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version; 0.1.0 (11/04/17). ## Introduction; This document defines a format for compressed data to be stored so that subranges of the data can be efficiently decompressed without requiring the entire document to be decompressed.; This is done by splitting up the input data into frames,; each of which are compressed independently,; and so can be decompressed independently.; Decompression then takes advantage of a provided 'seek table', which allows the decompressor to immediately jump to the desired data. This is done in a way that is compatible with the original Zstandard format by placing the seek table in a Zstandard skippable frame. ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`; - All numeric fields are little-endian unless specified otherwise. ## Format. The format consists of a number of frames (Zstandard compressed frames and skippable frames), followed by a final skippable frame at the end containing the seek table. ### Seek Table Format; The structure of the seek table frame is as follows:. |`Skippable_Magic_Number`|`Frame_Size`|`[Seek_Table_Entries]`|`Seek_Table_Footer`|; |------------------------|------------|----------------------|-------------------|; | 4 bytes | 4 bytes | 8-12 bytes each | 9 bytes |. __`Skippable_Magic_Number`__. Value : 0x184D2A5E.; This is for compatibility with [Zstandard skippable frames].; Since it is legal for other Zsta",MatchSource.DOCS,lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md:2811,Energy Efficiency,efficient,efficiently,2811," | 4 bytes | 4 bytes | 8-12 bytes each | 9 bytes |. __`Skippable_Magic_Number`__. Value : 0x184D2A5E.; This is for compatibility with [Zstandard skippable frames].; Since it is legal for other Zstandard skippable frames to use the same; magic number, it is not recommended for a decoder to recognize frames; solely on this. __`Frame_Size`__. The total size of the skippable frame, not including the `Skippable_Magic_Number` or `Frame_Size`.; This is for compatibility with [Zstandard skippable frames]. [Zstandard skippable frames]: https://github.com/facebook/zstd/blob/master/doc/zstd_compression_format.md#skippable-frames. #### `Seek_Table_Footer`; The seek table footer format is as follows:. |`Number_Of_Frames`|`Seek_Table_Descriptor`|`Seekable_Magic_Number`|; |------------------|-----------------------|-----------------------|; | 4 bytes | 1 byte | 4 bytes |. __`Seekable_Magic_Number`__. Value : 0x8F92EAB1.; This value must be the last bytes present in the compressed file so that decoders; can efficiently find it and determine if there is an actual seek table present. __`Number_Of_Frames`__. The number of stored frames in the data. __`Seek_Table_Descriptor`__. A bitfield describing the format of the seek table. | Bit number | Field name |; | ---------- | ---------- |; | 7 | `Checksum_Flag` |; | 6-2 | `Reserved_Bits` |; | 1-0 | `Unused_Bits` |. While only `Checksum_Flag` currently exists, there are 7 other bits in this field that can be used for future changes to the format,; for example the addition of inline dictionaries. __`Checksum_Flag`__. If the checksum flag is set, each of the seek table entries contains a 4 byte checksum of the uncompressed data contained in its frame. `Reserved_Bits` are not currently used but may be used in the future for breaking changes, so a compliant decoder should ensure they are set to 0. `Unused_Bits` may be used in the future for non-breaking changes, so a compliant decoder should not interpret these bits. #### __`Seek_Table_Entries`",MatchSource.DOCS,lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md:3379,Security,checksum,checksum,3379,"ek_Table_Footer`; The seek table footer format is as follows:. |`Number_Of_Frames`|`Seek_Table_Descriptor`|`Seekable_Magic_Number`|; |------------------|-----------------------|-----------------------|; | 4 bytes | 1 byte | 4 bytes |. __`Seekable_Magic_Number`__. Value : 0x8F92EAB1.; This value must be the last bytes present in the compressed file so that decoders; can efficiently find it and determine if there is an actual seek table present. __`Number_Of_Frames`__. The number of stored frames in the data. __`Seek_Table_Descriptor`__. A bitfield describing the format of the seek table. | Bit number | Field name |; | ---------- | ---------- |; | 7 | `Checksum_Flag` |; | 6-2 | `Reserved_Bits` |; | 1-0 | `Unused_Bits` |. While only `Checksum_Flag` currently exists, there are 7 other bits in this field that can be used for future changes to the format,; for example the addition of inline dictionaries. __`Checksum_Flag`__. If the checksum flag is set, each of the seek table entries contains a 4 byte checksum of the uncompressed data contained in its frame. `Reserved_Bits` are not currently used but may be used in the future for breaking changes, so a compliant decoder should ensure they are set to 0. `Unused_Bits` may be used in the future for non-breaking changes, so a compliant decoder should not interpret these bits. #### __`Seek_Table_Entries`__. `Seek_Table_Entries` consists of `Number_Of_Frames` (one for each frame in the data, not including the seek table frame) entries of the following form, in sequence:. |`Compressed_Size`|`Decompressed_Size`|`[Checksum]`|; |-----------------|-------------------|------------|; | 4 bytes | 4 bytes | 4 bytes |. __`Compressed_Size`__. The compressed size of the frame.; The cumulative sum of the `Compressed_Size` fields of frames `0` to `i` gives the offset in the compressed file of frame `i+1`. __`Decompressed_Size`__. The size of the decompressed data contained in the frame. For skippable or otherwise empty frames, this value is ",MatchSource.DOCS,lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md:3450,Security,checksum,checksum,3450,"ek_Table_Footer`; The seek table footer format is as follows:. |`Number_Of_Frames`|`Seek_Table_Descriptor`|`Seekable_Magic_Number`|; |------------------|-----------------------|-----------------------|; | 4 bytes | 1 byte | 4 bytes |. __`Seekable_Magic_Number`__. Value : 0x8F92EAB1.; This value must be the last bytes present in the compressed file so that decoders; can efficiently find it and determine if there is an actual seek table present. __`Number_Of_Frames`__. The number of stored frames in the data. __`Seek_Table_Descriptor`__. A bitfield describing the format of the seek table. | Bit number | Field name |; | ---------- | ---------- |; | 7 | `Checksum_Flag` |; | 6-2 | `Reserved_Bits` |; | 1-0 | `Unused_Bits` |. While only `Checksum_Flag` currently exists, there are 7 other bits in this field that can be used for future changes to the format,; for example the addition of inline dictionaries. __`Checksum_Flag`__. If the checksum flag is set, each of the seek table entries contains a 4 byte checksum of the uncompressed data contained in its frame. `Reserved_Bits` are not currently used but may be used in the future for breaking changes, so a compliant decoder should ensure they are set to 0. `Unused_Bits` may be used in the future for non-breaking changes, so a compliant decoder should not interpret these bits. #### __`Seek_Table_Entries`__. `Seek_Table_Entries` consists of `Number_Of_Frames` (one for each frame in the data, not including the seek table frame) entries of the following form, in sequence:. |`Compressed_Size`|`Decompressed_Size`|`[Checksum]`|; |-----------------|-------------------|------------|; | 4 bytes | 4 bytes | 4 bytes |. __`Compressed_Size`__. The compressed size of the frame.; The cumulative sum of the `Compressed_Size` fields of frames `0` to `i` gives the offset in the compressed file of frame `i+1`. __`Decompressed_Size`__. The size of the decompressed data contained in the frame. For skippable or otherwise empty frames, this value is ",MatchSource.DOCS,lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md:400,Usability,clear,clearly,400,"# Zstandard Seekable Format. ### Notices. Copyright (c) 2017-present Facebook, Inc. Permission is granted to copy and distribute this document; for any purpose and without charge,; including translations into other languages; and incorporation into compilations,; provided that the copyright notice and this notice are preserved,; and that any substantive changes or deletions from the original; are clearly marked.; Distribution of this document is unlimited. ### Version; 0.1.0 (11/04/17). ## Introduction; This document defines a format for compressed data to be stored so that subranges of the data can be efficiently decompressed without requiring the entire document to be decompressed.; This is done by splitting up the input data into frames,; each of which are compressed independently,; and so can be decompressed independently.; Decompression then takes advantage of a provided 'seek table', which allows the decompressor to immediately jump to the desired data. This is done in a way that is compatible with the original Zstandard format by placing the seek table in a Zstandard skippable frame. ### Overall conventions; In this document:; - square brackets i.e. `[` and `]` are used to indicate optional fields or parameters.; - the naming convention for identifiers is `Mixed_Case_With_Underscores`; - All numeric fields are little-endian unless specified otherwise. ## Format. The format consists of a number of frames (Zstandard compressed frames and skippable frames), followed by a final skippable frame at the end containing the seek table. ### Seek Table Format; The structure of the seek table frame is as follows:. |`Skippable_Magic_Number`|`Frame_Size`|`[Seek_Table_Entries]`|`Seek_Table_Footer`|; |------------------------|------------|----------------------|-------------------|; | 4 bytes | 4 bytes | 8-12 bytes each | 9 bytes |. __`Skippable_Magic_Number`__. Value : 0x184D2A5E.; This is for compatibility with [Zstandard skippable frames].; Since it is legal for other Zsta",MatchSource.DOCS,lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/seekable_format/zstd_seekable_compression_format.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md:508,Performance,optimiz,optimize,508,"Benchmarking Dictionary Builder. ### Permitted Argument:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in="". ###Running Test:; make test. ###Usage:; Benchmark given input files: make ARG= followed by permitted arguments. ### Examples:; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress"". ###Benchmarking Result:; - First Cover is optimize cover, second Cover uses optimized d and k from first one.; - For every f value of fastCover, the first one is optimize fastCover and the second one uses optimized d and k from first one. This is run for accel values from 1 to 10.; - Fourth column is chosen d and fifth column is chosen k. github:; NODICT 0.000004 2.999642 ; RANDOM 0.024560 8.791189 ; LEGACY 0.727109 8.173529 ; COVER 40.565676 10.652243 8 1298; COVER 3.608284 10.652243 8 1298; FAST f=15 a=1 4.181024 10.570882 8 1154; FAST f=15 a=1 0.040788 10.570882 8 1154; FAST f=15 a=2 3.548352 10.574287 6 1970; FAST f=15 a=2 0.035535 10.574287 6 1970; FAST f=15 a=3 3.287364 10.613950 6 1010; FAST f=15 a=3 0.032182 10.613950 6 1010; FAST f=15 a=4 3.184976 10.573883 6 1058; FAST f=15 a=4 0.029878 10.573883 6 1058; FAST f=15 a=5 3.045513 10.580640 8 1154; FAST f=15 a=5 0.022162 10.580640 8 1154; FAST f=15 a=6 3.003296 10.583677 6 1010; FAST f=15 a=6 0.028091 10.583677 6 1010; FAST f=15 a=7 2.952655 10.622551 6 1106; FAST f=15 a=7 0.02724 10.622551 6 1106; FAST f=15 a=8 2.945674 10.614657 6 1010; FAST f=15 a=8 0.027264 10.614657 6 1010; FAST f=15 a=9 3.153439 10.564018 8 1154; FAST f=15 a=9 0.020635 10.564018 8 1154; FAST f=15 a=10 2.950416 10.511454 6 1010; FAST f=15 a=10 0.026606 10.511454 6 1010; FAST f=16 a=1 3.970029 10.681035 8 1154; FAST f=16 a=1 0.038188 10.681035 8 1154; FAST f=16 a=2 3.422892 10.484978 6 1874; FAST f=16 a=2 0.034702 10.484978 6 1874; FAST f=16 a=3 3.215836 10.632631 8 1154; FAST f=16 a",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md:542,Performance,optimiz,optimized,542,"Benchmarking Dictionary Builder. ### Permitted Argument:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in="". ###Running Test:; make test. ###Usage:; Benchmark given input files: make ARG= followed by permitted arguments. ### Examples:; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress"". ###Benchmarking Result:; - First Cover is optimize cover, second Cover uses optimized d and k from first one.; - For every f value of fastCover, the first one is optimize fastCover and the second one uses optimized d and k from first one. This is run for accel values from 1 to 10.; - Fourth column is chosen d and fifth column is chosen k. github:; NODICT 0.000004 2.999642 ; RANDOM 0.024560 8.791189 ; LEGACY 0.727109 8.173529 ; COVER 40.565676 10.652243 8 1298; COVER 3.608284 10.652243 8 1298; FAST f=15 a=1 4.181024 10.570882 8 1154; FAST f=15 a=1 0.040788 10.570882 8 1154; FAST f=15 a=2 3.548352 10.574287 6 1970; FAST f=15 a=2 0.035535 10.574287 6 1970; FAST f=15 a=3 3.287364 10.613950 6 1010; FAST f=15 a=3 0.032182 10.613950 6 1010; FAST f=15 a=4 3.184976 10.573883 6 1058; FAST f=15 a=4 0.029878 10.573883 6 1058; FAST f=15 a=5 3.045513 10.580640 8 1154; FAST f=15 a=5 0.022162 10.580640 8 1154; FAST f=15 a=6 3.003296 10.583677 6 1010; FAST f=15 a=6 0.028091 10.583677 6 1010; FAST f=15 a=7 2.952655 10.622551 6 1106; FAST f=15 a=7 0.02724 10.622551 6 1106; FAST f=15 a=8 2.945674 10.614657 6 1010; FAST f=15 a=8 0.027264 10.614657 6 1010; FAST f=15 a=9 3.153439 10.564018 8 1154; FAST f=15 a=9 0.020635 10.564018 8 1154; FAST f=15 a=10 2.950416 10.511454 6 1010; FAST f=15 a=10 0.026606 10.511454 6 1010; FAST f=16 a=1 3.970029 10.681035 8 1154; FAST f=16 a=1 0.038188 10.681035 8 1154; FAST f=16 a=2 3.422892 10.484978 6 1874; FAST f=16 a=2 0.034702 10.484978 6 1874; FAST f=16 a=3 3.215836 10.632631 8 1154; FAST f=16 a",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md:628,Performance,optimiz,optimize,628,"Benchmarking Dictionary Builder. ### Permitted Argument:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in="". ###Running Test:; make test. ###Usage:; Benchmark given input files: make ARG= followed by permitted arguments. ### Examples:; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress"". ###Benchmarking Result:; - First Cover is optimize cover, second Cover uses optimized d and k from first one.; - For every f value of fastCover, the first one is optimize fastCover and the second one uses optimized d and k from first one. This is run for accel values from 1 to 10.; - Fourth column is chosen d and fifth column is chosen k. github:; NODICT 0.000004 2.999642 ; RANDOM 0.024560 8.791189 ; LEGACY 0.727109 8.173529 ; COVER 40.565676 10.652243 8 1298; COVER 3.608284 10.652243 8 1298; FAST f=15 a=1 4.181024 10.570882 8 1154; FAST f=15 a=1 0.040788 10.570882 8 1154; FAST f=15 a=2 3.548352 10.574287 6 1970; FAST f=15 a=2 0.035535 10.574287 6 1970; FAST f=15 a=3 3.287364 10.613950 6 1010; FAST f=15 a=3 0.032182 10.613950 6 1010; FAST f=15 a=4 3.184976 10.573883 6 1058; FAST f=15 a=4 0.029878 10.573883 6 1058; FAST f=15 a=5 3.045513 10.580640 8 1154; FAST f=15 a=5 0.022162 10.580640 8 1154; FAST f=15 a=6 3.003296 10.583677 6 1010; FAST f=15 a=6 0.028091 10.583677 6 1010; FAST f=15 a=7 2.952655 10.622551 6 1106; FAST f=15 a=7 0.02724 10.622551 6 1106; FAST f=15 a=8 2.945674 10.614657 6 1010; FAST f=15 a=8 0.027264 10.614657 6 1010; FAST f=15 a=9 3.153439 10.564018 8 1154; FAST f=15 a=9 0.020635 10.564018 8 1154; FAST f=15 a=10 2.950416 10.511454 6 1010; FAST f=15 a=10 0.026606 10.511454 6 1010; FAST f=16 a=1 3.970029 10.681035 8 1154; FAST f=16 a=1 0.038188 10.681035 8 1154; FAST f=16 a=2 3.422892 10.484978 6 1874; FAST f=16 a=2 0.034702 10.484978 6 1874; FAST f=16 a=3 3.215836 10.632631 8 1154; FAST f=16 a",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md:671,Performance,optimiz,optimized,671,"Benchmarking Dictionary Builder. ### Permitted Argument:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in="". ###Running Test:; make test. ###Usage:; Benchmark given input files: make ARG= followed by permitted arguments. ### Examples:; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress"". ###Benchmarking Result:; - First Cover is optimize cover, second Cover uses optimized d and k from first one.; - For every f value of fastCover, the first one is optimize fastCover and the second one uses optimized d and k from first one. This is run for accel values from 1 to 10.; - Fourth column is chosen d and fifth column is chosen k. github:; NODICT 0.000004 2.999642 ; RANDOM 0.024560 8.791189 ; LEGACY 0.727109 8.173529 ; COVER 40.565676 10.652243 8 1298; COVER 3.608284 10.652243 8 1298; FAST f=15 a=1 4.181024 10.570882 8 1154; FAST f=15 a=1 0.040788 10.570882 8 1154; FAST f=15 a=2 3.548352 10.574287 6 1970; FAST f=15 a=2 0.035535 10.574287 6 1970; FAST f=15 a=3 3.287364 10.613950 6 1010; FAST f=15 a=3 0.032182 10.613950 6 1010; FAST f=15 a=4 3.184976 10.573883 6 1058; FAST f=15 a=4 0.029878 10.573883 6 1058; FAST f=15 a=5 3.045513 10.580640 8 1154; FAST f=15 a=5 0.022162 10.580640 8 1154; FAST f=15 a=6 3.003296 10.583677 6 1010; FAST f=15 a=6 0.028091 10.583677 6 1010; FAST f=15 a=7 2.952655 10.622551 6 1106; FAST f=15 a=7 0.02724 10.622551 6 1106; FAST f=15 a=8 2.945674 10.614657 6 1010; FAST f=15 a=8 0.027264 10.614657 6 1010; FAST f=15 a=9 3.153439 10.564018 8 1154; FAST f=15 a=9 0.020635 10.564018 8 1154; FAST f=15 a=10 2.950416 10.511454 6 1010; FAST f=15 a=10 0.026606 10.511454 6 1010; FAST f=16 a=1 3.970029 10.681035 8 1154; FAST f=16 a=1 0.038188 10.681035 8 1154; FAST f=16 a=2 3.422892 10.484978 6 1874; FAST f=16 a=2 0.034702 10.484978 6 1874; FAST f=16 a=3 3.215836 10.632631 8 1154; FAST f=16 a",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md:297,Testability,test,test,297,"Benchmarking Dictionary Builder. ### Permitted Argument:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in="". ###Running Test:; make test. ###Usage:; Benchmark given input files: make ARG= followed by permitted arguments. ### Examples:; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress"". ###Benchmarking Result:; - First Cover is optimize cover, second Cover uses optimized d and k from first one.; - For every f value of fastCover, the first one is optimize fastCover and the second one uses optimized d and k from first one. This is run for accel values from 1 to 10.; - Fourth column is chosen d and fifth column is chosen k. github:; NODICT 0.000004 2.999642 ; RANDOM 0.024560 8.791189 ; LEGACY 0.727109 8.173529 ; COVER 40.565676 10.652243 8 1298; COVER 3.608284 10.652243 8 1298; FAST f=15 a=1 4.181024 10.570882 8 1154; FAST f=15 a=1 0.040788 10.570882 8 1154; FAST f=15 a=2 3.548352 10.574287 6 1970; FAST f=15 a=2 0.035535 10.574287 6 1970; FAST f=15 a=3 3.287364 10.613950 6 1010; FAST f=15 a=3 0.032182 10.613950 6 1010; FAST f=15 a=4 3.184976 10.573883 6 1058; FAST f=15 a=4 0.029878 10.573883 6 1058; FAST f=15 a=5 3.045513 10.580640 8 1154; FAST f=15 a=5 0.022162 10.580640 8 1154; FAST f=15 a=6 3.003296 10.583677 6 1010; FAST f=15 a=6 0.028091 10.583677 6 1010; FAST f=15 a=7 2.952655 10.622551 6 1106; FAST f=15 a=7 0.02724 10.622551 6 1106; FAST f=15 a=8 2.945674 10.614657 6 1010; FAST f=15 a=8 0.027264 10.614657 6 1010; FAST f=15 a=9 3.153439 10.564018 8 1154; FAST f=15 a=9 0.020635 10.564018 8 1154; FAST f=15 a=10 2.950416 10.511454 6 1010; FAST f=15 a=10 0.026606 10.511454 6 1010; FAST f=16 a=1 3.970029 10.681035 8 1154; FAST f=16 a=1 0.038188 10.681035 8 1154; FAST f=16 a=2 3.422892 10.484978 6 1874; FAST f=16 a=2 0.034702 10.484978 6 1874; FAST f=16 a=3 3.215836 10.632631 8 1154; FAST f=16 a",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/benchmarkDictBuilder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/fastCover/README.md:1024,Performance,optimiz,optimize,1024,"FastCover Dictionary Builder. ### Permitted Arguments:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in=""; Output Dictionary (out=dictName): if not provided, default to fastCoverDict; Dictionary ID (dictID=#): nonnegative number; if not provided, default to 0; Maximum Dictionary Size (maxdict=#): positive number; in bytes, if not provided, default to 110KB; Size of Selected Segment (k=#): positive number; in bytes; if not provided, default to 200; Size of Dmer (d=#): either 6 or 8; if not provided, default to 8; Number of steps (steps=#): positive number, if not provided, default to 32; Percentage of samples used for training(split=#): positive number; if not provided, default to 100. ###Running Test:; make test. ###Usage:; To build a FASTCOVER dictionary with the provided arguments: make ARG= followed by arguments; If k or d is not provided, the optimize version of FASTCOVER is run. ### Examples:; make ARG=""in=../../../lib/dictBuilder out=dict100 dictID=520""; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress""; ",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/fastCover/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/fastCover/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/fastCover/README.md:882,Testability,test,test,882,"FastCover Dictionary Builder. ### Permitted Arguments:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in=""; Output Dictionary (out=dictName): if not provided, default to fastCoverDict; Dictionary ID (dictID=#): nonnegative number; if not provided, default to 0; Maximum Dictionary Size (maxdict=#): positive number; in bytes, if not provided, default to 110KB; Size of Selected Segment (k=#): positive number; in bytes; if not provided, default to 200; Size of Dmer (d=#): either 6 or 8; if not provided, default to 8; Number of steps (steps=#): positive number, if not provided, default to 32; Percentage of samples used for training(split=#): positive number; if not provided, default to 100. ###Running Test:; make test. ###Usage:; To build a FASTCOVER dictionary with the provided arguments: make ARG= followed by arguments; If k or d is not provided, the optimize version of FASTCOVER is run. ### Examples:; make ARG=""in=../../../lib/dictBuilder out=dict100 dictID=520""; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress""; ",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/fastCover/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/fastCover/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/randomDictBuilder/README.md:644,Testability,test,test,644,"Random Dictionary Builder. ### Permitted Arguments:; Input File/Directory (in=fileName): required; file/directory used to build dictionary; if directory, will operate recursively for files inside directory; can include multiple files/directories, each following ""in=""; Output Dictionary (out=dictName): if not provided, default to defaultDict; Dictionary ID (dictID=#): nonnegative number; if not provided, default to 0; Maximum Dictionary Size (maxdict=#): positive number; in bytes, if not provided, default to 110KB; Size of Randomly Selected Segment (k=#): positive number; in bytes; if not provided, default to 200. ###Running Test:; make test. ###Usage:; To build a random dictionary with the provided arguments: make ARG= followed by arguments. ### Examples:; make ARG=""in=../../../lib/dictBuilder out=dict100 dictID=520""; make ARG=""in=../../../lib/dictBuilder in=../../../lib/compress""; ",MatchSource.DOCS,lib/zstd/contrib/experimental_dict_builders/randomDictBuilder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/contrib/experimental_dict_builders/randomDictBuilder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md:280,Security,checksum,checksums,280,"Educational Decoder; ===================. `zstd_decompress.c` is a self-contained implementation in C99 of a decoder,; according to the [Zstandard format specification].; While it does not implement as many features as the reference decoder,; such as the streaming API or content checksums, it is written to be easy to; follow and understand, to help understand how the Zstandard format works.; It's laid out to match the [format specification],; so it can be used to understand how complex segments could be implemented.; It also contains implementations of Huffman and FSE table decoding. [Zstandard format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md; [format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md. `harness.c` provides a simple test harness around the decoder:. harness <input-file> <output-file> [dictionary]. As an additional resource to be used with this decoder,; see the `decodecorpus` tool in the [tests] directory.; It generates valid Zstandard frames that can be used to verify; a Zstandard decoder implementation.; Note that to use the tool to verify this decoder implementation,; the --content-size flag should be set,; as this decoder does not handle streaming decoding,; and so it must know the decompressed size in advance. [tests]: https://github.com/facebook/zstd/blob/dev/tests/; ",MatchSource.DOCS,lib/zstd/doc/educational_decoder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md:827,Testability,test,test,827,"Educational Decoder; ===================. `zstd_decompress.c` is a self-contained implementation in C99 of a decoder,; according to the [Zstandard format specification].; While it does not implement as many features as the reference decoder,; such as the streaming API or content checksums, it is written to be easy to; follow and understand, to help understand how the Zstandard format works.; It's laid out to match the [format specification],; so it can be used to understand how complex segments could be implemented.; It also contains implementations of Huffman and FSE table decoding. [Zstandard format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md; [format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md. `harness.c` provides a simple test harness around the decoder:. harness <input-file> <output-file> [dictionary]. As an additional resource to be used with this decoder,; see the `decodecorpus` tool in the [tests] directory.; It generates valid Zstandard frames that can be used to verify; a Zstandard decoder implementation.; Note that to use the tool to verify this decoder implementation,; the --content-size flag should be set,; as this decoder does not handle streaming decoding,; and so it must know the decompressed size in advance. [tests]: https://github.com/facebook/zstd/blob/dev/tests/; ",MatchSource.DOCS,lib/zstd/doc/educational_decoder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md:1003,Testability,test,tests,1003,"Educational Decoder; ===================. `zstd_decompress.c` is a self-contained implementation in C99 of a decoder,; according to the [Zstandard format specification].; While it does not implement as many features as the reference decoder,; such as the streaming API or content checksums, it is written to be easy to; follow and understand, to help understand how the Zstandard format works.; It's laid out to match the [format specification],; so it can be used to understand how complex segments could be implemented.; It also contains implementations of Huffman and FSE table decoding. [Zstandard format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md; [format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md. `harness.c` provides a simple test harness around the decoder:. harness <input-file> <output-file> [dictionary]. As an additional resource to be used with this decoder,; see the `decodecorpus` tool in the [tests] directory.; It generates valid Zstandard frames that can be used to verify; a Zstandard decoder implementation.; Note that to use the tool to verify this decoder implementation,; the --content-size flag should be set,; as this decoder does not handle streaming decoding,; and so it must know the decompressed size in advance. [tests]: https://github.com/facebook/zstd/blob/dev/tests/; ",MatchSource.DOCS,lib/zstd/doc/educational_decoder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md:1337,Testability,test,tests,1337,"Educational Decoder; ===================. `zstd_decompress.c` is a self-contained implementation in C99 of a decoder,; according to the [Zstandard format specification].; While it does not implement as many features as the reference decoder,; such as the streaming API or content checksums, it is written to be easy to; follow and understand, to help understand how the Zstandard format works.; It's laid out to match the [format specification],; so it can be used to understand how complex segments could be implemented.; It also contains implementations of Huffman and FSE table decoding. [Zstandard format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md; [format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md. `harness.c` provides a simple test harness around the decoder:. harness <input-file> <output-file> [dictionary]. As an additional resource to be used with this decoder,; see the `decodecorpus` tool in the [tests] directory.; It generates valid Zstandard frames that can be used to verify; a Zstandard decoder implementation.; Note that to use the tool to verify this decoder implementation,; the --content-size flag should be set,; as this decoder does not handle streaming decoding,; and so it must know the decompressed size in advance. [tests]: https://github.com/facebook/zstd/blob/dev/tests/; ",MatchSource.DOCS,lib/zstd/doc/educational_decoder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md:1387,Testability,test,tests,1387,"Educational Decoder; ===================. `zstd_decompress.c` is a self-contained implementation in C99 of a decoder,; according to the [Zstandard format specification].; While it does not implement as many features as the reference decoder,; such as the streaming API or content checksums, it is written to be easy to; follow and understand, to help understand how the Zstandard format works.; It's laid out to match the [format specification],; so it can be used to understand how complex segments could be implemented.; It also contains implementations of Huffman and FSE table decoding. [Zstandard format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md; [format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md. `harness.c` provides a simple test harness around the decoder:. harness <input-file> <output-file> [dictionary]. As an additional resource to be used with this decoder,; see the `decodecorpus` tool in the [tests] directory.; It generates valid Zstandard frames that can be used to verify; a Zstandard decoder implementation.; Note that to use the tool to verify this decoder implementation,; the --content-size flag should be set,; as this decoder does not handle streaming decoding,; and so it must know the decompressed size in advance. [tests]: https://github.com/facebook/zstd/blob/dev/tests/; ",MatchSource.DOCS,lib/zstd/doc/educational_decoder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md:820,Usability,simpl,simple,820,"Educational Decoder; ===================. `zstd_decompress.c` is a self-contained implementation in C99 of a decoder,; according to the [Zstandard format specification].; While it does not implement as many features as the reference decoder,; such as the streaming API or content checksums, it is written to be easy to; follow and understand, to help understand how the Zstandard format works.; It's laid out to match the [format specification],; so it can be used to understand how complex segments could be implemented.; It also contains implementations of Huffman and FSE table decoding. [Zstandard format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md; [format specification]: https://github.com/facebook/zstd/blob/dev/doc/zstd_compression_format.md. `harness.c` provides a simple test harness around the decoder:. harness <input-file> <output-file> [dictionary]. As an additional resource to be used with this decoder,; see the `decodecorpus` tool in the [tests] directory.; It generates valid Zstandard frames that can be used to verify; a Zstandard decoder implementation.; Note that to use the tool to verify this decoder implementation,; the --content-size flag should be set,; as this decoder does not handle streaming decoding,; and so it must know the decompressed size in advance. [tests]: https://github.com/facebook/zstd/blob/dev/tests/; ",MatchSource.DOCS,lib/zstd/doc/educational_decoder/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/educational_decoder/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:1922,Availability,avail,available,1922,"y compression benchmark module with compression; levels starting from `-b` and ending with `-e` with iteration time of `-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic ZSTD libraries with Visual C++. Open `example\fullbench-dll.sln` to compile `fullbench-dll` that uses a; dynamic ZSTD library from the `dll` directory. The solution works with Visual C++; 2010 or newer. When one will open the solution with Visual C++ newer than 2010; then the solution will upgraded to the current version. #### Using ZSTD DLL with Visual C++. The header files from `include\` and the import library `dll\libzstd.lib`; are required to compile a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in project properties `C/C++` then `General`.; 2. The import library has to be added to `Additional Dependencies` that can; be found in project properties `Linker` then `Input`.; If one will provide only the name `libzstd.lib` without a full path to the library; the directory has to be added to `Linker\General\Ad",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:2989,Availability,avail,available,2989,"-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic ZSTD libraries with Visual C++. Open `example\fullbench-dll.sln` to compile `fullbench-dll` that uses a; dynamic ZSTD library from the `dll` directory. The solution works with Visual C++; 2010 or newer. When one will open the solution with Visual C++ newer than 2010; then the solution will upgraded to the current version. #### Using ZSTD DLL with Visual C++. The header files from `include\` and the import library `dll\libzstd.lib`; are required to compile a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in project properties `C/C++` then `General`.; 2. The import library has to be added to `Additional Dependencies` that can; be found in project properties `Linker` then `Input`.; If one will provide only the name `libzstd.lib` without a full path to the library; the directory has to be added to `Linker\General\Additional Library Directories`. The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`.; ",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:2293,Deployability,upgrade,upgraded,2293,"-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic ZSTD libraries with Visual C++. Open `example\fullbench-dll.sln` to compile `fullbench-dll` that uses a; dynamic ZSTD library from the `dll` directory. The solution works with Visual C++; 2010 or newer. When one will open the solution with Visual C++ newer than 2010; then the solution will upgraded to the current version. #### Using ZSTD DLL with Visual C++. The header files from `include\` and the import library `dll\libzstd.lib`; are required to compile a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in project properties `C/C++` then `General`.; 2. The import library has to be added to `Additional Dependencies` that can; be found in project properties `Linker` then `Input`.; If one will provide only the name `libzstd.lib` without a full path to the library; the directory has to be added to `Linker\General\Additional Library Directories`. The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`.; ",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:916,Testability,benchmark,benchmark,916,"ZSTD Windows binary package; ====================================. #### The package contents. - `zstd.exe` : Command Line Utility, supporting gzip-like arguments; - `dll\libzstd.dll` : The ZSTD dynamic library (DLL); - `dll\libzstd.lib` : The import library of the ZSTD dynamic library (DLL) for Visual C++; - `example\` : The example of usage of the ZSTD library; - `include\` : Header files required by the ZSTD library; - `static\libzstd_static.lib` : The static ZSTD library (LIB). #### Usage of Command Line Interface. Command Line Interface (CLI) supports gzip-like arguments.; By default CLI takes an input file and compresses it to an output file:; ```; Usage: zstd [arg] [input] [output]; ```; The full list of commands for CLI can be obtained with `-h` or `-H`. The ratio can; be improved with commands from `-3` to `-16` but higher levels also have slower; compression. CLI includes in-memory compression benchmark module with compression; levels starting from `-b` and ending with `-e` with iteration time of `-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:1716,Testability,test,test-dll,1716," [output]; ```; The full list of commands for CLI can be obtained with `-h` or `-H`. The ratio can; be improved with commands from `-3` to `-16` but higher levels also have slower; compression. CLI includes in-memory compression benchmark module with compression; levels starting from `-b` and ending with `-e` with iteration time of `-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic ZSTD libraries with Visual C++. Open `example\fullbench-dll.sln` to compile `fullbench-dll` that uses a; dynamic ZSTD library from the `dll` directory. The solution works with Visual C++; 2010 or newer. When one will open the solution with Visual C++ newer than 2010; then the solution will upgraded to the current version. #### Using ZSTD DLL with Visual C++. The header files from `include\` and the import library `dll\libzstd.lib`; are required to compile a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in project properties `C/C++` then `General`.; 2. The import library has to be added to `Additional",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:1822,Testability,test,test-dll,1822,"commands from `-3` to `-16` but higher levels also have slower; compression. CLI includes in-memory compression benchmark module with compression; levels starting from `-b` and ending with `-e` with iteration time of `-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic ZSTD libraries with Visual C++. Open `example\fullbench-dll.sln` to compile `fullbench-dll` that uses a; dynamic ZSTD library from the `dll` directory. The solution works with Visual C++; 2010 or newer. When one will open the solution with Visual C++ newer than 2010; then the solution will upgraded to the current version. #### Using ZSTD DLL with Visual C++. The header files from `include\` and the import library `dll\libzstd.lib`; are required to compile a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in project properties `C/C++` then `General`.; 2. The import library has to be added to `Additional Dependencies` that can; be found in project properties `Linker` then `Input`.; If one will provide only the name `l",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md:1836,Testability,test,test-dll,1836,"evels also have slower; compression. CLI includes in-memory compression benchmark module with compression; levels starting from `-b` and ending with `-e` with iteration time of `-i` seconds.; CLI supports aggregation of parameters i.e. `-b1`, `-e18`, and `-i1` can be joined; into `-b1e18i1`. #### The example of usage of static and dynamic ZSTD libraries with gcc/MinGW. Use `cd example` and `make` to build `fullbench-dll` and `fullbench-lib`.; `fullbench-dll` uses a dynamic ZSTD library from the `dll` directory.; `fullbench-lib` uses a static ZSTD library from the `lib` directory. #### Using ZSTD DLL with gcc/MinGW. The header files from `include\` and the dynamic library `dll\libzstd.dll`; are required to compile a project using gcc/MinGW.; The dynamic library has to be added to linking options.; It means that if a project that uses ZSTD consists of a single `test-dll.c`; file it should be linked with `dll\libzstd.dll`. For example:; ```; gcc $(CFLAGS) -Iinclude\ test-dll.c -o test-dll dll\libzstd.dll; ```; The compiled executable will require ZSTD DLL which is available at `dll\libzstd.dll`. #### The example of usage of static and dynamic ZSTD libraries with Visual C++. Open `example\fullbench-dll.sln` to compile `fullbench-dll` that uses a; dynamic ZSTD library from the `dll` directory. The solution works with Visual C++; 2010 or newer. When one will open the solution with Visual C++ newer than 2010; then the solution will upgraded to the current version. #### Using ZSTD DLL with Visual C++. The header files from `include\` and the import library `dll\libzstd.lib`; are required to compile a project using Visual C++. 1. The path to header files should be added to `Additional Include Directories` that can; be found in project properties `C/C++` then `General`.; 2. The import library has to be added to `Additional Dependencies` that can; be found in project properties `Linker` then `Input`.; If one will provide only the name `libzstd.lib` without a full path to the l",MatchSource.DOCS,lib/zstd/lib/dll/example/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/lib/dll/example/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:124,Availability,down,downloaded,124,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:187,Availability,down,download,187,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:653,Modifiability,config,configured,653,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:774,Modifiability,variab,variables,774,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:822,Modifiability,variab,variables,822,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:2233,Modifiability,variab,variables,2233,", the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=4; ```. where `TARGET` could be `simple_decompress`, `stream_round_trip`, etc. ### MSAN. Fuzzing with `libFuzzer` and `MSAN` will require building a C++ standard library; and libFuzzer with MSAN.; `fuzz.py` respects the environment variables / flags `MSAN_EXTRA_CPPFLAGS`,; `MSAN_EXTRA_CFLAGS`, `MSAN_EXTRA_CXXFLAGS`, `MSAN_EXTRA_LDFLAGS` to easily pass; the extra parameters only for MSAN. ## AFL. The default `LIB_FUZZING_ENGINE` is `libregression.a`, which produces a binary; that AFL can use. ```; # Build the fuzz targets; CC=afl-clang CXX=afl-clang++ ./fuzz.py build all --enable-asan --enable-ubsan; # Run the fuzzer without a memory limit because of ASAN; ./fuzz.py afl TARGET -m none; ```. ## Regression Testing. The regression rest supports the `all` target to run all the fuzzers in one; command. ```; CC=clang CXX=clang++ ./fuzz.py build all --enable-asan --enable-ubsan; ./fuzz.py regression all; CC=clang CXX=clang++ ./fuzz.py build all --enable-msan; ./fuzz.py regression all; ```; ",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:1071,Security,sanitiz,sanitizers,1071,"s for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=4; ```. where `TARGET` could be `simple_decompress`, `stream_round_trip`, etc. ### MSAN. Fuzzi",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:509,Testability,test,tests,509,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:697,Testability,log,log,697,"# Fuzzing. Each fuzzing target can be built with multiple engines.; Zstd provides a fuzz corpus for each target that can be downloaded with; the command:. ```; make corpora; ```. It will download each corpus into `./corpora/TARGET`. ## fuzz.py. `fuzz.py` is a helper script for building and running fuzzers.; Run `./fuzz.py -h` for the commands and run `./fuzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md:1379,Testability,test,tests,1379,"uzz.py COMMAND -h` for; command specific help. ### Generating Data. `fuzz.py` provides a utility to generate seed data for each fuzzer. ```; make -C ../tests decodecorpus; ./fuzz.py gen TARGET; ```. By default it outputs 100 samples, each at most 8KB into `corpora/TARGET-seed`,; but that can be configured with the `--number`, `--max-size-log` and `--seed`; flags. ### Build; It respects the usual build environment variables `CC`, `CFLAGS`, etc.; The environment variables can be overridden with the corresponding flags; `--cc`, `--cflags`, etc.; The specific fuzzing engine is selected with `LIB_FUZZING_ENGINE` or; `--lib-fuzzing-engine`, the default is `libregression.a`.; It has flags that can easily set up sanitizers `--enable-{a,ub,m}san`, and; coverage instrumentation `--enable-coverage`.; It sets sane defaults which can be overriden with flags `--debug`,; `--enable-ubsan-pointer-overlow`, etc.; Run `./fuzz.py build -h` for help. ### Running Fuzzers. `./fuzz.py` can run `libfuzzer`, `afl`, and `regression` tests.; See the help of the relevant command for options.; Flags not parsed by `fuzz.py` are passed to the fuzzing engine.; The command used to run the fuzzer is printed for debugging. ## LibFuzzer. ```; # Build libfuzzer if necessary; make libFuzzer; # Build the fuzz targets; ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan --lib-fuzzing-engine Fuzzer/libFuzzer.a --cc clang --cxx clang++; # OR equivalently; CC=clang CXX=clang++ LIB_FUZZING_ENGINE=Fuzzer/libFuzzer.a ./fuzz.py build all --enable-coverage --enable-asan --enable-ubsan; # Run the fuzzer; ./fuzz.py libfuzzer TARGET -max_len=8192 -jobs=4; ```. where `TARGET` could be `simple_decompress`, `stream_round_trip`, etc. ### MSAN. Fuzzing with `libFuzzer` and `MSAN` will require building a C++ standard library; and libFuzzer with MSAN.; `fuzz.py` respects the environment variables / flags `MSAN_EXTRA_CPPFLAGS`,; `MSAN_EXTRA_CFLAGS`, `MSAN_EXTRA_CXXFLAGS`, `MSAN_EXTRA_LDFLAGS` to easily pass; th",MatchSource.DOCS,lib/zstd/tests/fuzz/README.md,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/tests/fuzz/README.md
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:5637,Availability,error,errors,5637," results in profile search; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -fp-model precise""); endif (). # Apple specific features; if (APPLE); # macOS SDK started using _Atomic (in ucred.h) which g++ does not support; # __APPLE_API_STRICT_CONFORMANCE makes sysctl.h not include apis like ucred.h; # See: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=89864; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D__APPLE_API_STRICT_CONFORMANCE""); endif (). if (CMAKE_SYSTEM_NAME STREQUAL ""FreeBSD""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D_WITH_GETLINE""); endif (). if (CYGWIN); # default cygwin allocator (dlmalloc) locks on every allocation and destroys MT performance; add_subdirectory(lib/nedmalloc); # IPS4O seems to deadlock on cygwin; set(DISABLE_IPS4O 1); endif(). if ((CMAKE_CXX_COMPILER_ID STREQUAL ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""5.0.0""); OR (CMAKE_CXX_COMPILER_ID STREQUAL ""AppleClang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""9.1.0"")); # clang before v5 throws compile errors on ips4o; set(DISABLE_IPS4O 1); endif (). if (PPC64 OR SPARC OR ZARCH); # FIXME: investigate why on ppc the regression seems to fail randomly; set(DISABLE_IPS4O 1); endif (). set(MMSEQS_C_FLAGS ""${MMSEQS_CXX_FLAGS}""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -std=c++1y""); # Compiler-specific features; if (CMAKE_COMPILER_IS_CLANG AND (NOT EMSCRIPTEN)); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LANGUAGE_STANDARD ""c++11""); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LIBRARY ""libc++""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -stdlib=libc++""); endif (). if (USE_SYSTEM_ZSTD); include(FindPackageHandleStandardArgs); find_path(ZSTD_INCLUDE_DIRS NAMES zstd.h REQUIRED); # We use ZSTD_findDecompressedSize which is only available with ZSTD_STATIC_LINKING_ONLY; find_library(ZSTD_LIBRARIES NAMES libzstd.a libzstd_static REQUIRED); find_package_handle_standard_args(ZSTD DEFAULT_MSG ZSTD_LIBRARIES ZSTD_INCLUDE_DIRS); mark_as_advanced(ZSTD_LIBRARIES ZSTD_INCLUDE_DIRS); include_directories(${ZSTD_INCLUDE_DIRS});",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:6351,Availability,avail,available,6351,"on cygwin; set(DISABLE_IPS4O 1); endif(). if ((CMAKE_CXX_COMPILER_ID STREQUAL ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""5.0.0""); OR (CMAKE_CXX_COMPILER_ID STREQUAL ""AppleClang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""9.1.0"")); # clang before v5 throws compile errors on ips4o; set(DISABLE_IPS4O 1); endif (). if (PPC64 OR SPARC OR ZARCH); # FIXME: investigate why on ppc the regression seems to fail randomly; set(DISABLE_IPS4O 1); endif (). set(MMSEQS_C_FLAGS ""${MMSEQS_CXX_FLAGS}""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -std=c++1y""); # Compiler-specific features; if (CMAKE_COMPILER_IS_CLANG AND (NOT EMSCRIPTEN)); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LANGUAGE_STANDARD ""c++11""); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LIBRARY ""libc++""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -stdlib=libc++""); endif (). if (USE_SYSTEM_ZSTD); include(FindPackageHandleStandardArgs); find_path(ZSTD_INCLUDE_DIRS NAMES zstd.h REQUIRED); # We use ZSTD_findDecompressedSize which is only available with ZSTD_STATIC_LINKING_ONLY; find_library(ZSTD_LIBRARIES NAMES libzstd.a libzstd_static REQUIRED); find_package_handle_standard_args(ZSTD DEFAULT_MSG ZSTD_LIBRARIES ZSTD_INCLUDE_DIRS); mark_as_advanced(ZSTD_LIBRARIES ZSTD_INCLUDE_DIRS); include_directories(${ZSTD_INCLUDE_DIRS}); else (); # We use ZSTD_findDecompressedSize which is only available with ZSTD_STATIC_LINKING_ONLY; set(ZSTD_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/lib/zstd""); set(CMAKE_INSTALL_LIBDIR bin); set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_CURRENT_SOURCE_DIR}/lib/zstd/build/cmake/CMakeModules""); option(ZSTD_LEGACY_SUPPORT ""LEGACY SUPPORT"" OFF); option(ZSTD_BUILD_STATIC ""BUILD STATIC LIBRARIES"" ON); option(ZSTD_BUILD_SHARED ""BUILD SHARED LIBRARIES"" OFF); option(ZSTD_MULTITHREAD_SUPPORT ""MULTITHREADING SUPPORT"" OFF); option(ZSTD_BUILD_PROGRAMS ""BUILD PROGRAMS"" OFF); option(ZSTD_BUILD_CONTRIB ""BUILD CONTRIB"" OFF); option(ZSTD_BUILD_TESTS ""BUILD TESTS"" OFF); include_directories(lib/zstd/lib); add_subdirectory(l",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:6701,Availability,avail,available,6701,"set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LANGUAGE_STANDARD ""c++11""); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LIBRARY ""libc++""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -stdlib=libc++""); endif (). if (USE_SYSTEM_ZSTD); include(FindPackageHandleStandardArgs); find_path(ZSTD_INCLUDE_DIRS NAMES zstd.h REQUIRED); # We use ZSTD_findDecompressedSize which is only available with ZSTD_STATIC_LINKING_ONLY; find_library(ZSTD_LIBRARIES NAMES libzstd.a libzstd_static REQUIRED); find_package_handle_standard_args(ZSTD DEFAULT_MSG ZSTD_LIBRARIES ZSTD_INCLUDE_DIRS); mark_as_advanced(ZSTD_LIBRARIES ZSTD_INCLUDE_DIRS); include_directories(${ZSTD_INCLUDE_DIRS}); else (); # We use ZSTD_findDecompressedSize which is only available with ZSTD_STATIC_LINKING_ONLY; set(ZSTD_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/lib/zstd""); set(CMAKE_INSTALL_LIBDIR bin); set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_CURRENT_SOURCE_DIR}/lib/zstd/build/cmake/CMakeModules""); option(ZSTD_LEGACY_SUPPORT ""LEGACY SUPPORT"" OFF); option(ZSTD_BUILD_STATIC ""BUILD STATIC LIBRARIES"" ON); option(ZSTD_BUILD_SHARED ""BUILD SHARED LIBRARIES"" OFF); option(ZSTD_MULTITHREAD_SUPPORT ""MULTITHREADING SUPPORT"" OFF); option(ZSTD_BUILD_PROGRAMS ""BUILD PROGRAMS"" OFF); option(ZSTD_BUILD_CONTRIB ""BUILD CONTRIB"" OFF); option(ZSTD_BUILD_TESTS ""BUILD TESTS"" OFF); include_directories(lib/zstd/lib); add_subdirectory(lib/zstd/build/cmake/lib EXCLUDE_FROM_ALL); set_target_properties(libzstd_static PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); set(ZSTD_LIBRARIES libzstd_static); endif(). # tinyexpr; include_directories(lib/tinyexpr); add_subdirectory(lib/tinyexpr EXCLUDE_FROM_ALL). # microtar; include_directories(lib/microtar); add_subdirectory(lib/microtar). # simde; include_directories(lib/simde). include_directories(lib); include_directories(lib/simd); include_directories(lib/gzstream); include_directories(lib/alp); include_directories(lib/cacode); include_directories(lib/ksw2); include_directories(lib/xxhash);",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:75,Integrability,message,message,75,"cmake_minimum_required(VERSION 2.8.12 FATAL_ERROR); project(MMseqs CXX C); message(""-- Source Directory: ${CMAKE_CURRENT_SOURCE_DIR}""); message(""-- Project Directory: ${PROJECT_SOURCE_DIR}""); set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_CURRENT_SOURCE_DIR}/cmake""). set(FRAMEWORK_ONLY 0 CACHE BOOL ""Framework mode (don't create mmseqs executable)""); set(HAVE_SANITIZER 0 CACHE BOOL ""Have sanitizers""); set(INSTALL_UTIL 1 CACHE BOOL ""Install utility scripts""); set(VERSION_OVERRIDE """" CACHE STRING ""Override version string in help and usage messages""); set(DISABLE_IPS4O 0 CACHE BOOL ""Disabling IPS4O sorting library requiring 128-bit compare exchange operations""); set(HAVE_AVX2 0 CACHE BOOL ""Have CPU with AVX2""); set(HAVE_SSE4_1 0 CACHE BOOL ""Have CPU with SSE4.1""); set(HAVE_SSE2 0 CACHE BOOL ""Have CPU with SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_F",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:136,Integrability,message,message,136,"cmake_minimum_required(VERSION 2.8.12 FATAL_ERROR); project(MMseqs CXX C); message(""-- Source Directory: ${CMAKE_CURRENT_SOURCE_DIR}""); message(""-- Project Directory: ${PROJECT_SOURCE_DIR}""); set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_CURRENT_SOURCE_DIR}/cmake""). set(FRAMEWORK_ONLY 0 CACHE BOOL ""Framework mode (don't create mmseqs executable)""); set(HAVE_SANITIZER 0 CACHE BOOL ""Have sanitizers""); set(INSTALL_UTIL 1 CACHE BOOL ""Install utility scripts""); set(VERSION_OVERRIDE """" CACHE STRING ""Override version string in help and usage messages""); set(DISABLE_IPS4O 0 CACHE BOOL ""Disabling IPS4O sorting library requiring 128-bit compare exchange operations""); set(HAVE_AVX2 0 CACHE BOOL ""Have CPU with AVX2""); set(HAVE_SSE4_1 0 CACHE BOOL ""Have CPU with SSE4.1""); set(HAVE_SSE2 0 CACHE BOOL ""Have CPU with SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_F",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:547,Integrability,message,messages,547,"cmake_minimum_required(VERSION 2.8.12 FATAL_ERROR); project(MMseqs CXX C); message(""-- Source Directory: ${CMAKE_CURRENT_SOURCE_DIR}""); message(""-- Project Directory: ${PROJECT_SOURCE_DIR}""); set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_CURRENT_SOURCE_DIR}/cmake""). set(FRAMEWORK_ONLY 0 CACHE BOOL ""Framework mode (don't create mmseqs executable)""); set(HAVE_SANITIZER 0 CACHE BOOL ""Have sanitizers""); set(INSTALL_UTIL 1 CACHE BOOL ""Install utility scripts""); set(VERSION_OVERRIDE """" CACHE STRING ""Override version string in help and usage messages""); set(DISABLE_IPS4O 0 CACHE BOOL ""Disabling IPS4O sorting library requiring 128-bit compare exchange operations""); set(HAVE_AVX2 0 CACHE BOOL ""Have CPU with AVX2""); set(HAVE_SSE4_1 0 CACHE BOOL ""Have CPU with SSE4.1""); set(HAVE_SSE2 0 CACHE BOOL ""Have CPU with SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_F",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:1524,Integrability,message,message,1524,"""Disabling IPS4O sorting library requiring 128-bit compare exchange operations""); set(HAVE_AVX2 0 CACHE BOOL ""Have CPU with AVX2""); set(HAVE_SSE4_1 0 CACHE BOOL ""Have CPU with SSE4.1""); set(HAVE_SSE2 0 CACHE BOOL ""Have CPU with SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_FLAGS ""-fsigned-char""). # SIMD instruction sets support; set(MMSEQS_ARCH """"); if (HAVE_AVX2); if (CMAKE_COMPILER_IS_CLANG); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16""); else (); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16 -Wa,-q""); endif (); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE4_1); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse4.1 -mcx16""); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE2); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse2""); set(DISABLE_IPS4O 1); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_POWER9); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power9 -mvsx""); set(PPC64 1 CACHE IN",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:1640,Integrability,message,message,1640,"""Disabling IPS4O sorting library requiring 128-bit compare exchange operations""); set(HAVE_AVX2 0 CACHE BOOL ""Have CPU with AVX2""); set(HAVE_SSE4_1 0 CACHE BOOL ""Have CPU with SSE4.1""); set(HAVE_SSE2 0 CACHE BOOL ""Have CPU with SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_FLAGS ""-fsigned-char""). # SIMD instruction sets support; set(MMSEQS_ARCH """"); if (HAVE_AVX2); if (CMAKE_COMPILER_IS_CLANG); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16""); else (); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16 -Wa,-q""); endif (); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE4_1); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse4.1 -mcx16""); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE2); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse2""); set(DISABLE_IPS4O 1); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_POWER9); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power9 -mvsx""); set(PPC64 1 CACHE IN",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:1726,Integrability,message,message,1726,"ith SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_FLAGS ""-fsigned-char""). # SIMD instruction sets support; set(MMSEQS_ARCH """"); if (HAVE_AVX2); if (CMAKE_COMPILER_IS_CLANG); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16""); else (); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16 -Wa,-q""); endif (); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE4_1); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse4.1 -mcx16""); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE2); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse2""); set(DISABLE_IPS4O 1); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_POWER9); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power9 -mvsx""); set(PPC64 1 CACHE INTERNAL """"); elseif (HAVE_POWER8); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power8 -mvsx""); set(PPC64 1 CACHE INTERNAL """"); elseif (HAVE_ARM8); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -march=armv8-a+simd""); set(ARM 1 CACHE INTERNAL """")",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:1833,Integrability,message,message,1833,"ith SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_FLAGS ""-fsigned-char""). # SIMD instruction sets support; set(MMSEQS_ARCH """"); if (HAVE_AVX2); if (CMAKE_COMPILER_IS_CLANG); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16""); else (); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mavx2 -mcx16 -Wa,-q""); endif (); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE4_1); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse4.1 -mcx16""); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE2); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse2""); set(DISABLE_IPS4O 1); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_POWER9); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power9 -mvsx""); set(PPC64 1 CACHE INTERNAL """"); elseif (HAVE_POWER8); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power8 -mvsx""); set(PPC64 1 CACHE INTERNAL """"); elseif (HAVE_ARM8); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -march=armv8-a+simd""); set(ARM 1 CACHE INTERNAL """")",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:3531,Integrability,message,message,3531,"EQS_ARCH} -msse4.1 -mcx16""); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_SSE2); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -msse2""); set(DISABLE_IPS4O 1); set(X64 1 CACHE INTERNAL """"); elseif (HAVE_POWER9); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power9 -mvsx""); set(PPC64 1 CACHE INTERNAL """"); elseif (HAVE_POWER8); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -mcpu=power8 -mvsx""); set(PPC64 1 CACHE INTERNAL """"); elseif (HAVE_ARM8); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -march=armv8-a+simd""); set(ARM 1 CACHE INTERNAL """"); elseif (HAVE_S390X); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -march=z14 -mzarch -mzvector""); set(ZARCH 1 CACHE INTERNAL """"); endif (). if (NATIVE_ARCH AND (MMSEQS_ARCH STREQUAL """")); if (CMAKE_SYSTEM_PROCESSOR MATCHES ""^(arm.*|ARM.*|aarch64.*|AARCH64.*)""); set(ARM 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""PPC64*|ppc64*|powerpc64*""); set(PPC64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""amd64|AMD64""); set(X64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""x86|X86""); set(X86 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^s390""); set(ZARCH 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^sparc""); set(SPARC 1 CACHE INTERNAL """"); else (); message(WARNING ""CPU without native SIMD instructions. Performance will be bad.""); endif (); if (EMSCRIPTEN); set(MMSEQS_ARCH ""-msimd128 -s WASM=1 -s ASSERTIONS=1""); elseif (X86 OR X64); include(CheckSSEFeatures); if (NOT HAVE_SSE4_1_EXTENSIONS); if (NOT HAVE_SSE2_EXTENSIONS); message(FATAL_ERROR ""At least SSE2 is needed to compile""); endif (); message(WARNING ""At least SSE4.1 is needed for best performance""); endif (); # clang has a problem with march=native on travis; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.0.0""); set(MMSEQS_ARCH ""${SSE_FLAGS}""); else(); set(MMSEQS_ARCH ""-march=native""); endif(); elseif (PPC64 OR ARM); set(MMSEQS_ARCH ""-mcpu=native""); elseif (ZARCH); set(MMSEQS_ARCH ""-mcpu=native -mzvector""); else (); set(MMSEQS_A",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:3809,Integrability,message,message,3809,"CH} -march=armv8-a+simd""); set(ARM 1 CACHE INTERNAL """"); elseif (HAVE_S390X); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -march=z14 -mzarch -mzvector""); set(ZARCH 1 CACHE INTERNAL """"); endif (). if (NATIVE_ARCH AND (MMSEQS_ARCH STREQUAL """")); if (CMAKE_SYSTEM_PROCESSOR MATCHES ""^(arm.*|ARM.*|aarch64.*|AARCH64.*)""); set(ARM 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""PPC64*|ppc64*|powerpc64*""); set(PPC64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""amd64|AMD64""); set(X64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""x86|X86""); set(X86 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^s390""); set(ZARCH 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^sparc""); set(SPARC 1 CACHE INTERNAL """"); else (); message(WARNING ""CPU without native SIMD instructions. Performance will be bad.""); endif (); if (EMSCRIPTEN); set(MMSEQS_ARCH ""-msimd128 -s WASM=1 -s ASSERTIONS=1""); elseif (X86 OR X64); include(CheckSSEFeatures); if (NOT HAVE_SSE4_1_EXTENSIONS); if (NOT HAVE_SSE2_EXTENSIONS); message(FATAL_ERROR ""At least SSE2 is needed to compile""); endif (); message(WARNING ""At least SSE4.1 is needed for best performance""); endif (); # clang has a problem with march=native on travis; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.0.0""); set(MMSEQS_ARCH ""${SSE_FLAGS}""); else(); set(MMSEQS_ARCH ""-march=native""); endif(); elseif (PPC64 OR ARM); set(MMSEQS_ARCH ""-mcpu=native""); elseif (ZARCH); set(MMSEQS_ARCH ""-mcpu=native -mzvector""); else (); set(MMSEQS_ARCH ""-march=native""); endif (); endif (). if (NOT (MMSEQS_ARCH STREQUAL """")); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} ${MMSEQS_ARCH}""); endif (). if (CYGWIN OR ARM OR PPC64); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D_GNU_SOURCE=1""); endif (). if (CMAKE_COMPILER_IS_ICC); # default -fp-model results in inconsistent results in profile search; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -fp-model precise""); endif (). # Apple specific f",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:3878,Integrability,message,message,3878,"CH} -march=armv8-a+simd""); set(ARM 1 CACHE INTERNAL """"); elseif (HAVE_S390X); set(MMSEQS_ARCH ""${MMSEQS_ARCH} -march=z14 -mzarch -mzvector""); set(ZARCH 1 CACHE INTERNAL """"); endif (). if (NATIVE_ARCH AND (MMSEQS_ARCH STREQUAL """")); if (CMAKE_SYSTEM_PROCESSOR MATCHES ""^(arm.*|ARM.*|aarch64.*|AARCH64.*)""); set(ARM 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""PPC64*|ppc64*|powerpc64*""); set(PPC64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""amd64|AMD64""); set(X64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""x86|X86""); set(X86 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^s390""); set(ZARCH 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^sparc""); set(SPARC 1 CACHE INTERNAL """"); else (); message(WARNING ""CPU without native SIMD instructions. Performance will be bad.""); endif (); if (EMSCRIPTEN); set(MMSEQS_ARCH ""-msimd128 -s WASM=1 -s ASSERTIONS=1""); elseif (X86 OR X64); include(CheckSSEFeatures); if (NOT HAVE_SSE4_1_EXTENSIONS); if (NOT HAVE_SSE2_EXTENSIONS); message(FATAL_ERROR ""At least SSE2 is needed to compile""); endif (); message(WARNING ""At least SSE4.1 is needed for best performance""); endif (); # clang has a problem with march=native on travis; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.0.0""); set(MMSEQS_ARCH ""${SSE_FLAGS}""); else(); set(MMSEQS_ARCH ""-march=native""); endif(); elseif (PPC64 OR ARM); set(MMSEQS_ARCH ""-mcpu=native""); elseif (ZARCH); set(MMSEQS_ARCH ""-mcpu=native -mzvector""); else (); set(MMSEQS_ARCH ""-march=native""); endif (); endif (). if (NOT (MMSEQS_ARCH STREQUAL """")); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} ${MMSEQS_ARCH}""); endif (). if (CYGWIN OR ARM OR PPC64); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D_GNU_SOURCE=1""); endif (). if (CMAKE_COMPILER_IS_ICC); # default -fp-model results in inconsistent results in profile search; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -fp-model precise""); endif (). # Apple specific f",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:3930,Performance,perform,performance,3930,"YSTEM_PROCESSOR MATCHES ""^(arm.*|ARM.*|aarch64.*|AARCH64.*)""); set(ARM 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""PPC64*|ppc64*|powerpc64*""); set(PPC64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""amd64|AMD64""); set(X64 1 CACHE INTERNAL """"); elseif (CMAKE_SYSTEM_PROCESSOR MATCHES ""x86|X86""); set(X86 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^s390""); set(ZARCH 1 CACHE INTERNAL """"); elseif(CMAKE_SYSTEM_PROCESSOR MATCHES ""^sparc""); set(SPARC 1 CACHE INTERNAL """"); else (); message(WARNING ""CPU without native SIMD instructions. Performance will be bad.""); endif (); if (EMSCRIPTEN); set(MMSEQS_ARCH ""-msimd128 -s WASM=1 -s ASSERTIONS=1""); elseif (X86 OR X64); include(CheckSSEFeatures); if (NOT HAVE_SSE4_1_EXTENSIONS); if (NOT HAVE_SSE2_EXTENSIONS); message(FATAL_ERROR ""At least SSE2 is needed to compile""); endif (); message(WARNING ""At least SSE4.1 is needed for best performance""); endif (); # clang has a problem with march=native on travis; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.0.0""); set(MMSEQS_ARCH ""${SSE_FLAGS}""); else(); set(MMSEQS_ARCH ""-march=native""); endif(); elseif (PPC64 OR ARM); set(MMSEQS_ARCH ""-mcpu=native""); elseif (ZARCH); set(MMSEQS_ARCH ""-mcpu=native -mzvector""); else (); set(MMSEQS_ARCH ""-march=native""); endif (); endif (). if (NOT (MMSEQS_ARCH STREQUAL """")); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} ${MMSEQS_ARCH}""); endif (). if (CYGWIN OR ARM OR PPC64); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D_GNU_SOURCE=1""); endif (). if (CMAKE_COMPILER_IS_ICC); # default -fp-model results in inconsistent results in profile search; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -fp-model precise""); endif (). # Apple specific features; if (APPLE); # macOS SDK started using _Atomic (in ucred.h) which g++ does not support; # __APPLE_API_STRICT_CONFORMANCE makes sysctl.h not include apis like ucred.h; # See: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=89864; set(MMSE",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:5289,Performance,perform,performance,5289,"); else (); set(MMSEQS_ARCH ""-march=native""); endif (); endif (). if (NOT (MMSEQS_ARCH STREQUAL """")); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} ${MMSEQS_ARCH}""); endif (). if (CYGWIN OR ARM OR PPC64); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D_GNU_SOURCE=1""); endif (). if (CMAKE_COMPILER_IS_ICC); # default -fp-model results in inconsistent results in profile search; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -fp-model precise""); endif (). # Apple specific features; if (APPLE); # macOS SDK started using _Atomic (in ucred.h) which g++ does not support; # __APPLE_API_STRICT_CONFORMANCE makes sysctl.h not include apis like ucred.h; # See: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=89864; set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D__APPLE_API_STRICT_CONFORMANCE""); endif (). if (CMAKE_SYSTEM_NAME STREQUAL ""FreeBSD""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -D_WITH_GETLINE""); endif (). if (CYGWIN); # default cygwin allocator (dlmalloc) locks on every allocation and destroys MT performance; add_subdirectory(lib/nedmalloc); # IPS4O seems to deadlock on cygwin; set(DISABLE_IPS4O 1); endif(). if ((CMAKE_CXX_COMPILER_ID STREQUAL ""Clang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""5.0.0""); OR (CMAKE_CXX_COMPILER_ID STREQUAL ""AppleClang"" AND CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""9.1.0"")); # clang before v5 throws compile errors on ips4o; set(DISABLE_IPS4O 1); endif (). if (PPC64 OR SPARC OR ZARCH); # FIXME: investigate why on ppc the regression seems to fail randomly; set(DISABLE_IPS4O 1); endif (). set(MMSEQS_C_FLAGS ""${MMSEQS_CXX_FLAGS}""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -std=c++1y""); # Compiler-specific features; if (CMAKE_COMPILER_IS_CLANG AND (NOT EMSCRIPTEN)); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LANGUAGE_STANDARD ""c++11""); set(CMAKE_XCODE_ATTRIBUTE_CLANG_CXX_LIBRARY ""libc++""); set(MMSEQS_CXX_FLAGS ""${MMSEQS_CXX_FLAGS} -stdlib=libc++""); endif (). if (USE_SYSTEM_ZSTD); include(FindPackageHandleStandardArgs); find_path(ZSTD_INCLUDE_DIRS NAMES zstd.h REQUIRED",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt:395,Security,sanitiz,sanitizers,395,"cmake_minimum_required(VERSION 2.8.12 FATAL_ERROR); project(MMseqs CXX C); message(""-- Source Directory: ${CMAKE_CURRENT_SOURCE_DIR}""); message(""-- Project Directory: ${PROJECT_SOURCE_DIR}""); set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_CURRENT_SOURCE_DIR}/cmake""). set(FRAMEWORK_ONLY 0 CACHE BOOL ""Framework mode (don't create mmseqs executable)""); set(HAVE_SANITIZER 0 CACHE BOOL ""Have sanitizers""); set(INSTALL_UTIL 1 CACHE BOOL ""Install utility scripts""); set(VERSION_OVERRIDE """" CACHE STRING ""Override version string in help and usage messages""); set(DISABLE_IPS4O 0 CACHE BOOL ""Disabling IPS4O sorting library requiring 128-bit compare exchange operations""); set(HAVE_AVX2 0 CACHE BOOL ""Have CPU with AVX2""); set(HAVE_SSE4_1 0 CACHE BOOL ""Have CPU with SSE4.1""); set(HAVE_SSE2 0 CACHE BOOL ""Have CPU with SSE2""); set(HAVE_POWER9 0 CACHE BOOL ""Have POWER9 CPU""); set(HAVE_POWER8 0 CACHE BOOL ""Have POWER8 CPU""); set(HAVE_ARM8 0 CACHE BOOL ""Have ARMv8 CPU""); set(HAVE_S390X 0 CACHE BOOL ""Have s390x architecture""); set(NATIVE_ARCH 1 CACHE BOOL ""Assume native architecture for SIMD. Use one of the HAVE_* options or set CMAKE_CXX_FLAGS to the appropriate flags if you disable this.""); set(USE_SYSTEM_ZSTD 0 CACHE BOOL ""Use zstd provided by system instead of bundled version""). if (HAVE_SANITIZER); include(FindUBSan); include(FindASan); include(FindMSan); include(FindTSan); endif (). if (NOT CMAKE_BUILD_TYPE); set(CMAKE_BUILD_TYPE Release); endif (). # find compiler; if (CMAKE_CXX_COMPILER_ID MATCHES ""Clang""); message(""-- Compiler is clang(++)""); set(CMAKE_COMPILER_IS_CLANG 1); elseif (CMAKE_CXX_COMPILER_ID STREQUAL ""GNU""); message(""-- Compiler is GNU ""); if (CMAKE_CXX_COMPILER_VERSION VERSION_LESS ""4.9.0""); message(FATAL_ERROR ""Insufficient gcc version""); endif (); elseif (CMAKE_CXX_COMPILER_ID MATCHES ""Intel""); message(""-- Compiler is icc(++)""); set(CMAKE_COMPILER_IS_ICC 1); endif (). # see https://wiki.debian.org/ArchitectureSpecificsMemo for char signedness; set(MMSEQS_CXX_F",MatchSource.DOCS,CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:374,Availability,avail,availability,374,"set(HAVE_MPI 0 CACHE BOOL ""Have MPI""); set(HAVE_TESTS 0 CACHE BOOL ""Have Tests""); set(HAVE_SHELLCHECK 1 CACHE BOOL ""Have ShellCheck""); set(HAVE_GPROF 0 CACHE BOOL ""Have GPROF Profiler""); set(ENABLE_WERROR 0 CACHE BOOL ""Enable Warnings as Errors""); #set(DISABLE_LTO 0 CACHE BOOL ""Disable link-time optimization in non-debug builds""); set(REQUIRE_OPENMP 1 CACHE BOOL ""Require availability of OpenMP""). include(AppendTargetProperty). add_subdirectory(alignment); add_subdirectory(clustering); add_subdirectory(commons); add_subdirectory(linclust); add_subdirectory(multihit); add_subdirectory(prefiltering); add_subdirectory(taxonomy); add_subdirectory(util); add_subdirectory(workflow). add_library(mmseqs-framework; $<TARGET_OBJECTS:alp>; $<TARGET_OBJECTS:ksw2>; $<TARGET_OBJECTS:cacode>; ${alignment_header_files}; ${alignment_source_files}; ${clustering_header_files}; ${clustering_source_files}; ${commons_header_files}; ${commons_source_files}; ${prefiltering_header_files}; ${prefiltering_source_files}; ${multihit_header_files}; ${multihit_source_files}; ${taxonomy_header_files}; ${taxonomy_source_files}; ${linclust_source_files}; ${util_header_files}; ${util_source_files}; ${workflow_source_files}; CommandDeclarations.h; MMseqsBase.cpp; ). target_include_directories(mmseqs-framework PUBLIC ${CMAKE_BINARY_DIR}/generated); target_include_directories(mmseqs-framework PUBLIC ${PROJECT_BINARY_DIR}/generated); target_include_directories(mmseqs-framework PUBLIC alignment); target_include_directories(mmseqs-framework PUBLIC clustering); target_include_directories(mmseqs-framework PUBLIC commons); target_include_directories(mmseqs-framework PUBLIC multihit); target_include_directories(mmseqs-framework PUBLIC prefiltering); target_include_directories(mmseqs-framework PUBLIC linclust); target_include_directories(mmseqs-framework PUBLIC taxonomy); target_include_directories(mmseqs-framework PUBLIC util); target_include_directories(mmseqs-framework PUBLIC .). add_dependencies(mmseqs-framew",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:8692,Deployability,install,install,8692," if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework PUBLIC -DOPENMP=1); # For GCC we dont want to do this since it breaks macOS static builds; # It will link libgomp.a internally (through -fopenmp I guess); # and also link libgomp.dylib thus breaking static builds; if (NOT ""${CMAKE_CXX_COMPILER_ID}"" STREQUAL ""GNU""); target_link_libraries(mmseqs-framework ${OpenMP_CXX_LIBRARIES}); endif(); append_target_property(mmseqs-framework COMPILE_FLAGS ${OpenMP_CXX_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${OpenMP_CXX_FLAGS}); elseif (REQUIRE_OPENMP); message(FATAL_ERROR ""-- Could not find OpenMP. Skip check with -DREQUIRE_OPENMP=0.""); endif (). if (HAVE_GPROF); include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-pg GPROF_FOUND); if (GPROF_FOUND); append_target_property(mmseqs-framework COMPILE_FLAGS -pg); append_target_property(mmseqs-framework LINK_FLAGS -pg); else (); message(FATAL_ERROR ""-- Could not find GPROF""); endif (); endif (). if (NOT FRAMEWORK_ONLY); include(MMseqsSetupDerivedTarget); add_subdirectory(version); set(mmseqs_source_files mmseqs.cpp). add_executable(mmseqs${EXE_SUFFIX} ${mmseqs_source_files}); mmseqs_setup_derived_target(mmseqs${EXE_SUFFIX}); target_link_libraries(mmseqs${EXE_SUFFIX} version); install(TARGETS mmseqs${EXE_SUFFIX} DESTINATION bin). if (HAVE_TESTS); add_subdirectory(test); endif (); endif (); ",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:4163,Integrability,message,message,4163,"k_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main() {; FILE* tmpf = tmpfile();; void *tmp = mmap(NULL, 32, PROT_READ, MAP_SHARED, fileno(tmpf), 0);; int test = posix_madvise(tmp, 32, POSIX_MADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_MADVISE); if (HAVE_POSIX_MADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_MADVISE=1); endif (). if (NOT DISABLE_IPS4O); find_package(Atomic); if (ATOMIC_FOUND); target_link_libraries(mmseqs-framework ${ATOMIC_LIBRARIES}); target_compile_definitions(mmseqs-framework PUBLIC -DENABLE_IPS4O=1); message(""-- IPS4O sorting works""); else (); message(""-- OMPTL sorting fallback""); endif (); else (); message(""-- OMPTL sorting fallback""); endif (). target_link_libraries(mmseqs-framework tinyexpr ${ZSTD_LIBRARIES} microtar); if (CYGWIN); target_link_libraries(mmseqs-framework nedmalloc); endif (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compi",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:4207,Integrability,message,message,4207,"k_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main() {; FILE* tmpf = tmpfile();; void *tmp = mmap(NULL, 32, PROT_READ, MAP_SHARED, fileno(tmpf), 0);; int test = posix_madvise(tmp, 32, POSIX_MADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_MADVISE); if (HAVE_POSIX_MADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_MADVISE=1); endif (). if (NOT DISABLE_IPS4O); find_package(Atomic); if (ATOMIC_FOUND); target_link_libraries(mmseqs-framework ${ATOMIC_LIBRARIES}); target_compile_definitions(mmseqs-framework PUBLIC -DENABLE_IPS4O=1); message(""-- IPS4O sorting works""); else (); message(""-- OMPTL sorting fallback""); endif (); else (); message(""-- OMPTL sorting fallback""); endif (). target_link_libraries(mmseqs-framework tinyexpr ${ZSTD_LIBRARIES} microtar); if (CYGWIN); target_link_libraries(mmseqs-framework nedmalloc); endif (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compi",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:4264,Integrability,message,message,4264,"k_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main() {; FILE* tmpf = tmpfile();; void *tmp = mmap(NULL, 32, PROT_READ, MAP_SHARED, fileno(tmpf), 0);; int test = posix_madvise(tmp, 32, POSIX_MADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_MADVISE); if (HAVE_POSIX_MADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_MADVISE=1); endif (). if (NOT DISABLE_IPS4O); find_package(Atomic); if (ATOMIC_FOUND); target_link_libraries(mmseqs-framework ${ATOMIC_LIBRARIES}); target_compile_definitions(mmseqs-framework PUBLIC -DENABLE_IPS4O=1); message(""-- IPS4O sorting works""); else (); message(""-- OMPTL sorting fallback""); endif (); else (); message(""-- OMPTL sorting fallback""); endif (). target_link_libraries(mmseqs-framework tinyexpr ${ZSTD_LIBRARIES} microtar); if (CYGWIN); target_link_libraries(mmseqs-framework nedmalloc); endif (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compi",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:4781,Integrability,message,message,4781,"(tmpf);; return 0;; }""; HAVE_POSIX_MADVISE); if (HAVE_POSIX_MADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_MADVISE=1); endif (). if (NOT DISABLE_IPS4O); find_package(Atomic); if (ATOMIC_FOUND); target_link_libraries(mmseqs-framework ${ATOMIC_LIBRARIES}); target_compile_definitions(mmseqs-framework PUBLIC -DENABLE_IPS4O=1); message(""-- IPS4O sorting works""); else (); message(""-- OMPTL sorting fallback""); endif (); else (); message(""-- OMPTL sorting fallback""); endif (). target_link_libraries(mmseqs-framework tinyexpr ${ZSTD_LIBRARIES} microtar); if (CYGWIN); target_link_libraries(mmseqs-framework nedmalloc); endif (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compiles(""; #include <zlib.h>; int main() { gzFile file; return 0; }""; HAVE_ZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_ZLIB_CHECK); message(""-- ZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- ",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:5423,Integrability,message,message,5423,"f (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compiles(""; #include <zlib.h>; int main() { gzFile file; return 0; }""; HAVE_ZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_ZLIB_CHECK); message(""-- ZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); mess",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:5658,Integrability,message,message,5658,"f (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compiles(""; #include <zlib.h>; int main() { gzFile file; return 0; }""; HAVE_ZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_ZLIB_CHECK); message(""-- ZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); mess",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:5710,Integrability,message,message,5710,"f (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compiles(""; #include <zlib.h>; int main() { gzFile file; return 0; }""; HAVE_ZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_ZLIB_CHECK); message(""-- ZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); mess",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:5800,Integrability,message,message,5800,"RED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lz); set(CMAKE_REQUIRED_INCLUDES ${ZLIB_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${ZLIB_LIBRARIES}); check_cxx_source_compiles(""; #include <zlib.h>; int main() { gzFile file; return 0; }""; HAVE_ZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_ZLIB_CHECK); message(""-- ZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); message(""-- BZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${BZIP_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_BZLIB=1); target_link_libraries(mmseqs-framework ${BZIP2_LIBRARIES}); else (); message(""-- BZLIB does not work""); endif(); else (); message(""-- Could not find BZLIB""); endif (); endif (). # MPI; if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:6454,Integrability,message,message,6454," PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); message(""-- BZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${BZIP_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_BZLIB=1); target_link_libraries(mmseqs-framework ${BZIP2_LIBRARIES}); else (); message(""-- BZLIB does not work""); endif(); else (); message(""-- Could not find BZLIB""); endif (); endif (). # MPI; if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:6692,Integrability,message,message,6692," PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); message(""-- BZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${BZIP_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_BZLIB=1); target_link_libraries(mmseqs-framework ${BZIP2_LIBRARIES}); else (); message(""-- BZLIB does not work""); endif(); else (); message(""-- Could not find BZLIB""); endif (); endif (). # MPI; if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:6745,Integrability,message,message,6745," PUBLIC ${ZLIB_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1); target_link_libraries(mmseqs-framework ${ZLIB_LIBRARIES}); else (); message(""-- ZLIB does not work""); endif(); else (); message(""-- Could not find ZLIB""); endif (). find_package(BZip2 QUIET); if (BZIP2_FOUND); message(""-- Found BZLIB""); set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS}); set(OLD_CMAKE_REQUIRED_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); message(""-- BZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${BZIP_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_BZLIB=1); target_link_libraries(mmseqs-framework ${BZIP2_LIBRARIES}); else (); message(""-- BZLIB does not work""); endif(); else (); message(""-- Could not find BZLIB""); endif (); endif (). # MPI; if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:6867,Integrability,message,message,6867,"_INCLUDES ${CMAKE_REQUIRED_INCLUDES}); set(OLD_CMAKE_REQUIRED_LIBRARIES ${CMAKE_REQUIRED_LIBRARIES}); set(CMAKE_REQUIRED_FLAGS -lbz2); set(CMAKE_REQUIRED_INCLUDES ${BZIP_INCLUDE_DIRS}); set(CMAKE_REQUIRED_LIBRARIES ${BZIP2_LIBRARIES}); check_cxx_source_compiles(""; #include <bzlib.h>; int main() { bz_stream stream; return 0; }""; HAVE_BZLIB_CHECK); set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS}); set(CMAKE_REQUIRED_INCLUDES ${OLD_CMAKE_REQUIRED_INCLUDES}); set(CMAKE_REQUIRED_LIBRARIES ${OLD_CMAKE_REQUIRED_LIBRARIES}); if(HAVE_BZLIB_CHECK); message(""-- BZLIB works""); target_include_directories(mmseqs-framework PUBLIC ${BZIP_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_BZLIB=1); target_link_libraries(mmseqs-framework ${BZIP2_LIBRARIES}); else (); message(""-- BZLIB does not work""); endif(); else (); message(""-- Could not find BZLIB""); endif (); endif (). # MPI; if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework PUBLIC -DOPENMP=1); # For GCC we dont want to do this since it breaks macOS static builds; # It will link libgomp.a internally (through -fopenmp I guess); # and also link libgomp.dylib thus breaking static builds; if (NOT ""${CMAKE_CXX_COMPILER_ID}"" STREQUAL ""GNU""); target_link_libraries(mmseqs-framework ${OpenMP_CXX_LIBRARIES}); endif(); append_target_property(mmseqs-framework COMPILE_FLAGS ${OpenMP_CXX_FLA",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:7422,Integrability,message,message,7422,"lude_directories(mmseqs-framework PUBLIC ${BZIP_INCLUDE_DIRS}); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_BZLIB=1); target_link_libraries(mmseqs-framework ${BZIP2_LIBRARIES}); else (); message(""-- BZLIB does not work""); endif(); else (); message(""-- Could not find BZLIB""); endif (); endif (). # MPI; if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework PUBLIC -DOPENMP=1); # For GCC we dont want to do this since it breaks macOS static builds; # It will link libgomp.a internally (through -fopenmp I guess); # and also link libgomp.dylib thus breaking static builds; if (NOT ""${CMAKE_CXX_COMPILER_ID}"" STREQUAL ""GNU""); target_link_libraries(mmseqs-framework ${OpenMP_CXX_LIBRARIES}); endif(); append_target_property(mmseqs-framework COMPILE_FLAGS ${OpenMP_CXX_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${OpenMP_CXX_FLAGS}); elseif (REQUIRE_OPENMP); message(FATAL_ERROR ""-- Could not find OpenMP. Skip check with -DREQUIRE_OPENMP=0.""); endif (). if (HAVE_GPROF); include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-pg GPROF_FOUND); if (GPROF_FOUND); append_target_property(mmseqs-framework COMPILE_FLAGS -pg); append_target_property(mmseqs-framework LINK_FLAGS -pg); else (); message(FATAL_ERROR ""-- Could not find GPROF""); endif (); endif (). if (NOT FRAMEWORK_ONLY); include(MMseqsSetupDerivedTarget); add_subdirectory(version)",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:8008,Integrability,message,message,8008," if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework PUBLIC -DOPENMP=1); # For GCC we dont want to do this since it breaks macOS static builds; # It will link libgomp.a internally (through -fopenmp I guess); # and also link libgomp.dylib thus breaking static builds; if (NOT ""${CMAKE_CXX_COMPILER_ID}"" STREQUAL ""GNU""); target_link_libraries(mmseqs-framework ${OpenMP_CXX_LIBRARIES}); endif(); append_target_property(mmseqs-framework COMPILE_FLAGS ${OpenMP_CXX_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${OpenMP_CXX_FLAGS}); elseif (REQUIRE_OPENMP); message(FATAL_ERROR ""-- Could not find OpenMP. Skip check with -DREQUIRE_OPENMP=0.""); endif (). if (HAVE_GPROF); include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-pg GPROF_FOUND); if (GPROF_FOUND); append_target_property(mmseqs-framework COMPILE_FLAGS -pg); append_target_property(mmseqs-framework LINK_FLAGS -pg); else (); message(FATAL_ERROR ""-- Could not find GPROF""); endif (); endif (). if (NOT FRAMEWORK_ONLY); include(MMseqsSetupDerivedTarget); add_subdirectory(version); set(mmseqs_source_files mmseqs.cpp). add_executable(mmseqs${EXE_SUFFIX} ${mmseqs_source_files}); mmseqs_setup_derived_target(mmseqs${EXE_SUFFIX}); target_link_libraries(mmseqs${EXE_SUFFIX} version); install(TARGETS mmseqs${EXE_SUFFIX} DESTINATION bin). if (HAVE_TESTS); add_subdirectory(test); endif (); endif (); ",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:8338,Integrability,message,message,8338," if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework PUBLIC -DOPENMP=1); # For GCC we dont want to do this since it breaks macOS static builds; # It will link libgomp.a internally (through -fopenmp I guess); # and also link libgomp.dylib thus breaking static builds; if (NOT ""${CMAKE_CXX_COMPILER_ID}"" STREQUAL ""GNU""); target_link_libraries(mmseqs-framework ${OpenMP_CXX_LIBRARIES}); endif(); append_target_property(mmseqs-framework COMPILE_FLAGS ${OpenMP_CXX_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${OpenMP_CXX_FLAGS}); elseif (REQUIRE_OPENMP); message(FATAL_ERROR ""-- Could not find OpenMP. Skip check with -DREQUIRE_OPENMP=0.""); endif (). if (HAVE_GPROF); include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-pg GPROF_FOUND); if (GPROF_FOUND); append_target_property(mmseqs-framework COMPILE_FLAGS -pg); append_target_property(mmseqs-framework LINK_FLAGS -pg); else (); message(FATAL_ERROR ""-- Could not find GPROF""); endif (); endif (). if (NOT FRAMEWORK_ONLY); include(MMseqsSetupDerivedTarget); add_subdirectory(version); set(mmseqs_source_files mmseqs.cpp). add_executable(mmseqs${EXE_SUFFIX} ${mmseqs_source_files}); mmseqs_setup_derived_target(mmseqs${EXE_SUFFIX}); target_link_libraries(mmseqs${EXE_SUFFIX} version); install(TARGETS mmseqs${EXE_SUFFIX} DESTINATION bin). if (HAVE_TESTS); add_subdirectory(test); endif (); endif (); ",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:297,Performance,optimiz,optimization,297,"set(HAVE_MPI 0 CACHE BOOL ""Have MPI""); set(HAVE_TESTS 0 CACHE BOOL ""Have Tests""); set(HAVE_SHELLCHECK 1 CACHE BOOL ""Have ShellCheck""); set(HAVE_GPROF 0 CACHE BOOL ""Have GPROF Profiler""); set(ENABLE_WERROR 0 CACHE BOOL ""Enable Warnings as Errors""); #set(DISABLE_LTO 0 CACHE BOOL ""Disable link-time optimization in non-debug builds""); set(REQUIRE_OPENMP 1 CACHE BOOL ""Require availability of OpenMP""). include(AppendTargetProperty). add_subdirectory(alignment); add_subdirectory(clustering); add_subdirectory(commons); add_subdirectory(linclust); add_subdirectory(multihit); add_subdirectory(prefiltering); add_subdirectory(taxonomy); add_subdirectory(util); add_subdirectory(workflow). add_library(mmseqs-framework; $<TARGET_OBJECTS:alp>; $<TARGET_OBJECTS:ksw2>; $<TARGET_OBJECTS:cacode>; ${alignment_header_files}; ${alignment_source_files}; ${clustering_header_files}; ${clustering_source_files}; ${commons_header_files}; ${commons_source_files}; ${prefiltering_header_files}; ${prefiltering_source_files}; ${multihit_header_files}; ${multihit_source_files}; ${taxonomy_header_files}; ${taxonomy_source_files}; ${linclust_source_files}; ${util_header_files}; ${util_source_files}; ${workflow_source_files}; CommandDeclarations.h; MMseqsBase.cpp; ). target_include_directories(mmseqs-framework PUBLIC ${CMAKE_BINARY_DIR}/generated); target_include_directories(mmseqs-framework PUBLIC ${PROJECT_BINARY_DIR}/generated); target_include_directories(mmseqs-framework PUBLIC alignment); target_include_directories(mmseqs-framework PUBLIC clustering); target_include_directories(mmseqs-framework PUBLIC commons); target_include_directories(mmseqs-framework PUBLIC multihit); target_include_directories(mmseqs-framework PUBLIC prefiltering); target_include_directories(mmseqs-framework PUBLIC linclust); target_include_directories(mmseqs-framework PUBLIC taxonomy); target_include_directories(mmseqs-framework PUBLIC util); target_include_directories(mmseqs-framework PUBLIC .). add_dependencies(mmseqs-framew",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:2549,Performance,optimiz,optimization,2549,"rk PUBLIC multihit); target_include_directories(mmseqs-framework PUBLIC prefiltering); target_include_directories(mmseqs-framework PUBLIC linclust); target_include_directories(mmseqs-framework PUBLIC taxonomy); target_include_directories(mmseqs-framework PUBLIC util); target_include_directories(mmseqs-framework PUBLIC .). add_dependencies(mmseqs-framework generated). #if (NOT DISABLE_LTO); # string(TOUPPER ""${CMAKE_BUILD_TYPE}"" uppercase_CMAKE_BUILD_TYPE); # if (uppercase_CMAKE_BUILD_TYPE MATCHES ""^(RELEASE|RELWITHDEBINFO|MINSIZEREL)$""); # cmake_policy(SET CMP0069 NEW); # include(CheckIPOSupported); # check_ipo_supported(RESULT IPO_SUPPORTED); # if (IPO_SUPPORTED); # set_property(TARGET mmseqs-framework PROPERTY INTERPROCEDURAL_OPTIMIZATION TRUE); # endif (); # endif (); #endif (). append_target_property(mmseqs-framework COMPILE_FLAGS ${MMSEQS_CXX_FLAGS} -pedantic -Wall -Wextra -Wdisabled-optimization); append_target_property(mmseqs-framework LINK_FLAGS ${MMSEQS_CXX_FLAGS} -pedantic -Wall -Wextra -Wdisabled-optimization); if (NOT EMSCRIPTEN); append_target_property(mmseqs-framework COMPILE_FLAGS -fno-exceptions); append_target_property(mmseqs-framework LINK_FLAGS -fno-exceptions); endif(). if (ENABLE_WERROR); append_target_property(mmseqs-framework COMPILE_FLAGS -Werror -Wno-unused-command-line-argument); append_target_property(mmseqs-framework LINK_FLAGS -Werror -Wno-unused-command-line-argument); endif(). # needed for concat.h; include(CheckCXXSourceCompiles); check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main(",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:2670,Performance,optimiz,optimization,2670,"rk PUBLIC multihit); target_include_directories(mmseqs-framework PUBLIC prefiltering); target_include_directories(mmseqs-framework PUBLIC linclust); target_include_directories(mmseqs-framework PUBLIC taxonomy); target_include_directories(mmseqs-framework PUBLIC util); target_include_directories(mmseqs-framework PUBLIC .). add_dependencies(mmseqs-framework generated). #if (NOT DISABLE_LTO); # string(TOUPPER ""${CMAKE_BUILD_TYPE}"" uppercase_CMAKE_BUILD_TYPE); # if (uppercase_CMAKE_BUILD_TYPE MATCHES ""^(RELEASE|RELWITHDEBINFO|MINSIZEREL)$""); # cmake_policy(SET CMP0069 NEW); # include(CheckIPOSupported); # check_ipo_supported(RESULT IPO_SUPPORTED); # if (IPO_SUPPORTED); # set_property(TARGET mmseqs-framework PROPERTY INTERPROCEDURAL_OPTIMIZATION TRUE); # endif (); # endif (); #endif (). append_target_property(mmseqs-framework COMPILE_FLAGS ${MMSEQS_CXX_FLAGS} -pedantic -Wall -Wextra -Wdisabled-optimization); append_target_property(mmseqs-framework LINK_FLAGS ${MMSEQS_CXX_FLAGS} -pedantic -Wall -Wextra -Wdisabled-optimization); if (NOT EMSCRIPTEN); append_target_property(mmseqs-framework COMPILE_FLAGS -fno-exceptions); append_target_property(mmseqs-framework LINK_FLAGS -fno-exceptions); endif(). if (ENABLE_WERROR); append_target_property(mmseqs-framework COMPILE_FLAGS -Werror -Wno-unused-command-line-argument); append_target_property(mmseqs-framework LINK_FLAGS -Werror -Wno-unused-command-line-argument); endif(). # needed for concat.h; include(CheckCXXSourceCompiles); check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main(",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:3299,Testability,test,test,3299,"RPROCEDURAL_OPTIMIZATION TRUE); # endif (); # endif (); #endif (). append_target_property(mmseqs-framework COMPILE_FLAGS ${MMSEQS_CXX_FLAGS} -pedantic -Wall -Wextra -Wdisabled-optimization); append_target_property(mmseqs-framework LINK_FLAGS ${MMSEQS_CXX_FLAGS} -pedantic -Wall -Wextra -Wdisabled-optimization); if (NOT EMSCRIPTEN); append_target_property(mmseqs-framework COMPILE_FLAGS -fno-exceptions); append_target_property(mmseqs-framework LINK_FLAGS -fno-exceptions); endif(). if (ENABLE_WERROR); append_target_property(mmseqs-framework COMPILE_FLAGS -Werror -Wno-unused-command-line-argument); append_target_property(mmseqs-framework LINK_FLAGS -Werror -Wno-unused-command-line-argument); endif(). # needed for concat.h; include(CheckCXXSourceCompiles); check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main() {; FILE* tmpf = tmpfile();; void *tmp = mmap(NULL, 32, PROT_READ, MAP_SHARED, fileno(tmpf), 0);; int test = posix_madvise(tmp, 32, POSIX_MADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_MADVISE); if (HAVE_POSIX_MADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_MADVISE=1); endif (). if (NOT DISABLE_IPS4O); find_package(Atomic); if (ATOMIC_FOUND); target_link_libraries(mmseqs-framework ${ATOMIC_LIBRARIES}); target_compile_definitions(mmseqs-framework PUBLIC -DENABLE_IPS4O=1); message(""-- IPS4O sorting works""); else (); message(""-- OMPTL sorting fallback""); endif (); else (); message(""-- OMPTL sorting fallback""); endif (). target_link_libraries(mmseqs-framework tinyexpr ${ZSTD_LIBRARI",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:3750,Testability,test,test,3750,"mmseqs-framework LINK_FLAGS -fno-exceptions); endif(). if (ENABLE_WERROR); append_target_property(mmseqs-framework COMPILE_FLAGS -Werror -Wno-unused-command-line-argument); append_target_property(mmseqs-framework LINK_FLAGS -Werror -Wno-unused-command-line-argument); endif(). # needed for concat.h; include(CheckCXXSourceCompiles); check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>. int main() {; FILE* tmpf = tmpfile();; int input_desc = fileno(tmpf);; int test = posix_fadvise(input_desc, 0, 0, POSIX_FADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_FADVISE); if (HAVE_POSIX_FADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_FADVISE=1); endif (). check_cxx_source_compiles(""; #include <stdlib.h>; #include <fcntl.h>; #include <stdio.h>; #include <sys/mman.h>. int main() {; FILE* tmpf = tmpfile();; void *tmp = mmap(NULL, 32, PROT_READ, MAP_SHARED, fileno(tmpf), 0);; int test = posix_madvise(tmp, 32, POSIX_MADV_SEQUENTIAL);; fclose(tmpf);; return 0;; }""; HAVE_POSIX_MADVISE); if (HAVE_POSIX_MADVISE); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_POSIX_MADVISE=1); endif (). if (NOT DISABLE_IPS4O); find_package(Atomic); if (ATOMIC_FOUND); target_link_libraries(mmseqs-framework ${ATOMIC_LIBRARIES}); target_compile_definitions(mmseqs-framework PUBLIC -DENABLE_IPS4O=1); message(""-- IPS4O sorting works""); else (); message(""-- OMPTL sorting fallback""); endif (); else (); message(""-- OMPTL sorting fallback""); endif (). target_link_libraries(mmseqs-framework tinyexpr ${ZSTD_LIBRARIES} microtar); if (CYGWIN); target_link_libraries(mmseqs-framework nedmalloc); endif (). if (EMSCRIPTEN); target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_ZLIB=1 -DHAVE_BZLIB=1); append_target_property(mmseqs-framework COMPILE_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); append_target_property(mmseqs-framework LINK_FLAGS -s USE_ZLIB=1 -s USE_BZIP2=1); else (); find_package(ZLIB QUIET); if (ZLIB_FOUND); message(""-- Found ZLI",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt:8780,Testability,test,test,8780," if (HAVE_MPI); find_package(MPI REQUIRED); if (MPI_FOUND); message(""-- Found MPI""); target_include_directories(mmseqs-framework PUBLIC ${MPI_INCLUDE_PATH}); #Hack (OMPI_SKIP_MPICXX=1): https://github.com/open-mpi/ompi/issues/5157#issuecomment-388495496; target_compile_definitions(mmseqs-framework PUBLIC -DHAVE_MPI=1 -DOMPI_SKIP_MPICXX=1); target_link_libraries(mmseqs-framework ${MPI_LIBRARIES}); append_target_property(mmseqs-framework COMPILE_FLAGS ${MPI_COMPILE_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${MPI_LINK_FLAGS}); endif (); endif (). find_package(OpenMP QUIET); if (OPENMP_FOUND); message(""-- Found OpenMP""); target_compile_definitions(mmseqs-framework PUBLIC -DOPENMP=1); # For GCC we dont want to do this since it breaks macOS static builds; # It will link libgomp.a internally (through -fopenmp I guess); # and also link libgomp.dylib thus breaking static builds; if (NOT ""${CMAKE_CXX_COMPILER_ID}"" STREQUAL ""GNU""); target_link_libraries(mmseqs-framework ${OpenMP_CXX_LIBRARIES}); endif(); append_target_property(mmseqs-framework COMPILE_FLAGS ${OpenMP_CXX_FLAGS}); append_target_property(mmseqs-framework LINK_FLAGS ${OpenMP_CXX_FLAGS}); elseif (REQUIRE_OPENMP); message(FATAL_ERROR ""-- Could not find OpenMP. Skip check with -DREQUIRE_OPENMP=0.""); endif (). if (HAVE_GPROF); include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-pg GPROF_FOUND); if (GPROF_FOUND); append_target_property(mmseqs-framework COMPILE_FLAGS -pg); append_target_property(mmseqs-framework LINK_FLAGS -pg); else (); message(FATAL_ERROR ""-- Could not find GPROF""); endif (); endif (). if (NOT FRAMEWORK_ONLY); include(MMseqsSetupDerivedTarget); add_subdirectory(version); set(mmseqs_source_files mmseqs.cpp). add_executable(mmseqs${EXE_SUFFIX} ${mmseqs_source_files}); mmseqs_setup_derived_target(mmseqs${EXE_SUFFIX}); target_link_libraries(mmseqs${EXE_SUFFIX} version); install(TARGETS mmseqs${EXE_SUFFIX} DESTINATION bin). if (HAVE_TESTS); add_subdirectory(test); endif (); endif (); ",MatchSource.DOCS,src/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/util/CMakeLists.txt:0,Deployability,install,install,0,install(PROGRAMS; bash-completion.sh; DESTINATION util; ); ,MatchSource.DOCS,util/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/util/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/alp/readme.txt:264,Deployability,install,installed,264,"This directory contains C++ library files related to calculation of the Gumbel parameters for pairwise sequence alignment. Usage with ""make"". One way to use this library is with the ""make"" command. The following assumes you have ""make"" and a C++ compiler suitably installed. If you use the command line to enter the ""cpp"" directory and type ""make"", it should create a library file called ""libalp.a"". How to use the library is shown in the example directory. If you enter this directory and type ""make"", it should compile the test program: this will work only if it can find the header and library files. In ""example/Makefile"", the -I flag to the C preprocessor adds a directory to search for headers (""sls_alignment_evaluer.hpp""), the -L flag to the linker adds a directory to search for libraries, and -lalp specifies linking to ""libalp"". Please see the URL; http://www.ncbi.nlm.nih.gov/CBBresearch/Spouge/html_ncbi/html/index/software.html#6; for further information.; ",MatchSource.DOCS,lib/alp/readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/alp/readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/alp/readme.txt:525,Testability,test,test,525,"This directory contains C++ library files related to calculation of the Gumbel parameters for pairwise sequence alignment. Usage with ""make"". One way to use this library is with the ""make"" command. The following assumes you have ""make"" and a C++ compiler suitably installed. If you use the command line to enter the ""cpp"" directory and type ""make"", it should create a library file called ""libalp.a"". How to use the library is shown in the example directory. If you enter this directory and type ""make"", it should compile the test program: this will work only if it can find the header and library files. In ""example/Makefile"", the -I flag to the C preprocessor adds a directory to search for headers (""sls_alignment_evaluer.hpp""), the -L flag to the linker adds a directory to search for libraries, and -lalp specifies linking to ""libalp"". Please see the URL; http://www.ncbi.nlm.nih.gov/CBBresearch/Spouge/html_ncbi/html/index/software.html#6; for further information.; ",MatchSource.DOCS,lib/alp/readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/alp/readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/LICENSE.txt:137,Energy Efficiency,charge,charge,137,"The MIT License. Copyright (c) 2018- Dana-Farber Cancer Institute; 2017-2018 Broad Institute, Inc. Permission is hereby granted, free of charge, to any person obtaining; a copy of this software and associated documentation files (the; ""Software""), to deal in the Software without restriction, including; without limitation the rights to use, copy, modify, merge, publish,; distribute, sublicense, and/or sell copies of the Software, and to; permit persons to whom the Software is furnished to do so, subject to; the following conditions:. The above copyright notice and this permission notice shall be; included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND,; EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF; MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND; NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS; BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN; ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN; CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE; SOFTWARE.; ",MatchSource.DOCS,lib/ksw2/LICENSE.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/ksw2/LICENSE.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/License.txt:96,Energy Efficiency,charge,charge,96,"Boost Software License - Version 1.0 - August 17th, 2003. Permission is hereby granted, free of charge, to any person or organization; obtaining a copy of the software and accompanying documentation covered by; this license (the ""Software"") to use, reproduce, display, distribute,; execute, and transmit the Software, and to prepare derivative works of the; Software, and to permit third-parties to whom the Software is furnished to; do so, all subject to the following:. The copyright notices in the Software and this entire statement, including; the above license grant, this restriction and the following disclaimer,; must be included in all copies of the Software, in whole or in part, and; all derivative works of the Software, unless such copies or derivative; works are solely in the form of machine-executable object code generated by; a source language processor. THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR; IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,; FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT; SHALL THE COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE; FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN CONTRACT, TORT OR OTHERWISE,; ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER; DEALINGS IN THE SOFTWARE.; ",MatchSource.DOCS,lib/nedmalloc/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2704,Availability,down,down,2704,"createpool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3898,Availability,error,error,3898,"ead cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config define",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4645,Availability,failure,failure,4645,"rocessors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; thr",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:6392,Availability,failure,failure,6392,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2857,Deployability,release,release,2857,"createpool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:5776,Deployability,release,release,5776,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:6290,Deployability,patch,patches,6290,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:6403,Deployability,release,release,6403,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:6510,Deployability,release,release,6510,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1549,Energy Efficiency,allocate,allocates,1549,"the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits perf",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1685,Energy Efficiency,reduce,reduce,1685,"ry well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1871,Energy Efficiency,reduce,reduce,1871,"his allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable th",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1938,Energy Efficiency,allocate,allocated,1938,"e!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2491,Energy Efficiency,allocate,allocated,2491,"runk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code r",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3343,Energy Efficiency,power,power,3343,"code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory lea",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4040,Energy Efficiency,allocate,allocated,4040,"=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedpreallo",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:114,Modifiability,portab,portable,114,"nedalloc v1.05 15th June 2008:; -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=. by Niall Douglas (http://www.nedprod.com/programs/portable/nedmalloc/). Enclosed is nedalloc, an alternative malloc implementation for multiple; threads without lock contention based on dlmalloc v2.8.4. It is more; or less a newer implementation of ptmalloc2, the standard allocator in; Linux (which is based on dlmalloc v2.7.0) but also contains a per-thread; cache for maximum CPU scalability. It is licensed under the Boost Software License which basically means; you can do anything you like with it. This does not apply to the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2265,Modifiability,portab,portably,2265,"ter nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; wit",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4890,Modifiability,config,config,4890,"() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 c",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:425,Performance,cache,cache,425,"nedalloc v1.05 15th June 2008:; -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=. by Niall Douglas (http://www.nedprod.com/programs/portable/nedmalloc/). Enclosed is nedalloc, an alternative malloc implementation for multiple; threads without lock contention based on dlmalloc v2.8.4. It is more; or less a newer implementation of ptmalloc2, the standard allocator in; Linux (which is based on dlmalloc v2.7.0) but also contains a per-thread; cache for maximum CPU scalability. It is licensed under the Boost Software License which basically means; you can do anything you like with it. This does not apply to the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:447,Performance,scalab,scalability,447,"nedalloc v1.05 15th June 2008:; -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=. by Niall Douglas (http://www.nedprod.com/programs/portable/nedmalloc/). Enclosed is nedalloc, an alternative malloc implementation for multiple; threads without lock contention based on dlmalloc v2.8.4. It is more; or less a newer implementation of ptmalloc2, the standard allocator in; Linux (which is based on dlmalloc v2.7.0) but also contains a per-thread; cache for maximum CPU scalability. It is licensed under the Boost Software License which basically means; you can do anything you like with it. This does not apply to the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2324,Performance,cache,cache,2324,"ter nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; wit",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2589,Performance,perform,performance,2589,"runk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code r",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2744,Performance,cache,cache,2744,"createpool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2906,Performance,cache,cache,2906,"createpool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4376,Performance,cache,cache,4376,"ng a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4670,Performance,cache,cache,4670,"rocessors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; thr",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:5807,Performance,perform,performance,5807,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:6222,Performance,cache,cache,6222,"into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sanin for reporting this. v1.03 10th July 2006:; * Fixed memory corruption bug in threadcache code which only appeared with >4; threads and in heavy use of the threadcache. v1.02 15th May 2006:; * Integrated dlmalloc v2.8.4, fixing the win32 memory release problem and; improving performance still further. Speed is now up to twice the speed of v1.01; (average is 67% faster).; * Fixed win32 critical section implementation. Thanks to Pavel Kuznetsov; for reporting this.; * Wasn't locking mspace if all mspaces were locked. Thanks to Pavel Kuznetsov; for reporting this.; * Added Apple Mac OS X support. v1.01 24th February 2006:; * Fixed multiprocessor scaling problems by removing sources of cache sloshing; * Earl Chew <earl_chew <at> agilent <dot> com> sent patches for the following:; 1. size2binidx() wasn't working for default code path (non x86); 2. Fixed failure to release mspace lock under certain circumstances which; caused a deadlock. v1.00 1st January 2006:; * First release; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1994,Safety,avoid,avoided,1994,"e!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:2084,Safety,safe,safely,2084,"e!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4457,Safety,sanity check,sanity check,4457,"s than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where alloca",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:660,Testability,test,tested,660,"nedalloc v1.05 15th June 2008:; -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=. by Niall Douglas (http://www.nedprod.com/programs/portable/nedmalloc/). Enclosed is nedalloc, an alternative malloc implementation for multiple; threads without lock contention based on dlmalloc v2.8.4. It is more; or less a newer implementation of ptmalloc2, the standard allocator in; Linux (which is based on dlmalloc v2.7.0) but also contains a per-thread; cache for maximum CPU scalability. It is licensed under the Boost Software License which basically means; you can do anything you like with it. This does not apply to the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1184,Testability,test,test,1184,"ion for multiple; threads without lock contention based on dlmalloc v2.8.4. It is more; or less a newer implementation of ptmalloc2, the standard allocator in; Linux (which is based on dlmalloc v2.7.0) but also contains a per-thread; cache for maximum CPU scalability. It is licensed under the Boost Software License which basically means; you can do anything you like with it. This does not apply to the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache();",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:1198,Testability,test,test,1198,"ion for multiple; threads without lock contention based on dlmalloc v2.8.4. It is more; or less a newer implementation of ptmalloc2, the standard allocator in; Linux (which is based on dlmalloc v2.7.0) but also contains a per-thread; cache for maximum CPU scalability. It is licensed under the Boost Software License which basically means; you can do anything you like with it. This does not apply to the malloc.c.h; file which remains copyright to others. It has been tested on win32 (x86), win64 (x64), Linux (x64), FreeBSD (x64); and Apple MacOS X (x86). It works very well on all of these and is very; significantly faster than the system allocator on all of these platforms. By literally dropping in this allocator as a replacement for your system; allocator, you can see real world improvements of up to three times in normal; code!. To use:; -=-=-=-; Drop in nedmalloc.h, nedmalloc.c and malloc.c.h into your project.; Configure using the instructions in nedmalloc.h. Run and enjoy. To test, compile test.c. It will run a comparison between your system; allocator and nedalloc and tell you how much faster nedalloc is. It also; serves as an example of usage. Notes:; -=-=-=; If you want the very latest version of this allocator, get it from the; TnFOX SVN repository at svn://svn.berlios.de/viewcvs/tnfox/trunk/src/nedmalloc. Because of how nedalloc allocates an mspace per thread, it can cause; severe bloating of memory usage under certain allocation patterns.; You can substantially reduce this wastage by setting MAXTHREADSINPOOL; or the threads parameter to nedcreatepool() to a fraction of the number of; threads which would normally be in a pool at once. This will reduce; bloating at the cost of an increase in lock contention. If allocated size; is less than THREADCACHEMAX, locking is avoided 90-99% of the time and; if most of your allocations are below this value, you can safely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache();",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3092,Testability,test,test,3092,"ely set; MAXTHREADSINPOOL to one. You will suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Than",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3138,Testability,test,test,3138,"l suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this.",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3155,Testability,test,test,3155,"l suffer memory leakage unless you call neddisablethreadcache(); per pool for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this.",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3171,Testability,test,test,3171,"for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementati",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3239,Testability,test,test,3239,"for every thread which exits. This is because nedalloc cannot; portably know when a thread exits and thus when its thread cache can; be returned for use by other code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementati",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3534,Testability,benchmark,benchmark,3534,"ed as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked te",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3599,Testability,benchmark,benchmark,3599,"ur allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn91",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3709,Testability,test,test,3709,"n is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this.",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4512,Testability,test,test,4512,"ults are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. ",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:4540,Testability,test,test,4540,"IO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory leak of thread cache contents on disabling. Thanks to Earl; Chew for reporting this.; * Added a sanity check for freed blocks being valid.; * Reworked test.c into being a torture test.; * Fixed GCC assembler optimisation misspecification. v1.04alpha_svn915 7th October 2006:; * Fixed failure to unlock thread cache list if allocating a new list failed.; Thanks to Dmitry Chichkov for reporting this. Further thanks to Aleksey Sanin.; * Fixed realloc(0, <size>) segfaulting. Thanks to Dmitry Chichkov for; reporting this.; * Made config defines #ifndef so they can be overridden by the build system.; Thanks to Aleksey Sanin for suggesting this.; * Fixed deadlock in nedprealloc() due to unnecessary locking of preferred; thread mspace when mspace_realloc() always uses the original block's mspace; anyway. Thanks to Aleksey Sanin for reporting this.; * Made some speed improvements by hacking mspace_malloc() to no longer lock; its mspace, thus allowing the recursive mutex implementation to be removed; with an associated speed increase. Thanks to Aleksey Sanin for suggesting this.; * Fixed a bug where allocating mspaces overran its max limit. Thanks to; Aleksey Sani",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt:3449,Usability,simpl,simple,3449,"code. Don't forget pool zero, the system pool. For C++ type allocation patterns (where the same sizes of memory are; regularly allocated and deallocated as objects are created and destroyed),; the threadcache always benefits performance. If however your allocation; patterns are different, searching the threadcache may significantly slow; down your code - as a rule of thumb, if cache utilisation is below 80%; (see the source for neddisablethreadcache() for how to enable debug; printing in release mode) then you should disable the thread cache for; that thread. You can compile out the threadcache code by setting; THREADCACHEMAX to zero. Speed comparisons:; -=-=-=-=-=-=-=-=-=; See Benchmarks.xls for details. The enclosed test.c can do two things: it can be a torture test or a speed; test. The speed test is designed to be a representative synthetic; memory allocator test. It works by randomly mixing allocations with frees; with half of the allocation sizes being a two power multiple less than; 512 bytes (to mimic C++ stack instantiated objects) and the other half; being a simple random value less than 16Kb. The real world code results are from Tn's TestIO benchmark. This is a; heavily multithreaded and memory intensive benchmark with a lot of branching; and other stuff modern processors don't like so much. As you'll note, the; test doesn't show the benefits of the threadcache mostly due to the saturation; of the memory bus being the limiting factor. ChangeLog:; -=-=-=-=-=; v1.05 15th June 2008:; * { 1042 } Added error check for TLSSET() and TLSFREE() macros. Thanks to; Markus Elfring for reporting this.; * { 1043 } Fixed a segfault when freeing memory allocated using; nedindependent_comalloc(). Thanks to Pavel Vozenilek for reporting this. v1.04 14th July 2007:; * Fixed a bug with the new optimised implementation that failed to lock; on a realloc under certain conditions.; * Fixed lack of thread synchronisation in InitPool() causing pool corruption; * Fixed a memory lea",MatchSource.DOCS,lib/nedmalloc/Readme.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/nedmalloc/Readme.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:321,Deployability,release,released,321,"		 GNU LESSER GENERAL PUBLIC LICENSE; 		 Version 2.1, February 1999. Copyright (C) 1991, 1999 Free Software Foundation, Inc.; 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA; Everyone is permitted to copy and distribute verbatim copies; of this license document, but changing it is not allowed. [This is the first released version of the Lesser GPL. It also counts; as the successor of the GNU Library Public License, version 2, hence; the version number 2.1.]. 			 Preamble. The licenses for most software are designed to take away your; freedom to share and change it. By contrast, the GNU General Public; Licenses are intended to guarantee your freedom to share and change; free software--to make sure the software is free for all its users. This license, the Lesser General Public License, applies to some; specially designated software packages--typically libraries--of the; Free Software Foundation and other authors who decide to use it. You; can use it too, but we suggest you first think carefully about whether; this license or the ordinary General Public License is the better; strategy to use in any particular case, based on the explanations below. When we speak of free software, we are referring to freedom of use,; not price. Our General Public Licenses are designed to make sure that; you have the freedom to distribute copies of free software (and charge; for this service if you wish); that you receive source code or can get; it if you want it; that you can change the software and use pieces of; it in new free programs; and that you are informed that you can do; these things. To protect your rights, we need to make restrictions that forbid; distributors to deny you these rights or to ask you to surrender these; rights. These restrictions translate to certain responsibilities for; you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis; or for a fee, you must give the recipients all the r",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:7321,Deployability,install,installation,7321,"buted under the terms of; this Lesser General Public License (also called ""this License"").; Each licensee is addressed as ""you"". A ""library"" means a collection of software functions and/or data; prepared so as to be conveniently linked with application programs; (which use some of those functions and data) to form executables. The ""Library"", below, refers to any such software library or work; which has been distributed under these terms. A ""work based on the; Library"" means either the Library or any derivative work under; copyright law: that is to say, a work containing the Library or a; portion of it, either verbatim or with modifications and/or translated; straightforwardly into another language. (Hereinafter, translation is; included without limitation in the term ""modification"".). ""Source code"" for a work means the preferred form of the work for; making modifications to it. For a library, complete source code means; all the source code for all modules it contains, plus any associated; interface definition files, plus the scripts used to control compilation; and installation of the library. Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running a program using the Library is not restricted, and output from; such a program is covered only if its contents constitute a work based; on the Library (independent of the use of the Library in a tool for; writing it). Whether that is true depends on what the Library does; and what the program that uses the Library does.; ; 1. You may copy and distribute verbatim copies of the Library's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may char",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:15911,Deployability,install,installs,15911,"s License. Also, you must do one; of these things:. a) Accompany the work with the complete corresponding; machine-readable source code for the Library including whatever; changes were used in the work (which must be distributed under; Sections 1 and 2 above); and, if the work is an executable linked; with the Library, with the complete machine-readable ""work that; uses the Library"", as object code and/or source code, so that the; user can modify the Library and then relink to produce a modified; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in ei",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:1373,Energy Efficiency,charge,charge,1373,"ersion 2, hence; the version number 2.1.]. 			 Preamble. The licenses for most software are designed to take away your; freedom to share and change it. By contrast, the GNU General Public; Licenses are intended to guarantee your freedom to share and change; free software--to make sure the software is free for all its users. This license, the Lesser General Public License, applies to some; specially designated software packages--typically libraries--of the; Free Software Foundation and other authors who decide to use it. You; can use it too, but we suggest you first think carefully about whether; this license or the ordinary General Public License is the better; strategy to use in any particular case, based on the explanations below. When we speak of free software, we are referring to freedom of use,; not price. Our General Public Licenses are designed to make sure that; you have the freedom to distribute copies of free software (and charge; for this service if you wish); that you receive source code or can get; it if you want it; that you can change the software and use pieces of; it in new free programs; and that you are informed that you can do; these things. To protect your rights, we need to make restrictions that forbid; distributors to deny you these rights or to ask you to surrender these; rights. These restrictions translate to certain responsibilities for; you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis; or for a fee, you must give the recipients all the rights that we gave; you. You must make sure that they, too, receive or can get the source; code. If you link other code with the library, you must provide; complete object files to the recipients, so that they can relink them; with the library after making changes to the library and recompiling; it. And you must show them these terms so they know their rights. We protect your rights with a two-step method: (1) we copyright",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:8235,Energy Efficiency,charge,charge,8235,"ntrol compilation; and installation of the library. Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running a program using the Library is not restricted, and output from; such a program is covered only if its contents constitute a work based; on the Library (independent of the use of the Library in a tool for; writing it). Whether that is true depends on what the Library does; and what the program that uses the Library does.; ; 1. You may copy and distribute verbatim copies of the Library's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee.; ; 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:8882,Energy Efficiency,charge,charge,8882,"s; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee.; ; 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still operates, and performs whatever part of; its purpose remains meaningful. (For example, a function in a library to compute square roots has; a purpose that is entirely well-defined independent of the; application. Therefore, Subsection 2d requires that any; application-supplied function or table used by this function must; be optional: if the application does not supply it, the square; root function must still compute square roots.). These requirements apply to the modified work as a whole. If; identifiable sections of that work are not derived from the Library,; and can be re",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:16183,Energy Efficiency,charge,charge,16183," with the Library, with the complete machine-readable ""work that; uses the Library"", as object code and/or source code, so that the; user can modify the Library and then relink to produce a modified; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in either source or binary form) with the major; components (compiler, kernel, and so on) of the operating system on; which the executable runs, unless that component itself accompanies; the executable. It may happen that this requirement contradicts the license; restrictions of other proprietary librarie",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:7243,Integrability,interface,interface,7243,"buted under the terms of; this Lesser General Public License (also called ""this License"").; Each licensee is addressed as ""you"". A ""library"" means a collection of software functions and/or data; prepared so as to be conveniently linked with application programs; (which use some of those functions and data) to form executables. The ""Library"", below, refers to any such software library or work; which has been distributed under these terms. A ""work based on the; Library"" means either the Library or any derivative work under; copyright law: that is to say, a work containing the Library or a; portion of it, either verbatim or with modifications and/or translated; straightforwardly into another language. (Hereinafter, translation is; included without limitation in the term ""modification"".). ""Source code"" for a work means the preferred form of the work for; making modifications to it. For a library, complete source code means; all the source code for all modules it contains, plus any associated; interface definition files, plus the scripts used to control compilation; and installation of the library. Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running a program using the Library is not restricted, and output from; such a program is covered only if its contents constitute a work based; on the Library (independent of the use of the Library in a tool for; writing it). Whether that is true depends on what the Library does; and what the program that uses the Library does.; ; 1. You may copy and distribute verbatim copies of the Library's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may char",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:7732,Integrability,depend,depends,7732,"der; copyright law: that is to say, a work containing the Library or a; portion of it, either verbatim or with modifications and/or translated; straightforwardly into another language. (Hereinafter, translation is; included without limitation in the term ""modification"".). ""Source code"" for a work means the preferred form of the work for; making modifications to it. For a library, complete source code means; all the source code for all modules it contains, plus any associated; interface definition files, plus the scripts used to control compilation; and installation of the library. Activities other than copying, distribution and modification are not; covered by this License; they are outside its scope. The act of; running a program using the Library is not restricted, and output from; such a program is covered only if its contents constitute a work based; on the Library (independent of the use of the Library in a tool for; writing it). Whether that is true depends on what the Library does; and what the program that uses the Library does.; ; 1. You may copy and distribute verbatim copies of the Library's; complete source code as you receive it, in any medium, provided that; you conspicuously and appropriately publish on each copy an; appropriate copyright notice and disclaimer of warranty; keep intact; all the notices that refer to this License and to the absence of any; warranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee.; ; 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stati",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:15961,Integrability,interface,interface-compatible,15961,"s License. Also, you must do one; of these things:. a) Accompany the work with the complete corresponding; machine-readable source code for the Library including whatever; changes were used in the work (which must be distributed under; Sections 1 and 2 above); and, if the work is an executable linked; with the Library, with the complete machine-readable ""work that; uses the Library"", as object code and/or source code, so that the; user can modify the Library and then relink to produce a modified; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in ei",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:21423,Integrability,interface,interfaces,21423," the section as a whole is intended to apply in other circumstances. It is not the purpose of this section to induce you to infringe any; patents or other property right claims or to contest validity of any; such claims; this section has the sole purpose of protecting the; integrity of the free software distribution system which is; implemented by public license practices. Many people have made; generous contributions to the wide range of software distributed; through that system in reliance on consistent application of that; system; it is up to the author/donor to decide if he or she is willing; to distribute software through any other system and a licensee cannot; impose that choice. This section is intended to make thoroughly clear what is believed to; be a consequence of the rest of this License. 12. If the distribution and/or use of the Library is restricted in; certain countries either by patents or by copyrighted interfaces, the; original copyright holder who places the Library under this License may add; an explicit geographical distribution limitation excluding those countries,; so that distribution is permitted only in or among countries not thus; excluded. In such case, this License incorporates the limitation as if; written in the body of this License. 13. The Free Software Foundation may publish revised and/or new; versions of the Lesser General Public License from time to time.; Such new versions will be similar in spirit to the present version,; but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library; specifies a version number of this License which applies to it and; ""any later version"", you have the option of following the terms and; conditions either of that version or of any later version published by; the Free Software Foundation. If the Library does not specify a; license version number, you may choose any version ever published by; the Free Software Foundation.; ; 14. ",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:10266,Modifiability,extend,extend,10266,"at,; in the event an application does not supply such function or; table, the facility still operates, and performs whatever part of; its purpose remains meaningful. (For example, a function in a library to compute square roots has; a purpose that is entirely well-defined independent of the; application. Therefore, Subsection 2d requires that any; application-supplied function or table used by this function must; be optional: if the application does not supply it, the square; root function must still compute square roots.). These requirements apply to the modified work as a whole. If; identifiable sections of that work are not derived from the Library,; and can be reasonably considered independent and separate works in; themselves, then this License, and its terms, do not apply to those; sections when you distribute them as separate works. But when you; distribute the same sections as part of a whole which is a work based; on the Library, the distribution of the whole must be on the terms of; this License, whose permissions for other licensees extend to the; entire whole, and thus to each and every part regardless of who wrote; it. Thus, it is not the intent of this section to claim rights or contest; your rights to work written entirely by you; rather, the intent is to; exercise the right to control the distribution of derivative or; collective works based on the Library. In addition, mere aggregation of another work not based on the Library; with the Library (or with a work based on the Library) on a volume of; a storage or distribution medium does not bring the other work under; the scope of this License. 3. You may opt to apply the terms of the ordinary GNU General Public; License instead of this License to a given copy of the Library. To do; this, you must alter all the notices that refer to this License, so; that they refer to the ordinary GNU General Public License, version 2,; instead of to this License. (If a newer version than version 2 of the; ordinary GN",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:9313,Performance,perform,performs,9313,"rranty; and distribute a copy of this License along with the; Library. You may charge a fee for the physical act of transferring a copy,; and you may at your option offer warranty protection in exchange for a; fee.; ; 2. You may modify your copy or copies of the Library or any portion; of it, thus forming a work based on the Library, and copy and; distribute such modifications or work under the terms of Section 1; above, provided that you also meet all of these conditions:. a) The modified work must itself be a software library. b) You must cause the files modified to carry prominent notices; stating that you changed the files and the date of any change. c) You must cause the whole of the work to be licensed at no; charge to all third parties under the terms of this License. d) If a facility in the modified Library refers to a function or a; table of data to be supplied by an application program that uses; the facility, other than as an argument passed when the facility; is invoked, then you must make a good faith effort to ensure that,; in the event an application does not supply such function or; table, the facility still operates, and performs whatever part of; its purpose remains meaningful. (For example, a function in a library to compute square roots has; a purpose that is entirely well-defined independent of the; application. Therefore, Subsection 2d requires that any; application-supplied function or table used by this function must; be optional: if the application does not supply it, the square; root function must still compute square roots.). These requirements apply to the modified work as a whole. If; identifiable sections of that work are not derived from the Library,; and can be reasonably considered independent and separate works in; themselves, then this License, and its terms, do not apply to those; sections when you distribute them as separate works. But when you; distribute the same sections as part of a whole which is a work based; on the Library",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:16216,Performance,perform,performing,16216," with the Library, with the complete machine-readable ""work that; uses the Library"", as object code and/or source code, so that the; user can modify the Library and then relink to produce a modified; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in either source or binary form) with the major; components (compiler, kernel, and so on) of the operating system on; which the executable runs, unless that component itself accompanies; the executable. It may happen that this requirement contradicts the license; restrictions of other proprietary librarie",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:24714,Safety,safe,safest,24714," YOU; FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR; CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITY TO USE THE; LIBRARY (INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEING; RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A; FAILURE OF THE LIBRARY TO OPERATE WITH ANY OTHER SOFTWARE), EVEN IF; SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH; DAMAGES. 		 END OF TERMS AND CONDITIONS; ; How to Apply These Terms to Your New Libraries. If you develop a new library, and you want it to be of the greatest; possible use to the public, we recommend making it free software that; everyone can redistribute and change. You can do so by permitting; redistribution under these terms (or, alternatively, under the terms of the; ordinary General Public License). To apply these terms, attach the following notices to the library. It is; safest to attach them to the start of each source file to most effectively; convey the exclusion of warranty; and each file should have at least the; ""copyright"" line and a pointer to where the full notice is found. <one line to give the library's name and a brief idea of what it does.>; Copyright (C) <year> <name of author>. This library is free software; you can redistribute it and/or; modify it under the terms of the GNU Lesser General Public; License as published by the Free Software Foundation; either; version 2.1 of the License, or (at your option) any later version. This library is distributed in the hope that it will be useful,; but WITHOUT ANY WARRANTY; without even the implied warranty of; MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU; Lesser General Public License for more details. You should have received a copy of the GNU Lesser General Public; License along with this library; if not, write to the Free Software; Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA. Also add information on how to contact you by electronic and paper mail.",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:2966,Security,threat,threat,2966,"u must give the recipients all the rights that we gave; you. You must make sure that they, too, receive or can get the source; code. If you link other code with the library, you must provide; complete object files to the recipients, so that they can relink them; with the library after making changes to the library and recompiling; it. And you must show them these terms so they know their rights. We protect your rights with a two-step method: (1) we copyright the; library, and (2) we offer you this license, which gives you legal; permission to copy, distribute and/or modify the library. To protect each distributor, we want to make it very clear that; there is no warranty for the free library. Also, if the library is; modified by someone else and passed on, the recipients should know; that what they have is not the original version, so that the original; author's reputation will not be affected by problems that might be; introduced by others.; ; Finally, software patents pose a constant threat to the existence of; any free program. We wish to make sure that a company cannot; effectively restrict the users of a free program by obtaining a; restrictive license from a patent holder. Therefore, we insist that; any patent license obtained for a version of the library must be; consistent with the full freedom of use specified in this license. Most GNU software, including some libraries, is covered by the; ordinary GNU General Public License. This license, the GNU Lesser; General Public License, applies to certain designated libraries, and; is quite different from the ordinary General Public License. We use; this license for certain libraries in order to permit linking those; libraries into non-free programs. When a program is linked with a library, whether statically or using; a shared library, the combination of the two is legally speaking a; combined work, a derivative of the original library. The ordinary; General Public License therefore permits such linking only if th",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:6199,Security,authoriz,authorized,6199,"mission to use the GNU C Library in; non-free programs enables many more people to use the whole GNU; operating system, as well as its variant, the GNU/Linux operating; system. Although the Lesser General Public License is Less protective of the; users' freedom, it does ensure that the user of a program that is; linked with the Library has the freedom and the wherewithal to run; that program using a modified version of the Library. The precise terms and conditions for copying, distribution and; modification follow. Pay close attention to the difference between a; ""work based on the library"" and a ""work that uses the library"". The; former contains code derived from the library, whereas the latter must; be combined with the library in order to run.; ; 		 GNU LESSER GENERAL PUBLIC LICENSE; TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION. 0. This License Agreement applies to any software library or other; program which contains a notice placed by the copyright holder or; other authorized party saying it may be distributed under the terms of; this Lesser General Public License (also called ""this License"").; Each licensee is addressed as ""you"". A ""library"" means a collection of software functions and/or data; prepared so as to be conveniently linked with application programs; (which use some of those functions and data) to form executables. The ""Library"", below, refers to any such software library or work; which has been distributed under these terms. A ""work based on the; Library"" means either the Library or any derivative work under; copyright law: that is to say, a work containing the Library or a; portion of it, either verbatim or with modifications and/or translated; straightforwardly into another language. (Hereinafter, translation is; included without limitation in the term ""modification"".). ""Source code"" for a work means the preferred form of the work for; making modifications to it. For a library, complete source code means; all the source code fo",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:12108,Security,access,access,12108," Public License has appeared, then you can specify; that version instead if you wish.) Do not make any other change in; these notices.; ; Once this change is made in a given copy, it is irreversible for; that copy, so the ordinary GNU General Public License applies to all; subsequent copies and derivative works made from that copy. This option is useful when you wish to copy part of the code of; the Library into a program that is not a library. 4. You may copy and distribute the Library (or a portion or; derivative of it, under Section 2) in object code or executable form; under the terms of Sections 1 and 2 above provided that you accompany; it with the complete corresponding machine-readable source code, which; must be distributed under the terms of Sections 1 and 2 above on a; medium customarily used for software interchange. If distribution of object code is made by offering access to copy; from a designated place, then offering equivalent access to copy the; source code from the same place satisfies the requirement to; distribute the source code, even though third parties are not; compelled to copy the source along with the object code. 5. A program that contains no derivative of any portion of the; Library, but is designed to work with the Library by being compiled or; linked with it, is called a ""work that uses the Library"". Such a; work, in isolation, is not a derivative work of the Library, and; therefore falls outside the scope of this License. However, linking a ""work that uses the Library"" with the Library; creates an executable that is a derivative of the Library (because it; contains portions of the Library), rather than a ""work that uses the; library"". The executable is therefore covered by this License.; Section 6 states terms for distribution of such executables. When a ""work that uses the Library"" uses material from a header file; that is part of the Library, the object code for the work may be a; derivative work of the Library even though the sour",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:12174,Security,access,access,12174," Public License has appeared, then you can specify; that version instead if you wish.) Do not make any other change in; these notices.; ; Once this change is made in a given copy, it is irreversible for; that copy, so the ordinary GNU General Public License applies to all; subsequent copies and derivative works made from that copy. This option is useful when you wish to copy part of the code of; the Library into a program that is not a library. 4. You may copy and distribute the Library (or a portion or; derivative of it, under Section 2) in object code or executable form; under the terms of Sections 1 and 2 above provided that you accompany; it with the complete corresponding machine-readable source code, which; must be distributed under the terms of Sections 1 and 2 above on a; medium customarily used for software interchange. If distribution of object code is made by offering access to copy; from a designated place, then offering equivalent access to copy the; source code from the same place satisfies the requirement to; distribute the source code, even though third parties are not; compelled to copy the source along with the object code. 5. A program that contains no derivative of any portion of the; Library, but is designed to work with the Library by being compiled or; linked with it, is called a ""work that uses the Library"". Such a; work, in isolation, is not a derivative work of the Library, and; therefore falls outside the scope of this License. However, linking a ""work that uses the Library"" with the Library; creates an executable that is a derivative of the Library (because it; contains portions of the Library), rather than a ""work that uses the; library"". The executable is therefore covered by this License.; Section 6 states terms for distribution of such executables. When a ""work that uses the Library"" uses material from a header file; that is part of the Library, the object code for the work may be a; derivative work of the Library even though the sour",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:13515,Security,access,accessors,13515," Such a; work, in isolation, is not a derivative work of the Library, and; therefore falls outside the scope of this License. However, linking a ""work that uses the Library"" with the Library; creates an executable that is a derivative of the Library (because it; contains portions of the Library), rather than a ""work that uses the; library"". The executable is therefore covered by this License.; Section 6 states terms for distribution of such executables. When a ""work that uses the Library"" uses material from a header file; that is part of the Library, the object code for the work may be a; derivative work of the Library even though the source code is not.; Whether this is true is especially significant if the work can be; linked without the Library, or if the work is itself a library. The; threshold for this to be true is not precisely defined by law. If such an object file uses only numerical parameters, data; structure layouts and accessors, and small macros and small inline; functions (ten lines or less in length), then the use of the object; file is unrestricted, regardless of whether it is legally a derivative; work. (Executables containing this object code plus portions of the; Library will still fall under Section 6.). Otherwise, if the work is a derivative of the Library, you may; distribute the object code for the work under the terms of Section 6.; Any executables containing that work also fall under Section 6,; whether or not they are linked directly with the Library itself.; ; 6. As an exception to the Sections above, you may also combine or; link a ""work that uses the Library"" with the Library to produce a; work containing portions of the Library, and distribute that work; under terms of your choice, provided that the terms permit; modification of the work for the customer's own use and reverse; engineering for debugging such modifications. You must give prominent notice with each copy of the work that the; Library is used in it and that the Library and",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:16297,Security,access,access,16297,"d; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in either source or binary form) with the major; components (compiler, kernel, and so on) of the operating system on; which the executable runs, unless that component itself accompanies; the executable. It may happen that this requirement contradicts the license; restrictions of other proprietary libraries that do not normally; accompany the operating system. Such a contradiction means you cannot; use both them and the Library together in an executable that you; distribute.; ; 7. You may place lib",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:16355,Security,access,access,16355,"d; executable containing the modified Library. (It is understood; that the user who changes the contents of definitions files in the; Library will not necessarily be able to recompile the application; to use the modified definitions.). b) Use a suitable shared library mechanism for linking with the; Library. A suitable mechanism is one that (1) uses at run time a; copy of the library already present on the user's computer system,; rather than copying library functions into the executable, and (2); will operate properly with a modified version of the library, if; the user installs one, as long as the modified version is; interface-compatible with the version that the work was made with. c) Accompany the work with a written offer, valid for at; least three years, to give the same user the materials; specified in Subsection 6a, above, for a charge no more; than the cost of performing this distribution. d) If distribution of the work is made by offering access to copy; from a designated place, offer equivalent access to copy the above; specified materials from the same place. e) Verify that the user has already received a copy of these; materials or that you have already sent this user a copy. For an executable, the required form of the ""work that uses the; Library"" must include any data and utility programs needed for; reproducing the executable from it. However, as a special exception,; the materials to be distributed need not include anything that is; normally distributed (in either source or binary form) with the major; components (compiler, kernel, and so on) of the operating system on; which the executable runs, unless that component itself accompanies; the executable. It may happen that this requirement contradicts the license; restrictions of other proprietary libraries that do not normally; accompany the operating system. Such a contradiction means you cannot; use both them and the Library together in an executable that you; distribute.; ; 7. You may place lib",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:20763,Security,integrity,integrity,20763,"der, agreement or; otherwise) that contradict the conditions of this License, they do not; excuse you from the conditions of this License. If you cannot; distribute so as to satisfy simultaneously your obligations under this; License and any other pertinent obligations, then as a consequence you; may not distribute the Library at all. For example, if a patent; license would not permit royalty-free redistribution of the Library by; all those who receive copies directly or indirectly through you, then; the only way you could satisfy both it and this License would be to; refrain entirely from distribution of the Library. If any portion of this section is held invalid or unenforceable under any; particular circumstance, the balance of the section is intended to apply,; and the section as a whole is intended to apply in other circumstances. It is not the purpose of this section to induce you to infringe any; patents or other property right claims or to contest validity of any; such claims; this section has the sole purpose of protecting the; integrity of the free software distribution system which is; implemented by public license practices. Many people have made; generous contributions to the wide range of software distributed; through that system in reliance on consistent application of that; system; it is up to the author/donor to decide if he or she is willing; to distribute software through any other system and a licensee cannot; impose that choice. This section is intended to make thoroughly clear what is believed to; be a consequence of the rest of this License. 12. If the distribution and/or use of the Library is restricted in; certain countries either by patents or by copyrighted interfaces, the; original copyright holder who places the Library under this License may add; an explicit geographical distribution limitation excluding those countries,; so that distribution is permitted only in or among countries not thus; excluded. In such case, this License incorpora",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:2611,Usability,clear,clear,2611,"otect your rights, we need to make restrictions that forbid; distributors to deny you these rights or to ask you to surrender these; rights. These restrictions translate to certain responsibilities for; you if you distribute copies of the library or if you modify it. For example, if you distribute copies of the library, whether gratis; or for a fee, you must give the recipients all the rights that we gave; you. You must make sure that they, too, receive or can get the source; code. If you link other code with the library, you must provide; complete object files to the recipients, so that they can relink them; with the library after making changes to the library and recompiling; it. And you must show them these terms so they know their rights. We protect your rights with a two-step method: (1) we copyright the; library, and (2) we offer you this license, which gives you legal; permission to copy, distribute and/or modify the library. To protect each distributor, we want to make it very clear that; there is no warranty for the free library. Also, if the library is; modified by someone else and passed on, the recipients should know; that what they have is not the original version, so that the original; author's reputation will not be affected by problems that might be; introduced by others.; ; Finally, software patents pose a constant threat to the existence of; any free program. We wish to make sure that a company cannot; effectively restrict the users of a free program by obtaining a; restrictive license from a patent holder. Therefore, we insist that; any patent license obtained for a version of the library must be; consistent with the full freedom of use specified in this license. Most GNU software, including some libraries, is covered by the; ordinary GNU General Public License. This license, the GNU Lesser; General Public License, applies to certain designated libraries, and; is quite different from the ordinary General Public License. We use; this license for c",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:21228,Usability,clear,clear,21228,"tisfy both it and this License would be to; refrain entirely from distribution of the Library. If any portion of this section is held invalid or unenforceable under any; particular circumstance, the balance of the section is intended to apply,; and the section as a whole is intended to apply in other circumstances. It is not the purpose of this section to induce you to infringe any; patents or other property right claims or to contest validity of any; such claims; this section has the sole purpose of protecting the; integrity of the free software distribution system which is; implemented by public license practices. Many people have made; generous contributions to the wide range of software distributed; through that system in reliance on consistent application of that; system; it is up to the author/donor to decide if he or she is willing; to distribute software through any other system and a licensee cannot; impose that choice. This section is intended to make thoroughly clear what is believed to; be a consequence of the rest of this License. 12. If the distribution and/or use of the Library is restricted in; certain countries either by patents or by copyrighted interfaces, the; original copyright holder who places the Library under this License may add; an explicit geographical distribution limitation excluding those countries,; so that distribution is permitted only in or among countries not thus; excluded. In such case, this License incorporates the limitation as if; written in the body of this License. 13. The Free Software Foundation may publish revised and/or new; versions of the Lesser General Public License from time to time.; Such new versions will be similar in spirit to the present version,; but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library; specifies a version number of this License which applies to it and; ""any later version"", you have the option of following the terms and",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt:22835,Usability,guid,guided,22835,".; Such new versions will be similar in spirit to the present version,; but may differ in detail to address new problems or concerns. Each version is given a distinguishing version number. If the Library; specifies a version number of this License which applies to it and; ""any later version"", you have the option of following the terms and; conditions either of that version or of any later version published by; the Free Software Foundation. If the Library does not specify a; license version number, you may choose any version ever published by; the Free Software Foundation.; ; 14. If you wish to incorporate parts of the Library into other free; programs whose distribution conditions are incompatible with these,; write to the author to ask for permission. For software which is; copyrighted by the Free Software Foundation, write to the Free; Software Foundation; we sometimes make exceptions for this. Our; decision will be guided by the two goals of preserving the free status; of all derivatives of our free software and of promoting the sharing; and reuse of software generally. 			 NO WARRANTY. 15. BECAUSE THE LIBRARY IS LICENSED FREE OF CHARGE, THERE IS NO; WARRANTY FOR THE LIBRARY, TO THE EXTENT PERMITTED BY APPLICABLE LAW.; EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR; OTHER PARTIES PROVIDE THE LIBRARY ""AS IS"" WITHOUT WARRANTY OF ANY; KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE; IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE; LIBRARY IS WITH YOU. SHOULD THE LIBRARY PROVE DEFECTIVE, YOU ASSUME; THE COST OF ALL NECESSARY SERVICING, REPAIR OR CORRECTION. 16. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN; WRITING WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY; AND/OR REDISTRIBUTE THE LIBRARY AS PERMITTED ABOVE, BE LIABLE TO YOU; FOR DAMAGES, INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR; CONSEQUENTIAL DAMAG",MatchSource.DOCS,lib/omptl/License.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/omptl/License.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:1143,Deployability,install,install,1143,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:1194,Deployability,install,install,1194,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:161,Testability,log,log,161,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:185,Testability,log,logarithm,185,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:246,Testability,test,tests,246,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:306,Testability,test,tests,306,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:367,Testability,benchmark,benchmark,367,"cmake_minimum_required(VERSION 2.8.12). project(tinyexpr). option(TE_POW_FROM_RIGHT ""Evaluate exponents from right to left."" OFF); option(TE_NAT_LOG ""Define the log function as natural logarithm."" OFF); option(build_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); t",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:1312,Testability,test,test,1312,"ld_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); target_link_libraries(tinyexpr_example2 ${MATH_LIB}); endif(). if (build_tinyexpr_example3); add_executable(tinyexpr_example3 example3.c tinyexpr.c); target_link_libraries(tinyexpr_example3 ${MATH_LIB}); endif(); ",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:1452,Testability,test,test,1452,"ld_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); target_link_libraries(tinyexpr_example2 ${MATH_LIB}); endif(). if (build_tinyexpr_example3); add_executable(tinyexpr_example3 example3.c tinyexpr.c); target_link_libraries(tinyexpr_example3 ${MATH_LIB}); endif(); ",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt:1678,Testability,benchmark,benchmark,1678,"ld_tinyexpr_test ""Build TinyExpr tests."" OFF); option(build_tinyexpr_test_pr ""Build TinyExpr tests PR."" OFF); option(build_tinyexpr_bench ""Build TinyExpr benchmark."" OFF); option(build_tinyexpr_example ""Build TinyExpr example."" OFF); option(build_tinyexpr_example2 ""Build TinyExpr example 2."" OFF); option(build_tinyexpr_example3 ""Build TinyExpr example 3."" OFF). find_library(MATH_LIB m); if(NOT MATH_LIB); set(MATH_LIB """"); endif(). set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -ansi -Wall -Wshadow -fPIC -O3""). set(SOURCE_FILES; tinyexpr.c; tinyexpr.h; ). add_library(tinyexpr STATIC ${SOURCE_FILES}); set_target_properties(tinyexpr PROPERTIES COMPILE_FLAGS ""${MMSEQS_C_FLAGS}"" LINK_FLAGS ""${MMSEQS_C_FLAGS}""); if (TE_POW_FROM_RIGHT); target_compile_definitions(tinyexpr PRIVATE TE_POW_FROM_RIGHT); endif(); if (TE_NAT_LOG); target_compile_definitions(tinyexpr PRIVATE TE_NAT_LOG); endif(); target_link_libraries(tinyexpr ${MATH_LIB}); install(TARGETS tinyexpr ARCHIVE DESTINATION lib); install(FILES tinyexpr.h DESTINATION include COMPONENT Devel). if (build_tinyexpr_test); add_executable(tinyexpr_test test.c tinyexpr.c); target_link_libraries(tinyexpr_test ${MATH_LIB}); endif(). if (build_tinyexpr_test_pr); add_executable(tinyexpr_test_pr test.c tinyexpr.c); target_compile_definitions(tinyexpr_test_pr PRIVATE TE_POW_FROM_RIGHT TE_NAT_LOG); target_link_libraries(tinyexpr_test_pr ${MATH_LIB}); endif(). if (build_tinyexpr_bench); add_executable(tinyexpr_benchmark benchmark.c tinyexpr.c); target_link_libraries(tinyexpr_benchmark ${MATH_LIB}); endif(). if (build_tinyexpr_example); add_executable(tinyexpr_example example.c tinyexpr.c); target_link_libraries(tinyexpr_example ${MATH_LIB}); endif(). if (build_tinyexpr_example2); add_executable(tinyexpr_example2 example2.c tinyexpr.c); target_link_libraries(tinyexpr_example2 ${MATH_LIB}); endif(). if (build_tinyexpr_example3); add_executable(tinyexpr_example3 example3.c tinyexpr.c); target_link_libraries(tinyexpr_example3 ${MATH_LIB}); endif(); ",MatchSource.DOCS,lib/tinyexpr/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/tinyexpr/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt:621,Integrability,message,message,621,"# ################################################################; # Copyright (c) 2016-present, Yann Collet, Facebook, Inc.; # All rights reserved.; #; # This source code is licensed under both the BSD-style license (found in the; # LICENSE file in the root directory of this source tree) and the GPLv2 (found; # in the COPYING file in the root directory of this source tree).; # ################################################################. CMAKE_MINIMUM_REQUIRED(VERSION 2.8.9). PROJECT(zstd); SET(ZSTD_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/../..""). if (NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(STATUS ""No build type selected, defaulting to Release""); set(CMAKE_BUILD_TYPE ""Release""); endif(). LIST(APPEND CMAKE_MODULE_PATH ""${CMAKE_CURRENT_SOURCE_DIR}/CMakeModules""); INCLUDE(GNUInstallDirs). #-----------------------------------------------------------------------------; # Add extra compilation flags; #-----------------------------------------------------------------------------; INCLUDE(AddZstdCompilationFlags); ADD_ZSTD_COMPILATION_FLAGS(). # Always hide XXHash symbols; ADD_DEFINITIONS(-DXXH_NAMESPACE=ZSTD_). #-----------------------------------------------------------------------------; # Installation variables; #-----------------------------------------------------------------------------; MESSAGE(STATUS ""CMAKE_INSTALL_PREFIX: ${CMAKE_INSTALL_PREFIX}""); MESSAGE(STATUS ""CMAKE_INSTALL_LIBDIR: ${CMAKE_INSTALL_LIBDIR}""). #-----------------------------------------------------------------------------; # Options; #-----------------------------------------------------------------------------. # Legacy support; OPTION(ZSTD_LEGACY_SUPPORT ""LEGACY SUPPORT"" OFF). IF (ZSTD_LEGACY_SUPPORT); MESSAGE(STATUS ""ZSTD_LEGACY_SUPPORT defined!""); ADD_DEFINITIONS(-DZSTD_LEGACY_SUPPORT=4); ELSE (ZSTD_LEGACY_SUPPORT); MESSAGE(STATUS ""ZSTD_LEGACY_SUPPORT not defined!""); ADD_DEFINITIONS(-DZSTD_LEGACY_SUPPORT=0); ENDIF (ZSTD_LEGACY_SUPPORT). # Multi-threading support;",MatchSource.DOCS,lib/zstd/build/cmake/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt:2599,Integrability,depend,dependencies,2599,"T defined!""); ADD_DEFINITIONS(-DZSTD_LEGACY_SUPPORT=4); ELSE (ZSTD_LEGACY_SUPPORT); MESSAGE(STATUS ""ZSTD_LEGACY_SUPPORT not defined!""); ADD_DEFINITIONS(-DZSTD_LEGACY_SUPPORT=0); ENDIF (ZSTD_LEGACY_SUPPORT). # Multi-threading support; OPTION(ZSTD_MULTITHREAD_SUPPORT ""MULTITHREADING SUPPORT"" ON). IF (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is enabled""); ELSE (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is disabled""); ENDIF (ZSTD_MULTITHREAD_SUPPORT). OPTION(ZSTD_BUILD_PROGRAMS ""BUILD PROGRAMS"" ON); OPTION(ZSTD_BUILD_CONTRIB ""BUILD CONTRIB"" OFF); OPTION(ZSTD_BUILD_TESTS ""BUILD TESTS"" OFF); if (MSVC); OPTION(ZSTD_USE_STATIC_RUNTIME ""LINK TO STATIC RUN-TIME LIBRARIES"" OFF); endif (). #-----------------------------------------------------------------------------; # External dependencies; #-----------------------------------------------------------------------------; IF (ZSTD_MULTITHREAD_SUPPORT AND UNIX); SET(THREADS_PREFER_PTHREAD_FLAG ON); FIND_PACKAGE(Threads REQUIRED); IF(CMAKE_USE_PTHREADS_INIT); SET(THREADS_LIBS ""${CMAKE_THREAD_LIBS_INIT}""); ELSE(); MESSAGE(SEND_ERROR ""ZSTD currently does not support thread libraries other than pthreads""); ENDIF(); ENDIF (ZSTD_MULTITHREAD_SUPPORT AND UNIX). #-----------------------------------------------------------------------------; # Add source directories; #-----------------------------------------------------------------------------; ADD_SUBDIRECTORY(lib). IF (ZSTD_BUILD_PROGRAMS); IF (NOT ZSTD_BUILD_STATIC); MESSAGE(SEND_ERROR ""You need to build static library to build zstd CLI""); ENDIF (NOT ZSTD_BUILD_STATIC). ADD_SUBDIRECTORY(programs); ENDIF (ZSTD_BUILD_PROGRAMS). IF (ZSTD_BUILD_TESTS); IF (NOT ZSTD_BUILD_STATIC); MESSAGE(SEND_ERROR ""You need to build static library to build tests""); ENDIF (NOT ZSTD_BUILD_STATIC). ADD_SUBDIRECTORY(tests); ENDIF (ZSTD_BUILD_TESTS). IF (ZSTD_BUILD_CONTRIB); ADD_SUBDIRECTORY(contrib); ENDIF (ZSTD_BUILD_CONTRIB). #----------------------------",MatchSource.DOCS,lib/zstd/build/cmake/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt:1248,Modifiability,variab,variables,1248,"d; # in the COPYING file in the root directory of this source tree).; # ################################################################. CMAKE_MINIMUM_REQUIRED(VERSION 2.8.9). PROJECT(zstd); SET(ZSTD_SOURCE_DIR ""${CMAKE_CURRENT_SOURCE_DIR}/../..""). if (NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(STATUS ""No build type selected, defaulting to Release""); set(CMAKE_BUILD_TYPE ""Release""); endif(). LIST(APPEND CMAKE_MODULE_PATH ""${CMAKE_CURRENT_SOURCE_DIR}/CMakeModules""); INCLUDE(GNUInstallDirs). #-----------------------------------------------------------------------------; # Add extra compilation flags; #-----------------------------------------------------------------------------; INCLUDE(AddZstdCompilationFlags); ADD_ZSTD_COMPILATION_FLAGS(). # Always hide XXHash symbols; ADD_DEFINITIONS(-DXXH_NAMESPACE=ZSTD_). #-----------------------------------------------------------------------------; # Installation variables; #-----------------------------------------------------------------------------; MESSAGE(STATUS ""CMAKE_INSTALL_PREFIX: ${CMAKE_INSTALL_PREFIX}""); MESSAGE(STATUS ""CMAKE_INSTALL_LIBDIR: ${CMAKE_INSTALL_LIBDIR}""). #-----------------------------------------------------------------------------; # Options; #-----------------------------------------------------------------------------. # Legacy support; OPTION(ZSTD_LEGACY_SUPPORT ""LEGACY SUPPORT"" OFF). IF (ZSTD_LEGACY_SUPPORT); MESSAGE(STATUS ""ZSTD_LEGACY_SUPPORT defined!""); ADD_DEFINITIONS(-DZSTD_LEGACY_SUPPORT=4); ELSE (ZSTD_LEGACY_SUPPORT); MESSAGE(STATUS ""ZSTD_LEGACY_SUPPORT not defined!""); ADD_DEFINITIONS(-DZSTD_LEGACY_SUPPORT=0); ENDIF (ZSTD_LEGACY_SUPPORT). # Multi-threading support; OPTION(ZSTD_MULTITHREAD_SUPPORT ""MULTITHREADING SUPPORT"" ON). IF (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is enabled""); ELSE (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is disabled""); ENDIF (ZSTD_MULTITHREAD_SUPPORT). OPTION(ZSTD_BUILD_PROGRAMS ""BUILD PRO",MatchSource.DOCS,lib/zstd/build/cmake/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt:3568,Testability,test,tests,3568,"UPPORT ""MULTITHREADING SUPPORT"" ON). IF (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is enabled""); ELSE (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is disabled""); ENDIF (ZSTD_MULTITHREAD_SUPPORT). OPTION(ZSTD_BUILD_PROGRAMS ""BUILD PROGRAMS"" ON); OPTION(ZSTD_BUILD_CONTRIB ""BUILD CONTRIB"" OFF); OPTION(ZSTD_BUILD_TESTS ""BUILD TESTS"" OFF); if (MSVC); OPTION(ZSTD_USE_STATIC_RUNTIME ""LINK TO STATIC RUN-TIME LIBRARIES"" OFF); endif (). #-----------------------------------------------------------------------------; # External dependencies; #-----------------------------------------------------------------------------; IF (ZSTD_MULTITHREAD_SUPPORT AND UNIX); SET(THREADS_PREFER_PTHREAD_FLAG ON); FIND_PACKAGE(Threads REQUIRED); IF(CMAKE_USE_PTHREADS_INIT); SET(THREADS_LIBS ""${CMAKE_THREAD_LIBS_INIT}""); ELSE(); MESSAGE(SEND_ERROR ""ZSTD currently does not support thread libraries other than pthreads""); ENDIF(); ENDIF (ZSTD_MULTITHREAD_SUPPORT AND UNIX). #-----------------------------------------------------------------------------; # Add source directories; #-----------------------------------------------------------------------------; ADD_SUBDIRECTORY(lib). IF (ZSTD_BUILD_PROGRAMS); IF (NOT ZSTD_BUILD_STATIC); MESSAGE(SEND_ERROR ""You need to build static library to build zstd CLI""); ENDIF (NOT ZSTD_BUILD_STATIC). ADD_SUBDIRECTORY(programs); ENDIF (ZSTD_BUILD_PROGRAMS). IF (ZSTD_BUILD_TESTS); IF (NOT ZSTD_BUILD_STATIC); MESSAGE(SEND_ERROR ""You need to build static library to build tests""); ENDIF (NOT ZSTD_BUILD_STATIC). ADD_SUBDIRECTORY(tests); ENDIF (ZSTD_BUILD_TESTS). IF (ZSTD_BUILD_CONTRIB); ADD_SUBDIRECTORY(contrib); ENDIF (ZSTD_BUILD_CONTRIB). #-----------------------------------------------------------------------------; # Add clean-all target; #-----------------------------------------------------------------------------; ADD_CUSTOM_TARGET(clean-all; COMMAND ${CMAKE_BUILD_TOOL} clean; COMMAND rm -rf ${CMAKE_BINARY_DIR}/; ); ",MatchSource.DOCS,lib/zstd/build/cmake/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt:3625,Testability,test,tests,3625,"UPPORT ""MULTITHREADING SUPPORT"" ON). IF (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is enabled""); ELSE (ZSTD_MULTITHREAD_SUPPORT); MESSAGE(STATUS ""ZSTD_MULTITHREAD_SUPPORT is disabled""); ENDIF (ZSTD_MULTITHREAD_SUPPORT). OPTION(ZSTD_BUILD_PROGRAMS ""BUILD PROGRAMS"" ON); OPTION(ZSTD_BUILD_CONTRIB ""BUILD CONTRIB"" OFF); OPTION(ZSTD_BUILD_TESTS ""BUILD TESTS"" OFF); if (MSVC); OPTION(ZSTD_USE_STATIC_RUNTIME ""LINK TO STATIC RUN-TIME LIBRARIES"" OFF); endif (). #-----------------------------------------------------------------------------; # External dependencies; #-----------------------------------------------------------------------------; IF (ZSTD_MULTITHREAD_SUPPORT AND UNIX); SET(THREADS_PREFER_PTHREAD_FLAG ON); FIND_PACKAGE(Threads REQUIRED); IF(CMAKE_USE_PTHREADS_INIT); SET(THREADS_LIBS ""${CMAKE_THREAD_LIBS_INIT}""); ELSE(); MESSAGE(SEND_ERROR ""ZSTD currently does not support thread libraries other than pthreads""); ENDIF(); ENDIF (ZSTD_MULTITHREAD_SUPPORT AND UNIX). #-----------------------------------------------------------------------------; # Add source directories; #-----------------------------------------------------------------------------; ADD_SUBDIRECTORY(lib). IF (ZSTD_BUILD_PROGRAMS); IF (NOT ZSTD_BUILD_STATIC); MESSAGE(SEND_ERROR ""You need to build static library to build zstd CLI""); ENDIF (NOT ZSTD_BUILD_STATIC). ADD_SUBDIRECTORY(programs); ENDIF (ZSTD_BUILD_PROGRAMS). IF (ZSTD_BUILD_TESTS); IF (NOT ZSTD_BUILD_STATIC); MESSAGE(SEND_ERROR ""You need to build static library to build tests""); ENDIF (NOT ZSTD_BUILD_STATIC). ADD_SUBDIRECTORY(tests); ENDIF (ZSTD_BUILD_TESTS). IF (ZSTD_BUILD_CONTRIB); ADD_SUBDIRECTORY(contrib); ENDIF (ZSTD_BUILD_CONTRIB). #-----------------------------------------------------------------------------; # Add clean-all target; #-----------------------------------------------------------------------------; ADD_CUSTOM_TARGET(clean-all; COMMAND ${CMAKE_BUILD_TOOL} clean; COMMAND rm -rf ${CMAKE_BINARY_DIR}/; ); ",MatchSource.DOCS,lib/zstd/build/cmake/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt:1479,Performance,multi-thread,multi-threading,1479,"# #############################################################################; # Copyright (c) 2018-present Dima Krasner <dima@dimakrasner.com>; # lzutao <taolzu(at)gmail.com>; # All rights reserved.; #; # This source code is licensed under both the BSD-style license (found in the; # LICENSE file in the root directory of this source tree) and the GPLv2 (found; # in the COPYING file in the root directory of this source tree).; # #############################################################################. # Read guidelines from https://wiki.gnome.org/Initiatives/GnomeGoals/MesonPorting. option('legacy_level', type: 'integer', min: 0, max: 7, value: '5',; description: 'Support any legacy format: 7 to 1 for v0.7+ to v0.1+'); option('debug_level', type: 'integer', min: 0, max: 9, value: 1,; description: 'Enable run-time debug. See lib/common/debug.h'); option('backtrace', type: 'boolean', value: false,; description: 'Display a stack backtrace when execution generates a runtime exception'); option('static_runtime', type: 'boolean', value: false,; description: 'Link to static run-time libraries on MSVC'). option('build_programs', type: 'boolean', value: true,; description: 'Enable programs build'); option('build_tests', type: 'boolean', value: false,; description: 'Enable tests build'); option('build_contrib', type: 'boolean', value: false,; description: 'Enable contrib build'). option('multi_thread', type: 'feature', value: 'enabled',; description: 'Enable multi-threading when pthread is detected'); option('zlib', type: 'feature', value: 'auto',; description: 'Enable zlib support'); option('lzma', type: 'feature', value: 'auto',; description: 'Enable lzma support'); option('lz4', type: 'feature', value: 'auto',; description: 'Enable lz4 support'); ",MatchSource.DOCS,lib/zstd/build/meson/meson_options.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt:1511,Safety,detect,detected,1511,"# #############################################################################; # Copyright (c) 2018-present Dima Krasner <dima@dimakrasner.com>; # lzutao <taolzu(at)gmail.com>; # All rights reserved.; #; # This source code is licensed under both the BSD-style license (found in the; # LICENSE file in the root directory of this source tree) and the GPLv2 (found; # in the COPYING file in the root directory of this source tree).; # #############################################################################. # Read guidelines from https://wiki.gnome.org/Initiatives/GnomeGoals/MesonPorting. option('legacy_level', type: 'integer', min: 0, max: 7, value: '5',; description: 'Support any legacy format: 7 to 1 for v0.7+ to v0.1+'); option('debug_level', type: 'integer', min: 0, max: 9, value: 1,; description: 'Enable run-time debug. See lib/common/debug.h'); option('backtrace', type: 'boolean', value: false,; description: 'Display a stack backtrace when execution generates a runtime exception'); option('static_runtime', type: 'boolean', value: false,; description: 'Link to static run-time libraries on MSVC'). option('build_programs', type: 'boolean', value: true,; description: 'Enable programs build'); option('build_tests', type: 'boolean', value: false,; description: 'Enable tests build'); option('build_contrib', type: 'boolean', value: false,; description: 'Enable contrib build'). option('multi_thread', type: 'feature', value: 'enabled',; description: 'Enable multi-threading when pthread is detected'); option('zlib', type: 'feature', value: 'auto',; description: 'Enable zlib support'); option('lzma', type: 'feature', value: 'auto',; description: 'Enable lzma support'); option('lz4', type: 'feature', value: 'auto',; description: 'Enable lz4 support'); ",MatchSource.DOCS,lib/zstd/build/meson/meson_options.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt:1290,Testability,test,tests,1290,"# #############################################################################; # Copyright (c) 2018-present Dima Krasner <dima@dimakrasner.com>; # lzutao <taolzu(at)gmail.com>; # All rights reserved.; #; # This source code is licensed under both the BSD-style license (found in the; # LICENSE file in the root directory of this source tree) and the GPLv2 (found; # in the COPYING file in the root directory of this source tree).; # #############################################################################. # Read guidelines from https://wiki.gnome.org/Initiatives/GnomeGoals/MesonPorting. option('legacy_level', type: 'integer', min: 0, max: 7, value: '5',; description: 'Support any legacy format: 7 to 1 for v0.7+ to v0.1+'); option('debug_level', type: 'integer', min: 0, max: 9, value: 1,; description: 'Enable run-time debug. See lib/common/debug.h'); option('backtrace', type: 'boolean', value: false,; description: 'Display a stack backtrace when execution generates a runtime exception'); option('static_runtime', type: 'boolean', value: false,; description: 'Link to static run-time libraries on MSVC'). option('build_programs', type: 'boolean', value: true,; description: 'Enable programs build'); option('build_tests', type: 'boolean', value: false,; description: 'Enable tests build'); option('build_contrib', type: 'boolean', value: false,; description: 'Enable contrib build'). option('multi_thread', type: 'feature', value: 'enabled',; description: 'Enable multi-threading when pthread is detected'); option('zlib', type: 'feature', value: 'auto',; description: 'Enable zlib support'); option('lzma', type: 'feature', value: 'auto',; description: 'Enable lzma support'); option('lz4', type: 'feature', value: 'auto',; description: 'Enable lz4 support'); ",MatchSource.DOCS,lib/zstd/build/meson/meson_options.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt:520,Usability,guid,guidelines,520,"# #############################################################################; # Copyright (c) 2018-present Dima Krasner <dima@dimakrasner.com>; # lzutao <taolzu(at)gmail.com>; # All rights reserved.; #; # This source code is licensed under both the BSD-style license (found in the; # LICENSE file in the root directory of this source tree) and the GPLv2 (found; # in the COPYING file in the root directory of this source tree).; # #############################################################################. # Read guidelines from https://wiki.gnome.org/Initiatives/GnomeGoals/MesonPorting. option('legacy_level', type: 'integer', min: 0, max: 7, value: '5',; description: 'Support any legacy format: 7 to 1 for v0.7+ to v0.1+'); option('debug_level', type: 'integer', min: 0, max: 9, value: 1,; description: 'Enable run-time debug. See lib/common/debug.h'); option('backtrace', type: 'boolean', value: false,; description: 'Display a stack backtrace when execution generates a runtime exception'); option('static_runtime', type: 'boolean', value: false,; description: 'Link to static run-time libraries on MSVC'). option('build_programs', type: 'boolean', value: true,; description: 'Enable programs build'); option('build_tests', type: 'boolean', value: false,; description: 'Enable tests build'); option('build_contrib', type: 'boolean', value: false,; description: 'Enable contrib build'). option('multi_thread', type: 'feature', value: 'enabled',; description: 'Enable multi-threading when pthread is detected'); option('zlib', type: 'feature', value: 'auto',; description: 'Enable zlib support'); option('lzma', type: 'feature', value: 'auto',; description: 'Enable lzma support'); option('lz4', type: 'feature', value: 'auto',; description: 'Enable lz4 support'); ",MatchSource.DOCS,lib/zstd/build/meson/meson_options.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/meson/meson_options.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt:6422,Deployability,install,install,6422,"ibrary needs to be renamed to avoid conflict with import library; IF (MSVC); SET(STATIC_LIBRARY_BASE_NAME zstd_static); ELSE (); SET(STATIC_LIBRARY_BASE_NAME zstd); ENDIF (MSVC). # Define static and shared library names; IF (ZSTD_BUILD_SHARED); SET_TARGET_PROPERTIES(; libzstd_shared; PROPERTIES; OUTPUT_NAME zstd; SOVERSION ${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}); ENDIF (ZSTD_BUILD_SHARED). IF (ZSTD_BUILD_STATIC); SET_TARGET_PROPERTIES(; libzstd_static; PROPERTIES; OUTPUT_NAME ${STATIC_LIBRARY_BASE_NAME}); ENDIF (ZSTD_BUILD_STATIC). IF (UNIX); # pkg-config; SET(PREFIX ""${CMAKE_INSTALL_PREFIX}""); SET(LIBDIR ""${CMAKE_INSTALL_PREFIX}/${CMAKE_INSTALL_LIBDIR}""); SET(INCLUDEDIR ""${CMAKE_INSTALL_PREFIX}/include""); SET(VERSION ""${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}""); ADD_CUSTOM_TARGET(libzstd.pc ALL; ${CMAKE_COMMAND} -DIN=""${LIBRARY_DIR}/libzstd.pc.in"" -DOUT=""libzstd.pc""; -DPREFIX=""${PREFIX}"" -DLIBDIR=""${LIBDIR}"" -DINCLUDEDIR=""${INCLUDEDIR}"" -DVERSION=""${VERSION}""; -P ""${CMAKE_CURRENT_SOURCE_DIR}/pkgconfig.cmake""; COMMENT ""Creating pkg-config file""). INSTALL(FILES ""${CMAKE_CURRENT_BINARY_DIR}/libzstd.pc"" DESTINATION ""${LIBDIR}/pkgconfig""); ENDIF (UNIX). # install target; INSTALL(FILES; ${LIBRARY_DIR}/zstd.h; ${LIBRARY_DIR}/deprecated/zbuff.h; ${LIBRARY_DIR}/dictBuilder/zdict.h; ${LIBRARY_DIR}/dictBuilder/cover.h; ${LIBRARY_DIR}/common/zstd_errors.h; DESTINATION ""include""). IF (ZSTD_BUILD_SHARED); INSTALL(TARGETS libzstd_shared RUNTIME DESTINATION ""bin""; LIBRARY DESTINATION ""${CMAKE_INSTALL_LIBDIR}""; ARCHIVE DESTINATION ""${CMAKE_INSTALL_LIBDIR}""); ENDIF(); IF (ZSTD_BUILD_STATIC); INSTALL(TARGETS libzstd_static ARCHIVE DESTINATION ""${CMAKE_INSTALL_LIBDIR}""); ENDIF (ZSTD_BUILD_STATIC). # uninstall target; CONFIGURE_FILE(; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake_uninstall.cmake.in""; ""${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake""; IMMEDIATE @ONLY). ADD_CUSTOM_TARGET(uninstall; COMMAND ${CMAKE_COMMAND} -P ${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake); ",MatchSource.DOCS,lib/zstd/build/cmake/lib/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt:5799,Modifiability,config,config,5799,"ibzstd_shared APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_DLL_EXPORT=1;ZSTD_HEAPMODE=0;_CONSOLE;_CRT_SECURE_NO_WARNINGS""); ENDIF (ZSTD_BUILD_SHARED); IF (ZSTD_BUILD_STATIC); SET_PROPERTY(TARGET libzstd_static APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_HEAPMODE=0;_CRT_SECURE_NO_WARNINGS""); ENDIF (ZSTD_BUILD_STATIC); ENDIF (MSVC). # With MSVC static library needs to be renamed to avoid conflict with import library; IF (MSVC); SET(STATIC_LIBRARY_BASE_NAME zstd_static); ELSE (); SET(STATIC_LIBRARY_BASE_NAME zstd); ENDIF (MSVC). # Define static and shared library names; IF (ZSTD_BUILD_SHARED); SET_TARGET_PROPERTIES(; libzstd_shared; PROPERTIES; OUTPUT_NAME zstd; SOVERSION ${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}); ENDIF (ZSTD_BUILD_SHARED). IF (ZSTD_BUILD_STATIC); SET_TARGET_PROPERTIES(; libzstd_static; PROPERTIES; OUTPUT_NAME ${STATIC_LIBRARY_BASE_NAME}); ENDIF (ZSTD_BUILD_STATIC). IF (UNIX); # pkg-config; SET(PREFIX ""${CMAKE_INSTALL_PREFIX}""); SET(LIBDIR ""${CMAKE_INSTALL_PREFIX}/${CMAKE_INSTALL_LIBDIR}""); SET(INCLUDEDIR ""${CMAKE_INSTALL_PREFIX}/include""); SET(VERSION ""${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}""); ADD_CUSTOM_TARGET(libzstd.pc ALL; ${CMAKE_COMMAND} -DIN=""${LIBRARY_DIR}/libzstd.pc.in"" -DOUT=""libzstd.pc""; -DPREFIX=""${PREFIX}"" -DLIBDIR=""${LIBDIR}"" -DINCLUDEDIR=""${INCLUDEDIR}"" -DVERSION=""${VERSION}""; -P ""${CMAKE_CURRENT_SOURCE_DIR}/pkgconfig.cmake""; COMMENT ""Creating pkg-config file""). INSTALL(FILES ""${CMAKE_CURRENT_BINARY_DIR}/libzstd.pc"" DESTINATION ""${LIBDIR}/pkgconfig""); ENDIF (UNIX). # install target; INSTALL(FILES; ${LIBRARY_DIR}/zstd.h; ${LIBRARY_DIR}/deprecated/zbuff.h; ${LIBRARY_DIR}/dictBuilder/zdict.h; ${LIBRARY_DIR}/dictBuilder/cover.h; ${LIBRARY_DIR}/common/zstd_errors.h; DESTINATION ""include""). IF (ZSTD_BUILD_SHARED); INSTALL(TARGETS libzstd_shared RUNTIME DESTINATION ""bin""; LIBRARY DESTINATION ""${CMAKE_INSTALL_LIBDIR}""; ARCHIVE DESTINATION ""${CMAKE_INSTALL_LIBDIR}""); ENDIF(); IF (ZSTD_BUILD_STATIC); INSTALL(TARGETS libzstd_static ",MatchSource.DOCS,lib/zstd/build/cmake/lib/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt:6300,Modifiability,config,config,6300,"ibrary needs to be renamed to avoid conflict with import library; IF (MSVC); SET(STATIC_LIBRARY_BASE_NAME zstd_static); ELSE (); SET(STATIC_LIBRARY_BASE_NAME zstd); ENDIF (MSVC). # Define static and shared library names; IF (ZSTD_BUILD_SHARED); SET_TARGET_PROPERTIES(; libzstd_shared; PROPERTIES; OUTPUT_NAME zstd; SOVERSION ${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}); ENDIF (ZSTD_BUILD_SHARED). IF (ZSTD_BUILD_STATIC); SET_TARGET_PROPERTIES(; libzstd_static; PROPERTIES; OUTPUT_NAME ${STATIC_LIBRARY_BASE_NAME}); ENDIF (ZSTD_BUILD_STATIC). IF (UNIX); # pkg-config; SET(PREFIX ""${CMAKE_INSTALL_PREFIX}""); SET(LIBDIR ""${CMAKE_INSTALL_PREFIX}/${CMAKE_INSTALL_LIBDIR}""); SET(INCLUDEDIR ""${CMAKE_INSTALL_PREFIX}/include""); SET(VERSION ""${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}""); ADD_CUSTOM_TARGET(libzstd.pc ALL; ${CMAKE_COMMAND} -DIN=""${LIBRARY_DIR}/libzstd.pc.in"" -DOUT=""libzstd.pc""; -DPREFIX=""${PREFIX}"" -DLIBDIR=""${LIBDIR}"" -DINCLUDEDIR=""${INCLUDEDIR}"" -DVERSION=""${VERSION}""; -P ""${CMAKE_CURRENT_SOURCE_DIR}/pkgconfig.cmake""; COMMENT ""Creating pkg-config file""). INSTALL(FILES ""${CMAKE_CURRENT_BINARY_DIR}/libzstd.pc"" DESTINATION ""${LIBDIR}/pkgconfig""); ENDIF (UNIX). # install target; INSTALL(FILES; ${LIBRARY_DIR}/zstd.h; ${LIBRARY_DIR}/deprecated/zbuff.h; ${LIBRARY_DIR}/dictBuilder/zdict.h; ${LIBRARY_DIR}/dictBuilder/cover.h; ${LIBRARY_DIR}/common/zstd_errors.h; DESTINATION ""include""). IF (ZSTD_BUILD_SHARED); INSTALL(TARGETS libzstd_shared RUNTIME DESTINATION ""bin""; LIBRARY DESTINATION ""${CMAKE_INSTALL_LIBDIR}""; ARCHIVE DESTINATION ""${CMAKE_INSTALL_LIBDIR}""); ENDIF(); IF (ZSTD_BUILD_STATIC); INSTALL(TARGETS libzstd_static ARCHIVE DESTINATION ""${CMAKE_INSTALL_LIBDIR}""); ENDIF (ZSTD_BUILD_STATIC). # uninstall target; CONFIGURE_FILE(; ""${CMAKE_CURRENT_SOURCE_DIR}/cmake_uninstall.cmake.in""; ""${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake""; IMMEDIATE @ONLY). ADD_CUSTOM_TARGET(uninstall; COMMAND ${CMAKE_COMMAND} -P ${CMAKE_CURRENT_BINARY_DIR}/cmake_uninstall.cmake); ",MatchSource.DOCS,lib/zstd/build/cmake/lib/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt:5263,Safety,avoid,avoid,5263,"E_DEFINITIONS ""ZSTD_MULTITHREAD""); IF (UNIX); TARGET_LINK_LIBRARIES(libzstd_shared ${THREADS_LIBS}); ENDIF (); ENDIF(); ENDIF (ZSTD_BUILD_SHARED); IF (ZSTD_BUILD_STATIC); ADD_LIBRARY(libzstd_static STATIC ${Sources} ${Headers}); IF (ZSTD_MULTITHREAD_SUPPORT); SET_PROPERTY(TARGET libzstd_static APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_MULTITHREAD""); IF (UNIX); TARGET_LINK_LIBRARIES(libzstd_static ${THREADS_LIBS}); ENDIF (); ENDIF (); ENDIF (ZSTD_BUILD_STATIC). # Add specific compile definitions for MSVC project; IF (MSVC); IF (ZSTD_BUILD_SHARED); SET_PROPERTY(TARGET libzstd_shared APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_DLL_EXPORT=1;ZSTD_HEAPMODE=0;_CONSOLE;_CRT_SECURE_NO_WARNINGS""); ENDIF (ZSTD_BUILD_SHARED); IF (ZSTD_BUILD_STATIC); SET_PROPERTY(TARGET libzstd_static APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_HEAPMODE=0;_CRT_SECURE_NO_WARNINGS""); ENDIF (ZSTD_BUILD_STATIC); ENDIF (MSVC). # With MSVC static library needs to be renamed to avoid conflict with import library; IF (MSVC); SET(STATIC_LIBRARY_BASE_NAME zstd_static); ELSE (); SET(STATIC_LIBRARY_BASE_NAME zstd); ENDIF (MSVC). # Define static and shared library names; IF (ZSTD_BUILD_SHARED); SET_TARGET_PROPERTIES(; libzstd_shared; PROPERTIES; OUTPUT_NAME zstd; SOVERSION ${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}); ENDIF (ZSTD_BUILD_SHARED). IF (ZSTD_BUILD_STATIC); SET_TARGET_PROPERTIES(; libzstd_static; PROPERTIES; OUTPUT_NAME ${STATIC_LIBRARY_BASE_NAME}); ENDIF (ZSTD_BUILD_STATIC). IF (UNIX); # pkg-config; SET(PREFIX ""${CMAKE_INSTALL_PREFIX}""); SET(LIBDIR ""${CMAKE_INSTALL_PREFIX}/${CMAKE_INSTALL_LIBDIR}""); SET(INCLUDEDIR ""${CMAKE_INSTALL_PREFIX}/include""); SET(VERSION ""${LIBVER_MAJOR}.${LIBVER_MINOR}.${LIBVER_RELEASE}""); ADD_CUSTOM_TARGET(libzstd.pc ALL; ${CMAKE_COMMAND} -DIN=""${LIBRARY_DIR}/libzstd.pc.in"" -DOUT=""libzstd.pc""; -DPREFIX=""${PREFIX}"" -DLIBDIR=""${LIBDIR}"" -DINCLUDEDIR=""${INCLUDEDIR}"" -DVERSION=""${VERSION}""; -P ""${CMAKE_CURRENT_SOURCE_DIR}/pkgconfig.cmake""; COMMENT ""Creating pkg-config file""",MatchSource.DOCS,lib/zstd/build/cmake/lib/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/lib/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/programs/CMakeLists.txt:3485,Performance,multi-thread,multi-threading,3485,".1 ALL ${CMAKE_COMMAND} -E create_symlink zstd.1 unzstd.1 DEPENDS zstd.1 COMMENT ""Creating unzstd.1 symlink""). # Define MAN_INSTALL_DIR if necessary; IF (MAN_INSTALL_DIR); ELSE (MAN_INSTALL_DIR); SET(MAN_INSTALL_DIR ${CMAKE_INSTALL_PREFIX}/share/man/man1); ENDIF (MAN_INSTALL_DIR). INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/zstd.1 DESTINATION ""${MAN_INSTALL_DIR}""); INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/zstdcat.1 DESTINATION ""${MAN_INSTALL_DIR}""); INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/unzstd.1 DESTINATION ""${MAN_INSTALL_DIR}""); INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/zstdgrep.1 DESTINATION ""${MAN_INSTALL_DIR}""); INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/zstdless.1 DESTINATION ""${MAN_INSTALL_DIR}""). ADD_EXECUTABLE(zstd-frugal ${PROGRAMS_DIR}/zstdcli.c ${PROGRAMS_DIR}/util.c ${PROGRAMS_DIR}/fileio.c); TARGET_LINK_LIBRARIES(zstd-frugal libzstd_static); SET_PROPERTY(TARGET zstd-frugal APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_NOBENCH;ZSTD_NODICT""); ENDIF (UNIX). # Add multi-threading support definitions. IF (ZSTD_MULTITHREAD_SUPPORT); SET_PROPERTY(TARGET zstd APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_MULTITHREAD""). IF (UNIX); TARGET_LINK_LIBRARIES(zstd ${THREADS_LIBS}). ADD_CUSTOM_TARGET(zstdmt ALL ${CMAKE_COMMAND} -E create_symlink zstd zstdmt DEPENDS zstd COMMENT ""Creating zstdmt symlink""); INSTALL(FILES ${CMAKE_CURRENT_BINARY_DIR}/zstdmt DESTINATION ""bin""); ENDIF (UNIX); ENDIF (ZSTD_MULTITHREAD_SUPPORT). OPTION(ZSTD_ZLIB_SUPPORT ""ZLIB SUPPORT"" OFF); OPTION(ZSTD_LZMA_SUPPORT ""LZMA SUPPORT"" OFF). IF (ZSTD_ZLIB_SUPPORT); FIND_PACKAGE(ZLIB REQUIRED). IF (ZLIB_FOUND); INCLUDE_DIRECTORIES(${ZLIB_INCLUDE_DIRS}); TARGET_LINK_LIBRARIES(zstd ${ZLIB_LIBRARIES}); SET_PROPERTY(TARGET zstd APPEND PROPERTY COMPILE_DEFINITIONS ""ZSTD_GZCOMPRESS;ZSTD_GZDECOMPRESS""); ELSE (); MESSAGE(SEND_ERROR ""zlib library is missing""); ENDIF (); ENDIF (). IF (ZSTD_LZMA_SUPPORT); FIND_PACKAGE(LibLZMA REQUIRED). IF (LIBLZMA_FOUND); INCLUDE_DIRECTORIES(${LIBLZMA_INCLUDE_DIRS}); TARGET_LINK_LIBRAR",MatchSource.DOCS,lib/zstd/build/cmake/programs/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/programs/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/tests/CMakeLists.txt:1621,Testability,test,tests,1621,"/or; # other materials provided with the distribution.; #; # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND; # ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED; # WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE; # DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR; # ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES; # (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;; # LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON; # ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT; # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS; # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.; #; # You can contact the author at :; # - zstd homepage : http://www.zstd.net/; # ################################################################. PROJECT(tests). SET(CMAKE_INCLUDE_CURRENT_DIR TRUE). # Define programs directory, where sources and header files are located; SET(LIBRARY_DIR ${ZSTD_SOURCE_DIR}/lib); SET(PROGRAMS_DIR ${ZSTD_SOURCE_DIR}/programs); SET(TESTS_DIR ${ZSTD_SOURCE_DIR}/tests); INCLUDE_DIRECTORIES(${TESTS_DIR} ${PROGRAMS_DIR} ${LIBRARY_DIR} ${LIBRARY_DIR}/common ${LIBRARY_DIR}/compress ${LIBRARY_DIR}/dictBuilder). ADD_EXECUTABLE(datagen ${PROGRAMS_DIR}/datagen.c ${TESTS_DIR}/datagencli.c); TARGET_LINK_LIBRARIES(datagen libzstd_static). ADD_EXECUTABLE(fullbench ${PROGRAMS_DIR}/datagen.c ${PROGRAMS_DIR}/util.c ${PROGRAMS_DIR}/benchfn.c ${PROGRAMS_DIR}/benchzstd.c ${TESTS_DIR}/fullbench.c); TARGET_LINK_LIBRARIES(fullbench libzstd_static). ADD_EXECUTABLE(fuzzer ${PROGRAMS_DIR}/datagen.c ${PROGRAMS_DIR}/util.c ${TESTS_DIR}/fuzzer.c); TARGET_LINK_LIBRARIES(fuzzer libzstd_static). IF (UNIX); ADD_EXECUTABLE(paramgrill ${PROGRAMS_DIR}/benchfn.c ${PROGRAMS_DIR}/benchzstd.c ${PROGRAMS_DIR}/datagen.c ${PROGRAMS_DIR}/util.c ${TE",MatchSource.DOCS,lib/zstd/build/cmake/tests/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/tests/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/tests/CMakeLists.txt:1860,Testability,test,tests,1860,"RS AND CONTRIBUTORS ""AS IS"" AND; # ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED; # WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE; # DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR; # ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES; # (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;; # LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON; # ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT; # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS; # SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.; #; # You can contact the author at :; # - zstd homepage : http://www.zstd.net/; # ################################################################. PROJECT(tests). SET(CMAKE_INCLUDE_CURRENT_DIR TRUE). # Define programs directory, where sources and header files are located; SET(LIBRARY_DIR ${ZSTD_SOURCE_DIR}/lib); SET(PROGRAMS_DIR ${ZSTD_SOURCE_DIR}/programs); SET(TESTS_DIR ${ZSTD_SOURCE_DIR}/tests); INCLUDE_DIRECTORIES(${TESTS_DIR} ${PROGRAMS_DIR} ${LIBRARY_DIR} ${LIBRARY_DIR}/common ${LIBRARY_DIR}/compress ${LIBRARY_DIR}/dictBuilder). ADD_EXECUTABLE(datagen ${PROGRAMS_DIR}/datagen.c ${TESTS_DIR}/datagencli.c); TARGET_LINK_LIBRARIES(datagen libzstd_static). ADD_EXECUTABLE(fullbench ${PROGRAMS_DIR}/datagen.c ${PROGRAMS_DIR}/util.c ${PROGRAMS_DIR}/benchfn.c ${PROGRAMS_DIR}/benchzstd.c ${TESTS_DIR}/fullbench.c); TARGET_LINK_LIBRARIES(fullbench libzstd_static). ADD_EXECUTABLE(fuzzer ${PROGRAMS_DIR}/datagen.c ${PROGRAMS_DIR}/util.c ${TESTS_DIR}/fuzzer.c); TARGET_LINK_LIBRARIES(fuzzer libzstd_static). IF (UNIX); ADD_EXECUTABLE(paramgrill ${PROGRAMS_DIR}/benchfn.c ${PROGRAMS_DIR}/benchzstd.c ${PROGRAMS_DIR}/datagen.c ${PROGRAMS_DIR}/util.c ${TESTS_DIR}/paramgrill.c); TARGET_LINK_LIBRARIES(paramgrill libzstd_static m) #m is math library; ENDIF (UNIX); ",MatchSource.DOCS,lib/zstd/build/cmake/tests/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/build/cmake/tests/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/util/CMakeLists.txt:710,Availability,mask,masksequence,710,set(util_source_files; util/alignall.cpp; util/alignbykmer.cpp; util/appenddbtoindex.cpp; util/apply.cpp; util/clusthash.cpp; util/compress.cpp; util/convert2fasta.cpp; util/convertalignments.cpp; util/convertca3m.cpp; util/convertkb.cpp; util/convertmsa.cpp; util/convertprofiledb.cpp; util/createdb.cpp; util/dbtype.cpp; util/db2tar.cpp; util/indexdb.cpp; util/offsetalignment.cpp; util/createseqfiledb.cpp; util/createsubdb.cpp; util/view.cpp; util/createtsv.cpp; util/diffseqdbs.cpp; util/expandaln.cpp; util/extractalignedregion.cpp; util/extractdomains.cpp; util/extractorfs.cpp; util/orftocontig.cpp; util/touchdb.cpp; util/filtera3m.cpp; util/filterdb.cpp; util/gff2db.cpp; util/renamedbkeys.cpp; util/masksequence.cpp; util/maskbygff.cpp; util/mergeclusters.cpp; util/mergeresultsbyset.cpp; util/mergedbs.cpp; util/createclusterdb.cpp; util/msa2profile.cpp; util/msa2result.cpp; util/nrtotaxmapping.cpp; util/countkmer.cpp; util/pairaln.cpp; util/prefixid.cpp; util/profile2pssm.cpp; util/profile2neff.cpp; util/profile2seq.cpp; util/result2dnamsa.cpp; util/result2flat.cpp; util/result2msa.cpp; util/result2rbh.cpp; util/result2profile.cpp; util/result2repseq.cpp; util/result2stats.cpp; util/reverseseq.cpp; util/cpmvrmlndb.cpp; util/extractframes.cpp; util/sequence2profile.cpp; util/setextendeddbtype.cpp; util/sortresult.cpp; util/splitdb.cpp; util/setextendeddbtype.cpp; util/splitsequence.cpp; util/subtractdbs.cpp; util/summarizealis.cpp; util/summarizeheaders.cpp; util/summarizeresult.cpp; util/summarizetabs.cpp; util/swapresults.cpp; util/transitivealign.cpp; util/translatenucs.cpp; util/translateaa.cpp; util/tsv2db.cpp; util/tsv2exprofiledb.cpp; util/tar2db.cpp; util/unpackdb.cpp; util/proteinaln2nucl.cpp; util/versionstring.cpp; util/diskspaceavail.cpp; PARENT_SCOPE; ); ,MatchSource.DOCS,src/util/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/util/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/util/CMakeLists.txt:733,Availability,mask,maskbygff,733,set(util_source_files; util/alignall.cpp; util/alignbykmer.cpp; util/appenddbtoindex.cpp; util/apply.cpp; util/clusthash.cpp; util/compress.cpp; util/convert2fasta.cpp; util/convertalignments.cpp; util/convertca3m.cpp; util/convertkb.cpp; util/convertmsa.cpp; util/convertprofiledb.cpp; util/createdb.cpp; util/dbtype.cpp; util/db2tar.cpp; util/indexdb.cpp; util/offsetalignment.cpp; util/createseqfiledb.cpp; util/createsubdb.cpp; util/view.cpp; util/createtsv.cpp; util/diffseqdbs.cpp; util/expandaln.cpp; util/extractalignedregion.cpp; util/extractdomains.cpp; util/extractorfs.cpp; util/orftocontig.cpp; util/touchdb.cpp; util/filtera3m.cpp; util/filterdb.cpp; util/gff2db.cpp; util/renamedbkeys.cpp; util/masksequence.cpp; util/maskbygff.cpp; util/mergeclusters.cpp; util/mergeresultsbyset.cpp; util/mergedbs.cpp; util/createclusterdb.cpp; util/msa2profile.cpp; util/msa2result.cpp; util/nrtotaxmapping.cpp; util/countkmer.cpp; util/pairaln.cpp; util/prefixid.cpp; util/profile2pssm.cpp; util/profile2neff.cpp; util/profile2seq.cpp; util/result2dnamsa.cpp; util/result2flat.cpp; util/result2msa.cpp; util/result2rbh.cpp; util/result2profile.cpp; util/result2repseq.cpp; util/result2stats.cpp; util/reverseseq.cpp; util/cpmvrmlndb.cpp; util/extractframes.cpp; util/sequence2profile.cpp; util/setextendeddbtype.cpp; util/sortresult.cpp; util/splitdb.cpp; util/setextendeddbtype.cpp; util/splitsequence.cpp; util/subtractdbs.cpp; util/summarizealis.cpp; util/summarizeheaders.cpp; util/summarizeresult.cpp; util/summarizetabs.cpp; util/swapresults.cpp; util/transitivealign.cpp; util/translatenucs.cpp; util/translateaa.cpp; util/tsv2db.cpp; util/tsv2exprofiledb.cpp; util/tar2db.cpp; util/unpackdb.cpp; util/proteinaln2nucl.cpp; util/versionstring.cpp; util/diskspaceavail.cpp; PARENT_SCOPE; ); ,MatchSource.DOCS,src/util/CMakeLists.txt,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/src/util/CMakeLists.txt
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:2540,Availability,error,error,2540,"e highly improved using; a dictionary. Dictionary compression can be performed in:; - a single step (described as Simple dictionary API); - a single step, reusing a dictionary (described as Bulk-processing; dictionary API). Advanced experimental functions can be accessed using; `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h. Advanced experimental APIs should never be used with a dynamically-linked; library. They are not ""stable""; their definitions or signatures may change in; the future. Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapacity` is an upper bound of originalSize to regenerate.; If user cannot imply a maximum upper bound, it's better to use streaming mode to decompress data.; @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),; or an errorCode if it fails (which can be tested using ZSTD_isError()). . #define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1); #define ZSTD_CONTENTSIZE_ERROR (0ULL - 2); unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame.; `srcSize` must be at least as large as the frame header.; hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.; @return : - decompressed size of `src` frame content, if known; - ZSTD_C",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:3050,Availability,error,errorCode,3050,"Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapacity` is an upper bound of originalSize to regenerate.; If user cannot imply a maximum upper bound, it's better to use streaming mode to decompress data.; @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),; or an errorCode if it fails (which can be tested using ZSTD_isError()). . #define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1); #define ZSTD_CONTENTSIZE_ERROR (0ULL - 2); unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame.; `srcSize` must be at least as large as the frame header.; hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.; @return : - decompressed size of `src` frame content, if known; - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined; - ZSTD_CONTENTSIZE_ERROR if an error occurred (e.g. invalid magic number, srcSize too small); note 1 : a 0 return value means the frame is valid but ""empty"".; note 2 : decompressed size is an optional field, it may not be present, typically in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; Optionally, application can rely on s",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:3621,Availability,error,error,3621,"if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapacity` is an upper bound of originalSize to regenerate.; If user cannot imply a maximum upper bound, it's better to use streaming mode to decompress data.; @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),; or an errorCode if it fails (which can be tested using ZSTD_isError()). . #define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1); #define ZSTD_CONTENTSIZE_ERROR (0ULL - 2); unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame.; `srcSize` must be at least as large as the frame header.; hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.; @return : - decompressed size of `src` frame content, if known; - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined; - ZSTD_CONTENTSIZE_ERROR if an error occurred (e.g. invalid magic number, srcSize too small); note 1 : a 0 return value means the frame is valid but ""empty"".; note 2 : decompressed size is an optional field, it may not be present, typically in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; Optionally, application can rely on some implicit limit,; as ZSTD_decompress() only needs an upper bound of decompressed size.; (For example, data could be necessarily cut into blocks <= 16 KB).; note 3 : decompressed size is always present when compression is completed using single-pass functions,; such as ZSTD_compress(), ZSTD_compressCCtx() ZSTD_compress_usingDict() or ZSTD_compress_usingCDict().; note 4 : decompressed size can be very large (64-bits value),; potentially larger than what local system can handle as a single memory segment.",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:5150,Availability,error,error,5150,"be necessarily cut into blocks <= 16 KB).; note 3 : decompressed size is always present when compression is completed using single-pass functions,; such as ZSTD_compress(), ZSTD_compressCCtx() ZSTD_compress_usingDict() or ZSTD_compress_usingCDict().; note 4 : decompressed size can be very large (64-bits value),; potentially larger than what local system can handle as a single memory segment.; In which case, it's necessary to use streaming mode to decompress data.; note 5 : If source is untrusted, decompressed size could be wrong or intentionally modified.; Always ensure return value fits within application's authorized limits.; Each application can set its own limits.; note 6 : This function replaces ZSTD_getDecompressedSize() . unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);; NOTE: This function is now obsolete, in favor of ZSTD_getFrameContentSize().; Both functions work the same way, but ZSTD_getDecompressedSize() blends; ""empty"", ""unknown"" and ""error"" results to the same return value (0),; while ZSTD_getFrameContentSize() gives them separate return values.; @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:5821,Availability,error,error,5821,"uld be wrong or intentionally modified.; Always ensure return value fits within application's authorized limits.; Each application can set its own limits.; note 6 : This function replaces ZSTD_getDecompressedSize() . unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);; NOTE: This function is now obsolete, in favor of ZSTD_getFrameContentSize().; Both functions work the same way, but ZSTD_getDecompressedSize() blends; ""empty"", ""unknown"" and ""error"" results to the same return value (0),; while ZSTD_getFrameContentSize() gives them separate return values.; @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:5918,Availability,error,error,5918,"uld be wrong or intentionally modified.; Always ensure return value fits within application's authorized limits.; Each application can set its own limits.; note 6 : This function replaces ZSTD_getDecompressedSize() . unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);; NOTE: This function is now obsolete, in favor of ZSTD_getFrameContentSize().; Both functions work the same way, but ZSTD_getDecompressedSize() blends; ""empty"", ""unknown"" and ""error"" results to the same return value (0),; while ZSTD_getFrameContentSize() gives them separate return values.; @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:5990,Availability,avail,available,5990,"uld be wrong or intentionally modified.; Always ensure return value fits within application's authorized limits.; Each application can set its own limits.; note 6 : This function replaces ZSTD_getDecompressedSize() . unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);; NOTE: This function is now obsolete, in favor of ZSTD_getFrameContentSize().; Both functions work the same way, but ZSTD_getDecompressedSize() blends; ""empty"", ""unknown"" and ""error"" results to the same return value (0),; while ZSTD_getFrameContentSize() gives them separate return values.; @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12084,Availability,error,error,12084,"re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check if input has been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush()",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12835,Availability,error,error,12835,"been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and fully flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now effectively same object (>= v1.3.0) */. ZSTD_CStream management functionsZSTD_CStream* ZSTD_createCStream(void);; size_t ZSTD_freeCStream(ZSTD_CStream* zcs);. Streaming compression functionssize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; siz",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:13305,Availability,error,error,13305,"s guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and fully flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now effectively same object (>= v1.3.0) */. ZSTD_CStream management functionsZSTD_CStream* ZSTD_createCStream(void);; size_t ZSTD_freeCStream(ZSTD_CStream* zcs);. Streaming compression functionssize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);; size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);. size_t ZSTD_CStreamInSize(void); /**< recommended size for input buffer */. size_t ZSTD_CStreamOutSize(void); /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block in all circumstances. */. Streaming decompression - HowTo; A ZSTD_DStream object is required to track streaming op",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:15375,Availability,error,error,15375,"f decompression requires a dictionary.; @return : recommended first input size. Use ZSTD_decompressStream() repetitively to consume your input.; The function will update both `pos` fields.; If `input.pos < input.size`, some input has not been consumed.; It's up to the caller to present again remaining data.; The function tries to flush all data decoded immediately, repecting buffer sizes.; If `output.pos < output.size`, decoder has flushed everything it could.; But if `output.pos == output.size`, there is no such guarantee,; it's likely that some decoded data was not flushed and still remains within internal buffers.; In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.; When no additional input is provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.; @return : 0 when a frame is completely decoded and fully flushed,; or an error code, which can be tested using ZSTD_isError(),; or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :; the return value is a suggested next input size (a hint for better latency); that will never load more than the current frame.; . typedef ZSTD_DCtx ZSTD_DStream; /**< DCtx and DStream are now effectively same object (>= v1.3.0) */. ZSTD_DStream management functionsZSTD_DStream* ZSTD_createDStream(void);; size_t ZSTD_freeDStream(ZSTD_DStream* zds);. Streaming decompression functionssize_t ZSTD_initDStream(ZSTD_DStream* zds);; size_t ZSTD_decompressStream(ZSTD_DStream* zds, ZSTD_outBuffer* output, ZSTD_inBuffer* input);. size_t ZSTD_DStreamInSize(void); /*!< recommended size for input buffer */. size_t ZSTD_DStreamOutSize(void); /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */. ADVANCED AND EXPERIMENTAL FUNCTIONS; The definitions in this section are considered experimental.; They should never be used with a dynamic library, as prototypes may change in the",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:17721,Availability,error,error,17721,"fast, ZSTD_greedy, ZSTD_lazy, ZSTD_lazy2,; ZSTD_btlazy2, ZSTD_btopt, ZSTD_btultra } ZSTD_strategy; /* from faster to stronger */. typedef struct {; unsigned windowLog; /**< largest match distance : larger == more compression, more memory needed during decompression */; unsigned chainLog; /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */; unsigned hashLog; /**< dispatch table : larger == faster, more memory */; unsigned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:18909,Availability,error,error,18909,"DFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame or skippable frame; `srcSize` must be >= first frame size; @return : the compressed size of the first frame starting at `src`,; suitable to pass to `ZSTD_decompress` or similar,; or an error code if input is invalid . unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize);; `src` should point the start of a series of ZSTD encoded and/or skippable frames; `srcSize` must be the _exact_ size of this series; (i.e. there should be a frame boundary exactly at `srcSize` bytes after `src`); @return : - decompressed size of all data in all successive frames; - if the decompressed size cannot be determined: ZSTD_CONTENTSIZE_UNKNOWN; - if an error occurred: ZSTD_CONTENTSIZE_ERROR. note 1 : decompressed size is an optional field, that may not be present, especially in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; note 2 : decompressed size is always present when compression is done with",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:19386,Availability,error,error,19386,"oes not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame or skippable frame; `srcSize` must be >= first frame size; @return : the compressed size of the first frame starting at `src`,; suitable to pass to `ZSTD_decompress` or similar,; or an error code if input is invalid . unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize);; `src` should point the start of a series of ZSTD encoded and/or skippable frames; `srcSize` must be the _exact_ size of this series; (i.e. there should be a frame boundary exactly at `srcSize` bytes after `src`); @return : - decompressed size of all data in all successive frames; - if the decompressed size cannot be determined: ZSTD_CONTENTSIZE_UNKNOWN; - if an error occurred: ZSTD_CONTENTSIZE_ERROR. note 1 : decompressed size is an optional field, that may not be present, especially in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; note 2 : decompressed size is always present when compression is done with ZSTD_compress(); note 3 : decompressed size can be very large (64-bits value),; potentially larger than what local system can handle as a single memory segment.; In which case, it's necessary to use streaming mode to decompress data.; note 4 : If source is untrusted, decompressed size could be wrong or intentionally modified.; Always ensure result fits within application's authorized limits.; Each application can set its own limits.; note 5 : ZSTD_findDecompressedSize handles multiple frames, and so it must traverse the input to",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:20600,Availability,error,error,20600," be any size.; In which case, it's necessary to use streaming mode to decompress data.; note 2 : decompressed size is always present when compression is done with ZSTD_compress(); note 3 : decompressed size can be very large (64-bits value),; potentially larger than what local system can handle as a single memory segment.; In which case, it's necessary to use streaming mode to decompress data.; note 4 : If source is untrusted, decompressed size could be wrong or intentionally modified.; Always ensure result fits within application's authorized limits.; Each application can set its own limits.; note 5 : ZSTD_findDecompressedSize handles multiple frames, and so it must traverse the input to; read each contained frame header. This is fast as most of the data is skipped,; however it does mean that all frame data must be present and valid. . size_t ZSTD_frameHeaderSize(const void* src, size_t srcSize);; srcSize must be >= ZSTD_frameHeaderSize_prefix.; @return : size of the Frame Header,; or an error code (if srcSize is too small) . Memory management; size_t ZSTD_sizeof_CCtx(const ZSTD_CCtx* cctx);; size_t ZSTD_sizeof_DCtx(const ZSTD_DCtx* dctx);; size_t ZSTD_sizeof_CStream(const ZSTD_CStream* zcs);; size_t ZSTD_sizeof_DStream(const ZSTD_DStream* zds);; size_t ZSTD_sizeof_CDict(const ZSTD_CDict* cdict);; size_t ZSTD_sizeof_DDict(const ZSTD_DDict* ddict);; These functions give the current memory usage of selected object.; Object memory usage can evolve when re-used. . size_t ZSTD_estimateCCtxSize(int compressionLevel);; size_t ZSTD_estimateCCtxSize_usingCParams(ZSTD_compressionParameters cParams);; size_t ZSTD_estimateCCtxSize_usingCCtxParams(const ZSTD_CCtx_params* params);; size_t ZSTD_estimateDCtxSize(void);; These functions make it possible to estimate memory usage; of a future {D,C}Ctx, before its creation.; ZSTD_estimateCCtxSize() will provide a budget large enough for any compression level up to selected one.; It will also consider src size to be arbitrarily ""large"",",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:22030,Availability,error,error,22030," Object memory usage can evolve when re-used. . size_t ZSTD_estimateCCtxSize(int compressionLevel);; size_t ZSTD_estimateCCtxSize_usingCParams(ZSTD_compressionParameters cParams);; size_t ZSTD_estimateCCtxSize_usingCCtxParams(const ZSTD_CCtx_params* params);; size_t ZSTD_estimateDCtxSize(void);; These functions make it possible to estimate memory usage; of a future {D,C}Ctx, before its creation.; ZSTD_estimateCCtxSize() will provide a budget large enough for any compression level up to selected one.; It will also consider src size to be arbitrarily ""large"", which is worst case.; If srcSize is known to always be small, ZSTD_estimateCCtxSize_usingCParams() can provide a tighter estimation.; ZSTD_estimateCCtxSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.; ZSTD_estimateCCtxSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParam_setParameter(). Only single-threaded compression is supported. This function will return an error code if ZSTD_p_nbWorkers is >= 1.; Note : CCtx size estimation is only correct for single-threaded compression. . size_t ZSTD_estimateCStreamSize(int compressionLevel);; size_t ZSTD_estimateCStreamSize_usingCParams(ZSTD_compressionParameters cParams);; size_t ZSTD_estimateCStreamSize_usingCCtxParams(const ZSTD_CCtx_params* params);; size_t ZSTD_estimateDStreamSize(size_t windowSize);; size_t ZSTD_estimateDStreamSize_fromFrame(const void* src, size_t srcSize);; ZSTD_estimateCStreamSize() will provide a budget large enough for any compression level up to selected one.; It will also consider src size to be arbitrarily ""large"", which is worst case.; If srcSize is known to always be small, ZSTD_estimateCStreamSize_usingCParams() can provide a tighter estimation.; ZSTD_estimateCStreamSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.; ZSTD_estimateCStreamSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParam_setParameter(). On",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:23109,Availability,error,error,23109,"t for single-threaded compression. . size_t ZSTD_estimateCStreamSize(int compressionLevel);; size_t ZSTD_estimateCStreamSize_usingCParams(ZSTD_compressionParameters cParams);; size_t ZSTD_estimateCStreamSize_usingCCtxParams(const ZSTD_CCtx_params* params);; size_t ZSTD_estimateDStreamSize(size_t windowSize);; size_t ZSTD_estimateDStreamSize_fromFrame(const void* src, size_t srcSize);; ZSTD_estimateCStreamSize() will provide a budget large enough for any compression level up to selected one.; It will also consider src size to be arbitrarily ""large"", which is worst case.; If srcSize is known to always be small, ZSTD_estimateCStreamSize_usingCParams() can provide a tighter estimation.; ZSTD_estimateCStreamSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.; ZSTD_estimateCStreamSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParam_setParameter(). Only single-threaded compression is supported. This function will return an error code if ZSTD_p_nbWorkers is >= 1.; Note : CStream size estimation is only correct for single-threaded compression.; ZSTD_DStream memory budget depends on window Size.; This information can be passed manually, using ZSTD_estimateDStreamSize,; or deducted from a valid frame Header, using ZSTD_estimateDStreamSize_fromFrame();; Note : if streaming is init with function ZSTD_init?Stream_usingDict(),; an internal ?Dict will be created, which additional size is not estimated here.; In this case, get total size by adding ZSTD_estimate?DictSize . size_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel);; size_t ZSTD_estimateCDictSize_advanced(size_t dictSize, ZSTD_compressionParameters cParams, ZSTD_dictLoadMethod_e dictLoadMethod);; size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);; ZSTD_estimateCDictSize() will bet that src size is relatively ""small"", and content is copied, like ZSTD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it po",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:24869,Availability,error,error,24869,"tLoadMethod);; size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);; ZSTD_estimateCDictSize() will bet that src size is relatively ""small"", and content is copied, like ZSTD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().; Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.; . ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);; ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticCCtx() */; Initialize an object using a pre-allocated fixed-size buffer.; workspace: The memory area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; Note 3 : cParams : use ZSTD_getCParams() to convert a compression level; into its associated cParams.; Limitation 1 : currently not compatible with internal dictionary creation, triggered by; ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().; Limitation 2 : static cctx currently not compatible with multi-threading.; Limitation 3 : static dctx is incompatible with legacy support.; . ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:25032,Availability,avail,available,25032,"TD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().; Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.; . ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);; ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticCCtx() */; Initialize an object using a pre-allocated fixed-size buffer.; workspace: The memory area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; Note 3 : cParams : use ZSTD_getCParams() to convert a compression level; into its associated cParams.; Limitation 1 : currently not compatible with internal dictionary creation, triggered by; ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().; Limitation 2 : static cctx currently not compatible with multi-threading.; Limitation 3 : static dctx is incompatible with legacy support.; . ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; typedef void (*ZSTD_freeFunction) (void* opaque, void* address);; typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;; static ZSTD_customMem con",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:25059,Availability,error,error,25059,"TD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().; Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.; . ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);; ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticCCtx() */; Initialize an object using a pre-allocated fixed-size buffer.; workspace: The memory area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; Note 3 : cParams : use ZSTD_getCParams() to convert a compression level; into its associated cParams.; Limitation 1 : currently not compatible with internal dictionary creation, triggered by; ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().; Limitation 2 : static cctx currently not compatible with multi-threading.; Limitation 3 : static dctx is incompatible with legacy support.; . ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; typedef void (*ZSTD_freeFunction) (void* opaque, void* address);; typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;; static ZSTD_customMem con",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:30323,Availability,failure,failure,30323,"_DDict* ddict);; Provides the dictID of the dictionary loaded into `ddict`.; If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.; Non-conformant dictionaries can still be loaded, but as content-only dictionaries. . unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);; Provides the dictID required to decompressed the frame stored within `src`.; If @return == 0, the dictID could not be decoded.; This could for one of the following reasons :; - The frame does not require a dictionary to be decoded (most common case).; - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden information.; Note : this use case also happens when using a non-conformant dictionary.; - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).; - This is not a Zstandard frame.; When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code. . Advanced streaming functions; Advanced Streaming compression functionssize_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs, int compressionLevel, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If it is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN. Note that, for compatibility with older programs, ""0"" also disables frame content size field. It may be enabled in the future. */; size_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs, const void* dict, size_t dictSize, int compressionLevel); /**< creates of an internal CDict (incompatible with static CCtx), except if dict == NULL or dictSize < 8, in which case no dict is used. Note: dict is loaded with ZSTD_dm_auto (treated as a full zstd dictionary if it begins with ZSTD_MAGIC_DICTIONARY, else as raw content) and ZSTD_dlm_byCopy.*/; size_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs, const void* dict, size_t dictSize,; ZSTD_parameters params, ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:30416,Availability,error,error,30416,"_DDict* ddict);; Provides the dictID of the dictionary loaded into `ddict`.; If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.; Non-conformant dictionaries can still be loaded, but as content-only dictionaries. . unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);; Provides the dictID required to decompressed the frame stored within `src`.; If @return == 0, the dictID could not be decoded.; This could for one of the following reasons :; - The frame does not require a dictionary to be decoded (most common case).; - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden information.; Note : this use case also happens when using a non-conformant dictionary.; - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).; - This is not a Zstandard frame.; When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code. . Advanced streaming functions; Advanced Streaming compression functionssize_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs, int compressionLevel, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If it is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN. Note that, for compatibility with older programs, ""0"" also disables frame content size field. It may be enabled in the future. */; size_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs, const void* dict, size_t dictSize, int compressionLevel); /**< creates of an internal CDict (incompatible with static CCtx), except if dict == NULL or dictSize < 8, in which case no dict is used. Note: dict is loaded with ZSTD_dm_auto (treated as a full zstd dictionary if it begins with ZSTD_MAGIC_DICTIONARY, else as raw content) and ZSTD_dlm_byCopy.*/; size_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs, const void* dict, size_t dictSize,; ZSTD_parameters params, ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:32825,Availability,error,error,32825,"rams, unsigned long long pledgedSrcSize); /**< same as ZSTD_initCStream_usingCDict(), with control over frame parameters. pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. */. size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);; start a new compression job, using same parameters from previous job.; This is typically useful to skip dictionary loading stage, since it will re-use it in-place.; Note that zcs must be init at least once before using ZSTD_resetCStream().; If pledgedSrcSize is not known at reset time, use macro ZSTD_CONTENTSIZE_UNKNOWN.; If pledgedSrcSize > 0, its value must be correct, as it will be written in header, and controlled at the end.; For the time being, pledgedSrcSize==0 is interpreted as ""srcSize unknown"" for compatibility with older programs,; but it will change to mean ""empty"" in future version, so use macro ZSTD_CONTENTSIZE_UNKNOWN instead.; @return : 0, or an error code (which can be tested using ZSTD_isError()); . typedef struct {; unsigned long long ingested; /* nb input bytes read and buffered */; unsigned long long consumed; /* nb input bytes actually compressed */; unsigned long long produced; /* nb of compressed bytes generated and buffered */; unsigned long long flushed; /* nb of compressed bytes flushed : not provided; can be tracked from caller side */; unsigned currentJobID; /* MT only : latest started job nb */; unsigned nbActiveWorkers; /* MT only : nb of workers actively compressing at probe time */; } ZSTD_frameProgression;. size_t ZSTD_toFlushNow(ZSTD_CCtx* cctx);; Tell how many bytes are ready to be flushed immediately.; Useful for multithreading scenarios (nbWorkers >= 1).; Probe the oldest active job, defined as oldest job not yet entirely flushed,; and check its output buffer.; @return : amount of data stored in oldest job and ready to be flushed immediately.; if @return == 0, it means either :; + there is no active job (could be checked w",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:36267,Availability,recover,recover,36267,"g operations.; Use ZSTD_createCCtx() / ZSTD_freeCCtx() to manage resource.; ZSTD_CCtx object can be re-used multiple times within successive compression operations. Start by initializing a context.; Use ZSTD_compressBegin(), or ZSTD_compressBegin_usingDict() for dictionary compression,; or ZSTD_compressBegin_advanced(), for finer parameter control.; It's also possible to duplicate a reference context which has already been initialized, using ZSTD_copyCCtx(). Then, consume your input using ZSTD_compressContinue().; There are some important considerations to keep in mind when using this advanced function :; - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.; - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.; - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.; Worst case evaluation is provided by ZSTD_compressBound().; ZSTD_compressContinue() doesn't guarantee recover after a failed compression.; - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).; It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks); - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.; In which case, it will ""discard"" the relevant memory section from its history. Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.; It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.; Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders. `ZSTD_CCtx` object can be re-used (ZSTD_compressBegin()) to compress again. Buffer-less streaming compression functionssize_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);; size_t ZSTD_compressB",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:38967,Availability,error,errorCode,38967,"t known, use macro ZSTD_CONTENTSIZE_UNKNOWN */; size_t ZSTD_copyCCtx(ZSTD_CCtx* cctx, const ZSTD_CCtx* preparedCCtx, unsigned long long pledgedSrcSize); /**< note: if pledgedSrcSize is not known, use ZSTD_CONTENTSIZE_UNKNOWN */. Buffer-less streaming decompression (synchronous mode); A ZSTD_DCtx object is required to track streaming operations.; Use ZSTD_createDCtx() / ZSTD_freeDCtx() to manage it.; A ZSTD_DCtx object can be re-used multiple times. First typical operation is to retrieve frame parameters, using ZSTD_getFrameHeader().; Frame header is extracted from the beginning of compressed frame, so providing only the frame's beginning is enough.; Data fragment must be large enough to ensure successful decoding.; `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.; @result : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.; >0 : `srcSize` is too small, please provide at least @result bytes on next attempt.; errorCode, which can be tested using ZSTD_isError(). It fills a ZSTD_frameHeader structure with important information to correctly decode the frame,; such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:40285,Availability,error,error,40285,"uption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,; up to the moment there is not enough room left in the buffer to guarantee decoding another full block,; which maximum size is provided in `ZSTD_frameHeader` structure, field `blockSizeMax`.; At which point, decoding can resume from the beginning of the buffer.; Note that already decoded data stored in the buffer should be flushed before being overwritten. There are alternatives possible, for example using two or more buffers of size `windowSize` each, though they consume more memory. Finally, if you control the compression process, you can also ignore all buffer size rules,; as long as the encoder and decoder progress in ""lock-step"",; aka use exactly the same buffer sizes, break contiguity at the same place, etc. Once buffers are setup, start decompression, with ZSTD_decompressBegin().; If decom",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:41882,Availability,error,error,41882," of size `windowSize` each, though they consume more memory. Finally, if you control the compression process, you can also ignore all buffer size rules,; as long as the encoder and decoder progress in ""lock-step"",; aka use exactly the same buffer sizes, break contiguity at the same place, etc. Once buffers are setup, start decompression, with ZSTD_decompressBegin().; If decompression requires a dictionary, use ZSTD_decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict(). Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.; ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().; ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail. @result of ZSTD_decompressContinue() is the number of bytes regenerated within 'dst' (necessarily <= dstCapacity).; It can be zero : it just means ZSTD_decompressContinue() has decoded some metadata item.; It can also be an error code, which can be tested with ZSTD_isError(). A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.; Context can then be reset to start a new decompression. Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().; This information is not required to properly decode a frame. == Special case : skippable frames . Skippable frames allow integration of user-defined data into a flow of concatenated frames.; Skippable frames will be ignored (skipped) by decompressor.; The format of skippable frames is as follows :; a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F; b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits; c) Frame Content - any content (User Data) of length equal to Frame Size; For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buff",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:43124,Availability,avail,available,43124,"ntext can then be reset to start a new decompression. Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().; This information is not required to properly decode a frame. == Special case : skippable frames . Skippable frames allow integration of user-defined data into a flow of concatenated frames.; Skippable frames will be ignored (skipped) by decompressor.; The format of skippable frames is as follows :; a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F; b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits; c) Frame Content - any content (User Data) of length equal to Frame Size; For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buffer-less streaming decompression functionstypedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_frameType_e;; typedef struct {; unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means ""empty"" */; unsigned long long windowSize; /* can be very large, up to <= frameContentSize */; unsigned blockSizeMax;; ZSTD_frameType_e frameType; /* if == ZSTD_skippableFrame, frameContentSize is the size of skippable content */; unsigned headerSize;; unsigned dictID;; unsigned checksumFlag;; } ZSTD_frameHeader;; /** ZSTD_getFrameHeader() :; * decode Frame Header, or requires larger `srcSize`.; * @return : 0, `zfhPtr` is correctly filled,; * >0, `srcSize` is too small, value is wanted `srcSize` amount,; * or an error code, which can be tested using ZSTD_isError() */; size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize); /**< doesn't consume input */; size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize); /**< when frame content size is not known, pass in frameContentSize == ZST",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:43661,Availability,error,error,43661,"ableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buffer-less streaming decompression functionstypedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_frameType_e;; typedef struct {; unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means ""empty"" */; unsigned long long windowSize; /* can be very large, up to <= frameContentSize */; unsigned blockSizeMax;; ZSTD_frameType_e frameType; /* if == ZSTD_skippableFrame, frameContentSize is the size of skippable content */; unsigned headerSize;; unsigned dictID;; unsigned checksumFlag;; } ZSTD_frameHeader;; /** ZSTD_getFrameHeader() :; * decode Frame Header, or requires larger `srcSize`.; * @return : 0, `zfhPtr` is correctly filled,; * >0, `srcSize` is too small, value is wanted `srcSize` amount,; * or an error code, which can be tested using ZSTD_isError() */; size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize); /**< doesn't consume input */; size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize); /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */. typedef enum { ZSTDnit_frameHeader, ZSTDnit_blockHeader, ZSTDnit_block, ZSTDnit_lastBlock, ZSTDnit_checksum, ZSTDnit_skippableFrame } ZSTD_nextInputType_e;. New advanced API (experimental); typedef enum {; /* Opened question : should we have a format ZSTD_f_auto ?; * Today, it would mean exactly the same as ZSTD_f_zstd1.; * But, in the future, should several formats become supported,; * on the compression side, it would mean ""default format"".; * On the decompression side, it would mean ""automatic format detection"",; * so that ZSTD_f_zstd1 would mean ""accept *only* zstd frames"".; * Since meaning is a little different, another option could be to define different enums for compression and decompression.; * This question could be kept for later",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:52480,Availability,error,error,52480,"quency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : a strong exception to this rule is when first invocation sets ZSTD_e_end : it becomes a blocking call).; * More workers improve speed, but also increase memory usage.; * Default value is `0`, aka ""single-threaded mode"" : no worker is spawned, compression is performed inside Caller's thread, all invocations are blocking */; ZSTD_p_jobSize, /* Size of a compression job. This value is enforced only in non-blocking mode.; * Each compression job is completed in parallel, so this value indirectly controls the nb of active threads.; * 0 means default, which is dynamically determined based on compression parameters.; * Job s",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55198,Availability,error,error,55198,"ontrols whether the contents of a CDict are; * used in place, or whether they are copied into; * the working context.; *; * Accepts values from the ZSTD_dictAttachPref_e; * enum. See the comments on that enum for an; * explanation of the feature.; */; } ZSTD_cParameter;. size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55451,Availability,error,error,55451,"x_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Cr",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55712,Availability,error,error,55712,"ing compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates pre",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55756,Availability,error,error,55756,"),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictiona",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:56579,Availability,error,error,56579,"; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictionary will be used for all future compression jobs.; To return to ""no-dictionary"" situation, load a NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:57852,Availability,error,error,57852," NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all next compression jobs.; Note that compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just referenced, its lifetime must outlive CCtx. . size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (whi",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:58853,Availability,error,error,58853," can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just referenced, its lifetime must outlive CCtx. . size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing c",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:59834,Availability,error,error,59834,"ode (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing compression job and start a new one.; Any internal data not yet flushed is cancelled.; The parameters and dictionary are kept unchanged, to reset them use ZSTD_CCtx_resetParameters().; . size_t ZSTD_CCtx_resetParameters(ZSTD_CCtx* cctx);; All parameters are back to default values (compression level is ZSTD_CLEVEL_DEFAULT).; Dictionary (if any) is dropped.; Resetting parameters is only possible during frame initialization (before starting compression).; To reset the context use ZSTD_CCtx_reset().; @return 0 or an error code (which can be checked with ZSTD_isError()).; . typedef enum {; ZSTD_e_continue=0, /* collect more data, encoder decides when to output compressed result, for optimal compression ratio */; ZSTD_e_flush, /* flush any data provided so far,; * it creates (at least) one new block, that can be decoded immediately on reception;; * frame will continue: any future data can still reference previously compressed data, improving compression. */; ZSTD_e_end /* flush any r",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:60386,Availability,error,error,60386,"ich are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing compression job and start a new one.; Any internal data not yet flushed is cancelled.; The parameters and dictionary are kept unchanged, to reset them use ZSTD_CCtx_resetParameters().; . size_t ZSTD_CCtx_resetParameters(ZSTD_CCtx* cctx);; All parameters are back to default values (compression level is ZSTD_CLEVEL_DEFAULT).; Dictionary (if any) is dropped.; Resetting parameters is only possible during frame initialization (before starting compression).; To reset the context use ZSTD_CCtx_reset().; @return 0 or an error code (which can be checked with ZSTD_isError()).; . typedef enum {; ZSTD_e_continue=0, /* collect more data, encoder decides when to output compressed result, for optimal compression ratio */; ZSTD_e_flush, /* flush any data provided so far,; * it creates (at least) one new block, that can be decoded immediately on reception;; * frame will continue: any future data can still reference previously compressed data, improving compression. */; ZSTD_e_end /* flush any remaining data and close current frame.; * any additional data starts a new frame.; * each frame is independent (does not reference any content from previous frame). */; } ZSTD_EndDirective;. size_t ZSTD_compress_generic (ZSTD_CCtx* cctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input,; ZSTD_EndDirective endOp);; Behave about the same as ZSTD_compressStream. To note :; - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_setParameter(); - Compression parameters cannot be changed once compression is sta",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:62314,Availability,error,error,62314,"g compression, using ZSTD_CCtx_setParameter(); - Compression parameters cannot be changed once compression is started.; - outpot->pos must be <= dstCapacity, input->pos must be <= srcSize; - outpot->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.; - In single-thread mode (default), function is blocking : it completed its job before returning to caller.; - In multi-thread mode, function is non-blocking : it just acquires a copy of input, and distribute job to internal worker threads,; and then immediately returns, just indicating that there is some data remaining to be flushed.; The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.; - Exception : in multi-threading mode, if the first call requests a ZSTD_e_end directive, it is blocking : it will complete compression before giving back control to caller.; - @return provides a minimum amount of data remaining to be flushed from internal buffers; or an error code, which can be tested using ZSTD_isError().; if @return != 0, flush is not fully completed, there is still some data left within internal buffers.; This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.; For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.; - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),; only ZSTD_e_end or ZSTD_e_flush operations are allowed.; Before starting a new compression job, or changing compression parameters,; it is required to fully flush internal buffers.; . size_t ZSTD_compress_generic_simpleArgs (; ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos,; ZSTD_EndDirective endOp);; Same as ZSTD_compress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binders fro",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:65059,Availability,error,error,65059,"or single-threaded compression.; . size_t ZSTD_CCtxParams_reset(ZSTD_CCtx_params* params);; Reset params to default values.; . size_t ZSTD_CCtxParams_init(ZSTD_CCtx_params* cctxParams, int compressionLevel);; Initializes the compression parameters of cctxParams according to; compression level. All other parameters are reset to their default values.; . size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params);; Initializes the compression and frame parameters of cctxParams according to; params. All other parameters are reset to their default values.; . size_t ZSTD_CCtxParam_setParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned value);; Similar to ZSTD_CCtx_setParameter.; Set one compression parameter, selected by enum ZSTD_cParameter.; Parameters must be applied to a ZSTD_CCtx using ZSTD_CCtx_setParametersUsingCCtxParams().; Note : when `value` is an enum, cast it to unsigned for proper type checking.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtxParam_getParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned* value);; Similar to ZSTD_CCtx_getParameter.; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byR",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:65363,Availability,error,error,65363," parameters are reset to their default values.; . size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params);; Initializes the compression and frame parameters of cctxParams according to; params. All other parameters are reset to their default values.; . size_t ZSTD_CCtxParam_setParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned value);; Similar to ZSTD_CCtx_setParameter.; Set one compression parameter, selected by enum ZSTD_cParameter.; Parameters must be applied to a ZSTD_CCtx using ZSTD_CCtx_setParametersUsingCCtxParams().; Note : when `value` is an enum, cast it to unsigned for proper type checking.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtxParam_getParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned* value);; Similar to ZSTD_CCtx_getParameter.; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:66413,Availability,error,error,66413,"TD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; Note 2 : Loading a dictionary involves building tables,; which has a non-negligible impact on CPU usage and latency.; Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to select; how dictionary content will be interpreted and loaded.; . size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);; Reference a prepared dictionary, to be used to decompress next frames.; The dictionary remains active for decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:67274,Availability,error,error,67274,"e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; Note 2 : Loading a dictionary involves building tables,; which has a non-negligible impact on CPU usage and latency.; Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to select; how dictionary content will be interpreted and loaded.; . size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);; Reference a prepared dictionary, to be used to decompress next frames.; The dictionary remains active for decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""discards"" any previous one.; Special : adding a NULL DDict means ""return to no-dictionary mode"".; Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.; . size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; This is the reverse operation of ZSTD_CCtx_refPrefix(),; and must use the same prefix as the one used during compression.; Prefix is **only used once**. Reference is discarded at end of frame.; End of frame is reached when ZSTD_DCtx_decompress_generic() returns 0.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Adding any prefix (including NULL) i",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:68190,Availability,error,error,68190,"decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""discards"" any previous one.; Special : adding a NULL DDict means ""return to no-dictionary mode"".; Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.; . size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; This is the reverse operation of ZSTD_CCtx_refPrefix(),; and must use the same prefix as the one used during compression.; Prefix is **only used once**. Reference is discarded at end of frame.; End of frame is reached when ZSTD_DCtx_decompress_generic() returns 0.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary; Note 2 : Prefix buffer is referenced. It **must** outlive decompression job.; Prefix buffer must remain unmodified up to the end of frame,; reached when ZSTD_DCtx_decompress_generic() returns 0.; Note 3 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:69301,Availability,error,error,69301,"(including NULL) invalidates any previously set prefix or dictionary; Note 2 : Prefix buffer is referenced. It **must** outlive decompression job.; Prefix buffer must remain unmodified up to the end of frame,; reached when ZSTD_DCtx_decompress_generic() returns 0.; Note 3 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @return : an error code, which can be tested using ZSTD_isError(); if >0, a hint, nb of expected input bytes for next invocation.; `0` mea",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:69635,Availability,error,error,69635,"() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @return : an error code, which can be tested using ZSTD_isError(); if >0, a hint, nb of expected input bytes for next invocation.; `0` means : a frame has just been fully decoded and flushed.; . size_t ZSTD_decompress_generic_simpleArgs (; ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos);; Same as ZSTD_decompress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binder",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:70147,Availability,error,error,70147,"ault, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @return : an error code, which can be tested using ZSTD_isError(); if >0, a hint, nb of expected input bytes for next invocation.; `0` means : a frame has just been fully decoded and flushed.; . size_t ZSTD_decompress_generic_simpleArgs (; ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos);; Same as ZSTD_decompress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binders from dynamic languages; which have troubles handling structures containing memory pointers.; . void ZSTD_DCtx_reset(ZSTD_DCtx* dctx);; Return a DCtx to clean state.; If a decompression was ongoing, any internal data not yet flushed is cancelled.; All parameters are back to default values, including sticky ones.; Dictionary (if any) is dropped.; Parameters can be modified again after a reset.; . Block level API; Frame metadata cost is typically ~18 bytes, which can be non-negligible for very small blocks (< 100 bytes).; User will have to t",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:8584,Deployability,release,released,8584,"ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary creation.; Frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no); Note : ZSTD_compress_usingCDict() can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; dictBuffer ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:9668,Deployability,release,released,9668,"ted with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary creation.; Frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no); Note : ZSTD_compress_usingCDict() can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; dictBuffer can be released after DDict creation, as its content is copied inside DDict . size_t ZSTD_freeDDict(ZSTD_DDict* ddict);; Function frees memory allocated with ZSTD_createDDict() . size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_DDict* ddict);; Decompression using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_inBuffer;. typedef struct ZSTD_outBuffer_s {; void* dst; /**< start of output buffer */; size_t size; /**< size of output buffer */; size_t pos; /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is require",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:10330,Deployability,update,updated,10330," can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; dictBuffer can be released after DDict creation, as its content is copied inside DDict . size_t ZSTD_freeDDict(ZSTD_DDict* ddict);; Function frees memory allocated with ZSTD_createDDict() . size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_DDict* ddict);; Decompression using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_inBuffer;. typedef struct ZSTD_outBuffer_s {; void* dst; /**< start of output buffer */; size_t size; /**< size of output buffer */; size_t pos; /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is required to track streaming operation.; Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.; ZSTD_CStream objects can be reused multiple times on consecutive compression operations.; It is recommended to re-use ZSTD_CStream in situations where many streaming operations will be achieved consecutively,; since it will play nicer with system's memory, by re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict(",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:10569,Deployability,update,updated,10569,"gested dictionary, ready to start decompression operation without startup delay.; dictBuffer can be released after DDict creation, as its content is copied inside DDict . size_t ZSTD_freeDDict(ZSTD_DDict* ddict);; Function frees memory allocated with ZSTD_createDDict() . size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_DDict* ddict);; Decompression using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_inBuffer;. typedef struct ZSTD_outBuffer_s {; void* dst; /**< start of output buffer */; size_t size; /**< size of output buffer */; size_t pos; /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is required to track streaming operation.; Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.; ZSTD_CStream objects can be reused multiple times on consecutive compression operations.; It is recommended to re-use ZSTD_CStream in situations where many streaming operations will be achieved consecutively,; since it will play nicer with system's memory, by re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input`",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:10784,Deployability,release,release,10784,"TD_DDict* ddict);; Function frees memory allocated with ZSTD_createDDict() . size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_DDict* ddict);; Decompression using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_inBuffer;. typedef struct ZSTD_outBuffer_s {; void* dst; /**< start of output buffer */; size_t size; /**< size of output buffer */; size_t pos; /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is required to track streaming operation.; Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.; ZSTD_CStream objects can be reused multiple times on consecutive compression operations.; It is recommended to re-use ZSTD_CStream in situations where many streaming operations will be achieved consecutively,; since it will play nicer with system's memory, by re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:11530,Deployability,update,update,11530,"here writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is required to track streaming operation.; Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.; ZSTD_CStream objects can be reused multiple times on consecutive compression operations.; It is recommended to re-use ZSTD_CStream in situations where many streaming operations will be achieved consecutively,; since it will play nicer with system's memory, by re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check if input has been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12433,Deployability,update,updated,12433,"TD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check if input has been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and fully flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now eff",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:14315,Deployability,release,release,14315,"e),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now effectively same object (>= v1.3.0) */. ZSTD_CStream management functionsZSTD_CStream* ZSTD_createCStream(void);; size_t ZSTD_freeCStream(ZSTD_CStream* zcs);. Streaming compression functionssize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);; size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);. size_t ZSTD_CStreamInSize(void); /**< recommended size for input buffer */. size_t ZSTD_CStreamOutSize(void); /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block in all circumstances. */. Streaming decompression - HowTo; A ZSTD_DStream object is required to track streaming operations.; Use ZSTD_createDStream() and ZSTD_freeDStream() to create/release resources.; ZSTD_DStream objects can be re-used multiple times. Use ZSTD_initDStream() to start a new decompression operation,; or ZSTD_initDStream_usingDict() if decompression requires a dictionary.; @return : recommended first input size. Use ZSTD_decompressStream() repetitively to consume your input.; The function will update both `pos` fields.; If `input.pos < input.size`, some input has not been consumed.; It's up to the caller to present again remaining data.; The function tries to flush all data decoded immediately, repecting buffer sizes.; If `output.pos < output.size`, decoder has flushed everything it could.; But if `output.pos == output.size`, there is no such guarantee,; it's likely that some decoded data was not flushed and still remains within internal buffers.; In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.; When no additional input is provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:14647,Deployability,update,update,14647,"* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);; size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);. size_t ZSTD_CStreamInSize(void); /**< recommended size for input buffer */. size_t ZSTD_CStreamOutSize(void); /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block in all circumstances. */. Streaming decompression - HowTo; A ZSTD_DStream object is required to track streaming operations.; Use ZSTD_createDStream() and ZSTD_freeDStream() to create/release resources.; ZSTD_DStream objects can be re-used multiple times. Use ZSTD_initDStream() to start a new decompression operation,; or ZSTD_initDStream_usingDict() if decompression requires a dictionary.; @return : recommended first input size. Use ZSTD_decompressStream() repetitively to consume your input.; The function will update both `pos` fields.; If `input.pos < input.size`, some input has not been consumed.; It's up to the caller to present again remaining data.; The function tries to flush all data decoded immediately, repecting buffer sizes.; If `output.pos < output.size`, decoder has flushed everything it could.; But if `output.pos == output.size`, there is no such guarantee,; it's likely that some decoded data was not flushed and still remains within internal buffers.; In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.; When no additional input is provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.; @return : 0 when a frame is completely decoded and fully flushed,; or an error code, which can be tested using ZSTD_isError(),; or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :; the return value is a suggested next input size (a hint for better latency); that will never load more than ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:42295,Deployability,integrat,integration,42295,"decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict(). Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.; ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().; ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail. @result of ZSTD_decompressContinue() is the number of bytes regenerated within 'dst' (necessarily <= dstCapacity).; It can be zero : it just means ZSTD_decompressContinue() has decoded some metadata item.; It can also be an error code, which can be tested with ZSTD_isError(). A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.; Context can then be reset to start a new decompression. Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().; This information is not required to properly decode a frame. == Special case : skippable frames . Skippable frames allow integration of user-defined data into a flow of concatenated frames.; Skippable frames will be ignored (skipped) by decompressor.; The format of skippable frames is as follows :; a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F; b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits; c) Frame Content - any content (User Data) of length equal to Frame Size; For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buffer-less streaming decompression functionstypedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_frameType_e;; typedef struct {; unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means ""empty"" */; unsigned long long windowSize; /* can be very large, up to <= frameContentSize */; unsigned blockSizeMax;; ZSTD_frameType_e frameType; /* if == ZSTD_skippableFram",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:47550,Deployability,update,updates,47550,"ever, if experimentation shows that; * Zstd is making poor choices, it is possible to override that choice with; * this enum.; */; ZSTD_dictDefaultAttach = 0, /* Use the default heuristic. */; ZSTD_dictForceAttach = 1, /* Never copy the dictionary. */; ZSTD_dictForceCopy = 2, /* Always copy the dictionary. */; } ZSTD_dictAttachPref_e;. typedef enum {; /* compression format */; ZSTD_p_format = 10, /* See ZSTD_format_e enum definition.; * Cast selected format as unsigned for ZSTD_CCtx_setParameter() compatibility. */. /* compression parameters */; ZSTD_p_compressionLevel=100, /* Update all compression parameters according to pre-defined cLevel table; * Default level is ZSTD_CLEVEL_DEFAULT==3.; * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.; * Note 1 : it's possible to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other compression parameters.; * Note 3 : setting compressionLevel automatically updates ZSTD_p_compressLiterals. */; ZSTD_p_windowLog, /* Maximum allowed back-reference distance, expressed as power of 2.; * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.; * Special: value 0 means ""use default windowLog"".; * Note: Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slow",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:54804,Deployability,update,updated,54804,"====================================== */; /* experimental parameters - no stability guaranteed */; /* =================================================================== */. ZSTD_p_forceMaxWindow=1100, /* Force back-reference distances to remain < windowSize,; * even when referencing into Dictionary content (default:0) */; ZSTD_p_forceAttachDict, /* Controls whether the contents of a CDict are; * used in place, or whether they are copied into; * the working context.; *; * Accepts values from the ZSTD_dictAttachPref_e; * enum. See the comments on that enum for an; * explanation of the feature.; */; } ZSTD_cParameter;. size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:61517,Deployability,update,updated,61517,"continue=0, /* collect more data, encoder decides when to output compressed result, for optimal compression ratio */; ZSTD_e_flush, /* flush any data provided so far,; * it creates (at least) one new block, that can be decoded immediately on reception;; * frame will continue: any future data can still reference previously compressed data, improving compression. */; ZSTD_e_end /* flush any remaining data and close current frame.; * any additional data starts a new frame.; * each frame is independent (does not reference any content from previous frame). */; } ZSTD_EndDirective;. size_t ZSTD_compress_generic (ZSTD_CCtx* cctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input,; ZSTD_EndDirective endOp);; Behave about the same as ZSTD_compressStream. To note :; - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_setParameter(); - Compression parameters cannot be changed once compression is started.; - outpot->pos must be <= dstCapacity, input->pos must be <= srcSize; - outpot->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.; - In single-thread mode (default), function is blocking : it completed its job before returning to caller.; - In multi-thread mode, function is non-blocking : it just acquires a copy of input, and distribute job to internal worker threads,; and then immediately returns, just indicating that there is some data remaining to be flushed.; The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.; - Exception : in multi-threading mode, if the first call requests a ZSTD_e_end directive, it is blocking : it will complete compression before giving back control to caller.; - @return provides a minimum amount of data remaining to be flushed from internal buffers; or an error code, which can be tested using ZSTD_isError().; if @return != 0, flush is not fully completed, there is still some data left within internal buffe",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:65871,Deployability,update,updated,65871,"ameter.; Set one compression parameter, selected by enum ZSTD_cParameter.; Parameters must be applied to a ZSTD_CCtx using ZSTD_CCtx_setParametersUsingCCtxParams().; Note : when `value` is an enum, cast it to unsigned for proper type checking.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtxParam_getParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned* value);; Similar to ZSTD_CCtx_getParameter.; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; N",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:2368,Energy Efficiency,allocate,allocated,2368,"pression). Compression can be done in:; - a single step (described as Simple API); - a single step, reusing a context (described as Explicit context); - unbounded multiple steps (described as Streaming compression). The compression ratio achievable on small data can be highly improved using; a dictionary. Dictionary compression can be performed in:; - a single step (described as Simple dictionary API); - a single step, reusing a dictionary (described as Bulk-processing; dictionary API). Advanced experimental functions can be accessed using; `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h. Advanced experimental APIs should never be used with a dynamically-linked; library. They are not ""stable""; their definitions or signatures may change in; the future. Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapacity` is an upper bound of originalSize to regenerate.; If user cannot imply a maximum upper bound, it's better to use streaming mode to decompress data.; @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),; or an errorCode if it fails (which can be tested using ZSTD_isError()). . #define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1); #define ZSTD_CONTENTSIZE_ERROR (0ULL - 2); unsigned long long ZSTD_getFrameContentSize(const void *src, si",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:6093,Energy Efficiency,allocate,allocate,6093,"ZSTD_getDecompressedSize() blends; ""empty"", ""unknown"" and ""error"" results to the same return value (0),; while ZSTD_getFrameContentSize() gives them separate return values.; @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When decompressing many times,; it is recommended to allocate a context only once,; and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution. ; typedef struct ZSTD_DCtx_s ZSTD_DCtx;; ZSTD_DCtx* ZSTD_createDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:6605,Energy Efficiency,allocate,allocated,6605,"mula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When decompressing many times,; it is recommended to allocate a context only once,; and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution. ; typedef struct ZSTD_DCtx_s ZSTD_DCtx;; ZSTD_DCtx* ZSTD_createDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize);; Same as ZSTD_decompress(), requires an allocated ZSTD_DCtx (see ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionar",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:6727,Energy Efficiency,allocate,allocate,6727,"o */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When decompressing many times,; it is recommended to allocate a context only once,; and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution. ; typedef struct ZSTD_DCtx_s ZSTD_DCtx;; ZSTD_DCtx* ZSTD_createDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize);; Same as ZSTD_decompress(), requires an allocated ZSTD_DCtx (see ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacit",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:7190,Energy Efficiency,allocate,allocated,7190,"for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When decompressing many times,; it is recommended to allocate a context only once,; and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution. ; typedef struct ZSTD_DCtx_s ZSTD_DCtx;; ZSTD_DCtx* ZSTD_createDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize);; Same as ZSTD_decompress(), requires an allocated ZSTD_DCtx (see ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDi",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:8828,Energy Efficiency,allocate,allocated,8828,"mpression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary creation.; Frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no); Note : ZSTD_compress_usingCDict() can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; dictBuffer can be released after DDict creation, as its content is copied inside DDict . size_t ZSTD_freeDDict(ZSTD_DDict* ddict);; Function frees memory allocat",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:9804,Energy Efficiency,allocate,allocated,9804,"D_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary creation.; Frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no); Note : ZSTD_compress_usingCDict() can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; dictBuffer can be released after DDict creation, as its content is copied inside DDict . size_t ZSTD_freeDDict(ZSTD_DDict* ddict);; Function frees memory allocated with ZSTD_createDDict() . size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_DDict* ddict);; Decompression using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_inBuffer;. typedef struct ZSTD_outBuffer_s {; void* dst; /**< start of output buffer */; size_t size; /**< size of output buffer */; size_t pos; /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is required to track streaming operation.; Use ZSTD_createCStream() and ZSTD_freeCStream() to create/relea",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:11081,Energy Efficiency,allocate,allocated,11081,"ion using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where reading stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_inBuffer;. typedef struct ZSTD_outBuffer_s {; void* dst; /**< start of output buffer */; size_t size; /**< size of output buffer */; size_t pos; /**< position where writing stopped. Will be updated. Necessarily 0 <= pos <= size */; } ZSTD_outBuffer;. Streaming compression - HowTo; A ZSTD_CStream object is required to track streaming operation.; Use ZSTD_createCStream() and ZSTD_freeCStream() to create/release resources.; ZSTD_CStream objects can be reused multiple times on consecutive compression operations.; It is recommended to re-use ZSTD_CStream in situations where many streaming operations will be achieved consecutively,; since it will play nicer with system's memory, by re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check if input has been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @r",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:24508,Energy Efficiency,allocate,allocated,24508,"mateDStreamSize_fromFrame();; Note : if streaming is init with function ZSTD_init?Stream_usingDict(),; an internal ?Dict will be created, which additional size is not estimated here.; In this case, get total size by adding ZSTD_estimate?DictSize . size_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel);; size_t ZSTD_estimateCDictSize_advanced(size_t dictSize, ZSTD_compressionParameters cParams, ZSTD_dictLoadMethod_e dictLoadMethod);; size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);; ZSTD_estimateCDictSize() will bet that src size is relatively ""small"", and content is copied, like ZSTD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().; Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.; . ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);; ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticCCtx() */; Initialize an object using a pre-allocated fixed-size buffer.; workspace: The memory area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; Note 3 : cParams : use ZSTD_getCParams() to convert a compression level; into its associated cParams.; Limitation 1 : currently not compatible with internal dictionary cre",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:25184,Energy Efficiency,allocate,allocated,25184," Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.; . ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);; ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticCCtx() */; Initialize an object using a pre-allocated fixed-size buffer.; workspace: The memory area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; Note 3 : cParams : use ZSTD_getCParams() to convert a compression level; into its associated cParams.; Limitation 1 : currently not compatible with internal dictionary creation, triggered by; ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().; Limitation 2 : static cctx currently not compatible with multi-threading.; Limitation 3 : static dctx is incompatible with legacy support.; . ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; typedef void (*ZSTD_freeFunction) (void* opaque, void* address);; typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;; static ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL }; /**< this constant defers to stdlib's functions */; These prototypes make it possible to pass your own allo",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:39443,Energy Efficiency,allocate,allocate,39443,"n is to retrieve frame parameters, using ZSTD_getFrameHeader().; Frame header is extracted from the beginning of compressed frame, so providing only the frame's beginning is enough.; Data fragment must be large enough to ensure successful decoding.; `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.; @result : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.; >0 : `srcSize` is too small, please provide at least @result bytes on next attempt.; errorCode, which can be tested using ZSTD_isError(). It fills a ZSTD_frameHeader structure with important information to correctly decode the frame,; such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:40130,Energy Efficiency,efficient,efficient,40130,"t size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,; up to the moment there is not enough room left in the buffer to guarantee decoding another full block,; which maximum size is provided in `ZSTD_frameHeader` structure, field `blockSizeMax`.; At which point, decoding can resume from the beginning of the buffer.; Note that already decoded data stored in the buffer should be flushed before being overwritten. There are alternatives possible, for example using two or more buffers of size `windowSize` each, though they consume more memory. Finally, if you control the compression process, you can also ignore all buffer size rules,; as long as the encoder and decoder progress in ""lock-step"",; aka use exactly the same buffer sizes,",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:47662,Energy Efficiency,power,power,47662,"verride that choice with; * this enum.; */; ZSTD_dictDefaultAttach = 0, /* Use the default heuristic. */; ZSTD_dictForceAttach = 1, /* Never copy the dictionary. */; ZSTD_dictForceCopy = 2, /* Always copy the dictionary. */; } ZSTD_dictAttachPref_e;. typedef enum {; /* compression format */; ZSTD_p_format = 10, /* See ZSTD_format_e enum definition.; * Cast selected format as unsigned for ZSTD_CCtx_setParameter() compatibility. */. /* compression parameters */; ZSTD_p_compressionLevel=100, /* Update all compression parameters according to pre-defined cLevel table; * Default level is ZSTD_CLEVEL_DEFAULT==3.; * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.; * Note 1 : it's possible to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other compression parameters.; * Note 3 : setting compressionLevel automatically updates ZSTD_p_compressLiterals. */; ZSTD_p_windowLog, /* Maximum allowed back-reference distance, expressed as power of 2.; * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.; * Special: value 0 means ""use default windowLog"".; * Note: Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's st",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:48018,Energy Efficiency,power,power,48018,"ed format as unsigned for ZSTD_CCtx_setParameter() compatibility. */. /* compression parameters */; ZSTD_p_compressionLevel=100, /* Update all compression parameters according to pre-defined cLevel table; * Default level is ZSTD_CLEVEL_DEFAULT==3.; * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.; * Note 1 : it's possible to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other compression parameters.; * Note 3 : setting compressionLevel automatically updates ZSTD_p_compressLiterals. */; ZSTD_p_windowLog, /* Maximum allowed back-reference distance, expressed as power of 2.; * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.; * Special: value 0 means ""use default windowLog"".; * Note: Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's still useful when using ""dfast"" strategy,; * in which case it defines a secondary probe table.; * Special: value 0 means ""use default chainLog"". */; ZSTD_p_searchLog, /* Number of search attempts, as a power of 2.; * More attempts result in better and slower compression.; * This parameter is useless when using ""fast"" and ""dFast"" strategies.; * Special: value 0 mean",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:48370,Energy Efficiency,power,power,48370,"ble to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other compression parameters.; * Note 3 : setting compressionLevel automatically updates ZSTD_p_compressLiterals. */; ZSTD_p_windowLog, /* Maximum allowed back-reference distance, expressed as power of 2.; * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.; * Special: value 0 means ""use default windowLog"".; * Note: Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's still useful when using ""dfast"" strategy,; * in which case it defines a secondary probe table.; * Special: value 0 means ""use default chainLog"". */; ZSTD_p_searchLog, /* Number of search attempts, as a power of 2.; * More attempts result in better and slower compression.; * This parameter is useless when using ""fast"" and ""dFast"" strategies.; * Special: value 0 means ""use default searchLog"". */; ZSTD_p_minMatch, /* Minimum size of searched matches (note : repCode matches can be smaller).; * Larger values make faster compression and decompression, but decrease ratio.; * Must be clamped between ZSTD_SEARCHLENGTH_MIN and ZSTD_SEARCHLENGTH_MAX.; * Note that currently, for all strategies < btopt, effective minimu",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:48828,Energy Efficiency,power,power,48828,"Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's still useful when using ""dfast"" strategy,; * in which case it defines a secondary probe table.; * Special: value 0 means ""use default chainLog"". */; ZSTD_p_searchLog, /* Number of search attempts, as a power of 2.; * More attempts result in better and slower compression.; * This parameter is useless when using ""fast"" and ""dFast"" strategies.; * Special: value 0 means ""use default searchLog"". */; ZSTD_p_minMatch, /* Minimum size of searched matches (note : repCode matches can be smaller).; * Larger values make faster compression and decompression, but decrease ratio.; * Must be clamped between ZSTD_SEARCHLENGTH_MIN and ZSTD_SEARCHLENGTH_MAX.; * Note that currently, for all strategies < btopt, effective minimum is 4.; * , for all strategies > fast, effective maximum is 6.; * Special: value 0 means ""use default minMatchLength"". */; ZSTD_p_targetLength, /* Impact of this field depends on strategy.; * For strategies btopt & btultra:; * Length of Match considered ""good enough"" to stop search.; * Larger values make compression stronger, and slower.; * For strategy fast:; * Distance between match sampling.; * Larger values make compression faster, and weaker.; * Special",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:50614,Energy Efficiency,power,power,50614,"Match considered ""good enough"" to stop search.; * Larger values make compression stronger, and slower.; * For strategy fast:; * Distance between match sampling.; * Larger values make compression faster, and weaker.; * Special: value 0 means ""use default targetLength"". */; ZSTD_p_compressionStrategy, /* See ZSTD_strategy enum definition.; * Cast selected strategy as unsigned for ZSTD_CCtx_setParameter() compatibility.; * The higher the value of selected strategy, the more complex it is,; * resulting in stronger and slower compression.; * Special: value 0 means ""use default strategy"". */. ZSTD_p_enableLongDistanceMatching=160, /* Enable long distance matching.; * This parameter is designed to improve compression ratio; * for large inputs, by finding large matches at long distance.; * It increases memory usage and window size.; * Note: enabling this parameter increases ZSTD_p_windowLog to 128 MB; * except when expressly set to a different value. */; ZSTD_p_ldmHashLog, /* Size of the table for long distance matching, as a power of 2.; * Larger values increase memory usage and compression ratio,; * but decrease compression speed.; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX; * default: windowlog - 7.; * Special: value 0 means ""automatically determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WI",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:69164,Energy Efficiency,allocate,allocated,69164,"_decompress_generic() returns 0.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary; Note 2 : Prefix buffer is referenced. It **must** outlive decompression job.; Prefix buffer must remain unmodified up to the end of frame,; reached when ZSTD_DCtx_decompress_generic() returns 0.; Note 3 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @re",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:71205,Energy Efficiency,charge,charge,71205,"put bytes for next invocation.; `0` means : a frame has just been fully decoded and flushed.; . size_t ZSTD_decompress_generic_simpleArgs (; ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos);; Same as ZSTD_decompress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binders from dynamic languages; which have troubles handling structures containing memory pointers.; . void ZSTD_DCtx_reset(ZSTD_DCtx* dctx);; Return a DCtx to clean state.; If a decompression was ongoing, any internal data not yet flushed is cancelled.; All parameters are back to default values, including sticky ones.; Dictionary (if any) is dropped.; Parameters can be modified again after a reset.; . Block level API; Frame metadata cost is typically ~18 bytes, which can be non-negligible for very small blocks (< 100 bytes).; User will have to take in charge required information to regenerate data, such as compressed and content sizes. A few rules to respect :; - Compressing and decompressing require a context structure; + Use ZSTD_createCCtx() and ZSTD_createDCtx(); - It is necessary to init context before starting; + compression : any ZSTD_compressBegin*() variant, including with dictionary; + decompression : any ZSTD_decompressBegin*() variant, including with dictionary; + copyCCtx() and copyDCtx() can be used too; - Block size is limited, it must be <= ZSTD_getBlockSize() <= ZSTD_BLOCKSIZE_MAX == 128 KB; + If input is larger than a block size, it's necessary to split input data into multiple blocks; + For inputs larger than a single block size, consider using the regular ZSTD_compress() instead.; Frame metadata is not that costly, and quickly becomes negligible as source size grows larger.; - When a block is considered not compressible enough, ZSTD_compressBlock() result will be zero.; In which case, nothing is produced into `dst`.; + User must test for suc",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:8250,Integrability,message,messages,8250," ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary crea",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:23258,Integrability,depend,depends,23258,"_compressionParameters cParams);; size_t ZSTD_estimateCStreamSize_usingCCtxParams(const ZSTD_CCtx_params* params);; size_t ZSTD_estimateDStreamSize(size_t windowSize);; size_t ZSTD_estimateDStreamSize_fromFrame(const void* src, size_t srcSize);; ZSTD_estimateCStreamSize() will provide a budget large enough for any compression level up to selected one.; It will also consider src size to be arbitrarily ""large"", which is worst case.; If srcSize is known to always be small, ZSTD_estimateCStreamSize_usingCParams() can provide a tighter estimation.; ZSTD_estimateCStreamSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.; ZSTD_estimateCStreamSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParam_setParameter(). Only single-threaded compression is supported. This function will return an error code if ZSTD_p_nbWorkers is >= 1.; Note : CStream size estimation is only correct for single-threaded compression.; ZSTD_DStream memory budget depends on window Size.; This information can be passed manually, using ZSTD_estimateDStreamSize,; or deducted from a valid frame Header, using ZSTD_estimateDStreamSize_fromFrame();; Note : if streaming is init with function ZSTD_init?Stream_usingDict(),; an internal ?Dict will be created, which additional size is not estimated here.; In this case, get total size by adding ZSTD_estimate?DictSize . size_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel);; size_t ZSTD_estimateCDictSize_advanced(size_t dictSize, ZSTD_compressionParameters cParams, ZSTD_dictLoadMethod_e dictLoadMethod);; size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);; ZSTD_estimateCDictSize() will bet that src size is relatively ""small"", and content is copied, like ZSTD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().; Note : dictionaries created by reference (`ZSTD_dlm_by",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:39557,Integrability,depend,depending,39557,"racted from the beginning of compressed frame, so providing only the frame's beginning is enough.; Data fragment must be large enough to ensure successful decoding.; `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.; @result : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.; >0 : `srcSize` is too small, please provide at least @result bytes on next attempt.; errorCode, which can be tested using ZSTD_isError(). It fills a ZSTD_frameHeader structure with important information to correctly decode the frame,; such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,; up to the moment there is not enough room left in the buffer to guarantee decoding",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:39604,Integrability,interoperab,interoperability,39604,"ng is enough.; Data fragment must be large enough to ensure successful decoding.; `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.; @result : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.; >0 : `srcSize` is too small, please provide at least @result bytes on next attempt.; errorCode, which can be tested using ZSTD_isError(). It fills a ZSTD_frameHeader structure with important information to correctly decode the frame,; such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,; up to the moment there is not enough room left in the buffer to guarantee decoding another full block,; which maximum size is provided in `ZSTD_frameHeader` structur",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:42295,Integrability,integrat,integration,42295,"decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict(). Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.; ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().; ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail. @result of ZSTD_decompressContinue() is the number of bytes regenerated within 'dst' (necessarily <= dstCapacity).; It can be zero : it just means ZSTD_decompressContinue() has decoded some metadata item.; It can also be an error code, which can be tested with ZSTD_isError(). A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.; Context can then be reset to start a new decompression. Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().; This information is not required to properly decode a frame. == Special case : skippable frames . Skippable frames allow integration of user-defined data into a flow of concatenated frames.; Skippable frames will be ignored (skipped) by decompressor.; The format of skippable frames is as follows :; a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F; b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits; c) Frame Content - any content (User Data) of length equal to Frame Size; For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buffer-less streaming decompression functionstypedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_frameType_e;; typedef struct {; unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means ""empty"" */; unsigned long long windowSize; /* can be very large, up to <= frameContentSize */; unsigned blockSizeMax;; ZSTD_frameType_e frameType; /* if == ZSTD_skippableFram",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:49511,Integrability,depend,depends,49511,".; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's still useful when using ""dfast"" strategy,; * in which case it defines a secondary probe table.; * Special: value 0 means ""use default chainLog"". */; ZSTD_p_searchLog, /* Number of search attempts, as a power of 2.; * More attempts result in better and slower compression.; * This parameter is useless when using ""fast"" and ""dFast"" strategies.; * Special: value 0 means ""use default searchLog"". */; ZSTD_p_minMatch, /* Minimum size of searched matches (note : repCode matches can be smaller).; * Larger values make faster compression and decompression, but decrease ratio.; * Must be clamped between ZSTD_SEARCHLENGTH_MIN and ZSTD_SEARCHLENGTH_MAX.; * Note that currently, for all strategies < btopt, effective minimum is 4.; * , for all strategies > fast, effective maximum is 6.; * Special: value 0 means ""use default minMatchLength"". */; ZSTD_p_targetLength, /* Impact of this field depends on strategy.; * For strategies btopt & btultra:; * Length of Match considered ""good enough"" to stop search.; * Larger values make compression stronger, and slower.; * For strategy fast:; * Distance between match sampling.; * Larger values make compression faster, and weaker.; * Special: value 0 means ""use default targetLength"". */; ZSTD_p_compressionStrategy, /* See ZSTD_strategy enum definition.; * Cast selected strategy as unsigned for ZSTD_CCtx_setParameter() compatibility.; * The higher the value of selected strategy, the more complex it is,; * resulting in stronger and slower compression.; * Special: value 0 means ""use default strategy"". */. ZSTD_p_enableLongDistanceMatching=160, /* Enable long distance matching.; * This parameter is designed to improve compression ratio; * for large inputs, by finding large matches at long distance.; * It increases memory usage and window size.; * Note: enabling this parameter increases ZSTD_p_windowLog to 128 MB; * except ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:56952,Integrability,depend,dependent,56952,"NTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictionary will be used for all future compression jobs.; To return to ""no-dictionary"" situation, load a NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all next compression jobs.; Note that compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError())",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:59412,Integrability,depend,dependent,59412,"nce a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing compression job and start a new one.; Any internal data not yet flushed is cancelled.; The parameters and dictionary are kept unchanged, to reset them use ZSTD_CCtx_resetParameters().; . size_t ZSTD_CCtx_resetParameters(ZSTD_CCtx* cctx);; All parameters are back to default values (compression level is ZSTD_CLEVEL_DEFAULT).; Dictionary (if any) is dropped.; Resetting parameters is only possible during frame initialization (before starting compression).; To reset the context use ZSTD_CCtx_reset().; @return 0 or an error code",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:1157,Modifiability,extend,extend,1157,"I; Bulk processing dictionary API; Streaming; Streaming compression - HowTo; Streaming decompression - HowTo; ADVANCED AND EXPERIMENTAL FUNCTIONS; Frame size functions; Memory management; Advanced compression functions; Advanced decompression functions; Advanced streaming functions; Buffer-less and synchronous inner streaming functions; Buffer-less streaming compression (synchronous mode); Buffer-less streaming decompression (synchronous mode); New advanced API (experimental); Block level API. Introduction; zstd, short for Zstandard, is a fast lossless compression algorithm, targeting; real-time compression scenarios at zlib-level and better compression ratios.; The zstd compression library provides in-memory compression and decompression; functions. The library supports regular compression levels from 1 up to ZSTD_maxCLevel(),; which is currently 22. Levels >= 20, labeled `--ultra`, should be used with; caution, as they require more memory. The library also offers negative; compression levels, which extend the range of speed vs. ratio preferences.; The lower the level, the faster the speed (at the cost of compression). Compression can be done in:; - a single step (described as Simple API); - a single step, reusing a context (described as Explicit context); - unbounded multiple steps (described as Streaming compression). The compression ratio achievable on small data can be highly improved using; a dictionary. Dictionary compression can be performed in:; - a single step (described as Simple dictionary API); - a single step, reusing a dictionary (described as Bulk-processing; dictionary API). Advanced experimental functions can be accessed using; `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h. Advanced experimental APIs should never be used with a dynamically-linked; library. They are not ""stable""; their definitions or signatures may change in; the future. Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:21059,Modifiability,evolve,evolve,21059,"ong or intentionally modified.; Always ensure result fits within application's authorized limits.; Each application can set its own limits.; note 5 : ZSTD_findDecompressedSize handles multiple frames, and so it must traverse the input to; read each contained frame header. This is fast as most of the data is skipped,; however it does mean that all frame data must be present and valid. . size_t ZSTD_frameHeaderSize(const void* src, size_t srcSize);; srcSize must be >= ZSTD_frameHeaderSize_prefix.; @return : size of the Frame Header,; or an error code (if srcSize is too small) . Memory management; size_t ZSTD_sizeof_CCtx(const ZSTD_CCtx* cctx);; size_t ZSTD_sizeof_DCtx(const ZSTD_DCtx* dctx);; size_t ZSTD_sizeof_CStream(const ZSTD_CStream* zcs);; size_t ZSTD_sizeof_DStream(const ZSTD_DStream* zds);; size_t ZSTD_sizeof_CDict(const ZSTD_CDict* cdict);; size_t ZSTD_sizeof_DDict(const ZSTD_DDict* ddict);; These functions give the current memory usage of selected object.; Object memory usage can evolve when re-used. . size_t ZSTD_estimateCCtxSize(int compressionLevel);; size_t ZSTD_estimateCCtxSize_usingCParams(ZSTD_compressionParameters cParams);; size_t ZSTD_estimateCCtxSize_usingCCtxParams(const ZSTD_CCtx_params* params);; size_t ZSTD_estimateDCtxSize(void);; These functions make it possible to estimate memory usage; of a future {D,C}Ctx, before its creation.; ZSTD_estimateCCtxSize() will provide a budget large enough for any compression level up to selected one.; It will also consider src size to be arbitrarily ""large"", which is worst case.; If srcSize is known to always be small, ZSTD_estimateCCtxSize_usingCParams() can provide a tighter estimation.; ZSTD_estimateCCtxSize_usingCParams() can be used in tandem with ZSTD_getCParams() to create cParams from compressionLevel.; ZSTD_estimateCCtxSize_usingCCtxParams() can be used in tandem with ZSTD_CCtxParam_setParameter(). Only single-threaded compression is supported. This function will return an error code if ZSTD_p_nbWor",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:39595,Modifiability,extend,extended,39595,"ng is enough.; Data fragment must be large enough to ensure successful decoding.; `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.; @result : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.; >0 : `srcSize` is too small, please provide at least @result bytes on next attempt.; errorCode, which can be tested using ZSTD_isError(). It fills a ZSTD_frameHeader structure with important information to correctly decode the frame,; such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,; up to the moment there is not enough room left in the buffer to guarantee decoding another full block,; which maximum size is provided in `ZSTD_frameHeader` structur",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:45460,Modifiability,evolve,evolve,45460," On the decompression side, it would mean ""automatic format detection"",; * so that ZSTD_f_zstd1 would mean ""accept *only* zstd frames"".; * Since meaning is a little different, another option could be to define different enums for compression and decompression.; * This question could be kept for later, when there are actually multiple formats to support,; * but there is also the question of pinning enum values, and pinning value `0` is especially important */; ZSTD_f_zstd1 = 0, /* zstd frame format, specified in zstd_compression_format.md (default) */; ZSTD_f_zstd1_magicless, /* Variant of zstd frame format, without initial 4-bytes magic number.; * Useful to save 4 bytes per generated frame.; * Decoder cannot recognise automatically this format, requiring instructions. */; } ZSTD_format_e;. typedef enum {; /* Note: this enum and the behavior it controls are effectively internal; * implementation details of the compressor. They are expected to continue; * to evolve and should be considered only in the context of extremely; * advanced performance tuning.; *; * Zstd currently supports the use of a CDict in two ways:; *; * - The contents of the CDict can be copied into the working context. This; * means that the compression can search both the dictionary and input; * while operating on a single set of internal tables. This makes; * the compression faster per-byte of input. However, the initial copy of; * the CDict's tables incurs a fixed cost at the beginning of the; * compression. For small compressions (< 8 KB), that copy can dominate; * the cost of the compression.; *; * - The CDict's tables can be used in-place. In this model, compression is; * slower per input byte, because the compressor has to search two sets of; * tables. However, this model incurs no start-up cost (as long as the; * working context's tables can be reused). For small inputs, this can be; * faster than copying the CDict's tables.; *; * Zstd has a simple internal heuristic that selects which strateg",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:1605,Performance,perform,performed,1605,"for Zstandard, is a fast lossless compression algorithm, targeting; real-time compression scenarios at zlib-level and better compression ratios.; The zstd compression library provides in-memory compression and decompression; functions. The library supports regular compression levels from 1 up to ZSTD_maxCLevel(),; which is currently 22. Levels >= 20, labeled `--ultra`, should be used with; caution, as they require more memory. The library also offers negative; compression levels, which extend the range of speed vs. ratio preferences.; The lower the level, the faster the speed (at the cost of compression). Compression can be done in:; - a single step (described as Simple API); - a single step, reusing a context (described as Explicit context); - unbounded multiple steps (described as Streaming compression). The compression ratio achievable on small data can be highly improved using; a dictionary. Dictionary compression can be performed in:; - a single step (described as Simple dictionary API); - a single step, reusing a dictionary (described as Bulk-processing; dictionary API). Advanced experimental functions can be accessed using; `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h. Advanced experimental APIs should never be used with a dynamically-linked; library. They are not ""stable""; their definitions or signatures may change in; the future. Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; co",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:6291,Performance,multi-thread,multi-threaded,6291,"compressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isError(size_t code); /*!< tells if a `size_t` function result is an error code */; const char* ZSTD_getErrorName(size_t code); /*!< provides readable string from an error code */; int ZSTD_maxCLevel(void); /*!< maximum compression level available */. Explicit context; Compression context When compressing many times,; it is recommended to allocate a context just once, and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution in multi-threaded environments. ; typedef struct ZSTD_CCtx_s ZSTD_CCtx;; ZSTD_CCtx* ZSTD_createCCtx(void);; size_t ZSTD_freeCCtx(ZSTD_CCtx* cctx);. size_t ZSTD_compressCCtx(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When decompressing many times,; it is recommended to allocate a context only once,; and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution. ; typedef struct ZSTD_DCtx_s ZSTD_DCtx;; ZSTD_DCtx* ZSTD_createDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize);; Same as ZSTD_decompress(), requires an allocated ZSTD_DCtx (see ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compres",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:7523,Performance,load,loads,7523,"; int compressionLevel);; Same as ZSTD_compress(), requires an allocated ZSTD_CCtx (see ZSTD_createCCtx()). . Decompression context When decompressing many times,; it is recommended to allocate a context only once,; and re-use it for each successive compression operation.; This will make workload friendlier for system's memory.; Use one context per thread for parallel execution. ; typedef struct ZSTD_DCtx_s ZSTD_DCtx;; ZSTD_DCtx* ZSTD_createDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize);; Same as ZSTD_decompress(), requires an allocated ZSTD_DCtx (see ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:7966,Performance,load,loads,7966,"teDCtx(void);; size_t ZSTD_freeDCtx(ZSTD_DCtx* dctx);. size_t ZSTD_decompressDCtx(ZSTD_DCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize);; Same as ZSTD_decompress(), requires an allocated ZSTD_DCtx (see ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:8314,Performance,load,load,8314," ZSTD_createDCtx()) . Simple dictionary API; size_t ZSTD_compress_usingDict(ZSTD_CCtx* ctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; int compressionLevel);; Compression using a predefined Dictionary (see dictBuilder/zdict.h).; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary crea",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:8519,Performance,concurren,concurrently,8519," This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . size_t ZSTD_decompress_usingDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize);; Decompression using a predefined Dictionary (see dictBuilder/zdict.h).; Dictionary must be identical to the one used during compression.; Note : This function loads the dictionary, resulting in significant startup delay.; Note : When `dict == NULL || dictSize < 8` no dictionary is used. . Bulk processing dictionary API; ZSTD_CDict* ZSTD_createCDict(const void* dictBuffer, size_t dictSize,; int compressionLevel);; When compressing multiple messages / blocks with the same dictionary, it's recommended to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary creation.; Frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no); Note : ZSTD_compress_usingCDict() can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createD",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12174,Performance,latency,latency,12174,"pression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check if input has been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and full",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12944,Performance,perform,perform,12944,"sent again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and fully flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now effectively same object (>= v1.3.0) */. ZSTD_CStream management functionsZSTD_CStream* ZSTD_createCStream(void);; size_t ZSTD_freeCStream(ZSTD_CStream* zcs);. Streaming compression functionssize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);; size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);. size_t ZSTD_CStreamInSize(void); /**< recommended ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:15609,Performance,latency,latency,15609,"f decompression requires a dictionary.; @return : recommended first input size. Use ZSTD_decompressStream() repetitively to consume your input.; The function will update both `pos` fields.; If `input.pos < input.size`, some input has not been consumed.; It's up to the caller to present again remaining data.; The function tries to flush all data decoded immediately, repecting buffer sizes.; If `output.pos < output.size`, decoder has flushed everything it could.; But if `output.pos == output.size`, there is no such guarantee,; it's likely that some decoded data was not flushed and still remains within internal buffers.; In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.; When no additional input is provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.; @return : 0 when a frame is completely decoded and fully flushed,; or an error code, which can be tested using ZSTD_isError(),; or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :; the return value is a suggested next input size (a hint for better latency); that will never load more than the current frame.; . typedef ZSTD_DCtx ZSTD_DStream; /**< DCtx and DStream are now effectively same object (>= v1.3.0) */. ZSTD_DStream management functionsZSTD_DStream* ZSTD_createDStream(void);; size_t ZSTD_freeDStream(ZSTD_DStream* zds);. Streaming decompression functionssize_t ZSTD_initDStream(ZSTD_DStream* zds);; size_t ZSTD_decompressStream(ZSTD_DStream* zds, ZSTD_outBuffer* output, ZSTD_inBuffer* input);. size_t ZSTD_DStreamInSize(void); /*!< recommended size for input buffer */. size_t ZSTD_DStreamOutSize(void); /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */. ADVANCED AND EXPERIMENTAL FUNCTIONS; The definitions in this section are considered experimental.; They should never be used with a dynamic library, as prototypes may change in the",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:15635,Performance,load,load,15635,"f decompression requires a dictionary.; @return : recommended first input size. Use ZSTD_decompressStream() repetitively to consume your input.; The function will update both `pos` fields.; If `input.pos < input.size`, some input has not been consumed.; It's up to the caller to present again remaining data.; The function tries to flush all data decoded immediately, repecting buffer sizes.; If `output.pos < output.size`, decoder has flushed everything it could.; But if `output.pos == output.size`, there is no such guarantee,; it's likely that some decoded data was not flushed and still remains within internal buffers.; In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.; When no additional input is provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.; @return : 0 when a frame is completely decoded and fully flushed,; or an error code, which can be tested using ZSTD_isError(),; or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :; the return value is a suggested next input size (a hint for better latency); that will never load more than the current frame.; . typedef ZSTD_DCtx ZSTD_DStream; /**< DCtx and DStream are now effectively same object (>= v1.3.0) */. ZSTD_DStream management functionsZSTD_DStream* ZSTD_createDStream(void);; size_t ZSTD_freeDStream(ZSTD_DStream* zds);. Streaming decompression functionssize_t ZSTD_initDStream(ZSTD_DStream* zds);; size_t ZSTD_decompressStream(ZSTD_DStream* zds, ZSTD_outBuffer* output, ZSTD_inBuffer* input);. size_t ZSTD_DStreamInSize(void); /*!< recommended size for input buffer */. size_t ZSTD_DStreamOutSize(void); /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */. ADVANCED AND EXPERIMENTAL FUNCTIONS; The definitions in this section are considered experimental.; They should never be used with a dynamic library, as prototypes may change in the",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:18164,Performance,load,loaded,18164,"gned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame or skippable frame; `srcSize` must be >= first frame size; @return : the compressed size of the first frame starting at `src`,; suitable to pass to `ZSTD_decompress` or similar,; or an error code if input is invalid . unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize);; `src` should point the start of a series of ZSTD encoded and/or skippable frames; `srcSize` must be the _exact_ size of this series; (i.e. there sho",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:18267,Performance,load,load,18267,"gned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame or skippable frame; `srcSize` must be >= first frame size; @return : the compressed size of the first frame starting at `src`,; suitable to pass to `ZSTD_decompress` or similar,; or an error code if input is invalid . unsigned long long ZSTD_findDecompressedSize(const void* src, size_t srcSize);; `src` should point the start of a series of ZSTD encoded and/or skippable frames; `srcSize` must be the _exact_ size of this series; (i.e. there sho",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:25580,Performance,multi-thread,multi-threading,25580,"y area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; Note 3 : cParams : use ZSTD_getCParams() to convert a compression level; into its associated cParams.; Limitation 1 : currently not compatible with internal dictionary creation, triggered by; ZSTD_CCtx_loadDictionary(), ZSTD_initCStream_usingDict() or ZSTD_initDStream_usingDict().; Limitation 2 : static cctx currently not compatible with multi-threading.; Limitation 3 : static dctx is incompatible with legacy support.; . ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; typedef void (*ZSTD_freeFunction) (void* opaque, void* address);; typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;; static ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL }; /**< this constant defers to stdlib's functions */; These prototypes make it possible to pass your own allocation/free functions.; ZSTD_customMem is provided at creation time, using ZSTD_create*_advanced() variants listed below.; All allocation/free operations will be completed using these custom variants instead of regular ones.; . Advanced compression functions; ZSTD_CDict* ZSTD_createCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionL",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:27664,Performance,optimiz,optimize,27664,"tent is simply referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives CDict, it must remain read accessible throughout the lifetime of CDict . ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.; `estimatedSrcSize` value is optional, select 0 if not known . ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);; optimize params for a given `srcSize` and `dictSize`.; both values are optional, select `0` if unknown. . size_t ZSTD_compress_advanced (ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; ZSTD_parameters params);; Same as ZSTD_compress_usingDict(), with fine-tune control over each compression parameter . size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict, ZSTD_frameParameters fParams);; Same as ZSTD_compress_usingCDict(), with fine-tune control over frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* buffer, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.; Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is en",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:27991,Performance,tune,tune,27991,"e, size_t dictSize);; @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.; `estimatedSrcSize` value is optional, select 0 if not known . ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);; optimize params for a given `srcSize` and `dictSize`.; both values are optional, select `0` if unknown. . size_t ZSTD_compress_advanced (ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; ZSTD_parameters params);; Same as ZSTD_compress_usingDict(), with fine-tune control over each compression parameter . size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict, ZSTD_frameParameters fParams);; Same as ZSTD_compress_usingCDict(), with fine-tune control over frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* buffer, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.; Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.; Note 3 : Skippable Frame Identifiers are considered valid. . ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; Dictionary content is referenc",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:28266,Performance,tune,tune,28266,"dSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);; optimize params for a given `srcSize` and `dictSize`.; both values are optional, select `0` if unknown. . size_t ZSTD_compress_advanced (ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; ZSTD_parameters params);; Same as ZSTD_compress_usingDict(), with fine-tune control over each compression parameter . size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict, ZSTD_frameParameters fParams);; Same as ZSTD_compress_usingCDict(), with fine-tune control over frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* buffer, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.; Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.; Note 3 : Skippable Frame Identifiers are considered valid. . ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; Dictionary content is referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives DDict,; it must remain read accessible throughout the lifetime of DDict . unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);; Provides the dictID stored within dictiona",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:29272,Performance,load,loaded,29272," frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* buffer, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.; Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.; Note 3 : Skippable Frame Identifiers are considered valid. . ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; Dictionary content is referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives DDict,; it must remain read accessible throughout the lifetime of DDict . unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);; Provides the dictID stored within dictionary.; if @return == 0, the dictionary is not conformant with Zstandard specification.; It can still be loaded, but as a content-only dictionary. . unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);; Provides the dictID of the dictionary loaded into `ddict`.; If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.; Non-conformant dictionaries can still be loaded, but as content-only dictionaries. . unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);; Provides the dictID required to decompressed the frame stored within `src`.; If @return == 0, the dictID could not be decoded.; This could for one of the following reasons :; - The frame does not require a dictionary to be decoded (most common case).; - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden information.; Note : this use case also happens when using a non-conformant dictionary.; - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).; - This is not a Zstand",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:29415,Performance,load,loaded,29415,"er, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.; Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.; Note 3 : Skippable Frame Identifiers are considered valid. . ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; Dictionary content is referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives DDict,; it must remain read accessible throughout the lifetime of DDict . unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);; Provides the dictID stored within dictionary.; if @return == 0, the dictionary is not conformant with Zstandard specification.; It can still be loaded, but as a content-only dictionary. . unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);; Provides the dictID of the dictionary loaded into `ddict`.; If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.; Non-conformant dictionaries can still be loaded, but as content-only dictionaries. . unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);; Provides the dictID required to decompressed the frame stored within `src`.; If @return == 0, the dictID could not be decoded.; This could for one of the following reasons :; - The frame does not require a dictionary to be decoded (most common case).; - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden information.; Note : this use case also happens when using a non-conformant dictionary.; - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).; - This is not a Zstandard frame.; When identifying the exact failure cause, it's possible to use ZSTD_getFrameHea",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:29567,Performance,load,loaded,29567,"Identifiers are considered valid only if Legacy Support is enabled.; Note 3 : Skippable Frame Identifiers are considered valid. . ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; Dictionary content is referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives DDict,; it must remain read accessible throughout the lifetime of DDict . unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);; Provides the dictID stored within dictionary.; if @return == 0, the dictionary is not conformant with Zstandard specification.; It can still be loaded, but as a content-only dictionary. . unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);; Provides the dictID of the dictionary loaded into `ddict`.; If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.; Non-conformant dictionaries can still be loaded, but as content-only dictionaries. . unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);; Provides the dictID required to decompressed the frame stored within `src`.; If @return == 0, the dictID could not be decoded.; This could for one of the following reasons :; - The frame does not require a dictionary to be decoded (most common case).; - The frame was built with dictID intentionally removed. Whatever dictionary is necessary is a hidden information.; Note : this use case also happens when using a non-conformant dictionary.; - `srcSize` is too small, and as a result, the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).; - This is not a Zstandard frame.; When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code. . Advanced streaming functions; Advanced Streaming compression functionssize_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs, int compression",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:31103,Performance,load,loaded,31103,"the frame header could not be decoded (only possible if `srcSize < ZSTD_FRAMEHEADERSIZE_MAX`).; - This is not a Zstandard frame.; When identifying the exact failure cause, it's possible to use ZSTD_getFrameHeader(), which will provide a more precise error code. . Advanced streaming functions; Advanced Streaming compression functionssize_t ZSTD_initCStream_srcSize(ZSTD_CStream* zcs, int compressionLevel, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If it is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN. Note that, for compatibility with older programs, ""0"" also disables frame content size field. It may be enabled in the future. */; size_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs, const void* dict, size_t dictSize, int compressionLevel); /**< creates of an internal CDict (incompatible with static CCtx), except if dict == NULL or dictSize < 8, in which case no dict is used. Note: dict is loaded with ZSTD_dm_auto (treated as a full zstd dictionary if it begins with ZSTD_MAGIC_DICTIONARY, else as raw content) and ZSTD_dlm_byCopy.*/; size_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs, const void* dict, size_t dictSize,; ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. dict is loaded with ZSTD_dm_auto and ZSTD_dlm_byCopy. */; size_t ZSTD_initCStream_usingCDict(ZSTD_CStream* zcs, const ZSTD_CDict* cdict); /**< note : cdict will just be referenced, and must outlive compression session */; size_t ZSTD_initCStream_usingCDict_advanced(ZSTD_CStream* zcs, const ZSTD_CDict* cdict, ZSTD_frameParameters fParams, unsigned long long pledgedSrcSize); /**< same as ZSTD_initCStream_usingCDict(), with control over frame parameters. pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. */. size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);; start a new ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:31516,Performance,load,loaded,31516,"TD_CStream* zcs, int compressionLevel, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If it is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN. Note that, for compatibility with older programs, ""0"" also disables frame content size field. It may be enabled in the future. */; size_t ZSTD_initCStream_usingDict(ZSTD_CStream* zcs, const void* dict, size_t dictSize, int compressionLevel); /**< creates of an internal CDict (incompatible with static CCtx), except if dict == NULL or dictSize < 8, in which case no dict is used. Note: dict is loaded with ZSTD_dm_auto (treated as a full zstd dictionary if it begins with ZSTD_MAGIC_DICTIONARY, else as raw content) and ZSTD_dlm_byCopy.*/; size_t ZSTD_initCStream_advanced(ZSTD_CStream* zcs, const void* dict, size_t dictSize,; ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. dict is loaded with ZSTD_dm_auto and ZSTD_dlm_byCopy. */; size_t ZSTD_initCStream_usingCDict(ZSTD_CStream* zcs, const ZSTD_CDict* cdict); /**< note : cdict will just be referenced, and must outlive compression session */; size_t ZSTD_initCStream_usingCDict_advanced(ZSTD_CStream* zcs, const ZSTD_CDict* cdict, ZSTD_frameParameters fParams, unsigned long long pledgedSrcSize); /**< same as ZSTD_initCStream_usingCDict(), with control over frame parameters. pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. */. size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);; start a new compression job, using same parameters from previous job.; This is typically useful to skip dictionary loading stage, since it will re-use it in-place.; Note that zcs must be init at least once before using ZSTD_resetCStream().; If pledgedSrcSize is not known at reset time, use macro ZSTD_CONTENTSIZE_UNKNOWN.; If pledgedSrcSize > 0, its value must be correct, as it",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:32270,Performance,load,loading,32270,"m_advanced(ZSTD_CStream* zcs, const void* dict, size_t dictSize,; ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. dict is loaded with ZSTD_dm_auto and ZSTD_dlm_byCopy. */; size_t ZSTD_initCStream_usingCDict(ZSTD_CStream* zcs, const ZSTD_CDict* cdict); /**< note : cdict will just be referenced, and must outlive compression session */; size_t ZSTD_initCStream_usingCDict_advanced(ZSTD_CStream* zcs, const ZSTD_CDict* cdict, ZSTD_frameParameters fParams, unsigned long long pledgedSrcSize); /**< same as ZSTD_initCStream_usingCDict(), with control over frame parameters. pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. */. size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);; start a new compression job, using same parameters from previous job.; This is typically useful to skip dictionary loading stage, since it will re-use it in-place.; Note that zcs must be init at least once before using ZSTD_resetCStream().; If pledgedSrcSize is not known at reset time, use macro ZSTD_CONTENTSIZE_UNKNOWN.; If pledgedSrcSize > 0, its value must be correct, as it will be written in header, and controlled at the end.; For the time being, pledgedSrcSize==0 is interpreted as ""srcSize unknown"" for compatibility with older programs,; but it will change to mean ""empty"" in future version, so use macro ZSTD_CONTENTSIZE_UNKNOWN instead.; @return : 0, or an error code (which can be tested using ZSTD_isError()); . typedef struct {; unsigned long long ingested; /* nb input bytes read and buffered */; unsigned long long consumed; /* nb input bytes actually compressed */; unsigned long long produced; /* nb of compressed bytes generated and buffered */; unsigned long long flushed; /* nb of compressed bytes flushed : not provided; can be tracked from caller side */; unsigned currentJobID; /* MT only :",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:34099,Performance,concurren,concurrent,34099,"bytes read and buffered */; unsigned long long consumed; /* nb input bytes actually compressed */; unsigned long long produced; /* nb of compressed bytes generated and buffered */; unsigned long long flushed; /* nb of compressed bytes flushed : not provided; can be tracked from caller side */; unsigned currentJobID; /* MT only : latest started job nb */; unsigned nbActiveWorkers; /* MT only : nb of workers actively compressing at probe time */; } ZSTD_frameProgression;. size_t ZSTD_toFlushNow(ZSTD_CCtx* cctx);; Tell how many bytes are ready to be flushed immediately.; Useful for multithreading scenarios (nbWorkers >= 1).; Probe the oldest active job, defined as oldest job not yet entirely flushed,; and check its output buffer.; @return : amount of data stored in oldest job and ready to be flushed immediately.; if @return == 0, it means either :; + there is no active job (could be checked with ZSTD_frameProgression()), or; + oldest job is still actively compressing data,; but everything it has produced has also been flushed so far,; therefore flushing speed is currently limited by production speed of oldest job; irrespective of the speed of concurrent newer jobs.; . Advanced Streaming decompression functionstypedef enum { DStream_p_maxWindowSize } ZSTD_DStreamParameter_e;; size_t ZSTD_setDStreamParameter(ZSTD_DStream* zds, ZSTD_DStreamParameter_e paramType, unsigned paramValue); /* obsolete : this API will be removed in a future version */; size_t ZSTD_initDStream_usingDict(ZSTD_DStream* zds, const void* dict, size_t dictSize); /**< note: no dictionary will be used if dict == NULL or dictSize < 8 */; size_t ZSTD_initDStream_usingDDict(ZSTD_DStream* zds, const ZSTD_DDict* ddict); /**< note : ddict is referenced, it must outlive decompression session */; size_t ZSTD_resetDStream(ZSTD_DStream* zds); /**< re-use decompression parameters from previous init; saves dictionary loading */. Buffer-less and synchronous inner streaming functions; This is an advanced API, giving ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:34842,Performance,load,loading,34842,"to be flushed immediately.; Useful for multithreading scenarios (nbWorkers >= 1).; Probe the oldest active job, defined as oldest job not yet entirely flushed,; and check its output buffer.; @return : amount of data stored in oldest job and ready to be flushed immediately.; if @return == 0, it means either :; + there is no active job (could be checked with ZSTD_frameProgression()), or; + oldest job is still actively compressing data,; but everything it has produced has also been flushed so far,; therefore flushing speed is currently limited by production speed of oldest job; irrespective of the speed of concurrent newer jobs.; . Advanced Streaming decompression functionstypedef enum { DStream_p_maxWindowSize } ZSTD_DStreamParameter_e;; size_t ZSTD_setDStreamParameter(ZSTD_DStream* zds, ZSTD_DStreamParameter_e paramType, unsigned paramValue); /* obsolete : this API will be removed in a future version */; size_t ZSTD_initDStream_usingDict(ZSTD_DStream* zds, const void* dict, size_t dictSize); /**< note: no dictionary will be used if dict == NULL or dictSize < 8 */; size_t ZSTD_initDStream_usingDDict(ZSTD_DStream* zds, const ZSTD_DDict* ddict); /**< note : ddict is referenced, it must outlive decompression session */; size_t ZSTD_resetDStream(ZSTD_DStream* zds); /**< re-use decompression parameters from previous init; saves dictionary loading */. Buffer-less and synchronous inner streaming functions; This is an advanced API, giving full control over buffer management, for users which need direct control over memory.; But it's also a complex one, with several restrictions, documented below.; Prefer normal streaming API for an easier experience.; . Buffer-less streaming compression (synchronous mode); A ZSTD_CCtx object is required to track streaming operations.; Use ZSTD_createCCtx() / ZSTD_freeCCtx() to manage resource.; ZSTD_CCtx object can be re-used multiple times within successive compression operations. Start by initializing a context.; Use ZSTD_compressBegin(), or",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:45537,Performance,perform,performance,45537," On the decompression side, it would mean ""automatic format detection"",; * so that ZSTD_f_zstd1 would mean ""accept *only* zstd frames"".; * Since meaning is a little different, another option could be to define different enums for compression and decompression.; * This question could be kept for later, when there are actually multiple formats to support,; * but there is also the question of pinning enum values, and pinning value `0` is especially important */; ZSTD_f_zstd1 = 0, /* zstd frame format, specified in zstd_compression_format.md (default) */; ZSTD_f_zstd1_magicless, /* Variant of zstd frame format, without initial 4-bytes magic number.; * Useful to save 4 bytes per generated frame.; * Decoder cannot recognise automatically this format, requiring instructions. */; } ZSTD_format_e;. typedef enum {; /* Note: this enum and the behavior it controls are effectively internal; * implementation details of the compressor. They are expected to continue; * to evolve and should be considered only in the context of extremely; * advanced performance tuning.; *; * Zstd currently supports the use of a CDict in two ways:; *; * - The contents of the CDict can be copied into the working context. This; * means that the compression can search both the dictionary and input; * while operating on a single set of internal tables. This makes; * the compression faster per-byte of input. However, the initial copy of; * the CDict's tables incurs a fixed cost at the beginning of the; * compression. For small compressions (< 8 KB), that copy can dominate; * the cost of the compression.; *; * - The CDict's tables can be used in-place. In this model, compression is; * slower per input byte, because the compressor has to search two sets of; * tables. However, this model incurs no start-up cost (as long as the; * working context's tables can be reused). For small inputs, this can be; * faster than copying the CDict's tables.; *; * Zstd has a simple internal heuristic that selects which strateg",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:51662,Performance,optimiz,optimizing,51662," memory usage and compression ratio,; * but decrease compression speed.; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX; * default: windowlog - 7.; * Special: value 0 means ""automatically determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:52345,Performance,multi-thread,multi-threading,52345," 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : a strong exception to this rule is when first invocation sets ZSTD_e_end : it becomes a blocking call).; * More workers improve speed, but also increase memory usage.; * Default value is `0`, aka ""single-threaded mode"" : no worker is spawned, compression is performed inside Caller's thread, all invocations are blocking */; ZSTD_p_jobSize, /* Size of a compression job. This value is enforced only in non-blocking mode.; * Each compression job is completed in parallel, so this value indirectly controls the nb of active threads.; * 0 means defa",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:52415,Performance,multi-thread,multi-threading,52415," 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : a strong exception to this rule is when first invocation sets ZSTD_e_end : it becomes a blocking call).; * More workers improve speed, but also increase memory usage.; * Default value is `0`, aka ""single-threaded mode"" : no worker is spawned, compression is performed inside Caller's thread, all invocations are blocking */; ZSTD_p_jobSize, /* Size of a compression job. This value is enforced only in non-blocking mode.; * Each compression job is completed in parallel, so this value indirectly controls the nb of active threads.; * 0 means defa",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:52798,Performance,perform,performed,52798,"compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : a strong exception to this rule is when first invocation sets ZSTD_e_end : it becomes a blocking call).; * More workers improve speed, but also increase memory usage.; * Default value is `0`, aka ""single-threaded mode"" : no worker is spawned, compression is performed inside Caller's thread, all invocations are blocking */; ZSTD_p_jobSize, /* Size of a compression job. This value is enforced only in non-blocking mode.; * Each compression job is completed in parallel, so this value indirectly controls the nb of active threads.; * 0 means default, which is dynamically determined based on compression parameters.; * Job size must be a minimum of overlapSize, or 1 MB, whichever is largest.; * The minimum size is automatically and transparently enforced */; ZSTD_p_overlapSizeLog, /* Size of previous input reloaded at the beginning of each job.; * 0 => no ov",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:53113,Performance,perform,performed,53113,"tPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : a strong exception to this rule is when first invocation sets ZSTD_e_end : it becomes a blocking call).; * More workers improve speed, but also increase memory usage.; * Default value is `0`, aka ""single-threaded mode"" : no worker is spawned, compression is performed inside Caller's thread, all invocations are blocking */; ZSTD_p_jobSize, /* Size of a compression job. This value is enforced only in non-blocking mode.; * Each compression job is completed in parallel, so this value indirectly controls the nb of active threads.; * 0 means default, which is dynamically determined based on compression parameters.; * Job size must be a minimum of overlapSize, or 1 MB, whichever is largest.; * The minimum size is automatically and transparently enforced */; ZSTD_p_overlapSizeLog, /* Size of previous input reloaded at the beginning of each job.; * 0 => no overlap, 6(default) => use 1/8th of windowSize, >=9 => use full windowSize */. /* =================================================================== */; /* experimental parameters - no stability guaranteed */; /* =================================================================== */. ZSTD_p_forceMaxWindow=1100, /* Force back-reference distances to remain < windowSize,; * even when referencing into Dictio",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:54736,Performance,multi-thread,multi-threading,54736,"====================================== */; /* experimental parameters - no stability guaranteed */; /* =================================================================== */. ZSTD_p_forceMaxWindow=1100, /* Force back-reference distances to remain < windowSize,; * even when referencing into Dictionary content (default:0) */; ZSTD_p_forceAttachDict, /* Controls whether the contents of a CDict are; * used in place, or whether they are copied into; * the working context.; *; * Accepts values from the ZSTD_dictAttachPref_e; * enum. See the comments on that enum for an; * explanation of the feature.; */; } ZSTD_cParameter;. size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:56862,Performance,load,load,56862,"NTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictionary will be used for all future compression jobs.; To return to ""no-dictionary"" situation, load a NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all next compression jobs.; Note that compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError())",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:57062,Performance,load,loading,57062,"nsumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictionary will be used for all future compression jobs.; To return to ""no-dictionary"" situation, load a NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all next compression jobs.; Note that compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Add",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:57152,Performance,latency,latency,57152,"Ctx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictionary will be used for all future compression jobs.; To return to ""no-dictionary"" situation, load a NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all next compression jobs.; Note that compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:58579,Performance,perform,performing,58579," compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just referenced, its lifetime must outlive CCtx. . size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By defaul",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:58622,Performance,perform,performs,58622," compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just referenced, its lifetime must outlive CCtx. . size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By defaul",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:59512,Performance,latency,latency,59512,"d same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing compression job and start a new one.; Any internal data not yet flushed is cancelled.; The parameters and dictionary are kept unchanged, to reset them use ZSTD_CCtx_resetParameters().; . size_t ZSTD_CCtx_resetParameters(ZSTD_CCtx* cctx);; All parameters are back to default values (compression level is ZSTD_CLEVEL_DEFAULT).; Dictionary (if any) is dropped.; Resetting parameters is only possible during frame initialization (before starting compression).; To reset the context use ZSTD_CCtx_reset().; @return 0 or an error code (which can be checked with ZSTD_isError()).; . typedef enum {; ZSTD_e_continue=0, /* co",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:59585,Performance,load,loadDictionary,59585," in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing compression job and start a new one.; Any internal data not yet flushed is cancelled.; The parameters and dictionary are kept unchanged, to reset them use ZSTD_CCtx_resetParameters().; . size_t ZSTD_CCtx_resetParameters(ZSTD_CCtx* cctx);; All parameters are back to default values (compression level is ZSTD_CLEVEL_DEFAULT).; Dictionary (if any) is dropped.; Resetting parameters is only possible during frame initialization (before starting compression).; To reset the context use ZSTD_CCtx_reset().; @return 0 or an error code (which can be checked with ZSTD_isError()).; . typedef enum {; ZSTD_e_continue=0, /* collect more data, encoder decides when to output compressed result, for optimal c",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:61700,Performance,multi-thread,multi-thread,61700," improving compression. */; ZSTD_e_end /* flush any remaining data and close current frame.; * any additional data starts a new frame.; * each frame is independent (does not reference any content from previous frame). */; } ZSTD_EndDirective;. size_t ZSTD_compress_generic (ZSTD_CCtx* cctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input,; ZSTD_EndDirective endOp);; Behave about the same as ZSTD_compressStream. To note :; - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_setParameter(); - Compression parameters cannot be changed once compression is started.; - outpot->pos must be <= dstCapacity, input->pos must be <= srcSize; - outpot->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.; - In single-thread mode (default), function is blocking : it completed its job before returning to caller.; - In multi-thread mode, function is non-blocking : it just acquires a copy of input, and distribute job to internal worker threads,; and then immediately returns, just indicating that there is some data remaining to be flushed.; The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.; - Exception : in multi-threading mode, if the first call requests a ZSTD_e_end directive, it is blocking : it will complete compression before giving back control to caller.; - @return provides a minimum amount of data remaining to be flushed from internal buffers; or an error code, which can be tested using ZSTD_isError().; if @return != 0, flush is not fully completed, there is still some data left within internal buffers.; This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.; For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.; - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),; only ZSTD_e_end or ZSTD_e_flush operations are allo",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:62059,Performance,multi-thread,multi-threading,62059,"D_inBuffer* input,; ZSTD_EndDirective endOp);; Behave about the same as ZSTD_compressStream. To note :; - Compression parameters are pushed into CCtx before starting compression, using ZSTD_CCtx_setParameter(); - Compression parameters cannot be changed once compression is started.; - outpot->pos must be <= dstCapacity, input->pos must be <= srcSize; - outpot->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.; - In single-thread mode (default), function is blocking : it completed its job before returning to caller.; - In multi-thread mode, function is non-blocking : it just acquires a copy of input, and distribute job to internal worker threads,; and then immediately returns, just indicating that there is some data remaining to be flushed.; The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.; - Exception : in multi-threading mode, if the first call requests a ZSTD_e_end directive, it is blocking : it will complete compression before giving back control to caller.; - @return provides a minimum amount of data remaining to be flushed from internal buffers; or an error code, which can be tested using ZSTD_isError().; if @return != 0, flush is not fully completed, there is still some data left within internal buffers.; This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.; For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.; - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),; only ZSTD_e_end or ZSTD_e_flush operations are allowed.; Before starting a new compression job, or changing compression parameters,; it is required to fully flush internal buffers.; . size_t ZSTD_compress_generic_simpleArgs (; ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos,; ZSTD_EndDirective endOp);; S",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:66902,Performance,latency,latency,66902," overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; Note 2 : Loading a dictionary involves building tables,; which has a non-negligible impact on CPU usage and latency.; Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to select; how dictionary content will be interpreted and loaded.; . size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);; Reference a prepared dictionary, to be used to decompress next frames.; The dictionary remains active for decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""discards"" any previous one.; Special : adding a NULL DDict means ""return to no-dictionary mode"".; Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.; . size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:67019,Performance,load,loaded,67019,"tx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; Note 2 : Loading a dictionary involves building tables,; which has a non-negligible impact on CPU usage and latency.; Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to select; how dictionary content will be interpreted and loaded.; . size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);; Reference a prepared dictionary, to be used to decompress next frames.; The dictionary remains active for decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""discards"" any previous one.; Special : adding a NULL DDict means ""return to no-dictionary mode"".; Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.; . size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; This is the reverse operation of ZSTD_CCtx_refPrefix(),; and mu",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:17727,Safety,detect,detection,17727,"fast, ZSTD_greedy, ZSTD_lazy, ZSTD_lazy2,; ZSTD_btlazy2, ZSTD_btopt, ZSTD_btultra } ZSTD_strategy; /* from faster to stronger */. typedef struct {; unsigned windowLog; /**< largest match distance : larger == more compression, more memory needed during decompression */; unsigned chainLog; /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */; unsigned hashLog; /**< dispatch table : larger == faster, more memory */; unsigned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:36267,Safety,recover,recover,36267,"g operations.; Use ZSTD_createCCtx() / ZSTD_freeCCtx() to manage resource.; ZSTD_CCtx object can be re-used multiple times within successive compression operations. Start by initializing a context.; Use ZSTD_compressBegin(), or ZSTD_compressBegin_usingDict() for dictionary compression,; or ZSTD_compressBegin_advanced(), for finer parameter control.; It's also possible to duplicate a reference context which has already been initialized, using ZSTD_copyCCtx(). Then, consume your input using ZSTD_compressContinue().; There are some important considerations to keep in mind when using this advanced function :; - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.; - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.; - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.; Worst case evaluation is provided by ZSTD_compressBound().; ZSTD_compressContinue() doesn't guarantee recover after a failed compression.; - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).; It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks); - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.; In which case, it will ""discard"" the relevant memory section from its history. Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.; It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.; Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders. `ZSTD_CCtx` object can be re-used (ZSTD_compressBegin()) to compress again. Buffer-less streaming compression functionssize_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);; size_t ZSTD_compressB",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:36603,Safety,detect,detects,36603,"D_compressBegin_advanced(), for finer parameter control.; It's also possible to duplicate a reference context which has already been initialized, using ZSTD_copyCCtx(). Then, consume your input using ZSTD_compressContinue().; There are some important considerations to keep in mind when using this advanced function :; - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.; - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.; - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.; Worst case evaluation is provided by ZSTD_compressBound().; ZSTD_compressContinue() doesn't guarantee recover after a failed compression.; - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).; It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks); - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.; In which case, it will ""discard"" the relevant memory section from its history. Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.; It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.; Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders. `ZSTD_CCtx` object can be re-used (ZSTD_compressBegin()) to compress again. Buffer-less streaming compression functionssize_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);; size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel);; size_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize : If srcSize is not known at init ti",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:44549,Safety,detect,detection,44549,", `zfhPtr` is correctly filled,; * >0, `srcSize` is too small, value is wanted `srcSize` amount,; * or an error code, which can be tested using ZSTD_isError() */; size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize); /**< doesn't consume input */; size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize); /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */. typedef enum { ZSTDnit_frameHeader, ZSTDnit_blockHeader, ZSTDnit_block, ZSTDnit_lastBlock, ZSTDnit_checksum, ZSTDnit_skippableFrame } ZSTD_nextInputType_e;. New advanced API (experimental); typedef enum {; /* Opened question : should we have a format ZSTD_f_auto ?; * Today, it would mean exactly the same as ZSTD_f_zstd1.; * But, in the future, should several formats become supported,; * on the compression side, it would mean ""default format"".; * On the decompression side, it would mean ""automatic format detection"",; * so that ZSTD_f_zstd1 would mean ""accept *only* zstd frames"".; * Since meaning is a little different, another option could be to define different enums for compression and decompression.; * This question could be kept for later, when there are actually multiple formats to support,; * but there is also the question of pinning enum values, and pinning value `0` is especially important */; ZSTD_f_zstd1 = 0, /* zstd frame format, specified in zstd_compression_format.md (default) */; ZSTD_f_zstd1_magicless, /* Variant of zstd frame format, without initial 4-bytes magic number.; * Useful to save 4 bytes per generated frame.; * Decoder cannot recognise automatically this format, requiring instructions. */; } ZSTD_format_e;. typedef enum {; /* Note: this enum and the behavior it controls are effectively internal; * implementation details of the compressor. They are expected to continue; * to evolve and should be considered only in the context of extremely; * advanced performance tuning",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:1799,Security,access,accessed,1799," zstd compression library provides in-memory compression and decompression; functions. The library supports regular compression levels from 1 up to ZSTD_maxCLevel(),; which is currently 22. Levels >= 20, labeled `--ultra`, should be used with; caution, as they require more memory. The library also offers negative; compression levels, which extend the range of speed vs. ratio preferences.; The lower the level, the faster the speed (at the cost of compression). Compression can be done in:; - a single step (described as Simple API); - a single step, reusing a context (described as Explicit context); - unbounded multiple steps (described as Streaming compression). The compression ratio achievable on small data can be highly improved using; a dictionary. Dictionary compression can be performed in:; - a single step (described as Simple dictionary API); - a single step, reusing a dictionary (described as Bulk-processing; dictionary API). Advanced experimental functions can be accessed using; `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h. Advanced experimental APIs should never be used with a dynamically-linked; library. They are not ""stable""; their definitions or signatures may change in; the future. Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapaci",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:4773,Security,authoriz,authorized,4773,"2 : decompressed size is an optional field, it may not be present, typically in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; Optionally, application can rely on some implicit limit,; as ZSTD_decompress() only needs an upper bound of decompressed size.; (For example, data could be necessarily cut into blocks <= 16 KB).; note 3 : decompressed size is always present when compression is completed using single-pass functions,; such as ZSTD_compress(), ZSTD_compressCCtx() ZSTD_compress_usingDict() or ZSTD_compress_usingCDict().; note 4 : decompressed size can be very large (64-bits value),; potentially larger than what local system can handle as a single memory segment.; In which case, it's necessary to use streaming mode to decompress data.; note 5 : If source is untrusted, decompressed size could be wrong or intentionally modified.; Always ensure return value fits within application's authorized limits.; Each application can set its own limits.; note 6 : This function replaces ZSTD_getDecompressedSize() . unsigned long long ZSTD_getDecompressedSize(const void* src, size_t srcSize);; NOTE: This function is now obsolete, in favor of ZSTD_getFrameContentSize().; Both functions work the same way, but ZSTD_getDecompressedSize() blends; ""empty"", ""unknown"" and ""error"" results to the same return value (0),; while ZSTD_getFrameContentSize() gives them separate return values.; @return : decompressed size of `src` frame content _if known and not empty_, 0 otherwise. . Helper functions#define ZSTD_COMPRESSBOUND(srcSize) ((srcSize) + ((srcSize)>>8) + (((srcSize) < (128<<10)) ? (((128<<10) - (srcSize)) >> 11) /* margin, from 64 to 0 */ : 0)) /* this formula ensures that bound(A) + bound(B) <= bound(A+B) as long as A and B >= 128 KB */; size_t ZSTD_compressBound(size_t srcSize); /*!< maximum compressed size in worst case single-pass scenario */; unsigned ZSTD_isE",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:9282,Security,checksum,checksum,9282,"nded to load it just once.; ZSTD_createCDict() will create a digested dictionary, ready to start future compression operations without startup delay.; ZSTD_CDict can be created once and shared by multiple threads concurrently, since its usage is read-only.; `dictBuffer` can be released after ZSTD_CDict creation, since its content is copied within CDict; Note : A ZSTD_CDict can be created with an empty dictionary, but it is inefficient for small data. . size_t ZSTD_freeCDict(ZSTD_CDict* CDict);; Function frees memory allocated by ZSTD_createCDict(). . size_t ZSTD_compress_usingCDict(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict);; Compression using a digested Dictionary.; Faster startup than ZSTD_compress_usingDict(), recommended when same dictionary is used multiple times.; Note that compression level is decided during dictionary creation.; Frame parameters are hardcoded (dictID=yes, contentSize=yes, checksum=no); Note : ZSTD_compress_usingCDict() can be used with a ZSTD_CDict created from an empty dictionary.; But it is inefficient for small data, and it is recommended to use ZSTD_compressCCtx(). . ZSTD_DDict* ZSTD_createDDict(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; dictBuffer can be released after DDict creation, as its content is copied inside DDict . size_t ZSTD_freeDDict(ZSTD_DDict* ddict);; Function frees memory allocated with ZSTD_createDDict() . size_t ZSTD_decompress_usingDDict(ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_DDict* ddict);; Decompression using a digested Dictionary.; Faster startup than ZSTD_decompress_usingDict(), recommended when same dictionary is used multiple times. . Streaming; typedef struct ZSTD_inBuffer_s {; const void* src; /**< start of input buffer */; size_t size; /**< size of input buffer */; size_t pos; /**< position where r",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:17101,Security,hash,hashLog,17101,"recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */. ADVANCED AND EXPERIMENTAL FUNCTIONS; The definitions in this section are considered experimental.; They should never be used with a dynamic library, as prototypes may change in the future.; They are provided for advanced scenarios.; Use them only in association with static linking.; . int ZSTD_minCLevel(void); /*!< minimum negative compression level allowed */. typedef enum { ZSTD_fast=1, ZSTD_dfast, ZSTD_greedy, ZSTD_lazy, ZSTD_lazy2,; ZSTD_btlazy2, ZSTD_btopt, ZSTD_btultra } ZSTD_strategy; /* from faster to stronger */. typedef struct {; unsigned windowLog; /**< largest match distance : larger == more compression, more memory needed during decompression */; unsigned chainLog; /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */; unsigned hashLog; /**< dispatch table : larger == faster, more memory */; unsigned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawConten",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:17650,Security,checksum,checksumFlag,17650,"fast, ZSTD_greedy, ZSTD_lazy, ZSTD_lazy2,; ZSTD_btlazy2, ZSTD_btopt, ZSTD_btultra } ZSTD_strategy; /* from faster to stronger */. typedef struct {; unsigned windowLog; /**< largest match distance : larger == more compression, more memory needed during decompression */; unsigned chainLog; /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */; unsigned hashLog; /**< dispatch table : larger == faster, more memory */; unsigned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:17691,Security,checksum,checksum,17691,"fast, ZSTD_greedy, ZSTD_lazy, ZSTD_lazy2,; ZSTD_btlazy2, ZSTD_btopt, ZSTD_btultra } ZSTD_strategy; /* from faster to stronger */. typedef struct {; unsigned windowLog; /**< largest match distance : larger == more compression, more memory needed during decompression */; unsigned chainLog; /**< fully searched segment : larger == more compression, slower, more memory (useless for fast) */; unsigned hashLog; /**< dispatch table : larger == faster, more memory */; unsigned searchLog; /**< nb of searches : larger == more compression, slower */; unsigned searchLength; /**< match length searched : larger == faster decompression, sometimes less compression */; unsigned targetLength; /**< acceptable match size for optimal parser (only) : larger == more compression, slower */; ZSTD_strategy strategy;; } ZSTD_compressionParameters;. typedef struct {; unsigned contentSizeFlag; /**< 1: content size will be in frame header (when known) */; unsigned checksumFlag; /**< 1: generate a 32-bits checksum at end of frame, for error detection */; unsigned noDictIDFlag; /**< 1: no dictID will be saved into frame header (if dictionary compression) */; } ZSTD_frameParameters;. typedef struct {; ZSTD_compressionParameters cParams;; ZSTD_frameParameters fParams;; } ZSTD_parameters;. typedef enum {; ZSTD_dct_auto = 0, /* dictionary is ""full"" when starting with ZSTD_MAGIC_DICTIONARY, otherwise it is ""rawContent"" */; ZSTD_dct_rawContent, /* ensures dictionary is always loaded as rawContent, even if it starts with ZSTD_MAGIC_DICTIONARY */; ZSTD_dct_fullDict /* refuses to load a dictionary if it does not respect Zstandard's specification */; } ZSTD_dictContentType_e;. typedef enum {; ZSTD_dlm_byCopy = 0, /**< Copy dictionary content internally */; ZSTD_dlm_byRef, /**< Reference dictionary content -- the dictionary buffer must outlive its users. */; } ZSTD_dictLoadMethod_e;. Frame size functions; size_t ZSTD_findFrameCompressedSize(const void* src, size_t srcSize);; `src` should point to the start of",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:20135,Security,authoriz,authorized,20135,"be the _exact_ size of this series; (i.e. there should be a frame boundary exactly at `srcSize` bytes after `src`); @return : - decompressed size of all data in all successive frames; - if the decompressed size cannot be determined: ZSTD_CONTENTSIZE_UNKNOWN; - if an error occurred: ZSTD_CONTENTSIZE_ERROR. note 1 : decompressed size is an optional field, that may not be present, especially in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; note 2 : decompressed size is always present when compression is done with ZSTD_compress(); note 3 : decompressed size can be very large (64-bits value),; potentially larger than what local system can handle as a single memory segment.; In which case, it's necessary to use streaming mode to decompress data.; note 4 : If source is untrusted, decompressed size could be wrong or intentionally modified.; Always ensure result fits within application's authorized limits.; Each application can set its own limits.; note 5 : ZSTD_findDecompressedSize handles multiple frames, and so it must traverse the input to; read each contained frame header. This is fast as most of the data is skipped,; however it does mean that all frame data must be present and valid. . size_t ZSTD_frameHeaderSize(const void* src, size_t srcSize);; srcSize must be >= ZSTD_frameHeaderSize_prefix.; @return : size of the Frame Header,; or an error code (if srcSize is too small) . Memory management; size_t ZSTD_sizeof_CCtx(const ZSTD_CCtx* cctx);; size_t ZSTD_sizeof_DCtx(const ZSTD_DCtx* dctx);; size_t ZSTD_sizeof_CStream(const ZSTD_CStream* zcs);; size_t ZSTD_sizeof_DStream(const ZSTD_DStream* zds);; size_t ZSTD_sizeof_CDict(const ZSTD_CDict* cdict);; size_t ZSTD_sizeof_DDict(const ZSTD_DDict* ddict);; These functions give the current memory usage of selected object.; Object memory usage can evolve when re-used. . size_t ZSTD_estimateCCtxSize(int compr",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:26758,Security,access,accessible,26758,"< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; typedef void (*ZSTD_freeFunction) (void* opaque, void* address);; typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;; static ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL }; /**< this constant defers to stdlib's functions */; These prototypes make it possible to pass your own allocation/free functions.; ZSTD_customMem is provided at creation time, using ZSTD_create*_advanced() variants listed below.; All allocation/free operations will be completed using these custom variants instead of regular ones.; . Advanced compression functions; ZSTD_CDict* ZSTD_createCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionLevel);; Create a digested dictionary for compression; Dictionary content is simply referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives CDict, it must remain read accessible throughout the lifetime of CDict . ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.; `estimatedSrcSize` value is optional, select 0 if not known . ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);; optimize params for a given `srcSize` and `dictSize`.; both values are optional, s",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:27398,Security,checksum,checksum,27398," using these custom variants instead of regular ones.; . Advanced compression functions; ZSTD_CDict* ZSTD_createCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionLevel);; Create a digested dictionary for compression; Dictionary content is simply referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives CDict, it must remain read accessible throughout the lifetime of CDict . ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.; `estimatedSrcSize` value is optional, select 0 if not known . ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);; optimize params for a given `srcSize` and `dictSize`.; both values are optional, select `0` if unknown. . size_t ZSTD_compress_advanced (ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; ZSTD_parameters params);; Same as ZSTD_compress_usingDict(), with fine-tune control over each compression parameter . size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict, ZSTD_frameParameters fParams);; Same as ZSTD_compress_usingCDict(), with fine-tune control over frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* bu",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:27519,Security,authoriz,authorized,27519,"reateCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionLevel);; Create a digested dictionary for compression; Dictionary content is simply referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives CDict, it must remain read accessible throughout the lifetime of CDict . ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.; `estimatedSrcSize` value is optional, select 0 if not known . ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionParameters ZSTD_adjustCParams(ZSTD_compressionParameters cPar, unsigned long long srcSize, size_t dictSize);; optimize params for a given `srcSize` and `dictSize`.; both values are optional, select `0` if unknown. . size_t ZSTD_compress_advanced (ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const void* dict,size_t dictSize,; ZSTD_parameters params);; Same as ZSTD_compress_usingDict(), with fine-tune control over each compression parameter . size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict, ZSTD_frameParameters fParams);; Same as ZSTD_compress_usingCDict(), with fine-tune control over frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* buffer, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame I",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:29012,Security,access,accessible,29012,"trol over each compression parameter . size_t ZSTD_compress_usingCDict_advanced(ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; const ZSTD_CDict* cdict, ZSTD_frameParameters fParams);; Same as ZSTD_compress_usingCDict(), with fine-tune control over frame parameters . Advanced decompression functions; unsigned ZSTD_isFrame(const void* buffer, size_t size);; Tells if the content of `buffer` starts with a valid Frame Identifier.; Note : Frame Identifier is 4 bytes. If `size < 4`, @return will always be 0.; Note 2 : Legacy Frame Identifiers are considered valid only if Legacy Support is enabled.; Note 3 : Skippable Frame Identifiers are considered valid. . ZSTD_DDict* ZSTD_createDDict_byReference(const void* dictBuffer, size_t dictSize);; Create a digested dictionary, ready to start decompression operation without startup delay.; Dictionary content is referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives DDict,; it must remain read accessible throughout the lifetime of DDict . unsigned ZSTD_getDictID_fromDict(const void* dict, size_t dictSize);; Provides the dictID stored within dictionary.; if @return == 0, the dictionary is not conformant with Zstandard specification.; It can still be loaded, but as a content-only dictionary. . unsigned ZSTD_getDictID_fromDDict(const ZSTD_DDict* ddict);; Provides the dictID of the dictionary loaded into `ddict`.; If @return == 0, the dictionary is not conformant to Zstandard specification, or empty.; Non-conformant dictionaries can still be loaded, but as content-only dictionaries. . unsigned ZSTD_getDictID_fromFrame(const void* src, size_t srcSize);; Provides the dictID required to decompressed the frame stored within `src`.; If @return == 0, the dictID could not be decoded.; This could for one of the following reasons :; - The frame does not require a dictionary to be decoded (most common case).; - The frame was built with dictID intentionally removed. Whatever d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:36363,Security,access,accessible,36363," multiple times within successive compression operations. Start by initializing a context.; Use ZSTD_compressBegin(), or ZSTD_compressBegin_usingDict() for dictionary compression,; or ZSTD_compressBegin_advanced(), for finer parameter control.; It's also possible to duplicate a reference context which has already been initialized, using ZSTD_copyCCtx(). Then, consume your input using ZSTD_compressContinue().; There are some important considerations to keep in mind when using this advanced function :; - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.; - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.; - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.; Worst case evaluation is provided by ZSTD_compressBound().; ZSTD_compressContinue() doesn't guarantee recover after a failed compression.; - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).; It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks); - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.; In which case, it will ""discard"" the relevant memory section from its history. Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.; It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.; Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders. `ZSTD_CCtx` object can be re-used (ZSTD_compressBegin()) to compress again. Buffer-less streaming compression functionssize_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);; size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel);; size_t ZSTD_comp",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:36845,Security,checksum,checksum,36845,"t considerations to keep in mind when using this advanced function :; - ZSTD_compressContinue() has no internal buffer. It uses externally provided buffers only.; - Interface is synchronous : input is consumed entirely and produces 1+ compressed blocks.; - Caller must ensure there is enough space in `dst` to store compressed data under worst case scenario.; Worst case evaluation is provided by ZSTD_compressBound().; ZSTD_compressContinue() doesn't guarantee recover after a failed compression.; - ZSTD_compressContinue() presumes prior input ***is still accessible and unmodified*** (up to maximum distance size, see WindowLog).; It remembers all previous contiguous blocks, plus one separated memory segment (which can itself consists of multiple contiguous blocks); - ZSTD_compressContinue() detects that prior input has been overwritten when `src` buffer overlaps.; In which case, it will ""discard"" the relevant memory section from its history. Finish a frame with ZSTD_compressEnd(), which will write the last block(s) and optional checksum.; It's possible to use srcSize==0, in which case, it will write a final empty block to end the frame.; Without last block mark, frames are considered unfinished (hence corrupted) by compliant decoders. `ZSTD_CCtx` object can be re-used (ZSTD_compressBegin()) to compress again. Buffer-less streaming compression functionssize_t ZSTD_compressBegin(ZSTD_CCtx* cctx, int compressionLevel);; size_t ZSTD_compressBegin_usingDict(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, int compressionLevel);; size_t ZSTD_compressBegin_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_parameters params, unsigned long long pledgedSrcSize); /**< pledgedSrcSize : If srcSize is not known at init time, use ZSTD_CONTENTSIZE_UNKNOWN */; size_t ZSTD_compressBegin_usingCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict); /**< note: fails if cdict==NULL */; size_t ZSTD_compressBegin_usingCDict_advanced(ZSTD_CCtx* const cctx, const ZSTD_CDict* const cd",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:43423,Security,checksum,checksumFlag,43423,"ow of concatenated frames.; Skippable frames will be ignored (skipped) by decompressor.; The format of skippable frames is as follows :; a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F; b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits; c) Frame Content - any content (User Data) of length equal to Frame Size; For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buffer-less streaming decompression functionstypedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_frameType_e;; typedef struct {; unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means ""empty"" */; unsigned long long windowSize; /* can be very large, up to <= frameContentSize */; unsigned blockSizeMax;; ZSTD_frameType_e frameType; /* if == ZSTD_skippableFrame, frameContentSize is the size of skippable content */; unsigned headerSize;; unsigned dictID;; unsigned checksumFlag;; } ZSTD_frameHeader;; /** ZSTD_getFrameHeader() :; * decode Frame Header, or requires larger `srcSize`.; * @return : 0, `zfhPtr` is correctly filled,; * >0, `srcSize` is too small, value is wanted `srcSize` amount,; * or an error code, which can be tested using ZSTD_isError() */; size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize); /**< doesn't consume input */; size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize); /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */. typedef enum { ZSTDnit_frameHeader, ZSTDnit_blockHeader, ZSTDnit_block, ZSTDnit_lastBlock, ZSTDnit_checksum, ZSTDnit_skippableFrame } ZSTD_nextInputType_e;. New advanced API (experimental); typedef enum {; /* Opened question : should we have a format ZSTD_f_auto ?; * Today, it would mean exactly ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:48064,Security,hash,hashLog,48064,"lity. */. /* compression parameters */; ZSTD_p_compressionLevel=100, /* Update all compression parameters according to pre-defined cLevel table; * Default level is ZSTD_CLEVEL_DEFAULT==3.; * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.; * Note 1 : it's possible to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other compression parameters.; * Note 3 : setting compressionLevel automatically updates ZSTD_p_compressLiterals. */; ZSTD_p_windowLog, /* Maximum allowed back-reference distance, expressed as power of 2.; * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.; * Special: value 0 means ""use default windowLog"".; * Note: Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's still useful when using ""dfast"" strategy,; * in which case it defines a secondary probe table.; * Special: value 0 means ""use default chainLog"". */; ZSTD_p_searchLog, /* Number of search attempts, as a power of 2.; * More attempts result in better and slower compression.; * This parameter is useless when using ""fast"" and ""dFast"" strategies.; * Special: value 0 means ""use default searchLog"". */; ZSTD_p_minMatch, /* Minimum s",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:48293,Security,hash,hashLog,48293,"ich is controlled by ZSTD_CLEVEL_DEFAULT.; * Note 1 : it's possible to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other compression parameters.; * Note 3 : setting compressionLevel automatically updates ZSTD_p_compressLiterals. */; ZSTD_p_windowLog, /* Maximum allowed back-reference distance, expressed as power of 2.; * Must be clamped between ZSTD_WINDOWLOG_MIN and ZSTD_WINDOWLOG_MAX.; * Special: value 0 means ""use default windowLog"".; * Note: Using a window size greater than ZSTD_MAXWINDOWSIZE_DEFAULT (default: 2^27); * requires explicitly allowing such window size during decompression stage. */; ZSTD_p_hashLog, /* Size of the initial probe table, as a power of 2.; * Resulting table size is (1 << (hashLog+2)).; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX.; * Larger tables improve compression ratio of strategies <= dFast,; * and improve speed of strategies > dFast.; * Special: value 0 means ""use default hashLog"". */; ZSTD_p_chainLog, /* Size of the multi-probe search table, as a power of 2.; * Resulting table size is (1 << (chainLog+2)).; * Must be clamped between ZSTD_CHAINLOG_MIN and ZSTD_CHAINLOG_MAX.; * Larger tables result in better and slower compression.; * This parameter is useless when using ""fast"" strategy.; * Note it's still useful when using ""dfast"" strategy,; * in which case it defines a secondary probe table.; * Special: value 0 means ""use default chainLog"". */; ZSTD_p_searchLog, /* Number of search attempts, as a power of 2.; * More attempts result in better and slower compression.; * This parameter is useless when using ""fast"" and ""dFast"" strategies.; * Special: value 0 means ""use default searchLog"". */; ZSTD_p_minMatch, /* Minimum size of searched matches (note : repCode matches can be smaller).; * Larger values make faster compression and decompression, but decrease ratio.; * Must be clamped between ZSTD_SEARCHLENGTH_MIN and ZSTD_SEARCHLENGTH_MAX.; * N",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:50866,Security,hash,hashlog,50866,"th"". */; ZSTD_p_compressionStrategy, /* See ZSTD_strategy enum definition.; * Cast selected strategy as unsigned for ZSTD_CCtx_setParameter() compatibility.; * The higher the value of selected strategy, the more complex it is,; * resulting in stronger and slower compression.; * Special: value 0 means ""use default strategy"". */. ZSTD_p_enableLongDistanceMatching=160, /* Enable long distance matching.; * This parameter is designed to improve compression ratio; * for large inputs, by finding large matches at long distance.; * It increases memory usage and window size.; * Note: enabling this parameter increases ZSTD_p_windowLog to 128 MB; * except when expressly set to a different value. */; ZSTD_p_ldmHashLog, /* Size of the table for long distance matching, as a power of 2.; * Larger values increase memory usage and compression ratio,; * but decrease compression speed.; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX; * default: windowlog - 7.; * Special: value 0 means ""automatically determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 me",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:51216,Security,hash,hash,51216,"atching=160, /* Enable long distance matching.; * This parameter is designed to improve compression ratio; * for large inputs, by finding large matches at long distance.; * It increases memory usage and window size.; * Note: enabling this parameter increases ZSTD_p_windowLog to 128 MB; * except when expressly set to a different value. */; ZSTD_p_ldmHashLog, /* Size of the table for long distance matching, as a power of 2.; * Larger values increase memory usage and compression ratio,; * but decrease compression speed.; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX; * default: windowlog - 7.; * Special: value 0 means ""automatically determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content i",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:51528,Security,hash,hash,51528,"cept when expressly set to a different value. */; ZSTD_p_ldmHashLog, /* Size of the table for long distance matching, as a power of 2.; * Larger values increase memory usage and compression ratio,; * but decrease compression speed.; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX; * default: windowlog - 7.; * Special: value 0 means ""automatically determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error other",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:51673,Security,hash,hash,51673," memory usage and compression ratio,; * but decrease compression speed.; * Must be clamped between ZSTD_HASHLOG_MIN and ZSTD_HASHLOG_MAX; * default: windowlog - 7.; * Special: value 0 means ""automatically determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:51874,Security,hash,hashEveryLog,51874," determine hashlog"". */; ZSTD_p_ldmMinMatch, /* Minimum match size for long distance matcher.; * Larger/too small values usually decrease compression ratio.; * Must be clamped between ZSTD_LDM_MINMATCH_MIN and ZSTD_LDM_MINMATCH_MAX.; * Special: value 0 means ""use default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:52179,Security,checksum,checksum,52179,"se default value"" (default: 64). */; ZSTD_p_ldmBucketSizeLog, /* Log size of each bucket in the LDM hash table for collision resolution.; * Larger values improve collision resolution but decrease compression speed.; * The maximum value is ZSTD_LDM_BUCKETSIZELOG_MAX .; * Special: value 0 means ""use default value"" (default: 3). */; ZSTD_p_ldmHashEveryLog, /* Frequency of inserting/looking up entries in the LDM hash table.; * Must be clamped between 0 and (ZSTD_WINDOWLOG_MAX - ZSTD_HASHLOG_MIN).; * Default is MAX(0, (windowLog - ldmHashLog)), optimizing hash table usage.; * Larger values improve compression speed.; * Deviating far from default value will likely result in a compression ratio decrease.; * Special: value 0 means ""automatically determine hashEveryLog"". */. /* frame parameters */; ZSTD_p_contentSizeFlag=200, /* Content size will be written into frame header _whenever known_ (default:1); * Content size must be known at the beginning of compression,; * it is provided using ZSTD_CCtx_setPledgedSrcSize() */; ZSTD_p_checksumFlag, /* A 32-bits checksum of content is written at end of frame (default:0) */; ZSTD_p_dictIDFlag, /* When applicable, dictionary's ID is written into frame header (default:1) */. /* multi-threading parameters */; /* These parameters are only useful if multi-threading is enabled (ZSTD_MULTITHREAD).; * They return an error otherwise. */; ZSTD_p_nbWorkers=400, /* Select how many threads will be spawned to compress in parallel.; * When nbWorkers >= 1, triggers asynchronous mode :; * ZSTD_compress_generic() consumes some input, flush some output if possible, and immediately gives back control to caller,; * while compression work is performed in parallel, within worker threads.; * (note : a strong exception to this rule is when first invocation sets ZSTD_e_end : it becomes a blocking call).; * More workers improve speed, but also increase memory usage.; * Default value is `0`, aka ""single-threaded mode"" : no worker is spawned, compression is perf",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:54876,Security,hash,hashLog,54876,"====================================== */; /* experimental parameters - no stability guaranteed */; /* =================================================================== */. ZSTD_p_forceMaxWindow=1100, /* Force back-reference distances to remain < windowSize,; * even when referencing into Dictionary content (default:0) */; ZSTD_p_forceAttachDict, /* Controls whether the contents of a CDict are; * used in place, or whether they are copied into; * the working context.; *; * Accepts values from the ZSTD_dictAttachPref_e; * enum. See the comments on that enum for an; * explanation of the feature.; */; } ZSTD_cParameter;. size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:69068,Security,attack,attack,69068," Prefix is **only used once**. Reference is discarded at end of frame.; End of frame is reached when ZSTD_DCtx_decompress_generic() returns 0.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary; Note 2 : Prefix buffer is referenced. It **must** outlive decompression job.; Prefix buffer must remain unmodified up to the end of frame,; reached when ZSTD_DCtx_decompress_generic() returns 0.; Note 3 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:2577,Testability,test,tested,2577,"e highly improved using; a dictionary. Dictionary compression can be performed in:; - a single step (described as Simple dictionary API); - a single step, reusing a dictionary (described as Bulk-processing; dictionary API). Advanced experimental functions can be accessed using; `#define ZSTD_STATIC_LINKING_ONLY` before including zstd.h. Advanced experimental APIs should never be used with a dynamically-linked; library. They are not ""stable""; their definitions or signatures may change in; the future. Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapacity` is an upper bound of originalSize to regenerate.; If user cannot imply a maximum upper bound, it's better to use streaming mode to decompress data.; @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),; or an errorCode if it fails (which can be tested using ZSTD_isError()). . #define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1); #define ZSTD_CONTENTSIZE_ERROR (0ULL - 2); unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame.; `srcSize` must be at least as large as the frame header.; hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.; @return : - decompressed size of `src` frame content, if known; - ZSTD_C",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:3086,Testability,test,tested,3086,"Only static linking is allowed. Version; unsigned ZSTD_versionNumber(void); /**< useful to check dll version */. Default constant; Simple API; size_t ZSTD_compress( void* dst, size_t dstCapacity,; const void* src, size_t srcSize,; int compressionLevel);; Compresses `src` content as a single zstd compressed frame into already allocated `dst`.; Hint : compression runs faster if `dstCapacity` >= `ZSTD_compressBound(srcSize)`.; @return : compressed size written into `dst` (<= `dstCapacity),; or an error code if it fails (which can be tested using ZSTD_isError()). . size_t ZSTD_decompress( void* dst, size_t dstCapacity,; const void* src, size_t compressedSize);; `compressedSize` : must be the _exact_ size of some number of compressed and/or skippable frames.; `dstCapacity` is an upper bound of originalSize to regenerate.; If user cannot imply a maximum upper bound, it's better to use streaming mode to decompress data.; @return : the number of bytes decompressed into `dst` (<= `dstCapacity`),; or an errorCode if it fails (which can be tested using ZSTD_isError()). . #define ZSTD_CONTENTSIZE_UNKNOWN (0ULL - 1); #define ZSTD_CONTENTSIZE_ERROR (0ULL - 2); unsigned long long ZSTD_getFrameContentSize(const void *src, size_t srcSize);; `src` should point to the start of a ZSTD encoded frame.; `srcSize` must be at least as large as the frame header.; hint : any size >= `ZSTD_frameHeaderSize_max` is large enough.; @return : - decompressed size of `src` frame content, if known; - ZSTD_CONTENTSIZE_UNKNOWN if the size cannot be determined; - ZSTD_CONTENTSIZE_ERROR if an error occurred (e.g. invalid magic number, srcSize too small); note 1 : a 0 return value means the frame is valid but ""empty"".; note 2 : decompressed size is an optional field, it may not be present, typically in streaming mode.; When `return==ZSTD_CONTENTSIZE_UNKNOWN`, data to decompress could be any size.; In which case, it's necessary to use streaming mode to decompress data.; Optionally, application can rely on s",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12109,Testability,test,tested,12109,"re-using already allocated memory.; Use one separate ZSTD_CStream per thread for parallel execution. Start a new compression by initializing ZSTD_CStream context.; Use ZSTD_initCStream() to start a new compression operation.; Use variants ZSTD_initCStream_usingDict() or ZSTD_initCStream_usingCDict() for streaming with dictionary (experimental section). Use ZSTD_compressStream() as many times as necessary to consume input stream.; The function will automatically update both `pos` fields within `input` and `output`.; Note that the function may not consume the entire input,; for example, because the output buffer is already full,; in which case `input.pos < input.size`.; The caller must check if input has been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush()",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:12860,Testability,test,tested,12860,"been entirely consumed.; If not, the caller must make some room to receive more compressed data,; typically by emptying output buffer, or allocating a new output buffer,; and then present again remaining input data.; @return : a size hint, preferred nb of bytes to use as input for next function call; or an error code, which can be tested using ZSTD_isError().; Note 1 : it's just a hint, to help latency a little, any other value will work fine.; Note 2 : size hint is guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and fully flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now effectively same object (>= v1.3.0) */. ZSTD_CStream management functionsZSTD_CStream* ZSTD_createCStream(void);; size_t ZSTD_freeCStream(ZSTD_CStream* zcs);. Streaming compression functionssize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; siz",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:13330,Testability,test,tested,13330,"s guaranteed to be <= ZSTD_CStreamInSize(). At any moment, it's possible to flush whatever data might remain stuck within internal buffer,; using ZSTD_flushStream(). `output->pos` will be updated.; Note that, if `output->size` is too small, a single invocation of ZSTD_flushStream() might not be enough (return code > 0).; In which case, make some room to receive more compressed data, and call again ZSTD_flushStream().; @return : 0 if internal buffers are entirely flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). ZSTD_endStream() instructs to finish a frame.; It will perform a flush and write frame epilogue.; The epilogue is required for decoders to consider a frame completed.; flush() operation is the same, and follows same rules as ZSTD_flushStream().; @return : 0 if frame fully completed and fully flushed,; >0 if some data still present within internal buffer (the value is minimal estimation of remaining size),; or an error code, which can be tested using ZSTD_isError(). . typedef ZSTD_CCtx ZSTD_CStream; /**< CCtx and CStream are now effectively same object (>= v1.3.0) */. ZSTD_CStream management functionsZSTD_CStream* ZSTD_createCStream(void);; size_t ZSTD_freeCStream(ZSTD_CStream* zcs);. Streaming compression functionssize_t ZSTD_initCStream(ZSTD_CStream* zcs, int compressionLevel);; size_t ZSTD_compressStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output, ZSTD_inBuffer* input);; size_t ZSTD_flushStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);; size_t ZSTD_endStream(ZSTD_CStream* zcs, ZSTD_outBuffer* output);. size_t ZSTD_CStreamInSize(void); /**< recommended size for input buffer */. size_t ZSTD_CStreamOutSize(void); /**< recommended size for output buffer. Guarantee to successfully flush at least one complete compressed block in all circumstances. */. Streaming decompression - HowTo; A ZSTD_DStream object is required to track streaming op",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:15400,Testability,test,tested,15400,"f decompression requires a dictionary.; @return : recommended first input size. Use ZSTD_decompressStream() repetitively to consume your input.; The function will update both `pos` fields.; If `input.pos < input.size`, some input has not been consumed.; It's up to the caller to present again remaining data.; The function tries to flush all data decoded immediately, repecting buffer sizes.; If `output.pos < output.size`, decoder has flushed everything it could.; But if `output.pos == output.size`, there is no such guarantee,; it's likely that some decoded data was not flushed and still remains within internal buffers.; In which case, call ZSTD_decompressStream() again to flush whatever remains in the buffer.; When no additional input is provided, amount of data flushed is necessarily <= ZSTD_BLOCKSIZE_MAX.; @return : 0 when a frame is completely decoded and fully flushed,; or an error code, which can be tested using ZSTD_isError(),; or any other value > 0, which means there is still some decoding or flushing to do to complete current frame :; the return value is a suggested next input size (a hint for better latency); that will never load more than the current frame.; . typedef ZSTD_DCtx ZSTD_DStream; /**< DCtx and DStream are now effectively same object (>= v1.3.0) */. ZSTD_DStream management functionsZSTD_DStream* ZSTD_createDStream(void);; size_t ZSTD_freeDStream(ZSTD_DStream* zds);. Streaming decompression functionssize_t ZSTD_initDStream(ZSTD_DStream* zds);; size_t ZSTD_decompressStream(ZSTD_DStream* zds, ZSTD_outBuffer* output, ZSTD_inBuffer* input);. size_t ZSTD_DStreamInSize(void); /*!< recommended size for input buffer */. size_t ZSTD_DStreamOutSize(void); /*!< recommended size for output buffer. Guarantee to successfully flush at least one complete block in all circumstances. */. ADVANCED AND EXPERIMENTAL FUNCTIONS; The definitions in this section are considered experimental.; They should never be used with a dynamic library, as prototypes may change in the",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:24265,Testability,log,logically,24265,"am memory budget depends on window Size.; This information can be passed manually, using ZSTD_estimateDStreamSize,; or deducted from a valid frame Header, using ZSTD_estimateDStreamSize_fromFrame();; Note : if streaming is init with function ZSTD_init?Stream_usingDict(),; an internal ?Dict will be created, which additional size is not estimated here.; In this case, get total size by adding ZSTD_estimate?DictSize . size_t ZSTD_estimateCDictSize(size_t dictSize, int compressionLevel);; size_t ZSTD_estimateCDictSize_advanced(size_t dictSize, ZSTD_compressionParameters cParams, ZSTD_dictLoadMethod_e dictLoadMethod);; size_t ZSTD_estimateDDictSize(size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod);; ZSTD_estimateCDictSize() will bet that src size is relatively ""small"", and content is copied, like ZSTD_createCDict().; ZSTD_estimateCDictSize_advanced() makes it possible to control compression parameters precisely, like ZSTD_createCDict_advanced().; Note : dictionaries created by reference (`ZSTD_dlm_byRef`) are logically smaller.; . ZSTD_CCtx* ZSTD_initStaticCCtx(void* workspace, size_t workspaceSize);; ZSTD_CStream* ZSTD_initStaticCStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticCCtx() */; Initialize an object using a pre-allocated fixed-size buffer.; workspace: The memory area to emplace the object into.; Provided pointer *must be 8-bytes aligned*.; Buffer must outlive object.; workspaceSize: Use ZSTD_estimate*Size() to determine; how large workspace must be to support target scenario.; @return : pointer to object (same address as workspace, just different type),; or NULL if error (size too small, incorrect alignment, etc.); Note : zstd will never resize nor malloc() when using a static buffer.; If the object requires more memory than available,; zstd will just error out (typically ZSTD_error_memory_allocation).; Note 2 : there is no corresponding ""free"" function.; Since workspace is allocated externally, it must be freed externally too.; N",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:32850,Testability,test,tested,32850,"rams, unsigned long long pledgedSrcSize); /**< same as ZSTD_initCStream_usingCDict(), with control over frame parameters. pledgedSrcSize must be correct. If srcSize is not known at init time, use value ZSTD_CONTENTSIZE_UNKNOWN. */. size_t ZSTD_resetCStream(ZSTD_CStream* zcs, unsigned long long pledgedSrcSize);; start a new compression job, using same parameters from previous job.; This is typically useful to skip dictionary loading stage, since it will re-use it in-place.; Note that zcs must be init at least once before using ZSTD_resetCStream().; If pledgedSrcSize is not known at reset time, use macro ZSTD_CONTENTSIZE_UNKNOWN.; If pledgedSrcSize > 0, its value must be correct, as it will be written in header, and controlled at the end.; For the time being, pledgedSrcSize==0 is interpreted as ""srcSize unknown"" for compatibility with older programs,; but it will change to mean ""empty"" in future version, so use macro ZSTD_CONTENTSIZE_UNKNOWN instead.; @return : 0, or an error code (which can be tested using ZSTD_isError()); . typedef struct {; unsigned long long ingested; /* nb input bytes read and buffered */; unsigned long long consumed; /* nb input bytes actually compressed */; unsigned long long produced; /* nb of compressed bytes generated and buffered */; unsigned long long flushed; /* nb of compressed bytes flushed : not provided; can be tracked from caller side */; unsigned currentJobID; /* MT only : latest started job nb */; unsigned nbActiveWorkers; /* MT only : nb of workers actively compressing at probe time */; } ZSTD_frameProgression;. size_t ZSTD_toFlushNow(ZSTD_CCtx* cctx);; Tell how many bytes are ready to be flushed immediately.; Useful for multithreading scenarios (nbWorkers >= 1).; Probe the oldest active job, defined as oldest job not yet entirely flushed,; and check its output buffer.; @return : amount of data stored in oldest job and ready to be flushed immediately.; if @return == 0, it means either :; + there is no active job (could be checked w",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:38991,Testability,test,tested,38991,"t known, use macro ZSTD_CONTENTSIZE_UNKNOWN */; size_t ZSTD_copyCCtx(ZSTD_CCtx* cctx, const ZSTD_CCtx* preparedCCtx, unsigned long long pledgedSrcSize); /**< note: if pledgedSrcSize is not known, use ZSTD_CONTENTSIZE_UNKNOWN */. Buffer-less streaming decompression (synchronous mode); A ZSTD_DCtx object is required to track streaming operations.; Use ZSTD_createDCtx() / ZSTD_freeDCtx() to manage it.; A ZSTD_DCtx object can be re-used multiple times. First typical operation is to retrieve frame parameters, using ZSTD_getFrameHeader().; Frame header is extracted from the beginning of compressed frame, so providing only the frame's beginning is enough.; Data fragment must be large enough to ensure successful decoding.; `ZSTD_frameHeaderSize_max` bytes is guaranteed to always be large enough.; @result : 0 : successful decoding, the `ZSTD_frameHeader` structure is correctly filled.; >0 : `srcSize` is too small, please provide at least @result bytes on next attempt.; errorCode, which can be tested using ZSTD_isError(). It fills a ZSTD_frameHeader structure with important information to correctly decode the frame,; such as the dictionary ID, content size, or maximum back-reference distance (`windowSize`).; Note that these values could be wrong, either because of data corruption, or because a 3rd party deliberately spoofs false information.; As a consequence, check that values remain within valid application range.; For example, do not allocate memory blindly, check that `windowSize` is within expectation.; Each application can set its own limits, depending on local restrictions.; For extended interoperability, it is recommended to support `windowSize` of at least 8 MB. ZSTD_decompressContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:41907,Testability,test,tested,41907," of size `windowSize` each, though they consume more memory. Finally, if you control the compression process, you can also ignore all buffer size rules,; as long as the encoder and decoder progress in ""lock-step"",; aka use exactly the same buffer sizes, break contiguity at the same place, etc. Once buffers are setup, start decompression, with ZSTD_decompressBegin().; If decompression requires a dictionary, use ZSTD_decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict(). Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.; ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().; ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail. @result of ZSTD_decompressContinue() is the number of bytes regenerated within 'dst' (necessarily <= dstCapacity).; It can be zero : it just means ZSTD_decompressContinue() has decoded some metadata item.; It can also be an error code, which can be tested with ZSTD_isError(). A frame is fully decoded when ZSTD_nextSrcSizeToDecompress() returns zero.; Context can then be reset to start a new decompression. Note : it's possible to know if next input to present is a header or a block, using ZSTD_nextInputType().; This information is not required to properly decode a frame. == Special case : skippable frames . Skippable frames allow integration of user-defined data into a flow of concatenated frames.; Skippable frames will be ignored (skipped) by decompressor.; The format of skippable frames is as follows :; a) Skippable frame ID - 4 Bytes, Little endian format, any value from 0x184D2A50 to 0x184D2A5F; b) Frame Size - 4 Bytes, Little endian format, unsigned 32-bits; c) Frame Content - any content (User Data) of length equal to Frame Size; For skippable frames ZSTD_getFrameHeader() returns zfhPtr->frameType==ZSTD_skippableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buff",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:43686,Testability,test,tested,43686,"ableFrame.; For skippable frames ZSTD_decompressContinue() always returns 0 : it only skips the content. Buffer-less streaming decompression functionstypedef enum { ZSTD_frame, ZSTD_skippableFrame } ZSTD_frameType_e;; typedef struct {; unsigned long long frameContentSize; /* if == ZSTD_CONTENTSIZE_UNKNOWN, it means this field is not available. 0 means ""empty"" */; unsigned long long windowSize; /* can be very large, up to <= frameContentSize */; unsigned blockSizeMax;; ZSTD_frameType_e frameType; /* if == ZSTD_skippableFrame, frameContentSize is the size of skippable content */; unsigned headerSize;; unsigned dictID;; unsigned checksumFlag;; } ZSTD_frameHeader;; /** ZSTD_getFrameHeader() :; * decode Frame Header, or requires larger `srcSize`.; * @return : 0, `zfhPtr` is correctly filled,; * >0, `srcSize` is too small, value is wanted `srcSize` amount,; * or an error code, which can be tested using ZSTD_isError() */; size_t ZSTD_getFrameHeader(ZSTD_frameHeader* zfhPtr, const void* src, size_t srcSize); /**< doesn't consume input */; size_t ZSTD_decodingBufferSize_min(unsigned long long windowSize, unsigned long long frameContentSize); /**< when frame content size is not known, pass in frameContentSize == ZSTD_CONTENTSIZE_UNKNOWN */. typedef enum { ZSTDnit_frameHeader, ZSTDnit_blockHeader, ZSTDnit_block, ZSTDnit_lastBlock, ZSTDnit_checksum, ZSTDnit_skippableFrame } ZSTD_nextInputType_e;. New advanced API (experimental); typedef enum {; /* Opened question : should we have a format ZSTD_f_auto ?; * Today, it would mean exactly the same as ZSTD_f_zstd1.; * But, in the future, should several formats become supported,; * on the compression side, it would mean ""default format"".; * On the decompression side, it would mean ""automatic format detection"",; * so that ZSTD_f_zstd1 would mean ""accept *only* zstd frames"".; * Since meaning is a little different, another option could be to define different enums for compression and decompression.; * This question could be kept for later",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55223,Testability,test,tested,55223,"ontrols whether the contents of a CDict are; * used in place, or whether they are copied into; * the working context.; *; * Accepts values from the ZSTD_dictAttachPref_e; * enum. See the comments on that enum for an; * explanation of the feature.; */; } ZSTD_cParameter;. size_t ZSTD_CCtx_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55476,Testability,test,tested,55476,"x_setParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned value);; Set one compression parameter, selected by enum ZSTD_cParameter.; Setting a parameter is generally only possible during frame initialization (before starting compression).; Exception : when using multi-threading mode (nbThreads >= 1),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Cr",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:55781,Testability,test,tested,55781,"),; following parameters can be updated _during_ compression (within same frame):; => compressionLevel, hashLog, chainLog, searchLog, minMatch, targetLength and strategy.; new parameters will be active on next job, or after a flush().; Note : when `value` type is not unsigned (int, or enum), cast it to unsigned for proper type checking.; @result : informational value (typically, value being set, correctly clamped),; or an error code (which can be tested with ZSTD_isError()). . size_t ZSTD_CCtx_getParameter(ZSTD_CCtx* cctx, ZSTD_cParameter param, unsigned* value);; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setPledgedSrcSize(ZSTD_CCtx* cctx, unsigned long long pledgedSrcSize);; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictiona",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:56604,Testability,test,tested,56604,"; Total input data size to be compressed as a single frame.; This value will be controlled at the end, and result in error if not respected.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : 0 means zero, empty.; In order to mean ""unknown content size"", pass constant ZSTD_CONTENTSIZE_UNKNOWN.; ZSTD_CONTENTSIZE_UNKNOWN is default value for any new compression job.; Note 2 : If all data is provided and consumed in a single round,; this value is overriden by srcSize instead. . size_t ZSTD_CCtx_loadDictionary(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_byReference(ZSTD_CCtx* cctx, const void* dict, size_t dictSize);; size_t ZSTD_CCtx_loadDictionary_advanced(ZSTD_CCtx* cctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal CDict from `dict` buffer.; Decompression will have to use same dictionary.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding a NULL (or 0-size) dictionary invalidates previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : Dictionary will be used for all future compression jobs.; To return to ""no-dictionary"" situation, load a NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:57877,Testability,test,tested,57877," NULL dictionary; Note 2 : Loading a dictionary involves building tables, which are dependent on compression parameters.; For this reason, compression parameters cannot be changed anymore after loading a dictionary.; It's also a CPU consuming operation, with non-negligible impact on latency.; Note 3 :`dict` content will be copied internally.; Use ZSTD_CCtx_loadDictionary_byReference() to reference dictionary content instead.; In such a case, dictionary buffer must outlive its users.; Note 4 : Use ZSTD_CCtx_loadDictionary_advanced(); to precisely select how dictionary content must be interpreted. . size_t ZSTD_CCtx_refCDict(ZSTD_CCtx* cctx, const ZSTD_CDict* cdict);; Reference a prepared dictionary, to be used for all next compression jobs.; Note that compression parameters are enforced from within CDict,; and supercede any compression parameter previously set within CCtx.; The dictionary will remain valid for future compression jobs using same CCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just referenced, its lifetime must outlive CCtx. . size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (whi",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:58878,Testability,test,tested,58878," can be tested with ZSTD_isError()).; Special : adding a NULL CDict means ""return to no-dictionary mode"".; Note 1 : Currently, only one dictionary can be managed.; Adding a new dictionary effectively ""discards"" any previous one.; Note 2 : CDict is just referenced, its lifetime must outlive CCtx. . size_t ZSTD_CCtx_refPrefix(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_CCtx_refPrefix_advanced(ZSTD_CCtx* cctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; Decompression will need same prefix to properly regenerate data.; Compressing with a prefix is similar in outcome as performing a diff and compressing it,; but performs much faster, especially during decompression (compression speed is tunable with compression level).; Note that prefix is **only used once**. Tables are discarded at end of compression job (ZSTD_e_end).; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special: Adding any prefix (including NULL) invalidates any previous prefix or dictionary; Note 1 : Prefix buffer is referenced. It **must** outlive compression job.; Its contain must remain unmodified up to end of compression (ZSTD_e_end).; Note 2 : If the intention is to diff some large src data blob with some prior version of itself,; ensure that the window size is large enough to contain the entire source.; See ZSTD_p_windowLog.; Note 3 : Referencing a prefix involves building tables, which are dependent on compression parameters.; It's a CPU consuming operation, with non-negligible impact on latency.; If there is a need to use same prefix multiple times, consider loadDictionary instead.; Note 4 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode. . void ZSTD_CCtx_reset(ZSTD_CCtx* cctx);; Return a CCtx to clean state.; Useful after an error, or to interrupt an ongoing c",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:62339,Testability,test,tested,62339,"g compression, using ZSTD_CCtx_setParameter(); - Compression parameters cannot be changed once compression is started.; - outpot->pos must be <= dstCapacity, input->pos must be <= srcSize; - outpot->pos and input->pos will be updated. They are guaranteed to remain below their respective limit.; - In single-thread mode (default), function is blocking : it completed its job before returning to caller.; - In multi-thread mode, function is non-blocking : it just acquires a copy of input, and distribute job to internal worker threads,; and then immediately returns, just indicating that there is some data remaining to be flushed.; The function nonetheless guarantees forward progress : it will return only after it reads or write at least 1+ byte.; - Exception : in multi-threading mode, if the first call requests a ZSTD_e_end directive, it is blocking : it will complete compression before giving back control to caller.; - @return provides a minimum amount of data remaining to be flushed from internal buffers; or an error code, which can be tested using ZSTD_isError().; if @return != 0, flush is not fully completed, there is still some data left within internal buffers.; This is useful for ZSTD_e_flush, since in this case more flushes are necessary to empty all buffers.; For ZSTD_e_end, @return == 0 when internal buffers are fully flushed and frame is completed.; - after a ZSTD_e_end directive, if internal buffer is not fully flushed (@return != 0),; only ZSTD_e_end or ZSTD_e_flush operations are allowed.; Before starting a new compression job, or changing compression parameters,; it is required to fully flush internal buffers.; . size_t ZSTD_compress_generic_simpleArgs (; ZSTD_CCtx* cctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos,; ZSTD_EndDirective endOp);; Same as ZSTD_compress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binders fro",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:65084,Testability,test,tested,65084,"or single-threaded compression.; . size_t ZSTD_CCtxParams_reset(ZSTD_CCtx_params* params);; Reset params to default values.; . size_t ZSTD_CCtxParams_init(ZSTD_CCtx_params* cctxParams, int compressionLevel);; Initializes the compression parameters of cctxParams according to; compression level. All other parameters are reset to their default values.; . size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params);; Initializes the compression and frame parameters of cctxParams according to; params. All other parameters are reset to their default values.; . size_t ZSTD_CCtxParam_setParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned value);; Similar to ZSTD_CCtx_setParameter.; Set one compression parameter, selected by enum ZSTD_cParameter.; Parameters must be applied to a ZSTD_CCtx using ZSTD_CCtx_setParametersUsingCCtxParams().; Note : when `value` is an enum, cast it to unsigned for proper type checking.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtxParam_getParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned* value);; Similar to ZSTD_CCtx_getParameter.; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byR",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:65388,Testability,test,tested,65388," parameters are reset to their default values.; . size_t ZSTD_CCtxParams_init_advanced(ZSTD_CCtx_params* cctxParams, ZSTD_parameters params);; Initializes the compression and frame parameters of cctxParams according to; params. All other parameters are reset to their default values.; . size_t ZSTD_CCtxParam_setParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned value);; Similar to ZSTD_CCtx_setParameter.; Set one compression parameter, selected by enum ZSTD_cParameter.; Parameters must be applied to a ZSTD_CCtx using ZSTD_CCtx_setParametersUsingCCtxParams().; Note : when `value` is an enum, cast it to unsigned for proper type checking.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtxParam_getParameter(ZSTD_CCtx_params* params, ZSTD_cParameter param, unsigned* value);; Similar to ZSTD_CCtx_getParameter.; Get the requested value of one compression parameter, selected by enum ZSTD_cParameter.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; . size_t ZSTD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:66438,Testability,test,tested,66438,"TD_CCtx_setParametersUsingCCtxParams(; ZSTD_CCtx* cctx, const ZSTD_CCtx_params* params);; Apply a set of ZSTD_CCtx_params to the compression context.; This can be done even after compression is started,; if nbWorkers==0, this will have no impact until a new compression is started.; if nbWorkers>=1, new parameters will be picked up at next job,; with a few restrictions (windowLog, pledgedSrcSize, nbWorkers, jobSize, and overlapLog are not updated).; . Advanced decompression API/* ==================================== */. size_t ZSTD_DCtx_loadDictionary(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_byReference(ZSTD_DCtx* dctx, const void* dict, size_t dictSize);; size_t ZSTD_DCtx_loadDictionary_advanced(ZSTD_DCtx* dctx, const void* dict, size_t dictSize, ZSTD_dictLoadMethod_e dictLoadMethod, ZSTD_dictContentType_e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; Note 2 : Loading a dictionary involves building tables,; which has a non-negligible impact on CPU usage and latency.; Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to select; how dictionary content will be interpreted and loaded.; . size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);; Reference a prepared dictionary, to be used to decompress next frames.; The dictionary remains active for decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:67299,Testability,test,tested,67299,"e dictContentType);; Create an internal DDict from dict buffer,; to be used to decompress next frames.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Special : Adding a NULL (or 0-size) dictionary invalidates any previous dictionary,; meaning ""return to no-dictionary mode"".; Note 1 : `dict` content will be copied internally.; Use ZSTD_DCtx_loadDictionary_byReference(); to reference dictionary content instead.; In which case, the dictionary buffer must outlive its users.; Note 2 : Loading a dictionary involves building tables,; which has a non-negligible impact on CPU usage and latency.; Note 3 : Use ZSTD_DCtx_loadDictionary_advanced() to select; how dictionary content will be interpreted and loaded.; . size_t ZSTD_DCtx_refDDict(ZSTD_DCtx* dctx, const ZSTD_DDict* ddict);; Reference a prepared dictionary, to be used to decompress next frames.; The dictionary remains active for decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""discards"" any previous one.; Special : adding a NULL DDict means ""return to no-dictionary mode"".; Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.; . size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; This is the reverse operation of ZSTD_CCtx_refPrefix(),; and must use the same prefix as the one used during compression.; Prefix is **only used once**. Reference is discarded at end of frame.; End of frame is reached when ZSTD_DCtx_decompress_generic() returns 0.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Adding any prefix (including NULL) i",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:68215,Testability,test,tested,68215,"decompression of future frames using same DCtx.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Currently, only one dictionary can be managed.; Referencing a new dictionary effectively ""discards"" any previous one.; Special : adding a NULL DDict means ""return to no-dictionary mode"".; Note 2 : DDict is just referenced, its lifetime must outlive its usage from DCtx.; . size_t ZSTD_DCtx_refPrefix(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize);; size_t ZSTD_DCtx_refPrefix_advanced(ZSTD_DCtx* dctx,; const void* prefix, size_t prefixSize,; ZSTD_dictContentType_e dictContentType);; Reference a prefix (single-usage dictionary) for next compression job.; This is the reverse operation of ZSTD_CCtx_refPrefix(),; and must use the same prefix as the one used during compression.; Prefix is **only used once**. Reference is discarded at end of frame.; End of frame is reached when ZSTD_DCtx_decompress_generic() returns 0.; @result : 0, or an error code (which can be tested with ZSTD_isError()).; Note 1 : Adding any prefix (including NULL) invalidates any previously set prefix or dictionary; Note 2 : Prefix buffer is referenced. It **must** outlive decompression job.; Prefix buffer must remain unmodified up to the end of frame,; reached when ZSTD_DCtx_decompress_generic() returns 0.; Note 3 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a d",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:69326,Testability,test,tested,69326,"(including NULL) invalidates any previously set prefix or dictionary; Note 2 : Prefix buffer is referenced. It **must** outlive decompression job.; Prefix buffer must remain unmodified up to the end of frame,; reached when ZSTD_DCtx_decompress_generic() returns 0.; Note 3 : By default, the prefix is treated as raw content (ZSTD_dm_rawContent).; Use ZSTD_CCtx_refPrefix_advanced() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @return : an error code, which can be tested using ZSTD_isError(); if >0, a hint, nb of expected input bytes for next invocation.; `0` mea",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:69660,Testability,test,tested,69660,"() to alter dictMode.; Note 4 : Referencing a raw content prefix has almost no cpu nor memory cost.; A fulldict prefix is more costly though.; . size_t ZSTD_DCtx_setMaxWindowSize(ZSTD_DCtx* dctx, size_t maxWindowSize);; Refuses allocating internal buffers for frames requiring a window size larger than provided limit.; This is useful to prevent a decoder context from reserving too much memory for itself (potential attack scenario).; This parameter is only useful in streaming mode, since no internal buffer is allocated in direct mode.; By default, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @return : an error code, which can be tested using ZSTD_isError(); if >0, a hint, nb of expected input bytes for next invocation.; `0` means : a frame has just been fully decoded and flushed.; . size_t ZSTD_decompress_generic_simpleArgs (; ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos);; Same as ZSTD_decompress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binder",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:70172,Testability,test,tested,70172,"ault, a decompression context accepts all window sizes <= (1 << ZSTD_WINDOWLOG_MAX); @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_DCtx_setFormat(ZSTD_DCtx* dctx, ZSTD_format_e format);; Instruct the decoder context about what kind of data to decode next.; This instruction is mandatory to decode data without a fully-formed header,; such ZSTD_f_zstd1_magicless for example.; @return : 0, or an error code (which can be tested using ZSTD_isError()).; . size_t ZSTD_getFrameHeader_advanced(ZSTD_frameHeader* zfhPtr,; const void* src, size_t srcSize, ZSTD_format_e format);; same as ZSTD_getFrameHeader(),; with added capability to select a format (like ZSTD_f_zstd1_magicless) . size_t ZSTD_decompress_generic(ZSTD_DCtx* dctx,; ZSTD_outBuffer* output,; ZSTD_inBuffer* input);; Behave the same as ZSTD_decompressStream.; Decompression parameters cannot be changed once decompression is started.; @return : an error code, which can be tested using ZSTD_isError(); if >0, a hint, nb of expected input bytes for next invocation.; `0` means : a frame has just been fully decoded and flushed.; . size_t ZSTD_decompress_generic_simpleArgs (; ZSTD_DCtx* dctx,; void* dst, size_t dstCapacity, size_t* dstPos,; const void* src, size_t srcSize, size_t* srcPos);; Same as ZSTD_decompress_generic(),; but using only integral types as arguments.; Argument list is larger than ZSTD_{in,out}Buffer,; but can be helpful for binders from dynamic languages; which have troubles handling structures containing memory pointers.; . void ZSTD_DCtx_reset(ZSTD_DCtx* dctx);; Return a DCtx to clean state.; If a decompression was ongoing, any internal data not yet flushed is cancelled.; All parameters are back to default values, including sticky ones.; Dictionary (if any) is dropped.; Parameters can be modified again after a reset.; . Block level API; Frame metadata cost is typically ~18 bytes, which can be non-negligible for very small blocks (< 100 bytes).; User will have to t",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:72222,Testability,test,test,72222," after a reset.; . Block level API; Frame metadata cost is typically ~18 bytes, which can be non-negligible for very small blocks (< 100 bytes).; User will have to take in charge required information to regenerate data, such as compressed and content sizes. A few rules to respect :; - Compressing and decompressing require a context structure; + Use ZSTD_createCCtx() and ZSTD_createDCtx(); - It is necessary to init context before starting; + compression : any ZSTD_compressBegin*() variant, including with dictionary; + decompression : any ZSTD_decompressBegin*() variant, including with dictionary; + copyCCtx() and copyDCtx() can be used too; - Block size is limited, it must be <= ZSTD_getBlockSize() <= ZSTD_BLOCKSIZE_MAX == 128 KB; + If input is larger than a block size, it's necessary to split input data into multiple blocks; + For inputs larger than a single block size, consider using the regular ZSTD_compress() instead.; Frame metadata is not that costly, and quickly becomes negligible as source size grows larger.; - When a block is considered not compressible enough, ZSTD_compressBlock() result will be zero.; In which case, nothing is produced into `dst`.; + User must test for such outcome and deal directly with uncompressed data; + ZSTD_decompressBlock() doesn't accept uncompressed data as input !!!; + In case of multiple successive blocks, should some of them be uncompressed,; decoder must be informed of their existence in order to follow proper history.; Use ZSTD_insertBlock() for such a case. Raw zstd block functionssize_t ZSTD_getBlockSize (const ZSTD_CCtx* cctx);; size_t ZSTD_compressBlock (ZSTD_CCtx* cctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);; size_t ZSTD_decompressBlock(ZSTD_DCtx* dctx, void* dst, size_t dstCapacity, const void* src, size_t srcSize);; size_t ZSTD_insertBlock (ZSTD_DCtx* dctx, const void* blockStart, size_t blockSize); /**< insert uncompressed block into `dctx` history. Useful for multi-blocks decompression. */. ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:26635,Usability,simpl,simply,26635,"y not compatible with multi-threading.; Limitation 3 : static dctx is incompatible with legacy support.; . ZSTD_DStream* ZSTD_initStaticDStream(void* workspace, size_t workspaceSize); /**< same as ZSTD_initStaticDCtx() */. typedef void* (*ZSTD_allocFunction) (void* opaque, size_t size);; typedef void (*ZSTD_freeFunction) (void* opaque, void* address);; typedef struct { ZSTD_allocFunction customAlloc; ZSTD_freeFunction customFree; void* opaque; } ZSTD_customMem;; static ZSTD_customMem const ZSTD_defaultCMem = { NULL, NULL, NULL }; /**< this constant defers to stdlib's functions */; These prototypes make it possible to pass your own allocation/free functions.; ZSTD_customMem is provided at creation time, using ZSTD_create*_advanced() variants listed below.; All allocation/free operations will be completed using these custom variants instead of regular ones.; . Advanced compression functions; ZSTD_CDict* ZSTD_createCDict_byReference(const void* dictBuffer, size_t dictSize, int compressionLevel);; Create a digested dictionary for compression; Dictionary content is simply referenced, and therefore stays in dictBuffer.; It is important that dictBuffer outlives CDict, it must remain read accessible throughout the lifetime of CDict . ZSTD_compressionParameters ZSTD_getCParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; @return ZSTD_compressionParameters structure for a selected compression level and estimated srcSize.; `estimatedSrcSize` value is optional, select 0 if not known . ZSTD_parameters ZSTD_getParams(int compressionLevel, unsigned long long estimatedSrcSize, size_t dictSize);; same as ZSTD_getCParams(), but @return a full `ZSTD_parameters` object instead of sub-component `ZSTD_compressionParameters`.; All fields of `ZSTD_frameParameters` are set to default : contentSize=1, checksum=0, noDictID=0 . size_t ZSTD_checkCParams(ZSTD_compressionParameters params);; Ensure param values remain within authorized range . ZSTD_compressionPara",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:40690,Usability,resume,resume,40690,"essContinue() needs previous data blocks during decompression, up to `windowSize` bytes.; ZSTD_decompressContinue() is very sensitive to contiguity,; if 2 blocks don't follow each other, make sure that either the compressor breaks contiguity at the same place,; or that previous contiguous segment is large enough to properly handle maximum back-reference distance.; There are multiple ways to guarantee this condition. The most memory efficient way is to use a round buffer of sufficient size.; Sufficient size is determined by invoking ZSTD_decodingBufferSize_min(),; which can @return an error code if required value is too large for current system (in 32-bits mode).; In a round buffer methodology, ZSTD_decompressContinue() decompresses each block next to previous one,; up to the moment there is not enough room left in the buffer to guarantee decoding another full block,; which maximum size is provided in `ZSTD_frameHeader` structure, field `blockSizeMax`.; At which point, decoding can resume from the beginning of the buffer.; Note that already decoded data stored in the buffer should be flushed before being overwritten. There are alternatives possible, for example using two or more buffers of size `windowSize` each, though they consume more memory. Finally, if you control the compression process, you can also ignore all buffer size rules,; as long as the encoder and decoder progress in ""lock-step"",; aka use exactly the same buffer sizes, break contiguity at the same place, etc. Once buffers are setup, start decompression, with ZSTD_decompressBegin().; If decompression requires a dictionary, use ZSTD_decompressBegin_usingDict() or ZSTD_decompressBegin_usingDDict(). Then use ZSTD_nextSrcSizeToDecompress() and ZSTD_decompressContinue() alternatively.; ZSTD_nextSrcSizeToDecompress() tells how many bytes to provide as 'srcSize' to ZSTD_decompressContinue().; ZSTD_decompressContinue() requires this _exact_ amount of bytes, or it will fail. @result of ZSTD_decompressContinue() ",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html:46438,Usability,simpl,simple,46438,"be considered only in the context of extremely; * advanced performance tuning.; *; * Zstd currently supports the use of a CDict in two ways:; *; * - The contents of the CDict can be copied into the working context. This; * means that the compression can search both the dictionary and input; * while operating on a single set of internal tables. This makes; * the compression faster per-byte of input. However, the initial copy of; * the CDict's tables incurs a fixed cost at the beginning of the; * compression. For small compressions (< 8 KB), that copy can dominate; * the cost of the compression.; *; * - The CDict's tables can be used in-place. In this model, compression is; * slower per input byte, because the compressor has to search two sets of; * tables. However, this model incurs no start-up cost (as long as the; * working context's tables can be reused). For small inputs, this can be; * faster than copying the CDict's tables.; *; * Zstd has a simple internal heuristic that selects which strategy to use; * at the beginning of a compression. However, if experimentation shows that; * Zstd is making poor choices, it is possible to override that choice with; * this enum.; */; ZSTD_dictDefaultAttach = 0, /* Use the default heuristic. */; ZSTD_dictForceAttach = 1, /* Never copy the dictionary. */; ZSTD_dictForceCopy = 2, /* Always copy the dictionary. */; } ZSTD_dictAttachPref_e;. typedef enum {; /* compression format */; ZSTD_p_format = 10, /* See ZSTD_format_e enum definition.; * Cast selected format as unsigned for ZSTD_CCtx_setParameter() compatibility. */. /* compression parameters */; ZSTD_p_compressionLevel=100, /* Update all compression parameters according to pre-defined cLevel table; * Default level is ZSTD_CLEVEL_DEFAULT==3.; * Special: value 0 means default, which is controlled by ZSTD_CLEVEL_DEFAULT.; * Note 1 : it's possible to pass a negative compression level by casting it to unsigned type.; * Note 2 : setting a level sets all default values of other com",MatchSource.DOCS,lib/zstd/doc/zstd_manual.html,soedinglab,MMseqs2,15-6f452,https://github.com/soedinglab/mmseqs2/wiki,https://github.com/soedinglab/MMseqs2/tree/15-6f452/lib/zstd/doc/zstd_manual.html
