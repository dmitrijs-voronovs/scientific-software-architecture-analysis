id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11665,Testability,assert,assertions,11665," The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11734,Testability,assert,assertions,11734," The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11797,Testability,assert,assertions,11797,"f grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11823,Testability,test,test,11823,"f grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline ch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11942,Testability,test,test,11942," having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; som",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:11982,Testability,assert,assertions,11982," having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; som",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12014,Testability,assert,assertions,12014," having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; som",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12158,Testability,test,test,12158,"ode there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12208,Testability,assert,assertions,12208,". Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12241,Testability,test,test,12241,". Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12383,Testability,assert,assertions,12383,"ork we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/llc test.ll. This will generate FileCheck assertions, and insert a ``NOTE:`` line at the; top to indicate that assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12728,Testability,test,tests,12728,"assertions were automatically generated. If you want to update assertions in an existing test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12772,Testability,test,test,12772,"isting test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12793,Testability,assert,assert,12793,"isting test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12830,Testability,test,test,12830,"isting test case, pass the `-u` option; which first checks the ``NOTE:`` line exists and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:12882,Testability,test,test,12882,"and matches the script name. Sometimes a test absolutely depends on hand-written assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13023,Testability,test,test,13023," assertions and should not; have assertions automatically generated. In that case, add the text ``NOTE: Do; not autogenerate`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13127,Testability,test,tests,13127,"e`` to the first line, and the scripts will skip that test. It; is a good idea to explain why generated assertions will not work for the test; so future developers will understand what is going on. These are the most common scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13270,Testability,test,tests,13270,"mmon scripts and their purposes/applications in generating; assertions:. .. code-block:: none. update_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumber",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13418,Testability,test,tests,13418,"_analyze_test_checks.py; opt -passes='print<cost-model>'. update_cc_test_checks.py; C/C++, or clang/clang++ (IR checks). update_llc_test_checks.py; llc (assembly checks). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13591,Testability,test,tested,13591,"). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13623,Testability,test,test,13623,"). update_mca_test_checks.py; llvm-mca. update_mir_test_checks.py; llc (MIR checks). update_test_checks.py; opt. Precommit workflow for tests; ----------------------------. If the test does not crash, assert, or infinite loop, commit the test with; baseline check-lines first. That is, the test will show a miscompile or; missing optimization. Add a ""TODO"" or ""FIXME"" comment to indicate that; something is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:13963,Testability,test,tests,13963,"ing is expected to change in a test. A follow-up patch with code changes to the compiler will then show check-line; differences to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14111,Testability,test,tests,14111,"s to the tests, so it is easier to see the effect of the patch.; Remove TODO/FIXME comments added in the previous step if a problem is solved. Baseline tests (no-functional-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14338,Testability,test,test,14338,"-change or NFC patch) may be pushed to main; without pre-commit review if you have commit access. Best practices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14395,Testability,test,test,14395,"tices for regression tests; -----------------------------------. - Use auto-generated check lines (produced by the scripts mentioned above); whenever feasible.; - Include comments about what is tested/expected in a particular test. If there; are relevant issues in the bug tracker, add references to those bug reports; (for example, ""See PR999 for more details"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, conside",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:14663,Testability,test,test,14663,"ails"").; - Avoid undefined behavior and poison/undef values unless necessary. For; example, do not use patterns like ``br i1 undef``, which are likely to break; as a result of future optimizations.; - Minimize tests by removing unnecessary instructions, metadata, attributes,; etc. Tools like ``llvm-reduce`` can help automate this.; - Outside PhaseOrdering tests, only run a minimal set of passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:15085,Testability,test,test,15085,"f passes. For example,; prefer ``opt -S -passes=instcombine`` over ``opt -S -O3``.; - Avoid unnamed instructions/blocks (such as ``%0`` or ``1:``), because they may; require renumbering on future test modifications. These can be removed by; running the test through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:15401,Testability,test,test,15401,"st through ``opt -S -passes=instnamer``.; - Try to give values (including variables, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; dep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:15467,Testability,test,test,15467,"les, blocks and functions) meaningful; names, and avoid retaining complex names generated by the optimization; pipeline (such as ``%foo.0.0.0.0.0.0``). Extra files; -----------. If your test requires extra files besides the file containing the ``RUN:`` lines; and the extra files are small, consider specifying them in the same file and; using ``split-file`` to extract them. For example,. .. code-block:: llvm. ; RUN: split-file %s %t; ; RUN: llvm-link -S %t/a.ll %t/b.ll | FileCheck %s. ; CHECK: ... ;--- a.ll; ...; ;--- b.ll; ... The parts are separated by the regex ``^(.|//)--- <part>``. If you want to test relative line numbers like ``[[#@LINE+1]]``, specify; ``--leading-lines`` to add leading empty lines to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:16203,Testability,test,test,16203,"s to preserve line numbers. If the extra files are large, the idiomatic place to put them is in a subdirectory ``Inputs``.; You can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:16269,Testability,test,tests,16269,"u can then refer to the extra files as ``%S/Inputs/foo.bar``. For example, consider ``test/Linker/ident.ll``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:16415,Testability,test,tests,16415,"``. The directory structure is; as follows::. test/; Linker/; ident.ll; Inputs/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end feature",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:16467,Testability,test,test,16467,"/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:16518,Testability,test,tested,16518,"/; ident.a.ll; ident.b.ll. For convenience, these are the contents:. .. code-block:: llvm. ;;;;; ident.ll:. ; RUN: llvm-link %S/Inputs/ident.a.ll %S/Inputs/ident.b.ll -S | FileCheck %s. ; Verify that multiple input llvm.ident metadata are linked together. ; CHECK-DAG: !llvm.ident = !{!0, !1, !2}; ; CHECK-DAG: ""Compiler V1""; ; CHECK-DAG: ""Compiler V2""; ; CHECK-DAG: ""Compiler V3"". ;;;;; Inputs/ident.a.ll:. !llvm.ident = !{!0, !1}; !0 = metadata !{metadata !""Compiler V1""}; !1 = metadata !{metadata !""Compiler V2""}. ;;;;; Inputs/ident.b.ll:. !llvm.ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:17024,Testability,test,test,17024,"ident = !{!0}; !0 = metadata !{metadata !""Compiler V3""}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:17093,Testability,test,tests,17093,"}. For symmetry reasons, ``ident.ll`` is just a dummy file that doesn't; actually participate in the test besides holding the ``RUN:`` lines. .. note::. Some existing tests use ``RUN: true`` in extra files instead of just; putting the extra files in an ``Inputs/`` directory. This pattern is; deprecated. Fragile tests; -------------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:17294,Testability,test,tests,17294,"---------. It is easy to write a fragile test that would fail spuriously if the tool being; tested outputs a full path to the input file. For example, :program:`opt` by; default outputs a ``ModuleID``:. .. code-block:: console. $ cat example.ll; define i32 @main() nounwind {; ret i32 0; }. $ opt -S /path/to/example.ll; ; ModuleID = '/path/to/example.ll'. define i32 @main() nounwind {; ret i32 0; }. ``ModuleID`` can unexpectedly match against ``CHECK`` lines. For example:. .. code-block:: llvm. ; RUN: opt -S %s | FileCheck. define i32 @main() nounwind {; ; CHECK-NOT: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:17958,Testability,test,test,17958,"T: load; ret i32 0; }. This test will fail if placed into a ``download`` directory. To make your tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18083,Testability,test,tests,18083,"tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18108,Testability,test,test,18108,"tests robust, always use ``opt ... < %s`` in the RUN line.; :program:`opt` does not output a ``ModuleID`` when input comes from stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18218,Testability,test,tests,18218,"stdin. Platform-Specific Tests; -----------------------. Whenever adding tests that require the knowledge of a specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18326,Testability,test,test,18326," specific platform,; either related to code generated, specific output or back-end features,; you must make sure to isolate the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18439,Testability,test,test,18439," the features, so that buildbots that; run on different architectures (and don't even compile all back-ends),; don't fail. The first problem is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18536,Testability,test,tests,18536,"em is to check for target-specific output, for example sizes; of structures, paths and architecture names, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific con",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18690,Testability,test,test,18690,"ames, for example:. * Tests containing Windows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:18719,Testability,test,tests,18719,"ows paths will fail on Linux and vice-versa.; * Tests that check for ``x86_64`` somewhere in the text will fail anywhere else.; * Tests where the debug information calculates the size of types and structures. Also, if the test rely on any behaviour that is coded in any back-end, it must; go in its own directory. So, for instance, code generator tests for ARM go; into ``test/CodeGen/ARM`` and so on. Those directories contain a special; ``lit`` configuration file that ensure all tests in that directory will; only run if a specific back-end is compiled and available. For instance, on ``test/CodeGen/ARM``, the ``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. So",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19225,Testability,test,testing,19225,"``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19373,Testability,test,test,19373,"``lit.local.cfg`` is:. .. code-block:: python. config.suffixes = ['.ll', '.c', '.cpp', '.test']; if not 'ARM' in config.root.targets:; config.unsupported = True. Other platform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19505,Testability,test,test,19505,"atform-specific tests are those that depend on a specific feature; of a specific sub-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19555,Testability,test,tests,19555,"-architecture, for example only to Intel chips that support ``AVX2``. For instance, ``test/CodeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19718,Testability,test,test,19718,"odeGen/X86/psubus.ll`` tests three sub-architecture; variants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is sati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19740,Testability,test,tests,19740,"ariants:. .. code-block:: llvm. ; RUN: llc -mcpu=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19816,Testability,test,test,19816,"u=core2 < %s | FileCheck %s -check-prefix=SSE2; ; RUN: llc -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19853,Testability,test,test,19853,"c -mcpu=corei7-avx < %s | FileCheck %s -check-prefix=AVX1; ; RUN: llc -mcpu=core-avx2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:19896,Testability,test,test,19896,"x2 < %s | FileCheck %s -check-prefix=AVX2. And the checks are different:. .. code-block:: llvm. ; SSE2: @test1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20023,Testability,test,test,20023,"t1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20067,Testability,assert,asserts,20067,"t1; ; SSE2: psubusw LCPI0_0(%rip), %xmm0; ; AVX1: @test1; ; AVX1: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20089,Testability,assert,asserts,20089,": vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20105,Testability,test,test,20105,": vpsubusw LCPI0_0(%rip), %xmm0, %xmm0; ; AVX2: @test1; ; AVX2: vpsubusw LCPI0_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:20182,Testability,test,test,20182,"_0(%rip), %xmm0, %xmm0. So, if you're testing for a behaviour that you know is platform-specific or; depends on special features of sub-architectures, you must add the specific; triple, test with the specific FileCheck and put it into the specific; directory that will filter out all other architectures. Constraining test execution; ---------------------------. Some tests can be run only in specific configurations, such as; with debug builds or on particular platforms. Use ``REQUIRES``; and ``UNSUPPORTED`` to control when the test is enabled. Some tests are expected to fail. For example, there may be a known bug; that the test detect. Use ``XFAIL`` to mark a test as an expected failure.; An ``XFAIL`` test will be successful if its execution fails, and; will be a failure if its execution succeeds. .. code-block:: llvm. ; This test will be only enabled in the build with asserts.; ; REQUIRES: asserts; ; This test is disabled when running on Linux.; ; UNSUPPORTED: system-linux; ; This test is expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21186,Testability,test,test,21186,"s expected to fail when targeting PowerPC.; ; XFAIL: target=powerpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21252,Testability,test,test,21252,"erpc{{.*}}. ``REQUIRES`` and ``UNSUPPORTED`` and ``XFAIL`` all accept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expect",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21309,Testability,test,test,21309,"ccept a comma-separated; list of boolean expressions. The values in each expression may be:. - Features added to ``config.available_features`` by configuration files such as ``lit.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of thes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21442,Testability,test,test,21442,"it.cfg``.; String comparison of features is case-sensitive. Furthermore, a boolean expression can; contain any Python regular expression enclosed in ``{{ }}``, in which case the boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21639,Testability,test,test,21639,"he boolean; expression is satisfied if any feature matches the regular expression. Regular; expressions can appear inside an identifier, so for example ``he{{l+}}o`` would match; ``helo``, ``hello``, ``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21864,Testability,log,logical,21864,"``helllo``, and so on.; - The default target triple, preceded by the string ``target=`` (for example,; ``target=x86_64-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:21945,Testability,log,logical,21945,"-pc-windows-msvc``). Typically regular expressions are used; to match parts of the triple (for example, ``target={{.*}}-windows{{.*}}``; to match any Windows target triple). | ``REQUIRES`` enables the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22150,Testability,test,test,22150,"les the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22237,Testability,test,test,22237,"les the test if all expressions are true.; | ``UNSUPPORTED`` disables the test if any expression is true.; | ``XFAIL`` expects the test to fail if any expression is true. As a special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22336,Testability,test,test,22336," special case, ``XFAIL: *`` is expected to fail everywhere. .. code-block:: llvm. ; This test is disabled when running on Windows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22431,Testability,test,test,22431,"dows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22518,Testability,test,test,22518,"dows,; ; and is disabled when targeting Linux, except for Android Linux.; ; UNSUPPORTED: system-windows, target={{.*linux.*}} && !target={{.*android.*}}; ; This test is expected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22594,Testability,test,test,22594,"xpected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22688,Testability,test,test,22688,"xpected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:22730,Testability,test,test,22730,"xpected to fail when targeting PowerPC or running on Darwin.; ; XFAIL: target=powerpc{{.*}}, system-darwin. Tips for writing constraints; ----------------------------. **``REQUIRES`` and ``UNSUPPORTED``**. These are logical inverses. In principle, ``UNSUPPORTED`` isn't absolutely; necessary (the logical negation could be used with ``REQUIRES`` to get; exactly the same effect), but it can make these clauses easier to read and; understand. Generally, people use ``REQUIRES`` to state things that the test; depends on to operate correctly, and ``UNSUPPORTED`` to exclude cases where; the test is expected never to work. **``UNSUPPORTED`` and ``XFAIL``**. Both of these indicate that the test isn't expected to work; however, they; have different effects. ``UNSUPPORTED`` causes the test to be skipped;; this saves execution time, but then you'll never know whether the test; actually would start working. Conversely, ``XFAIL`` actually runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:23615,Testability,test,test,23615,"runs the test; but expects a failure output, taking extra execution time but alerting you; if/when the test begins to behave correctly (an XPASS test result). You; need to decide which is more appropriate in each case. **Using ``target=...``**. Checking the target triple can be tricky; it's easy to mis-specify. For; example, ``target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:23917,Testability,test,test,23917,"`target=mips{{.*}}`` will match not only mips, but also mipsel,; mips64, and mips64el. ``target={{.*}}-linux-gnu`` will match; x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24044,Testability,test,test,24044,"x86_64-unknown-linux-gnu, but not armv8l-unknown-linux-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24100,Testability,test,test,24100,"-gnueabihf.; Prefer to use hyphens to delimit triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24147,Testability,test,test,24147,"triple components (``target=mips-{{.*}}``); and it's generally a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24233,Testability,test,test,24233," a good idea to use a trailing wildcard to allow for; unexpected suffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24285,Testability,test,test,24285,"ffixes. Also, it's generally better to write regular expressions that use entire; triple components, than to do something clever to shorten them. For; example, to match both freebsd and netbsd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands to the file system separator, i.e. ``/`` or ``\`` on Windows. ``%/s, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24448,Testability,test,test,24448,"sd in an expression, you could write; ``target={{.*(free|net)bsd.*}}`` and that would work. However, it would; prevent a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands to the file system separator, i.e. ``/`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24613,Testability,test,tests,24613,"event a ``grep freebsd`` from finding this test. Better to use:; ``target={{.+-freebsd.*}} || target={{.+-netbsd.*}}``. Substitutions; -------------. Besides replacing LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands to the file system separator, i.e. ``/`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:24730,Testability,test,test,24730,"ng LLVM tool names the following substitutions are performed in; RUN lines:. ``%%``; Replaced by a single ``%``. This allows escaping other substitutions. ``%s``; File path to the test case's source. This is suitable for passing on the; command line as the input to an LLVM tool. Example: ``/home/user/llvm/test/MC/ELF/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands to the file system separator, i.e. ``/`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``; ``%{/s:real}, %{/S:real}, %{/t:real}, %{/T:real}``. Act like the corresponding substitution, including with ``/``, but use; the real path by expanding all symbolic ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:25079,Testability,test,test,25079,"F/foo_test.s``. ``%S``; Directory path to the test case's source. Example: ``/home/user/llvm/test/MC/ELF``. ``%t``; File path to a temporary file name that could be used for this test case.; The file name won't conflict with other test cases. You can append to it; if you need multiple temporaries. This is useful as the destination of; some redirected output. Example: ``/home/user/llvm.build/test/MC/ELF/Output/foo_test.s.tmp``. ``%T``; Directory of ``%t``. Deprecated. Shouldn't be used, because it can be easily; misused and cause race conditions between tests. Use ``rm -rf %t && mkdir %t`` instead if a temporary directory is necessary. Example: ``/home/user/llvm.build/test/MC/ELF/Output``. ``%{pathsep}``. Expands to the path separator, i.e. ``:`` (or ``;`` on Windows). ``${fs-src-root}``; Expands to the root component of file system paths for the source directory,; i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on Windows. ``${fs-tmp-root}``; Expands to the root component of file system paths for the test's temporary; directory, i.e. ``/`` on Unix systems or ``C:\`` (or another drive) on; Windows. ``${fs-sep}``; Expands to the file system separator, i.e. ``/`` or ``\`` on Windows. ``%/s, %/S, %/t, %/T``. Act like the corresponding substitution above but replace any ``\``; character with a ``/``. This is useful to normalize path separators. Example: ``%s: C:\Desktop Files/foo_test.s.tmp``. Example: ``%/s: C:/Desktop Files/foo_test.s.tmp``. ``%{s:real}, %{S:real}, %{t:real}, %{T:real}``; ``%{/s:real}, %{/S:real}, %{/t:real}, %{/T:real}``. Act like the corresponding substitution, including with ``/``, but use; the real path by expanding all symbolic links and substitute drives. Example: ``%s: S:\foo_test.s.tmp``. Example: ``%{/s:real}: C:/SDrive/foo_test.s.tmp``. ``%:s, %:S, %:t, %:T``. Act like the corresponding substitution above but remove colons at; the beginning of Windows paths. This is useful to allow concatenation; of absolute paths on Windows to produc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:27122,Testability,test,tests,27122,"top Files\foo_test.s.tmp``. ``%errc_<ERRCODE>``. Some error messages may be substituted to allow different spellings; based on the host platform. The following error codes are currently supported:; ENOENT, EISDIR, EINVAL, EACCES. Example: ``Linux %errc_ENOENT: No such file or directory``. Example: ``Windows %errc_ENOENT: no such file or directory``. ``%if feature %{<if branch>%} %else %{<else branch>%}``. Conditional substitution: if ``feature`` is available it expands to; ``<if branch>``, otherwise it expands to ``<else branch>``.; ``%else %{<else branch>%}`` is optional and treated like ``%else %{%}``; if not present. ``%(line)``, ``%(line+<number>)``, ``%(line-<number>)``. The number of the line where this substitution is used, with an; optional integer offset. These expand only if they appear; immediately in ``RUN:``, ``DEFINE:``, and ``REDEFINE:`` directives.; Occurrences in substitutions defined elsewhere are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shlibext``; The suffix for the host platforms shared library files. This includes the; period as the first character. Example: ``.so`` (Linux), ``.dylib`` (macOS), ``.dll`` (Windows). ``%exeext``; The suffix for the host platforms executable files. This includes the; period as the first character. Example: ``.exe`` (Windows), empty on Linux. **Clang-specific substitutions:**. ``%clang``; Invokes the Clang driver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:27174,Testability,test,test,27174,"top Files\foo_test.s.tmp``. ``%errc_<ERRCODE>``. Some error messages may be substituted to allow different spellings; based on the host platform. The following error codes are currently supported:; ENOENT, EISDIR, EINVAL, EACCES. Example: ``Linux %errc_ENOENT: No such file or directory``. Example: ``Windows %errc_ENOENT: no such file or directory``. ``%if feature %{<if branch>%} %else %{<else branch>%}``. Conditional substitution: if ``feature`` is available it expands to; ``<if branch>``, otherwise it expands to ``<else branch>``.; ``%else %{<else branch>%}`` is optional and treated like ``%else %{%}``; if not present. ``%(line)``, ``%(line+<number>)``, ``%(line-<number>)``. The number of the line where this substitution is used, with an; optional integer offset. These expand only if they appear; immediately in ``RUN:``, ``DEFINE:``, and ``REDEFINE:`` directives.; Occurrences in substitutions defined elsewhere are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shlibext``; The suffix for the host platforms shared library files. This includes the; period as the first character. Example: ``.so`` (Linux), ``.dylib`` (macOS), ``.dll`` (Windows). ``%exeext``; The suffix for the host platforms executable files. This includes the; period as the first character. Example: ``.exe`` (Windows), empty on Linux. **Clang-specific substitutions:**. ``%clang``; Invokes the Clang driver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28018,Testability,test,test,28018,"e are never expanded.; For example, this can be used in tests with multiple RUN lines,; which reference the test file's line numbers. **LLVM-specific substitutions:**. ``%shlibext``; The suffix for the host platforms shared library files. This includes the; period as the first character. Example: ``.so`` (Linux), ``.dylib`` (macOS), ``.dll`` (Windows). ``%exeext``; The suffix for the host platforms executable files. This includes the; period as the first character. Example: ``.exe`` (Windows), empty on Linux. **Clang-specific substitutions:**. ``%clang``; Invokes the Clang driver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFIN",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28151,Testability,test,test,28151,"e's line numbers. **LLVM-specific substitutions:**. ``%shlibext``; The suffix for the host platforms shared library files. This includes the; period as the first character. Example: ``.so`` (Linux), ``.dylib`` (macOS), ``.dll`` (Windows). ``%exeext``; The suffix for the host platforms executable files. This includes the; period as the first character. Example: ``.exe`` (Windows), empty on Linux. **Clang-specific substitutions:**. ``%clang``; Invokes the Clang driver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modif",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28389,Testability,test,test,28389,"he first character. Example: ``.so`` (Linux), ``.dylib`` (macOS), ``.dll`` (Windows). ``%exeext``; The suffix for the host platforms executable files. This includes the; period as the first character. Example: ``.exe`` (Windows), empty on Linux. **Clang-specific substitutions:**. ``%clang``; Invokes the Clang driver. ``%clang_cpp``; Invokes the Clang driver for C++. ``%clang_cl``; Invokes the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28735,Testability,test,tests,28735,"the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcfla",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:28746,Testability,test,test,28746,"the CL-compatible Clang driver. ``%clangxx``; Invokes the G++-compatible Clang driver. ``%clang_cc1``; Invokes the Clang frontend. ``%itanium_abi_triple``, ``%ms_abi_triple``; These substitutions can be used to get the current target triple adjusted to; the desired ABI. For example, if the test suite is running with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcfla",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29013,Testability,test,test,29013," with the; ``i686-pc-win32`` target, ``%itanium_abi_triple`` will expand to; ``i686-pc-mingw32``. This allows a test to run with a specific ABI without; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29149,Testability,test,test,29149,"hout; constraining it to a specific triple. **FileCheck-specific substitutions:**. ``%ProtectFileCheckOutput``; This should precede a ``FileCheck`` call if and only if the call's textual; output affects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{che",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29324,Testability,test,test,29324,"ffects test results. It's usually easy to tell: just look for; redirection or piping of the ``FileCheck`` call's stdout or stderr. .. _Test-specific substitutions:. **Test-specific substitutions:**. Additional substitutions can be defined as follows:. - Lit configuration files (e.g., ``lit.cfg`` or ``lit.local.cfg``) can define; substitutions for all tests in a test directory. They do so by extending the; substitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29843,Testability,test,test,29843,"stitution list, ``config.substitutions``. Each item in the list is a tuple; consisting of a pattern and its replacement, which lit applies using python's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its par",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:29871,Testability,test,test,29871,"on's; ``re.sub`` function.; - To define substitutions within a single test file, lit supports the; ``DEFINE:`` and ``REDEFINE:`` directives, described in detail below. So that; they have no effect on other test files, these directives modify a copy of the; substitution list that is produced by lit configuration files. For example, the following directives can be inserted into a test file to define; ``%{cflags}`` and ``%{fcflags}`` substitutions with empty initial values, which; serve as the parameters of another newly defined ``%{check}`` substitution:. .. code-block:: llvm. ; DEFINE: %{cflags} =; ; DEFINE: %{fcflags} =. ; DEFINE: %{check} = \; ; DEFINE: %clang_cc1 -verify -fopenmp -fopenmp-version=51 %{cflags} \; ; DEFINE: -emit-llvm -o - %s | \; ; DEFINE: FileCheck %{fcflags} %s. Alternatively, the above substitutions can be defined in a lit configuration; file to be shared with other test files. Either way, the test file can then; specify directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:30892,Testability,test,test,30892,"y directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:33085,Testability,test,test,33085," of itself, whether directly or via other; substitutions, should be avoided. It usually produces an infinitely recursive; definition that cannot be fully expanded. It does *not* define the; substitution in terms of its previous value, even when using ``REDEFINE:``. The relationship between the ``DEFINE:`` and ``REDEFINE:`` directive is; analogous to the relationship between a variable declaration and variable; assignment in many programming languages:. - ``DEFINE: %{name} = value``. This directive assigns the specified value to a new substitution whose; pattern is ``%{name}``, or it reports an error if there is already a; substitution whose pattern contains ``%{name}`` because that could produce; confusing expansions (e.g., a lit configuration file might define a; substitution with the pattern ``%{name}\[0\]``). The new substitution is; inserted at the start of the substitution list so that it will expand first.; Thus, its value can contain any substitution previously defined, whether in; the same test file or in a lit configuration file, and both will expand. - ``REDEFINE: %{name} = value``. This directive assigns the specified value to an existing substitution whose; pattern is ``%{name}``, or it reports an error if there are no substitutions; with that pattern or if there are multiple substitutions whose patterns; contain ``%{name}``. The substitution's current position in the substitution; list does not change so that expansion order relative to other existing; substitutions is preserved. The following properties apply to both the ``DEFINE:`` and ``REDEFINE:``; directives:. - **Substitution name**: In the directive, whitespace immediately before or; after ``%{name}`` is optional and discarded. ``%{name}`` must start with; ``%{``, it must end with ``}``, and the rest must start with a letter or; underscore and contain only alphanumeric characters, hyphens, underscores, and; colons. This syntax has a few advantages:. - It is impossible for ``%{name}`` to contain se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36676,Testability,test,test,36676,"ions in a ``RUN:``; line, lit makes only one pass through the substitution list by default. Thus,; if substitutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configurati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38071,Testability,test,tests,38071,"e, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of line",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38309,Testability,test,tests,38309,"ces the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38594,Testability,test,test,38594,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38751,Testability,test,test,38751,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:38948,Testability,test,test,38948,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:39214,Testability,test,test,39214,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:39257,Testability,test,test,39257,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:39312,Testability,test,test,39312,"ting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit to 1 will thus cause lit to report an error instead of; producing incorrect output. Options; -------. The llvm lit configuration allows to customize some things with user options:. ``llc``, ``opt``, ...; Substitute the respective llvm tool name with a custom command line. This; allows to specify custom paths and default arguments for these tools.; Example:. % llvm-lit ""-Dllc=llc -verify-machineinstrs"". ``run_long_tests``; Enable the execution of long running tests. ``llvm_site_config``; Load the specified lit configuration instead of the default one. Other Features; --------------. To make RUN line writing easier, there are several helper programs. These; helpers are in the PATH when running tests, so you can just call them using; their name. For example:. ``not``; This program runs its arguments and then inverts the result code from it.; Zero result codes become 1. Non-zero result codes become 0. To make the output more useful, :program:`lit` will scan; the lines of the test case for ones that contain a pattern that matches; ``PR[0-9]+``. This is the syntax for specifying a PR (Problem Report) number; that is related to the test case. The number after ""PR"" specifies the; LLVM Bugzilla number. When a PR number is specified, it will be used in; the pass/fail reporting. This is useful to quickly get some context when; a test fails. Finally, any line that contains ""END."" will cause the special; interpretation of lines to terminate. This is generally done right after; the last RUN: line. This has two side effects:. (a) it prevents special interpretation of lines that are part of the test; program, not the instructions to the test case, and. (b) it speeds things up for really big test cases by avoiding; interpretation of the remainder of the file.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:6788,Usability,simpl,simply,6788,"ke check LIT_ARGS=""-v --vg --vg-leak"". to enable testing with valgrind and with leak checking enabled. To run individual tests or subsets of tests, you can use the ``llvm-lit``; script which is built as part of LLVM. For example, to run the; ``Integer/BitPacked.ll`` test by itself you can run:. .. code-block:: bash. % llvm-lit ~/llvm/test/Integer/BitPacked.ll. or to run all of the ARM CodeGen tests:. .. code-block:: bash. % llvm-lit ~/llvm/test/CodeGen/ARM. The regression tests will use the Python psutil module only if installed in a; **non-user** location. Under Linux, install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:7397,Usability,simpl,simple,7397,"install with sudo or within a virtual; environment. Under Windows, install Python for all users and then run; ``pip install psutil`` in an elevated command prompt. For more information on using the :program:`lit` tool, see ``llvm-lit --help``; or the :doc:`lit man page <CommandGuide/lit>`. Debugging Information tests; ---------------------------. To run debugging information tests simply add the ``cross-project-tests``; project to your ``LLVM_ENABLE_PROJECTS`` define on the cmake; command-line. Regression test structure; =========================. The LLVM regression tests are driven by :program:`lit` and are located in the; ``llvm/test`` directory. This directory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:8051,Usability,simpl,simply,8051,"ory contains a large array of small tests that exercise; various features of LLVM and to ensure that regressions do not occur.; The directory is broken into several sub-directories, each focused on a; particular area of LLVM. Writing new regression tests; ----------------------------. The regression test structure is very simple, but does require some; information to be set. This information is gathered via ``cmake``; and is written to a file, ``test/lit.site.cfg.py`` in the build directory.; The ``llvm/test`` Makefile does this work for you. In order for the regression tests to work, each directory of tests must; have a ``lit.local.cfg`` file. :program:`lit` looks for this file to determine; how to run the tests. This file is just Python code and thus is very; flexible, but we've standardized it for the LLVM regression tests. If; you're adding a directory of tests, just copy ``lit.local.cfg`` from; another directory to get running. The standard ``lit.local.cfg`` simply; specifies which files to look in for tests. Any directory that contains; only directories does not need the ``lit.local.cfg`` file. Read the :doc:`Lit; documentation <CommandGuide/lit>` for more information. Each test file must contain lines starting with ""RUN:"" that tell :program:`lit`; how to run it. If there are no RUN lines, :program:`lit` will issue an error; while running a test. RUN lines are specified in the comments of the test program using the; keyword ``RUN`` followed by a colon, and lastly the command (pipeline); to execute. Together, these lines form the ""script"" that :program:`lit`; executes to run the test case. The syntax of the RUN lines is similar to a; shell's syntax for pipelines including I/O redirection and variable; substitution. However, even though these lines may *look* like a shell; script, they are not. RUN lines are interpreted by :program:`lit`.; Consequently, the syntax differs from shell in a few ways. You can specify; as many RUN lines as needed. :program:`lit` perfo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:10603,Usability,simpl,simple,10603,"ding in ``\`` are concatenated until a RUN line that doesn't end in; ``\`` is found. This concatenated set of RUN lines then constitutes one; execution. :program:`lit` will substitute variables and arrange for the pipeline; to be executed. If any process in the pipeline fails, the entire line (and; test case) fails too. Below is an example of legal RUN lines in a ``.ll`` file:. .. code-block:: llvm. ; RUN: llvm-as < %s | llvm-dis > %t1; ; RUN: llvm-dis < %s.bc-13 > %t2; ; RUN: diff %t1 %t2. As with a Unix shell, the RUN lines permit pipelines and I/O; redirection to be used. There are some quoting rules that you must pay attention to when writing; your RUN lines. In general nothing needs to be quoted. :program:`lit` won't; strip off any quote characters so they will get passed to the invoked program.; To avoid this use curly braces to tell :program:`lit` that it should treat; everything enclosed as one value. In general, you should strive to keep your RUN lines as simple as possible,; using them only to run tools that generate textual output you can then examine.; The recommended way to examine output to figure out if the test passes is using; the :doc:`FileCheck tool <CommandGuide/FileCheck>`. *[The usage of grep in RUN; lines is deprecated - please do not send or commit patches that use it.]*. Put related tests into a single file rather than having a separate file per; test. Check if there are files already covering your feature and consider; adding your code there instead of creating a new file. Generating assertions in regression tests; -----------------------------------------. Some regression test cases are very large and complex to write/update by hand.; In that case to reduce the human work we can use the scripts available in; llvm/utils/ to generate the assertions. For example to generate assertions in an :program:`llc`-based test, after; adding one or more RUN lines use:. .. code-block:: bash. % llvm/utils/update_llc_test_checks.py --llc-binary build/bin/ll",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:30833,Usability,simpl,simple,30833,"y directives like the following to redefine the parameter substitutions as; desired before each use of ``%{check}`` in a ``RUN:`` line:. .. code-block:: llvm. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0 -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu -fopenmp-simd; ; REDEFINE: %{fcflags} = -check-prefix=SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-apple-darwin10.6.0; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. ; REDEFINE: %{cflags} = -triple x86_64-unknown-linux-gnu; ; REDEFINE: %{fcflags} = -check-prefix=NO-SIMD; ; RUN: %{check}. Besides providing initial values, the initial ``DEFINE:`` directives for the; parameter substitutions in the above example serve a second purpose: they; establish the substitution order so that both ``%{check}`` and its parameters; expand as desired. There's a simple way to remember the required definition; order in a test file: define a substitution before any substitution that might; refer to it. In general, substitution expansion behaves as follows:. - Upon arriving at each ``RUN:`` line, lit expands all substitutions in that; ``RUN:`` line using their current values from the substitution list. No; substitution expansion is performed immediately at ``DEFINE:`` and; ``REDEFINE:`` directives except ``%(line)``, ``%(line+<number>)``, and; ``%(line-<number>)``.; - When expanding substitutions in a ``RUN:`` line, lit makes only one pass; through the substitution list by default. In this case, a substitution must; have been inserted earlier in the substitution list than any substitution; appearing in its value in order for the latter to expand. (For greater; flexibility, you can enable multiple passes through the substitution list by; setting `recursiveExpansionLimit`_ in a lit configuration file.); - While lit configuration files can insert anywhere in the substitution list,; the insertion behavior of the `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst:36585,Usability,simpl,simple,36585,"ror. .. _recursiveExpansionLimit:. **recursiveExpansionLimit:**. As described in the previous section, when expanding substitutions in a ``RUN:``; line, lit makes only one pass through the substitution list by default. Thus,; if substitutions are not defined in the proper order, some will remain in the; ``RUN:`` line unexpanded. For example, the following directives refer to; ``%{inner}`` within ``%{outer}`` but do not define ``%{inner}`` until after; ``%{outer}``:. .. code-block:: llvm. ; By default, this definition order does not enable full expansion. ; DEFINE: %{outer} = %{inner}; ; DEFINE: %{inner} = expanded. ; RUN: echo '%{outer}'. ``DEFINE:`` inserts substitutions at the start of the substitution list, so; ``%{inner}`` expands first but has no effect because the original ``RUN:`` line; does not contain ``%{inner}``. Next, ``%{outer}`` expands, and the output of; the ``echo`` command becomes:. .. code-block:: shell. %{inner}. Of course, one way to fix this simple case is to reverse the definitions of; ``%{outer}`` and ``%{inner}``. However, if a test has a complex set of; substitutions that can all reference each other, there might not exist a; sufficient substitution order. To address such use cases, lit configuration files support; ``config.recursiveExpansionLimit``, which can be set to a non-negative integer; to specify the maximum number of passes through the substitution list. Thus, in; the above example, setting the limit to 2 would cause lit to make a second pass; that expands ``%{inner}`` in the ``RUN:`` line, and the output from the ``echo``; command when then be:. .. code-block:: shell. expanded. To improve performance, lit will stop making passes when it notices the ``RUN:``; line has stopped changing. In the above example, setting the limit higher than; 2 is thus harmless. To facilitate debugging, after reaching the limit, lit will make one extra pass; and report an error if the ``RUN:`` line changes again. In the above example,; setting the limit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestingGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestingGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:675,Availability,down,down,675,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1254,Availability,avail,available,1254,"* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3364,Availability,avail,available,3364," They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3943,Availability,failure,failures,3943," on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:980,Deployability,configurat,configuration,980,"ed); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1133,Deployability,install,installed,1133,"ed); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1476,Deployability,install,installed,1476,". .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left uns",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2062,Deployability,configurat,configuration,2062,"r; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2115,Deployability,configurat,configuration,2115,"r; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4205,Integrability,depend,depending,4205," different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4642,Integrability,depend,dependent,4642," are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a tes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:798,Modifiability,config,configure,798,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:980,Modifiability,config,configuration,980,"ed); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1210,Modifiability,config,configure,1210,"* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1277,Modifiability,config,configured,1277,"* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1369,Modifiability,config,configure,1369,"he test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1774,Modifiability,config,configured,1774,"onfigure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1842,Modifiability,config,configure,1842,"onfigure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2062,Modifiability,config,configuration,2062,"r; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2115,Modifiability,config,configuration,2115,"r; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2482,Modifiability,config,configure,2482,"c or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2737,Modifiability,config,configure,2737," need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a nu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2957,Modifiability,variab,variable,2957,"*--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3083,Modifiability,variab,variable,3083,"p (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3587,Performance,optimiz,optimization,3587,"``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5173,Performance,optimiz,optimizations,5173,"pending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5442,Performance,optimiz,optimization,5442,"rectories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | tota",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:6154,Performance,optimiz,optimization,6154," run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:40,Testability,test,test-suite,40,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:175,Testability,test,tests,175,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:311,Testability,test,test,311,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:375,Testability,test,test,375,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:444,Testability,test,test-suite,444,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:534,Testability,test,test-suite,534,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:549,Testability,test,test-suite,549,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:915,Testability,test,test,915,"======================================; test-suite Makefile Guide (deprecated); ======================================. .. contents::; :local:. Overview; ========. First, all tests are executed within the LLVM object directory tree.; They *are not* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1239,Testability,test,test,1239,"* executed inside of the LLVM source tree. This is because; the test suite creates temporary files during execution. To run the test suite, you need to use the following steps:. #. Check out the ``test-suite`` module with:. .. code-block:: bash. % git clone https://github.com/llvm/llvm-test-suite.git test-suite. #. FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1552,Testability,test,test,1552," FIXME: these directions are outdated and won't work. Figure out; what the correct thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1648,Testability,test,test-suite,1648,"ect thing to do is, and write it down here. #. Configure and build ``llvm``. #. Configure and build ``llvm-gcc``. #. Install ``llvm-gcc`` somewhere. #. *Re-configure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1829,Testability,test,test,1829,"onfigure* ``llvm`` from the top level of each build tree (LLVM; object directory tree) in which you want to run the test suite, just; as you do before building LLVM. During the *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1954,Testability,test,tests,1954," *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:1969,Testability,test,test-suite,1969," *re-configuration*, you must either: (1) have ``llvm-gcc``; you just built in your path, or (2) specify the directory where your; just-built ``llvm-gcc`` is installed using; ``--with-llvmgccdir=$LLVM_GCC_DIR``. You must also tell the configure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2235,Testability,test,tests,2235,"gure machinery that the test suite is; available so it can be configured for your build tree:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2352,Testability,test,tests,2352," cd $LLVM_OBJ_ROOT ; $LLVM_SRC_ROOT/configure [--with-llvmgccdir=$LLVM_GCC_DIR]. [Remember that ``$LLVM_GCC_DIR`` is the directory where you; *installed* llvm-gcc, not its src or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2539,Testability,benchmark,benchmarks,2539,"c or obj directory.]. #. You can now run the test suite from your build tree as follows:. .. code-block:: bash. % cd $LLVM_OBJ_ROOT/projects/test-suite; % make. Note that the second and third steps only need to be done once. After; you have the suite checked out and configured, you don't need to do it; again (unless the test code or configure script changes). Configuring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2843,Testability,test,tests,2843,"guring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:2856,Testability,test,test-suite,2856,"guring External Tests; ==========================. In order to run the External tests in the ``test-suite`` module, you; must specify *--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3018,Testability,test,test,3018,"*--with-externals*. This must be done during the; *re-configuration* step (see above), and the ``llvm`` re-configuration; must recognize the previously-built ``llvm-gcc``. If any of these is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3201,Testability,test,tester,3201," is; missing or neglected, the External tests won't work. * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3262,Testability,test,test,3262,". * *--with-externals*. * *--with-externals=<directory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For examp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3295,Testability,test,tests,3295,"ory>*. This tells LLVM where to find any external tests. They are expected to; be in specifically named subdirectories of <``directory``>. If; ``directory`` is left unspecified, ``configure`` uses the default value; ``/home/vadve/shared/benchmarks/speccpu2000/benchspec``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-P",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3734,Testability,test,tests,3734,"d from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4111,Testability,test,test,4111," different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4145,Testability,test,test,4145," different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4272,Testability,test,test,4272,"ts, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4330,Testability,test,test,4330,"ts, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4438,Testability,log,logs,4438,"d for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:4965,Testability,test,test,4965,"res are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5004,Testability,test,test-suite,5004,"r output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5082,Testability,test,test,5082,"r is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test su",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5350,Testability,test,tester,5350," these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5698,Testability,test,test,5698,"ys shown at the end of the run and; the results are always stored in the ``report.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBenc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5806,Testability,test,test-suite,5806,"rt.<type>.format`` file (when; running with ``TEST=<type>``). The ``report`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5879,Testability,test,test,5879,"rt`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prola",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:5894,Testability,test,test-suite,5894,"rt`` also generate a file; called ``report.<type>.raw.out`` containing the output of the entire; test run. Writing Custom Tests for the test-suite; =======================================. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prola",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:6070,Testability,test,test,6070,"=====. Assuming you can run the test suite, (e.g.; ""``gmake TEST=nightly report``"" should work), it is really easy to run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:6143,Testability,test,testing,6143," run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:6199,Testability,test,test,6199," run; optimizations or code generator components against every program in the; tree, collecting statistics or running custom checks for correctness. At; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:6286,Testability,test,test-suite,6286,"; base, this is how the nightly tester works, it's just one example of a; general framework. Lets say that you have an LLVM optimization pass, and you want to see; how many times it triggers. First thing you should do is add an LLVM; `statistic <ProgrammersManual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for this is in ``test-suite/TEST.libcalls.*``. The format is; pretty simple: the Makefile indicates how to run the test (in this case,; ""``opt -simplify-lib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:7180,Testability,test,test-suite,7180,"anual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for this is in ``test-suite/TEST.libcalls.*``. The format is; pretty simple: the Makefile indicates how to run the test (in this case,; ""``opt -simplify-libcalls -stats``""), and the report contains one line; for each column of the output. The first value is the header for the; column and the second is the regex to grep the output of the command; for. There are lots of example reports that can do fancy stuff.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:7278,Testability,test,test,7278,"anual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for this is in ``test-suite/TEST.libcalls.*``. The format is; pretty simple: the Makefile indicates how to run the test (in this case,; ""``opt -simplify-libcalls -stats``""), and the report contains one line; for each column of the output. The first value is the header for the; column and the second is the regex to grep the output of the command; for. There are lots of example reports that can do fancy stuff.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3538,Usability,guid,guide,3538,"``. Subdirectory; names known to LLVM include:. * spec95. * speccpu2000. * speccpu2006. * povray31. Others are added from time to time, and can be determined from; ``configure``. Running Different Tests; =======================. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3771,Usability,simpl,simple,3771,"====. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:3785,Usability,simpl,simply,3785,"====. In addition to the regular ""whole program"" tests, the ``test-suite``; module also provides a mechanism for compiling the programs in different; ways. If the variable TEST is defined on the ``gmake`` command line, the; test system will include a Makefile named; ``TEST.<value of TEST variable>.Makefile``. This Makefile can modify; build rules to yield different results. For example, the LLVM nightly tester uses ``TEST.nightly.Makefile`` to; create the nightly test reports. To run the nightly tests, run; ``gmake TEST=nightly``. There are several TEST Makefiles available in the tree. Some of them are; designed for internal LLVM research and will not work outside of the; LLVM research group. They may still be valuable, however, as a guide to; writing your own TEST Makefile for any optimization or analysis passes; that you develop with LLVM. Generating Test Output; ======================. There are a number of ways to run the tests and generate output. The; most simple one is simply running ``gmake`` with no arguments. This will; compile and run all programs in the tree using a number of different; methods and compare results. Any failures are reported in the output,; but are likely drowned in the other output. Passes are not reported; explicitly. Somewhat better is running ``gmake TEST=sometest test``, which runs the; specified test and usually adds per-program summaries to the output; (depending on which sometest you use). For example, the ``nightly`` test; explicitly outputs TEST-PASS or TEST-FAIL for every test after each; program. Though these lines are still drowned in the output, it's easy; to grep the output logs in the Output directories. Even better are the ``report`` and ``report.format`` targets (where; ``format`` is one of ``html``, ``csv``, ``text`` or ``graphs``). The; exact contents of the report are dependent on which ``TEST`` you are; running, but the text results are always shown at the end of the run and; the results are always stored in the ``re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:7232,Usability,simpl,simple,7232,"anual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for this is in ``test-suite/TEST.libcalls.*``. The format is; pretty simple: the Makefile indicates how to run the test (in this case,; ""``opt -simplify-libcalls -stats``""), and the report contains one line; for each column of the output. The first value is the header for the; column and the second is the regex to grep the output of the command; for. There are lots of example reports that can do fancy stuff.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst:7307,Usability,simpl,simplify-libcalls,7307,"anual.html#Statistic>`_ to your pass, which will; tally counts of things you care about. Following this, you can set up a test and a report that collects these; and formats them for easy viewing. This consists of two files, a; ""``test-suite/TEST.XXX.Makefile``"" fragment (where XXX is the name of; your test) and a ""``test-suite/TEST.XXX.report``"" file that indicates; how to format the output into a table. There are many example reports of; various levels of sophistication included with the test suite, and the; framework is very general. If you are interested in testing an optimization pass, check out the; ""libcalls"" test as an example. It can be run like this:. .. code-block:: bash. % cd llvm/projects/test-suite/MultiSource/Benchmarks # or some other level; % make TEST=libcalls report. This will do a bunch of stuff, then eventually print a table like this:. ::. Name | total | #exit |; ...; FreeBench/analyzer/analyzer | 51 | 6 |; FreeBench/fourinarow/fourinarow | 1 | 1 |; FreeBench/neural/neural | 19 | 9 |; FreeBench/pifft/pifft | 5 | 3 |; MallocBench/cfrac/cfrac | 1 | * |; MallocBench/espresso/espresso | 52 | 12 |; MallocBench/gs/gs | 4 | * |; Prolangs-C/TimberWolfMC/timberwolfmc | 302 | * |; Prolangs-C/agrep/agrep | 33 | 12 |; Prolangs-C/allroots/allroots | * | * |; Prolangs-C/assembler/assembler | 47 | * |; Prolangs-C/bison/mybison | 74 | * |; ... This basically is grepping the -stats output and displaying it in a; table. You can also use the ""TEST=libcalls report.html"" target to get; the table in HTML form, similarly for report.csv and report.tex. The source for this is in ``test-suite/TEST.libcalls.*``. The format is; pretty simple: the Makefile indicates how to run the test (in this case,; ""``opt -simplify-libcalls -stats``""), and the report contains one line; for each column of the output. The first value is the header for the; column and the second is the regex to grep the output of the command; for. There are lots of example reports that can do fancy stuff.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TestSuiteMakefileGuide.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2062,Deployability,update,updated,2062,"tadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13633,Deployability,pipeline,pipeline,13633,".followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transfor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13697,Deployability,pipeline,pipeline,13697,"ould increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:14750,Deployability,pipeline,pipeline,14750,"imization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another passes' followup; attribute. The pass ``-transform-warning`` (``WarnMissedTransformationsPass``); emits such warnings. It should be placed after the last transformation; pass. The current pass pipeline has a fixed order in which transformations; passes are executed. A transformation can be in the followup of a pass; that is executed later and thus leftover. For instance, a loop nest; cannot be distributed and then interchanged with the current pass; pipeline. The loop distribution will execute, but there is no loop; interchange pass following such that any loop interchange metadata will; be ignored. The ``-transform-warning`` should emit a warning in this; case. Future versions of LLVM may fix this by executing transformations using; a dynamic ordering.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:15115,Deployability,pipeline,pipeline,15115,"imization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another passes' followup; attribute. The pass ``-transform-warning`` (``WarnMissedTransformationsPass``); emits such warnings. It should be placed after the last transformation; pass. The current pass pipeline has a fixed order in which transformations; passes are executed. A transformation can be in the followup of a pass; that is executed later and thus leftover. For instance, a loop nest; cannot be distributed and then interchanged with the current pass; pipeline. The loop distribution will execute, but there is no loop; interchange pass following such that any loop interchange metadata will; be ignored. The ``-transform-warning`` should emit a warning in this; case. Future versions of LLVM may fix this by executing transformations using; a dynamic ordering.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:15376,Deployability,pipeline,pipeline,15376,"imization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another passes' followup; attribute. The pass ``-transform-warning`` (``WarnMissedTransformationsPass``); emits such warnings. It should be placed after the last transformation; pass. The current pass pipeline has a fixed order in which transformations; passes are executed. A transformation can be in the followup of a pass; that is executed later and thus leftover. For instance, a loop nest; cannot be distributed and then interchanged with the current pass; pipeline. The loop distribution will execute, but there is no loop; interchange pass following such that any loop interchange metadata will; be ignored. The ``-transform-warning`` should emit a warning in this; case. Future versions of LLVM may fix this by executing transformations using; a dynamic ordering.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:11758,Integrability,depend,dependencies,11758,"d-jam; as well as an additional inner loop unrolling. If no follow-up; attribute specified for a generated loop, it is added automatically. Loop Distribution; -----------------. The LoopDistribution pass tries to separate vectorizable parts of a loop; from the non-vectorizable part (which otherwise would make the entire; loop non-vectorizable). Conceptually, it transforms a loop such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would incr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12019,Integrability,depend,dependencies,12019,"he non-vectorizable part (which otherwise would make the entire; loop non-vectorizable). Conceptually, it transforms a loop such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13597,Integrability,depend,depends,13597,".followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transfor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:11872,Modifiability,inherit,inherit,11872,"ibution; -----------------. The LoopDistribution pass tries to separate vectorizable parts of a loop; from the non-vectorizable part (which otherwise would make the entire; loop non-vectorizable). Conceptually, it transforms a loop such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. F",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12103,Modifiability,inherit,inherit,12103,"such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12347,Modifiability,inherit,inherits,12347," for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:339,Performance,perform,perform,339,".. _transformation-metadata:. ============================; Code Transformation Metadata; ============================. .. contents::; :local:. Overview; ========. LLVM transformation passes can be controlled by attaching metadata to; the code to transform. By default, transformation passes use heuristics; to determine whether or not to perform transformations, and when doing; so, other details of how the transformations are applied (e.g., which; vectorization factor to select).; Unless the optimizer is otherwise directed, transformations are applied; conservatively. This conservatism generally allows the optimizer to; avoid unprofitable transformations, but in practice, this results in the; optimizer not applying transformations that would be highly profitable. Frontends can give additional hints to LLVM passes on which; transformations they should apply. This can be additional knowledge that; cannot be derived from the emitted IR, or directives passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attribut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:496,Performance,optimiz,optimizer,496,".. _transformation-metadata:. ============================; Code Transformation Metadata; ============================. .. contents::; :local:. Overview; ========. LLVM transformation passes can be controlled by attaching metadata to; the code to transform. By default, transformation passes use heuristics; to determine whether or not to perform transformations, and when doing; so, other details of how the transformations are applied (e.g., which; vectorization factor to select).; Unless the optimizer is otherwise directed, transformations are applied; conservatively. This conservatism generally allows the optimizer to; avoid unprofitable transformations, but in practice, this results in the; optimizer not applying transformations that would be highly profitable. Frontends can give additional hints to LLVM passes on which; transformations they should apply. This can be additional knowledge that; cannot be derived from the emitted IR, or directives passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attribut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:613,Performance,optimiz,optimizer,613,".. _transformation-metadata:. ============================; Code Transformation Metadata; ============================. .. contents::; :local:. Overview; ========. LLVM transformation passes can be controlled by attaching metadata to; the code to transform. By default, transformation passes use heuristics; to determine whether or not to perform transformations, and when doing; so, other details of how the transformations are applied (e.g., which; vectorization factor to select).; Unless the optimizer is otherwise directed, transformations are applied; conservatively. This conservatism generally allows the optimizer to; avoid unprofitable transformations, but in practice, this results in the; optimizer not applying transformations that would be highly profitable. Frontends can give additional hints to LLVM passes on which; transformations they should apply. This can be additional knowledge that; cannot be derived from the emitted IR, or directives passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attribut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:701,Performance,optimiz,optimizer,701,".. _transformation-metadata:. ============================; Code Transformation Metadata; ============================. .. contents::; :local:. Overview; ========. LLVM transformation passes can be controlled by attaching metadata to; the code to transform. By default, transformation passes use heuristics; to determine whether or not to perform transformations, and when doing; so, other details of how the transformations are applied (e.g., which; vectorization factor to select).; Unless the optimizer is otherwise directed, transformations are applied; conservatively. This conservatism generally allows the optimizer to; avoid unprofitable transformations, but in practice, this results in the; optimizer not applying transformations that would be highly profitable. Frontends can give additional hints to LLVM passes on which; transformations they should apply. This can be additional knowledge that; cannot be derived from the emitted IR, or directives passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attribut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2290,Performance,optimiz,optimizer,2290,"ns. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2563,Performance,optimiz,optimization-missed,2563,"op attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enab",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2729,Performance,optimiz,optimizer,2729," node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additiona",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2802,Performance,optimiz,optimization,2802,"nstance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additional attributes; including followup-transformations to be specified. Specifying multiple; transformations in th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:5481,Performance,optimiz,optimization,5481,"y add attributes itself.; For instance, the vectorizer adds a ``llvm.loop.isvectorized`` attribute and; all attributes from the original loop excluding its loop vectorizer; attributes. To avoid this, an empty followup attribute can be used, e.g. .. code-block:: llvm. !3 = !{!""llvm.loop.vectorize.followup_vectorized""}. The followup attributes of a transformation that cannot be applied will; never be added to a loop and are therefore effectively ignored. This means; that any followup-transformation in such attributes requires that its; prior transformations are applied before the followup-transformation.; The user should receive a warning about the first transformation in the; transformation chain that could not be applied if it a forced; transformation. All following transformations are skipped. Pass-Specific Transformation Metadata; =====================================. Transformation options are specific to each transformation. In the; following, we present the model for each LLVM loop optimization pass and; the metadata to influence them. Loop Vectorization and Interleaving; -----------------------------------. Loop vectorization and interleaving is interpreted as a single; transformation. It is interpreted as forced if; ``!{""llvm.loop.vectorize.enable"", i1 true}`` is set. Assuming the pre-vectorization loop is. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. then the code after vectorization will be approximately (assuming an; SIMD width of 4):. .. code-block:: c. int i = 0;; if (rtc) {; for (; i + 3 < n; i+=4) // vectorized/interleaved loop; Stmt(i:i+3);; }; for (; i < n; i+=1) // epilogue loop; Stmt(i);. where ``rtc`` is a generated runtime check. ``llvm.loop.vectorize.followup_vectorized`` will set the attributes for; the vectorized loop. If not specified, ``llvm.loop.isvectorized`` is; combined with the original loop's attributes to avoid it being; vectorized multiple times. ``llvm.loop.vectorize.followup_epilogue`` will set the a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:7079,Performance,optimiz,optimize,7079,"/interleaved loop; Stmt(i:i+3);; }; for (; i < n; i+=1) // epilogue loop; Stmt(i);. where ``rtc`` is a generated runtime check. ``llvm.loop.vectorize.followup_vectorized`` will set the attributes for; the vectorized loop. If not specified, ``llvm.loop.isvectorized`` is; combined with the original loop's attributes to avoid it being; vectorized multiple times. ``llvm.loop.vectorize.followup_epilogue`` will set the attributes for; the remainder loop. If not specified, it will have the original loop's; attributes combined with ``llvm.loop.isvectorized`` and; ``llvm.loop.unroll.runtime.disable`` (unless the original loop already; has unroll metadata). The attributes specified by ``llvm.loop.vectorize.followup_all`` are; added to both loops. When using a follow-up attribute, it replaces any automatically deduced; attributes for the generated loop in question. Therefore it is; recommended to add ``llvm.loop.isvectorized`` to; ``llvm.loop.vectorize.followup_all`` which avoids that the loop; vectorizer tries to optimize the loops again. Loop Unrolling; --------------. Unrolling is interpreted as forced any ``!{!""llvm.loop.unroll.enable""}``; metadata or option (``llvm.loop.unroll.count``, ``llvm.loop.unroll.full``); is present. Unrolling can be full unrolling, partial unrolling of a loop; with constant trip count or runtime unrolling of a loop with a trip; count unknown at compile-time. If the loop has been unrolled fully, there is no followup-loop. For; partial/runtime unrolling, the original loop of. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. is transformed into (using an unroll factor of 4):. .. code-block:: c. int i = 0;; for (; i + 3 < n; i+=4) { // unrolled loop; Stmt(i);; Stmt(i+1);; Stmt(i+2);; Stmt(i+3);; }; for (; i < n; i+=1) // remainder loop; Stmt(i);. ``llvm.loop.unroll.followup_unrolled`` will set the loop attributes of; the unrolled loop. If not specified, the attributes of the original loop; without the ``llvm.loop.unroll.*``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12698,Performance,optimiz,optimized,12698,"lowup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13684,Performance,optimiz,optimization,13684,"ould increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:13872,Performance,perform,performs,13872,"lock:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:14162,Performance,perform,performs,14162,"= B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another passes' followup; attribute. The pass ``-transform-warning`` (``WarnMissedTransformationsPass``); emits such warnings. It should be placed after the last transformation; pass. The current pass pipeline has a fixed order in which transformations; pa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:14326,Performance,perform,performs,14326,"--------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The default optimization pipeline (anything higher than; ``-O0``) has the following order. When using the legacy pass manager:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - VersioningLICM (if enabled); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). When using the legacy pass manager with LTO:. - LoopInterchange (if enabled); - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopVectorizer; - LoopUnroll (partial and runtime unrolling). When using the new pass manager:. - SimpleLoopUnroll/LoopFullUnroll (only performs full unrolling); - LoopDistribute; - LoopVectorizer; - LoopUnrollAndJam (if enabled); - LoopUnroll (partial and runtime unrolling). Leftover Transformations; ========================. Forced transformations that have not been applied after the last; transformation pass should be reported to the user. The transformation; passes themselves cannot be responsible for this reporting because they; might not be in the pipeline, there might be multiple passes able to; apply a transformation (e.g. ``LoopInterchange`` and Polly) or a; transformation attribute may be 'hidden' inside another passes' followup; attribute. The pass ``-transform-warning`` (``WarnMissedTransformationsPass``); emits such warnings. It should be placed after the last transformation; pass. The current pass pipeline has a fixed order in which transformations; passes are executed. A transformation can be in the followup of a pass; that is executed later and thus leftover. For instance, a loop nest; cannot be distributed and then interchanged with the current pass; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:627,Safety,avoid,avoid,627,".. _transformation-metadata:. ============================; Code Transformation Metadata; ============================. .. contents::; :local:. Overview; ========. LLVM transformation passes can be controlled by attaching metadata to; the code to transform. By default, transformation passes use heuristics; to determine whether or not to perform transformations, and when doing; so, other details of how the transformations are applied (e.g., which; vectorization factor to select).; Unless the optimizer is otherwise directed, transformations are applied; conservatively. This conservatism generally allows the optimizer to; avoid unprofitable transformations, but in practice, this results in the; optimizer not applying transformations that would be highly profitable. Frontends can give additional hints to LLVM passes on which; transformations they should apply. This can be additional knowledge that; cannot be derived from the emitted IR, or directives passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attribut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:2661,Safety,safe,safe,2661,"ata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:3104,Safety,avoid,avoid,3104,"============. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additional attributes; including followup-transformations to be specified. Specifying multiple; transformations in the same metadata node is possible for compatibility; reasons, but their execution order is undefined. For instance, when; ``llvm.loop.vectorize.enable`` and ``llvm.loop.unroll.enable`` are; specified at the same time, unrolling may occur either before or after; vectorization. As an example, the following instru",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:3305,Safety,avoid,avoids,3305,"eficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, applying a different; transformation before it might be inadvertent due to being applied on a; different loop or the loop not existing anymore. To avoid having to; explicitly disable an unknown number of passes, the attribute; ``llvm.loop.disable_nonforced`` disables all optional, high-level,; restructuring transformations. The following example avoids the loop being altered before being; vectorized, for instance being unrolled. .. code-block:: llvm. br i1 %exitcond, label %for.exit, label %for.header, !llvm.loop !0; ...; !0 = distinct !{!0, !1, !2}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}. After a transformation is applied, follow-up attributes are set on the; transformed and/or new loop(s). This allows additional attributes; including followup-transformations to be specified. Specifying multiple; transformations in the same metadata node is possible for compatibility; reasons, but their execution order is undefined. For instance, when; ``llvm.loop.vectorize.enable`` and ``llvm.loop.unroll.enable`` are; specified at the same time, unrolling may occur either before or after; vectorization. As an example, the following instructs a loop to be vectorized and only; then unrolled. .. code-block:: llvm. !0 = distinct !{!0, !1, !2, !3}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:4666,Safety,avoid,avoid,4666,"r new loop(s). This allows additional attributes; including followup-transformations to be specified. Specifying multiple; transformations in the same metadata node is possible for compatibility; reasons, but their execution order is undefined. For instance, when; ``llvm.loop.vectorize.enable`` and ``llvm.loop.unroll.enable`` are; specified at the same time, unrolling may occur either before or after; vectorization. As an example, the following instructs a loop to be vectorized and only; then unrolled. .. code-block:: llvm. !0 = distinct !{!0, !1, !2, !3}; !1 = !{!""llvm.loop.vectorize.enable"", i1 true}; !2 = !{!""llvm.loop.disable_nonforced""}; !3 = !{!""llvm.loop.vectorize.followup_vectorized"", !{""llvm.loop.unroll.enable""}}. If, and only if, no followup is specified, the pass may add attributes itself.; For instance, the vectorizer adds a ``llvm.loop.isvectorized`` attribute and; all attributes from the original loop excluding its loop vectorizer; attributes. To avoid this, an empty followup attribute can be used, e.g. .. code-block:: llvm. !3 = !{!""llvm.loop.vectorize.followup_vectorized""}. The followup attributes of a transformation that cannot be applied will; never be added to a loop and are therefore effectively ignored. This means; that any followup-transformation in such attributes requires that its; prior transformations are applied before the followup-transformation.; The user should receive a warning about the first transformation in the; transformation chain that could not be applied if it a forced; transformation. All following transformations are skipped. Pass-Specific Transformation Metadata; =====================================. Transformation options are specific to each transformation. In the; following, we present the model for each LLVM loop optimization pass and; the metadata to influence them. Loop Vectorization and Interleaving; -----------------------------------. Loop vectorization and interleaving is interpreted as a single; transformation. It",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:6379,Safety,avoid,avoid,6379,"sformation options are specific to each transformation. In the; following, we present the model for each LLVM loop optimization pass and; the metadata to influence them. Loop Vectorization and Interleaving; -----------------------------------. Loop vectorization and interleaving is interpreted as a single; transformation. It is interpreted as forced if; ``!{""llvm.loop.vectorize.enable"", i1 true}`` is set. Assuming the pre-vectorization loop is. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. then the code after vectorization will be approximately (assuming an; SIMD width of 4):. .. code-block:: c. int i = 0;; if (rtc) {; for (; i + 3 < n; i+=4) // vectorized/interleaved loop; Stmt(i:i+3);; }; for (; i < n; i+=1) // epilogue loop; Stmt(i);. where ``rtc`` is a generated runtime check. ``llvm.loop.vectorize.followup_vectorized`` will set the attributes for; the vectorized loop. If not specified, ``llvm.loop.isvectorized`` is; combined with the original loop's attributes to avoid it being; vectorized multiple times. ``llvm.loop.vectorize.followup_epilogue`` will set the attributes for; the remainder loop. If not specified, it will have the original loop's; attributes combined with ``llvm.loop.isvectorized`` and; ``llvm.loop.unroll.runtime.disable`` (unless the original loop already; has unroll metadata). The attributes specified by ``llvm.loop.vectorize.followup_all`` are; added to both loops. When using a follow-up attribute, it replaces any automatically deduced; attributes for the generated loop in question. Therefore it is; recommended to add ``llvm.loop.isvectorized`` to; ``llvm.loop.vectorize.followup_all`` which avoids that the loop; vectorizer tries to optimize the loops again. Loop Unrolling; --------------. Unrolling is interpreted as forced any ``!{!""llvm.loop.unroll.enable""}``; metadata or option (``llvm.loop.unroll.count``, ``llvm.loop.unroll.full``); is present. Unrolling can be full unrolling, partial unrolling of a loop; with c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:7037,Safety,avoid,avoids,7037,"/interleaved loop; Stmt(i:i+3);; }; for (; i < n; i+=1) // epilogue loop; Stmt(i);. where ``rtc`` is a generated runtime check. ``llvm.loop.vectorize.followup_vectorized`` will set the attributes for; the vectorized loop. If not specified, ``llvm.loop.isvectorized`` is; combined with the original loop's attributes to avoid it being; vectorized multiple times. ``llvm.loop.vectorize.followup_epilogue`` will set the attributes for; the remainder loop. If not specified, it will have the original loop's; attributes combined with ``llvm.loop.isvectorized`` and; ``llvm.loop.unroll.runtime.disable`` (unless the original loop already; has unroll metadata). The attributes specified by ``llvm.loop.vectorize.followup_all`` are; added to both loops. When using a follow-up attribute, it replaces any automatically deduced; attributes for the generated loop in question. Therefore it is; recommended to add ``llvm.loop.isvectorized`` to; ``llvm.loop.vectorize.followup_all`` which avoids that the loop; vectorizer tries to optimize the loops again. Loop Unrolling; --------------. Unrolling is interpreted as forced any ``!{!""llvm.loop.unroll.enable""}``; metadata or option (``llvm.loop.unroll.count``, ``llvm.loop.unroll.full``); is present. Unrolling can be full unrolling, partial unrolling of a loop; with constant trip count or runtime unrolling of a loop with a trip; count unknown at compile-time. If the loop has been unrolled fully, there is no followup-loop. For; partial/runtime unrolling, the original loop of. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. is transformed into (using an unroll factor of 4):. .. code-block:: c. int i = 0;; for (; i + 3 < n; i+=4) { // unrolled loop; Stmt(i);; Stmt(i+1);; Stmt(i+2);; Stmt(i+3);; }; for (; i < n; i+=1) // remainder loop; Stmt(i);. ``llvm.loop.unroll.followup_unrolled`` will set the loop attributes of; the unrolled loop. If not specified, the attributes of the original loop; without the ``llvm.loop.unroll.*``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:8499,Safety,avoid,avoid,8499,"ime unrolling, the original loop of. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; Stmt(i);. is transformed into (using an unroll factor of 4):. .. code-block:: c. int i = 0;; for (; i + 3 < n; i+=4) { // unrolled loop; Stmt(i);; Stmt(i+1);; Stmt(i+2);; Stmt(i+3);; }; for (; i < n; i+=1) // remainder loop; Stmt(i);. ``llvm.loop.unroll.followup_unrolled`` will set the loop attributes of; the unrolled loop. If not specified, the attributes of the original loop; without the ``llvm.loop.unroll.*`` attributes are copied and; ``llvm.loop.unroll.disable`` added to it. ``llvm.loop.unroll.followup_remainder`` defines the attributes of the; remainder loop. If not specified the remainder loop will have no; attributes. The remainder loop might not be present due to being fully; unrolled in which case this attribute has no effect. Attributes defined in ``llvm.loop.unroll.followup_all`` are added to the; unrolled and remainder loops. To avoid that the partially unrolled loop is unrolled again, it is; recommended to add ``llvm.loop.unroll.disable`` to; ``llvm.loop.unroll.followup_all``. If no follow-up attribute specified; for a generated loop, it is added automatically. Unroll-And-Jam; --------------. Unroll-and-jam uses the following transformation model (here with an; unroll factor if 2). Currently, it does not support a fallback version; when the transformation is unsafe. .. code-block:: c. for (int i = 0; i < n; i+=1) { // original outer loop; Fore(i);; for (int j = 0; j < m; j+=1) // original inner loop; SubLoop(i, j);; Aft(i);; }. .. code-block:: c. int i = 0;; for (; i + 1 < n; i+=2) { // unrolled outer loop; Fore(i);; Fore(i+1);; for (int j = 0; j < m; j+=1) { // unrolled inner loop; SubLoop(i, j);; SubLoop(i+1, j);; }; Aft(i);; Aft(i+1);; }; for (; i < n; i+=1) { // remainder outer loop; Fore(i);; for (int j = 0; j < m; j+=1) // remainder inner loop; SubLoop(i, j);; Aft(i);; }. ``llvm.loop.unroll_and_jam.followup_outer`` will set the loop attributes; o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:8938,Safety,unsafe,unsafe,8938,"lowup_unrolled`` will set the loop attributes of; the unrolled loop. If not specified, the attributes of the original loop; without the ``llvm.loop.unroll.*`` attributes are copied and; ``llvm.loop.unroll.disable`` added to it. ``llvm.loop.unroll.followup_remainder`` defines the attributes of the; remainder loop. If not specified the remainder loop will have no; attributes. The remainder loop might not be present due to being fully; unrolled in which case this attribute has no effect. Attributes defined in ``llvm.loop.unroll.followup_all`` are added to the; unrolled and remainder loops. To avoid that the partially unrolled loop is unrolled again, it is; recommended to add ``llvm.loop.unroll.disable`` to; ``llvm.loop.unroll.followup_all``. If no follow-up attribute specified; for a generated loop, it is added automatically. Unroll-And-Jam; --------------. Unroll-and-jam uses the following transformation model (here with an; unroll factor if 2). Currently, it does not support a fallback version; when the transformation is unsafe. .. code-block:: c. for (int i = 0; i < n; i+=1) { // original outer loop; Fore(i);; for (int j = 0; j < m; j+=1) // original inner loop; SubLoop(i, j);; Aft(i);; }. .. code-block:: c. int i = 0;; for (; i + 1 < n; i+=2) { // unrolled outer loop; Fore(i);; Fore(i+1);; for (int j = 0; j < m; j+=1) { // unrolled inner loop; SubLoop(i, j);; SubLoop(i+1, j);; }; Aft(i);; Aft(i+1);; }; for (; i < n; i+=1) { // remainder outer loop; Fore(i);; for (int j = 0; j < m; j+=1) // remainder inner loop; SubLoop(i, j);; Aft(i);; }. ``llvm.loop.unroll_and_jam.followup_outer`` will set the loop attributes; of the unrolled outer loop. If not specified, the attributes of the; original outer loop without the ``llvm.loop.unroll.*`` attributes are; copied and ``llvm.loop.unroll.disable`` added to it. ``llvm.loop.unroll_and_jam.followup_inner`` will set the loop attributes; of the unrolled inner loop. If not specified, the attributes of the; original inner loop are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:10552,Safety,avoid,avoid,10552,"e attributes of the; original outer loop without the ``llvm.loop.unroll.*`` attributes are; copied and ``llvm.loop.unroll.disable`` added to it. ``llvm.loop.unroll_and_jam.followup_inner`` will set the loop attributes; of the unrolled inner loop. If not specified, the attributes of the; original inner loop are used unchanged. ``llvm.loop.unroll_and_jam.followup_remainder_outer`` sets the loop; attributes of the outer remainder loop. If not specified it will not; have any attributes. The remainder loop might not be present due to; being fully unrolled. ``llvm.loop.unroll_and_jam.followup_remainder_inner`` sets the loop; attributes of the inner remainder loop. If not specified it will have; the attributes of the original inner loop. It the outer remainder loop; is unrolled, the inner remainder loop might be present multiple times. Attributes defined in ``llvm.loop.unroll_and_jam.followup_all`` are; added to all of the aforementioned output loops. To avoid that the unrolled loop is unrolled again, it is; recommended to add ``llvm.loop.unroll.disable`` to; ``llvm.loop.unroll_and_jam.followup_all``. It suppresses unroll-and-jam; as well as an additional inner loop unrolling. If no follow-up; attribute specified for a generated loop, it is added automatically. Loop Distribution; -----------------. The LoopDistribution pass tries to separate vectorizable parts of a loop; from the non-vectorizable part (which otherwise would make the entire; loop non-vectorizable). Conceptually, it transforms a loop such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 +",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12012,Safety,unsafe,unsafe,12012,"he non-vectorizable part (which otherwise would make the entire; loop non-vectorizable). Conceptually, it transforms a loop such as. .. code-block:: c. for (int i = 1; i < n; i+=1) { // original loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }. into the following code:. .. code-block:: c. if (rtc) {; for (int i = 1; i < n; i+=1) // coincident loop; A[i] = i;; for (int i = 1; i < n; i+=1) // coincident loop; B[i] = 2 + B[i];; for (int i = 1; i < n; i+=1) // sequential loop; C[i] = 3 + C[i - 1];; } else {; for (int i = 1; i < n; i+=1) { // fallback loop; A[i] = i;; B[i] = 2 + B[i];; C[i] = 3 + C[i - 1];; }; }. where ``rtc`` is a generated runtime check. ``llvm.loop.distribute.followup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:12620,Safety,avoid,avoids,12620,"lowup_coincident`` sets the loop attributes of; all loops without loop-carried dependencies (i.e. vectorizable loops).; There might be more than one such loops. If not defined, the loops will; inherit the original loop's attributes. ``llvm.loop.distribute.followup_sequential`` sets the loop attributes of the; loop with potentially unsafe dependencies. There should be at most one; such loop. If not defined, the loop will inherit the original loop's; attributes. ``llvm.loop.distribute.followup_fallback`` defines the loop attributes; for the fallback loop, which is a copy of the original loop for when; loop versioning is required. If undefined, the fallback loop inherits; all attributes from the original loop. Attributes defined in ``llvm.loop.distribute.followup_all`` are added to; all of the aforementioned output loops. It is recommended to add ``llvm.loop.disable_nonforced`` to; ``llvm.loop.distribute.followup_fallback``. This avoids that the; fallback version (which is likely never executed) is further optimized; which would increase the code size. Versioning LICM; ---------------. The pass hoists code out of loops that are only loop-invariant when; dynamic conditions apply. For instance, it transforms the loop. .. code-block:: c. for (int i = 0; i < n; i+=1) // original loop; A[i] = B[0];. into:. .. code-block:: c. if (rtc) {; auto b = B[0];; for (int i = 0; i < n; i+=1) // versioned loop; A[i] = b;; } else {; for (int i = 0; i < n; i+=1) // unversioned loop; A[i] = B[0];; }. The runtime condition (``rtc``) checks that the array ``A`` and the; element `B[0]` do not alias. Currently, this transformation does not support followup-attributes. Loop Interchange; ----------------. Currently, the ``LoopInterchange`` pass does not use any metadata. Ambiguous Transformation Order; ==============================. If there multiple transformations defined, the order in which they are; executed depends on the order in LLVM's pass pipeline, which is subject; to change. The def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst:1930,Security,access,access,1930,"es passed from the; user/programmer. OpenMP pragmas are an example of the latter. If any such metadata is dropped from the program, the code's semantics; must not change. Metadata on Loops; =================. Attributes can be attached to loops as described in :ref:`llvm.loop`.; Attributes can describe properties of the loop, disable transformations,; force specific transformations and set transformation options. Because metadata nodes are immutable (with the exception of; ``MDNode::replaceOperandWith`` which is dangerous to use on uniqued; metadata), in order to add or remove a loop attributes, a new ``MDNode``; must be created and assigned as the new ``llvm.loop`` metadata. Any; connection between the old ``MDNode`` and the loop is lost. The; ``llvm.loop`` node is also used as LoopID (``Loop::getLoopID()``), i.e.; the loop effectively gets a new identifier. For instance,; ``llvm.mem.parallel_loop_access`` references the LoopID. Therefore, if; the parallel access property is to be preserved after adding/removing; loop attributes, any ``llvm.mem.parallel_loop_access`` reference must be; updated to the new LoopID. Transformation Metadata Structure; =================================. Some attributes describe code transformations (unrolling, vectorizing,; loop distribution, etc.). They can either be a hint to the optimizer; that a transformation might be beneficial, instruction to use a specific; option, , or convey a specific request from the user (such as; ``#pragma clang loop`` or ``#pragma omp simd``). If a transformation is forced but cannot be carried-out for any reason,; an optimization-missed warning must be emitted. Semantic information; such as a transformation being safe (e.g.; ``llvm.mem.parallel_loop_access``) can be unused by the optimizer; without generating a warning. Unless explicitly disabled, any optimization pass may heuristically; determine whether a transformation is beneficial and apply it. If; metadata for another transformation was specified, ap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TransformMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TransformMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5544,Availability,avail,available,5544,"`!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:6252,Availability,avail,available,6252,"will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:264,Energy Efficiency,efficient,efficiently,264,"=============; Type Metadata; =============. Type metadata is a mechanism that allows IR modules to co-operatively build; pointer sets corresponding to addresses within a given set of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5153,Energy Efficiency,efficient,efficient,5153,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:6623,Energy Efficiency,efficient,efficiently,6623,"tegrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:928,Modifiability,variab,variables,928,"=============; Type Metadata; =============. Type metadata is a mechanism that allows IR modules to co-operatively build; pointer sets corresponding to addresses within a given set of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:1549,Modifiability,inherit,inheritance,1549," mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::offset-to-top, &B::rtti, &B::f, &B::g; C, C::offset-to-top, &C::rtti, &C::h; D, D::offset-to-top, &D::rtti, &D::f, &D::h, D::offset-to-top, &D::rtti, thunk for &D::h. When an object of type A is constructed, the address of ``&A::f`` in A's; virtual table object is stored in the object's vtable pointer. In ABI parlance; this address is known as an `address point`_. Similarly, when an object of type; B is constructed, the address of ``&B::f`` is stored in the vtable pointer. In; this way, the vtable in B's virtual table object is compatible wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:2622,Modifiability,inherit,inheritance,2622,"ct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::offset-to-top, &B::rtti, &B::f, &B::g; C, C::offset-to-top, &C::rtti, &C::h; D, D::offset-to-top, &D::rtti, &D::f, &D::h, D::offset-to-top, &D::rtti, thunk for &D::h. When an object of type A is constructed, the address of ``&A::f`` in A's; virtual table object is stored in the object's vtable pointer. In ABI parlance; this address is known as an `address point`_. Similarly, when an object of type; B is constructed, the address of ``&B::f`` is stored in the vtable pointer. In; this way, the vtable in B's virtual table object is compatible with A's vtable. D is a little more complicated, due to the use of multiple inheritance. Its; virtual table object contains two vtables, one compatible with A's vtable and; the other compatible with C's vtable. Objects of type D contain two virtual; pointers, one belonging to the A subobject and containing the address of; the vtable compatible with A's vtable, and the other belonging to the C; subobject and containing the address of the vtable compatible with C's vtable. The full set of compatibility information for the above class hierarchy is; shown below. The following table shows the name of a class, the offset of an; address point within that class's vtable and the name of one of the classes; with which that address point is compatible. .. csv-table:: Type Offsets for A, B, C, D; :header: VTable for, Offset, Compatible Class. A, 16, A; B, 16, A; , , B; C, 16, C; D, 16, A; , , D; , 48, C. The next step is to encode this compatibility information into the IR. The way; this is done is to create type metadata named after each of the co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:9594,Modifiability,inherit,inherited,9594,"l call which could use it is known to the compiler, or; whether another translation unit could introduce more calls through the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:4708,Performance,load,load,4708,"ty; information for the above hierarchy:. ::. @_ZTV1A = constant [...], !type !0; @_ZTV1B = constant [...], !type !0, !type !1; @_ZTV1C = constant [...], !type !2; @_ZTV1D = constant [...], !type !0, !type !3, !type !4. !0 = !{i64 16, !""_ZTS1A""}; !1 = !{i64 16, !""_ZTS1B""}; !2 = !{i64 16, !""_ZTS1C""}; !3 = !{i64 16, !""_ZTS1D""}; !4 = !{i64 48, !""_ZTS1C""}. With this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5073,Performance,optimiz,optimization,5073,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5171,Performance,perform,perform,5171,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:9292,Performance,load,load,9292,"ithub.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.h. ``!vcall_visibility`` Metadata; ==============================. In order to allow removing unused function pointers from vtables, we need to; know whether every virtual call which could use it is known to the compiler, or; whether another translation unit could introduce more calls through the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all functio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10176,Performance,perform,performed,10176,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10335,Performance,load,loads,10335,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10475,Performance,load,load,10475,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10494,Performance,load,load,10494,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10593,Performance,load,load,10593,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10693,Performance,load,loads,10693,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:215,Security,integrity,integrity,215,"=============; Type Metadata; =============. Type metadata is a mechanism that allows IR modules to co-operatively build; pointer sets corresponding to addresses within a given set of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:1240,Security,integrity,integrity,1240,"s this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::offset-to-top, &B::rtti, &B::f, &B::g; C, C::offset-to-top, &C::rtti, &C::h; D, D::offset-to-top, &D::rtti, &D::f, &D::h, D::offset-to-top, &D::rtti, thunk for &D::h. When an object of type A is constructed, the address of ``&A::f`` in A's; vir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5612,Security,integrity,integrity,5612,"B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for layi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:6701,Security,integrity,integrity,6701,"ble,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast void ()* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid3""); ret i1 %x; }. defi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:10671,Security,access,accessed,10671,"gh the vtable.; This is not the same as the linkage of the vtable, because call sites could be; using a pointer of a more widely-visible base class. For example, consider this; code:. .. code-block:: c++. __attribute__((visibility(""default""))); struct A {; virtual void f();; };. __attribute__((visibility(""hidden""))); struct B : A {; virtual void f();; };. With LTO, we know that all code which can see the declaration of ``B`` is; visible to us. However, a pointer to a ``B`` could be cast to ``A*`` and passed; to another linkage unit, which could then call ``f`` on it. This call would; load from the vtable for ``B`` (using the object pointer), and then call; ``B::f``. This means we can't remove the function pointer from ``B``'s vtable,; or the implementation of ``B::f``. However, if we can see all code which knows; about any dynamic base class (which would be the case if ``B`` only inherited; from classes with hidden visibility), then this optimisation would be valid. This concept is represented in IR by the ``!vcall_visibility`` metadata; attached to vtable objects, with the following values:. .. list-table::; :header-rows: 1; :widths: 10 90. * - Value; - Behavior. * - 0 (or omitted); - **Public**; Virtual function calls using this vtable could be made from external; code. * - 1; - **Linkage Unit**; All virtual function calls which might use this vtable are in the; current LTO unit, meaning they will be in the current module once; LTO linking has been performed. * - 2; - **Translation Unit**; All virtual function calls which might use this vtable are in the; current module. In addition, all function pointer loads from a vtable marked with the; ``!vcall_visibility`` metadata (with a non-zero value) must be done using the; :ref:`llvm.type.checked.load <type.checked.load>` intrinsic, so that virtual; calls sites can be correlated with the vtables which they might load from.; Other parts of the vtable (RTTI, offset-to-top, ...) can still be accessed with; normal loads.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:1125,Testability,test,test,1125,"sets corresponding to addresses within a given set of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::offset-to-top, &B::rtti, &B::f, &B::g; C, C::offset-to-top, &C::rtti, &C::h; D, D::offset-to-top, &D::rtti, &D::f, &D::h, D::offse",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:1136,Testability,test,test,1136,"t of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::offset-to-top, &B::rtti, &B::f, &B::g; C, C::offset-to-top, &C::rtti, &C::h; D, D::offset-to-top, &D::rtti, &D::f, &D::h, D::offset-to-top, &D::rtti, thunk for &D::h. When an obj",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:1155,Testability,test,test,1155,"t of globals. LLVM's; `control flow integrity`_ implementation uses this metadata to efficiently; check (at each call site) that a given address corresponds to either a; valid vtable or function pointer for a given class or function type, and its; whole-program devirtualization pass uses the metadata to identify potential; callees for a given virtual call. To use the mechanism, a client creates metadata nodes with two elements:. 1. a byte offset into the global (generally zero for functions); 2. a metadata object representing an identifier for the type. These metadata nodes are associated with globals by using global object; metadata attachments with the ``!type`` metadata kind. Each type identifier must exclusively identify either global variables; or functions. .. admonition:: Limitation. The current implementation only supports attaching metadata to functions on; the x86-32 and x86-64 architectures. An intrinsic, :ref:`llvm.type.test <type.test>`, is used to test whether a; given pointer is associated with a type identifier. .. _control flow integrity: https://clang.llvm.org/docs/ControlFlowIntegrity.html. Representing Type Information using Type Metadata; =================================================. This section describes how Clang represents C++ type information associated with; virtual tables using type metadata. Consider the following inheritance hierarchy:. .. code-block:: c++. struct A {; virtual void f();; };. struct B : A {; virtual void f();; virtual void g();; };. struct C {; virtual void h();; };. struct D : A, C {; virtual void f();; virtual void h();; };. The virtual table objects for A, B, C and D look like this (under the Itanium ABI):. .. csv-table:: Virtual Table Layout for A, B, C, D; :header: Class, 0, 1, 2, 3, 4, 5, 6. A, A::offset-to-top, &A::rtti, &A::f; B, B::offset-to-top, &B::rtti, &B::f, &B::g; C, C::offset-to-top, &C::rtti, &C::h; D, D::offset-to-top, &D::rtti, &D::f, &D::h, D::offset-to-top, &D::rtti, thunk for &D::h. When an obj",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:4170,Testability,test,test,4170,"ble and the name of one of the classes; with which that address point is compatible. .. csv-table:: Type Offsets for A, B, C, D; :header: VTable for, Offset, Compatible Class. A, 16, A; B, 16, A; , , B; C, 16, C; D, 16, A; , , D; , 48, C. The next step is to encode this compatibility information into the IR. The way; this is done is to create type metadata named after each of the compatible; classes, with which we associate each of the compatible address points in; each vtable. For example, these type metadata entries encode the compatibility; information for the above hierarchy:. ::. @_ZTV1A = constant [...], !type !0; @_ZTV1B = constant [...], !type !0, !type !1; @_ZTV1C = constant [...], !type !2; @_ZTV1D = constant [...], !type !0, !type !3, !type !4. !0 = !{i64 16, !""_ZTS1A""}; !1 = !{i64 16, !""_ZTS1B""}; !2 = !{i64 16, !""_ZTS1C""}; !3 = !{i64 16, !""_ZTS1D""}; !4 = !{i64 48, !""_ZTS1C""}. With this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:4191,Testability,test,test,4191,"ble and the name of one of the classes; with which that address point is compatible. .. csv-table:: Type Offsets for A, B, C, D; :header: VTable for, Offset, Compatible Class. A, 16, A; B, 16, A; , , B; C, 16, C; D, 16, A; , , D; , 48, C. The next step is to encode this compatibility information into the IR. The way; this is done is to create type metadata named after each of the compatible; classes, with which we associate each of the compatible address points in; each vtable. For example, these type metadata entries encode the compatibility; information for the above hierarchy:. ::. @_ZTV1A = constant [...], !type !0; @_ZTV1B = constant [...], !type !0, !type !1; @_ZTV1C = constant [...], !type !2; @_ZTV1D = constant [...], !type !0, !type !3, !type !4. !0 = !{i64 16, !""_ZTS1A""}; !1 = !{i64 16, !""_ZTS1B""}; !2 = !{i64 16, !""_ZTS1C""}; !3 = !{i64 16, !""_ZTS1D""}; !4 = !{i64 48, !""_ZTS1C""}. With this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:4293,Testability,test,test,4293,"mpatible Class. A, 16, A; B, 16, A; , , B; C, 16, C; D, 16, A; , , D; , 48, C. The next step is to encode this compatibility information into the IR. The way; this is done is to create type metadata named after each of the compatible; classes, with which we associate each of the compatible address points in; each vtable. For example, these type metadata entries encode the compatibility; information for the above hierarchy:. ::. @_ZTV1A = constant [...], !type !0; @_ZTV1B = constant [...], !type !0, !type !1; @_ZTV1C = constant [...], !type !2; @_ZTV1D = constant [...], !type !0, !type !3, !type !4. !0 = !{i64 16, !""_ZTS1A""}; !1 = !{i64 16, !""_ZTS1B""}; !2 = !{i64 16, !""_ZTS1C""}; !3 = !{i64 16, !""_ZTS1D""}; !4 = !{i64 48, !""_ZTS1C""}. With this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5001,Testability,test,tests,5001,"= !{i64 16, !""_ZTS1B""}; !2 = !{i64 16, !""_ZTS1C""}; !3 = !{i64 16, !""_ZTS1D""}; !4 = !{i64 48, !""_ZTS1C""}. With this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5036,Testability,test,test,5036,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5191,Testability,test,tests,5191,"th this type metadata, we can now use the ``llvm.type.test`` intrinsic to; test whether a given pointer is compatible with a type identifier. Working; backwards, if ``llvm.type.test`` returns true for a particular pointer,; we can also statically determine the identities of the virtual functions; that a particular virtual call may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5411,Testability,test,test,5411,"ll may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:5432,Testability,test,test,5432,"ll may call. For example, if a program assumes; a pointer to be a member of ``!""_ZST1A""``, we know that the address can; be only be one of ``_ZTV1A+16``, ``_ZTV1B+16`` or ``_ZTV1D+16`` (i.e. the; address points of the vtables of A, B and D respectively). If we then load; an address from that pointer, we know that the address can only be one of; ``&A::f``, ``&B::f`` or ``&D::f``. .. _address point: https://itanium-cxx-abi.github.io/cxx-abi/abi.html#vtable-general. Testing Addresses For Type Membership; =====================================. If a program tests an address using ``llvm.type.test``, this will cause; a link-time optimization pass, ``LowerTypeTests``, to replace calls to this; intrinsic with efficient code to perform type member tests. At a high level,; the pass will lay out referenced globals in a consecutive memory region in; the object file, construct bit vectors that map onto that memory region,; and generate code at each of the ``llvm.type.test`` call sites to test; pointers against those bit vectors. Because of the layout manipulation, the; globals' definitions must be available at LTO time. For more information,; see the `control flow integrity design document`_. A type identifier that identifies functions is transformed into a jump table,; which is a block of code consisting of one branch instruction for each; of the functions associated with the type identifier that branches to the; target function. The pass will redirect any taken function addresses to the; corresponding jump table entry. In the object file's symbol table, the jump; table entries take the identities of the original functions, so that addresses; taken outside the module will pass any verification done inside the module. Jump tables may call external functions, so their definitions need not; be available at LTO time. Note that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:7251,Testability,test,test,7251,"ote that if an externally defined function is; associated with a type identifier, there is no guarantee that its identity; within the module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast void ()* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid3""); ret i1 %x; }. define void @main() {; %a1 = call i1 @foo(i32* @a) ; returns 1; %b1 = call i1 @foo(i32* @b) ; returns 1; %c1 = call i1 @foo(i32* @c) ; returns 0; %a2 = call i1 @bar(i32* @a) ; returns 0; %b2 = call i1 @bar(i32* @b) ; returns 1; %c2 = call i1 @bar(i32* @c) ; returns 1; %d02 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 0)) ; returns 0; %d12 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 1)) ; returns 1; %e = call i1 @baz(void ()* @e) ; returns 1; %f = call i1 @baz(void ()* @f) ; returns 0; %g = call i1 @baz(void ()* @g) ; returns 1; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:7385,Testability,test,test,7385,"module will be the same as its identity outside of the module,; as the former will be the jump table entry if a jump table is necessary. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast void ()* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid3""); ret i1 %x; }. define void @main() {; %a1 = call i1 @foo(i32* @a) ; returns 1; %b1 = call i1 @foo(i32* @b) ; returns 1; %c1 = call i1 @foo(i32* @c) ; returns 0; %a2 = call i1 @bar(i32* @a) ; returns 0; %b2 = call i1 @bar(i32* @b) ; returns 1; %c2 = call i1 @bar(i32* @c) ; returns 1; %d02 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 0)) ; returns 0; %d12 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 1)) ; returns 1; %e = call i1 @baz(void ()* @e) ; returns 1; %f = call i1 @baz(void ()* @f) ; returns 0; %g = call i1 @baz(void ()* @g) ; returns 1; ret void; }. .. _GlobalLayoutBuilder: https://github.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:7518,Testability,test,test,7518,"ry. The `GlobalLayoutBuilder`_ class is responsible for laying out the globals; efficiently to minimize the sizes of the underlying bitsets. .. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast void ()* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid3""); ret i1 %x; }. define void @main() {; %a1 = call i1 @foo(i32* @a) ; returns 1; %b1 = call i1 @foo(i32* @b) ; returns 1; %c1 = call i1 @foo(i32* @c) ; returns 0; %a2 = call i1 @bar(i32* @a) ; returns 0; %b2 = call i1 @bar(i32* @b) ; returns 1; %c2 = call i1 @bar(i32* @c) ; returns 1; %d02 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 0)) ; returns 0; %d12 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 1)) ; returns 1; %e = call i1 @baz(void ()* @e) ; returns 1; %f = call i1 @baz(void ()* @f) ; returns 0; %g = call i1 @baz(void ()* @g) ; returns 1; ret void; }. .. _GlobalLayoutBuilder: https://github.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.h. ``!vcall_visibility`` Metadata; ==============================. In order to allow removing unused function pointers from vtables, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst:7659,Testability,test,test,7659,".. _control flow integrity design document: https://clang.llvm.org/docs/ControlFlowIntegrityDesign.html. :Example:. ::. target datalayout = ""e-p:32:32"". @a = internal global i32 0, !type !0; @b = internal global i32 0, !type !0, !type !1; @c = internal global i32 0, !type !1; @d = internal global [2 x i32] [i32 0, i32 0], !type !2. define void @e() !type !3 {; ret void; }. define void @f() {; ret void; }. declare void @g() !type !3. !0 = !{i32 0, !""typeid1""}; !1 = !{i32 0, !""typeid2""}; !2 = !{i32 4, !""typeid2""}; !3 = !{i32 0, !""typeid3""}. declare i1 @llvm.type.test(i8* %ptr, metadata %typeid) nounwind readnone. define i1 @foo(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid1""); ret i1 %x; }. define i1 @bar(i32* %p) {; %pi8 = bitcast i32* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid2""); ret i1 %x; }. define i1 @baz(void ()* %p) {; %pi8 = bitcast void ()* %p to i8*; %x = call i1 @llvm.type.test(i8* %pi8, metadata !""typeid3""); ret i1 %x; }. define void @main() {; %a1 = call i1 @foo(i32* @a) ; returns 1; %b1 = call i1 @foo(i32* @b) ; returns 1; %c1 = call i1 @foo(i32* @c) ; returns 0; %a2 = call i1 @bar(i32* @a) ; returns 0; %b2 = call i1 @bar(i32* @b) ; returns 1; %c2 = call i1 @bar(i32* @c) ; returns 1; %d02 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 0)) ; returns 0; %d12 = call i1 @bar(i32* getelementptr ([2 x i32]* @d, i32 0, i32 1)) ; returns 1; %e = call i1 @baz(void ()* @e) ; returns 1; %f = call i1 @baz(void ()* @f) ; returns 0; %g = call i1 @baz(void ()* @g) ; returns 1; ret void; }. .. _GlobalLayoutBuilder: https://github.com/llvm/llvm-project/blob/main/llvm/include/llvm/Transforms/IPO/LowerTypeTests.h. ``!vcall_visibility`` Metadata; ==============================. In order to allow removing unused function pointers from vtables, we need to; know whether every virtual call which could use it is known to the compiler, or; whether another translation unit could introduce",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/TypeMetadata.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/TypeMetadata.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2584,Deployability,configurat,configurations,2584,"pileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:4095,Deployability,update,update,4095,"n. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebugInfo>`; This document specifies how to correctly update debug info in various kinds; of code transformations. :doc:`InstrRefDebugInfo`; This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the final; stages of compilation. :doc:`RemoveDIsDebugInfo`; This is a migration guide describing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profiles. Code Generation; ---------------. :doc:`WritingAnLLVMBackend`; Information on how to write LLVM backends for machine targets. :doc:`CodeGenerator`; The design and implementation of the LLVM code generator. Useful if you are; working on retargetting LLVM to a new architecture, designing a new codegen; pass, or enhancing existing components. :doc:`TableGen <TableGen/index>`; Describes the TableGen tool, which is used heavily by the LLVM code; genera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:3612,Integrability,interface,interface,3612,"-------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebugInfo>`; This document specifies how to correctly update debug info in various kinds; of code transformations. :doc:`InstrRefDebugInfo`; This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the final; stages of compilation. :doc:`RemoveDIsDebugInfo`; This is a migration guide describing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profile",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2507,Modifiability,portab,portable,2507,"g and testing LLVM/Clang on ARM. :doc:`HowToBuildWithPGO`; Notes on building LLVM/Clang with PGO. :doc:`HowToCrossCompileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2584,Modifiability,config,configurations,2584,"pileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :do",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:3003,Modifiability,variab,variables,3003," Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:4277,Modifiability,variab,variable,4277,"ility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebugInfo>`; This document specifies how to correctly update debug info in various kinds; of code transformations. :doc:`InstrRefDebugInfo`; This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the final; stages of compilation. :doc:`RemoveDIsDebugInfo`; This is a migration guide describing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profiles. Code Generation; ---------------. :doc:`WritingAnLLVMBackend`; Information on how to write LLVM backends for machine targets. :doc:`CodeGenerator`; The design and implementation of the LLVM code generator. Useful if you are; working on retargetting LLVM to a new architecture, designing a new codegen; pass, or enhancing existing components. :doc:`TableGen <TableGen/index>`; Describes the TableGen tool, which is used heavily by the LLVM code; generator. ==========; GlobalISel; ==========. :doc:`MIRPatterns <GlobalISel/MIRPatterns>`; Describes the design of MIR Patterns and how to use them. ===; JIT; ===. :doc:`MCJITDesig",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2853,Performance,optimiz,optimizations,2853,"s code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:3065,Performance,optimiz,optimization,3065,"dingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:3648,Performance,optimiz,optimizer,3648,"-------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebugInfo>`; This document specifies how to correctly update debug info in various kinds; of code transformations. :doc:`InstrRefDebugInfo`; This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the final; stages of compilation. :doc:`RemoveDIsDebugInfo`; This is a migration guide describing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profile",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:3751,Performance,optimiz,optimization,3751,"gAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebugInfo>`; This document specifies how to correctly update debug info in various kinds; of code transformations. :doc:`InstrRefDebugInfo`; This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the final; stages of compilation. :doc:`RemoveDIsDebugInfo`; This is a migration guide describing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profiles. Code Generation; ---------------. :doc:`WritingAnLLVMBackend`; Information on how to write LLVM backends f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2977,Safety,safe,safety,2977," Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Information about the MemorySSA utility in LLVM, as well as how to use it. :doc:`LoopTerminology`; A document describing Loops and associated terms as used in LLVM. :doc:`CycleTerminology`; A document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:1446,Testability,test,testing,1446,"EndianNEON; BuildingADistribution; CFIVerify; CMake; CMakePrimer; CodeGenerator; CodeOfConduct; CommandLine; CompileCudaWithLLVM; CoverageMappingFormat; CycleTerminology; DebuggingJITedCode; DirectXUsage; Docker; FatLTO; ExtendingLLVM; GitHub; GoldPlugin; GlobalISel/MIRPatterns; HowToBuildOnARM; HowToBuildWithPGO; HowToBuildWindowsItaniumPrograms; HowToCrossCompileBuiltinsOnArm; HowToCrossCompileLLVM; HowToUpdateDebugInfo; InstrProfileFormat; InstrRefDebugInfo; LinkTimeOptimization; LoopTerminology; MarkdownQuickstartTemplate; MemorySSA; MergeFunctions; MCJITDesignAndImplementation; MisExpect; ORCv2; OpaquePointers; JITLink; NewPassManager; NVPTXUsage; Phabricator; Passes; ReportingGuide; ResponseGuide; Remarks; RemoveDIsDebugInfo; RISCVUsage; SourceLevelDebugging; SPIRVUsage; StackSafetyAnalysis; SupportLibrary; TableGen/index; TableGenFundamentals; Vectorizers; WritingAnLLVMPass; WritingAnLLVMNewPMPass; WritingAnLLVMBackend; yaml2obj. Clang; -----. :doc:`HowToBuildOnARM`; Notes on building and testing LLVM/Clang on ARM. :doc:`HowToBuildWithPGO`; Notes on building LLVM/Clang with PGO. :doc:`HowToCrossCompileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:1596,Testability,test,testing,1596,"pingFormat; CycleTerminology; DebuggingJITedCode; DirectXUsage; Docker; FatLTO; ExtendingLLVM; GitHub; GoldPlugin; GlobalISel/MIRPatterns; HowToBuildOnARM; HowToBuildWithPGO; HowToBuildWindowsItaniumPrograms; HowToCrossCompileBuiltinsOnArm; HowToCrossCompileLLVM; HowToUpdateDebugInfo; InstrProfileFormat; InstrRefDebugInfo; LinkTimeOptimization; LoopTerminology; MarkdownQuickstartTemplate; MemorySSA; MergeFunctions; MCJITDesignAndImplementation; MisExpect; ORCv2; OpaquePointers; JITLink; NewPassManager; NVPTXUsage; Phabricator; Passes; ReportingGuide; ResponseGuide; Remarks; RemoveDIsDebugInfo; RISCVUsage; SourceLevelDebugging; SPIRVUsage; StackSafetyAnalysis; SupportLibrary; TableGen/index; TableGenFundamentals; Vectorizers; WritingAnLLVMPass; WritingAnLLVMNewPMPass; WritingAnLLVMBackend; yaml2obj. Clang; -----. :doc:`HowToBuildOnARM`; Notes on building and testing LLVM/Clang on ARM. :doc:`HowToBuildWithPGO`; Notes on building LLVM/Clang with PGO. :doc:`HowToCrossCompileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advance",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:6128,Testability,test,testing,6128,"=. :doc:`MIRPatterns <GlobalISel/MIRPatterns>`; Describes the design of MIR Patterns and how to use them. ===; JIT; ===. :doc:`MCJITDesignAndImplementation`; Describes the inner workings of MCJIT execution engine. :doc:`ORCv2`; Describes the design and implementation of the ORC APIs, including some; usage examples, and a guide for users transitioning from ORCv1 to ORCv2. :doc:`JITLink`; Describes the design and APIs for the JITLink library, ORC's new JIT; linker. :doc:`DebuggingJITedCode`; How to debug JITed code with GDB. Additional Topics; -----------------. :doc:`CommandLine`; Provides information on using the command line parsing library. :doc:`ExtendingLLVM`; Look here to see how to add instructions and intrinsics to LLVM. :doc:`AddingConstrainedIntrinsics`; Gives the steps necessary when adding a new constrained math intrinsic; to LLVM. :doc:`HowToBuildWindowsItaniumPrograms`; Notes on assembling a Windows Itanium environment. :doc:`HowToCrossCompileBuiltinsOnArm`; Notes on cross-building and testing the compiler-rt builtins for Arm. :doc:`BigEndianNEON`; LLVM's support for generating NEON instructions on big endian ARM targets is; somewhat nonintuitive. This document explains the implementation and rationale. :doc:`AArch64SME`; LLVM's support for AArch64 SME ACLE and ABI. :doc:`CompileCudaWithLLVM`; LLVM support for CUDA. :doc:`NVPTXUsage`; This document describes using the NVPTX backend to compile GPU kernels. :doc:`AMDGPUUsage`; This document describes using the AMDGPU backend to compile GPU kernels. :doc:`AMDGPUDwarfExtensionsForHeterogeneousDebugging`; This document describes DWARF extensions to support heterogeneous debugging; for targets such as the AMDGPU backend. :doc:`AMDGPUDwarfExtensionAllowLocationDescriptionOnTheDwarfExpressionStack/AMDGPUDwarfExtensionAllowLocationDescriptionOnTheDwarfExpressionStack`; This document describes a DWARF extension to allow location descriptions on; the DWARF expression stack. It is part of; :doc:`AMDGPUDwarfExtension",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2082,Usability,guid,guide,2082,"icator; Passes; ReportingGuide; ResponseGuide; Remarks; RemoveDIsDebugInfo; RISCVUsage; SourceLevelDebugging; SPIRVUsage; StackSafetyAnalysis; SupportLibrary; TableGen/index; TableGenFundamentals; Vectorizers; WritingAnLLVMPass; WritingAnLLVMNewPMPass; WritingAnLLVMBackend; yaml2obj. Clang; -----. :doc:`HowToBuildOnARM`; Notes on building and testing LLVM/Clang on ARM. :doc:`HowToBuildWithPGO`; Notes on building LLVM/Clang with PGO. :doc:`HowToCrossCompileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:2223,Usability,guid,guide,2223,"ackSafetyAnalysis; SupportLibrary; TableGen/index; TableGenFundamentals; Vectorizers; WritingAnLLVMPass; WritingAnLLVMNewPMPass; WritingAnLLVMBackend; yaml2obj. Clang; -----. :doc:`HowToBuildOnARM`; Notes on building and testing LLVM/Clang on ARM. :doc:`HowToBuildWithPGO`; Notes on building LLVM/Clang with PGO. :doc:`HowToCrossCompileLLVM`; Notes on cross-building and testing LLVM/Clang. `How to build the C, C++, ObjC, and ObjC++ front end`__; Instructions for building the clang front-end from source. .. __: https://clang.llvm.org/get_started.html. :doc:`CoverageMappingFormat`; This describes the format and encoding used for LLVMs code coverage mapping. :doc:`CFIVerify`; A description of the verification tool for Control Flow Integrity. LLVM Builds and Distributions; -----------------------------. :doc:`BuildingADistribution`; A best-practices guide for using LLVM's CMake build system to package and; distribute LLVM-based tools. :doc:`CMake`; An addendum to the main Getting Started guide for those using the `CMake; build system <http://www.cmake.org>`_. :doc:`Docker`; A reference for using Dockerfiles provided with LLVM. :doc:`Support Library <SupportLibrary>`; This document describes the LLVM Support Library (``lib/Support``) and; how to keep LLVM source code portable. :doc:`AdvancedBuilds`; This document describes more advanced build configurations. Optimizations; -------------. :doc:`WritingAnLLVMPass`; Information on how to write LLVM transformations and analyses. :doc:`WritingAnLLVMNewPMPass`; Information on how to write LLVM transformations under the new pass; manager. :doc:`Passes`; A list of optimizations and analyses implemented in LLVM. :doc:`StackSafetyAnalysis`; This document describes the design of the stack safety analysis of local; variables. :doc:`MergeFunctions`; Describes functions merging optimization. :doc:`AliasAnalysis`; Information on how to write a new alias analysis implementation or how to; use existing analyses. :doc:`MemorySSA`; Informat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:4395,Usability,guid,guide,4395," document describing cycles as a generalization of loops. :doc:`Vectorizers`; This document describes the current status of vectorization in LLVM. :doc:`LinkTimeOptimization`; This document describes the interface between LLVM intermodular optimizer; and the linker and its design. :doc:`GoldPlugin`; How to build your programs with link-time optimization on Linux. :doc:`Remarks`; A reference on the implementation of remarks in LLVM. :doc:`Source Level Debugging with LLVM <SourceLevelDebugging>`; This document describes the design and philosophy behind the LLVM; source-level debugger. :doc:`How to Update Debug Info <HowToUpdateDebugInfo>`; This document specifies how to correctly update debug info in various kinds; of code transformations. :doc:`InstrRefDebugInfo`; This document explains how LLVM uses value tracking, or instruction; referencing, to determine variable locations for debug info in the final; stages of compilation. :doc:`RemoveDIsDebugInfo`; This is a migration guide describing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profiles. Code Generation; ---------------. :doc:`WritingAnLLVMBackend`; Information on how to write LLVM backends for machine targets. :doc:`CodeGenerator`; The design and implementation of the LLVM code generator. Useful if you are; working on retargetting LLVM to a new architecture, designing a new codegen; pass, or enhancing existing components. :doc:`TableGen <TableGen/index>`; Describes the TableGen tool, which is used heavily by the LLVM code; generator. ==========; GlobalISel; ==========. :doc:`MIRPatterns <GlobalISel/MIRPatterns>`; Describes the design of MIR Patterns and how to use them. ===; JIT; ===. :doc:`MCJITDesignAndImplementation`; Describes the inner workings of MCJIT execution engine. :doc:`ORCv2`; Describes the design and implementation of the ORC APIs, including ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst:5437,Usability,guid,guide,5437,"bing how to move from debug info using; intrinsics such as dbg.value to using the non-instruction DPValue object. :doc:`InstrProfileFormat`; This document explains two binary formats of instrumentation-based profiles. Code Generation; ---------------. :doc:`WritingAnLLVMBackend`; Information on how to write LLVM backends for machine targets. :doc:`CodeGenerator`; The design and implementation of the LLVM code generator. Useful if you are; working on retargetting LLVM to a new architecture, designing a new codegen; pass, or enhancing existing components. :doc:`TableGen <TableGen/index>`; Describes the TableGen tool, which is used heavily by the LLVM code; generator. ==========; GlobalISel; ==========. :doc:`MIRPatterns <GlobalISel/MIRPatterns>`; Describes the design of MIR Patterns and how to use them. ===; JIT; ===. :doc:`MCJITDesignAndImplementation`; Describes the inner workings of MCJIT execution engine. :doc:`ORCv2`; Describes the design and implementation of the ORC APIs, including some; usage examples, and a guide for users transitioning from ORCv1 to ORCv2. :doc:`JITLink`; Describes the design and APIs for the JITLink library, ORC's new JIT; linker. :doc:`DebuggingJITedCode`; How to debug JITed code with GDB. Additional Topics; -----------------. :doc:`CommandLine`; Provides information on using the command line parsing library. :doc:`ExtendingLLVM`; Look here to see how to add instructions and intrinsics to LLVM. :doc:`AddingConstrainedIntrinsics`; Gives the steps necessary when adding a new constrained math intrinsic; to LLVM. :doc:`HowToBuildWindowsItaniumPrograms`; Notes on assembling a Windows Itanium environment. :doc:`HowToCrossCompileBuiltinsOnArm`; Notes on cross-building and testing the compiler-rt builtins for Arm. :doc:`BigEndianNEON`; LLVM's support for generating NEON instructions on big endian ARM targets is; somewhat nonintuitive. This document explains the implementation and rationale. :doc:`AArch64SME`; LLVM's support for AArch64 SME ACLE an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/UserGuides.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/UserGuides.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:668,Availability,reliab,reliably,668,"==================; Vectorization Plan; ==================. .. contents::; :local:. Abstract; ========; The vectorization transformation can be rather complicated, involving several; potential alternatives, especially for outer-loops [1]_ but also possibly for; innermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:2352,Availability,reliab,reliably,2352,"sibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular, if the best option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:8046,Availability,down,down,8046,"e-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analyses for making these decisions, to fully; support compositional and iterative decision making. Some decisions are local to an instruction in the loop, such as whether to widen; it into a vector instruction or replicate it, keeping the generated instructions; in place. Other decisions, however, involve moving i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:9375,Availability,mask,masks,9375," the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analyses for making these decisions, to fully; support compositional and iterative decision making. Some decisions are local to an instruction in the loop, such as whether to widen; it into a vector instruction or replicate it, keeping the generated instructions; in place. Other decisions, however, involve moving instructions, replacing them; with other instructions, and/or introducing new instructions. For example, a; cast may sink past a later instruction and be widened to handle first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:9706,Availability,mask,masks,9706,"t compositional and iterative decision making. Some decisions are local to an instruction in the loop, such as whether to widen; it into a vector instruction or replicate it, keeping the generated instructions; in place. Other decisions, however, involve moving instructions, replacing them; with other instructions, and/or introducing new instructions. For example, a; cast may sink past a later instruction and be widened to handle first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:9811,Availability,mask,masks,9811,"to widen; it into a vector instruction or replicate it, keeping the generated instructions; in place. Other decisions, however, involve moving instructions, replacing them; with other instructions, and/or introducing new instructions. For example, a; cast may sink past a later instruction and be widened to handle first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited for short SIMD architectures"", Dorit; Nuzman and Ayal Zaks, PACT 2008. .. [2] ""Proposal for function vectorization and l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:10538,Deployability,upgrade,upgrade,10538,"el the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited for short SIMD architectures"", Dorit; Nuzman and Ayal Zaks, PACT 2008. .. [2] ""Proposal for function vectorization and loop vectorization with function; calls"", Xinmin Tian, [`cfe-dev; <http://lists.llvm.org/pipermail/cfe-dev/2016-March/047732.html>`_].,; March 2, 2016.; See also `review <https://reviews.llvm.org/D22792>`_. .. [3] ""Throttling Automatic Vectorization: When Less is More"", Vasileios; Porpodas and Tim Jones, PACT 2015 and LLVM Developers' Meeting 2015. .. [4] ""Exploiting mixed SIMD parallelism by reducing data reorganization; overhead"", Hao Zhou and Jingling Xue, CGO 2016. .. [5] ""Register Allocation via Hierarchical Graph Coloring"", David Callahan and; Brian Koblenz, PLDI 1991. .. [6] ""Structural analysis: A new approach to flow analysis in optimizing; compilers"", M. Sharir, Journal of Computer Languages, Jan. 1980. .. [7] ""Enabling",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:2945,Energy Efficiency,efficient,efficiently,2945,"manipulating VPlans must not modify the input IR.; In particular, if the best option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3058,Energy Efficiency,efficient,efficiently,3058," option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan compr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3115,Energy Efficiency,efficient,efficiently,3115,"hing Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7725,Energy Efficiency,schedul,scheduling,7725," Recipe. A Recipe; may specify how its ingredients are to be transformed to produce the output IR; instructions; e.g., cloned once, replicated multiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analys",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7768,Modifiability,extend,extend,7768,"tiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analyses for making these decisions, to fully; support compositional and iterative decision making. Some decisions are local to an instruction in the l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:10593,Modifiability,extend,extend,10593,"el the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited for short SIMD architectures"", Dorit; Nuzman and Ayal Zaks, PACT 2008. .. [2] ""Proposal for function vectorization and loop vectorization with function; calls"", Xinmin Tian, [`cfe-dev; <http://lists.llvm.org/pipermail/cfe-dev/2016-March/047732.html>`_].,; March 2, 2016.; See also `review <https://reviews.llvm.org/D22792>`_. .. [3] ""Throttling Automatic Vectorization: When Less is More"", Vasileios; Porpodas and Tim Jones, PACT 2015 and LLVM Developers' Meeting 2015. .. [4] ""Exploiting mixed SIMD parallelism by reducing data reorganization; overhead"", Hao Zhou and Jingling Xue, CGO 2016. .. [5] ""Register Allocation via Hierarchical Graph Coloring"", David Callahan and; Brian Koblenz, PLDI 1991. .. [6] ""Structural analysis: A new approach to flow analysis in optimizing; compilers"", M. Sharir, Journal of Computer Languages, Jan. 1980. .. [7] ""Enabling",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:319,Performance,perform,performance,319,"==================; Vectorization Plan; ==================. .. contents::; :local:. Abstract; ========; The vectorization transformation can be rather complicated, involving several; potential alternatives, especially for outer-loops [1]_ but also possibly for; innermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:613,Performance,optimiz,optimizing,613,"==================; Vectorization Plan; ==================. .. contents::; :local:. Abstract; ========; The vectorization transformation can be rather complicated, involving several; potential alternatives, especially for outer-loops [1]_ but also possibly for; innermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:686,Performance,perform,performing,686,"==================; Vectorization Plan; ==================. .. contents::; :local:. Abstract; ========; The vectorization transformation can be rather complicated, involving several; potential alternatives, especially for outer-loops [1]_ but also possibly for; innermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:1237,Performance,optimiz,optimizations,1237,"ermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular, if the best option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3197,Performance,load,loads,3197,"lt. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector code.; d. Function vectorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3919,Performance,optimiz,optimizing,3919,"ctorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It can construct, optimize and discard one or more VPlans,; each VPlan modelling a distinct way to vectorize the loop or the loop nest.; Once the best VPlan is determined, including the best VF and UF, this VPlan; drives the generation of output IR. :VPlan:; A model of a vectorized candidate for a given input IR loop or loop nest. This; candidate is represented using a Hierarchical CFG. VPlan supports estimating; the cost and driving the generation of the output IR code it represents. :Hierarchical CFG:; A control-flow graph whose nodes are basic-blocks or Hierarchical CFG's. The; Hierarchical CFG data structure is similar to the Tile Tree [5]_, where; cross-Tile edges are lifted to connect Tiles instead of the original",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:4185,Performance,optimiz,optimize,4185," modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It can construct, optimize and discard one or more VPlans,; each VPlan modelling a distinct way to vectorize the loop or the loop nest.; Once the best VPlan is determined, including the best VF and UF, this VPlan; drives the generation of output IR. :VPlan:; A model of a vectorized candidate for a given input IR loop or loop nest. This; candidate is represented using a Hierarchical CFG. VPlan supports estimating; the cost and driving the generation of the output IR code it represents. :Hierarchical CFG:; A control-flow graph whose nodes are basic-blocks or Hierarchical CFG's. The; Hierarchical CFG data structure is similar to the Tile Tree [5]_, where; cross-Tile edges are lifted to connect Tiles instead of the original; basic-blocks as in Sharir [6]_, promoting the Tile encapsulation. The terms; Region and Block are used rather than Tile [5]_ to avoid confusion with loop; tiling. :VPBlockBase:; The building block of the Hierarchical CFG. A pure-virtual base-class of; VPBasicBlock and VPRegionBlock, see below. VPBlockBase models the hierarchical; cont",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:7629,Performance,optimiz,optimizations,7629," Recipe. A Recipe; may specify how its ingredients are to be transformed to produce the output IR; instructions; e.g., cloned once, replicated multiple times or widened; according to selected VF. :VPValue:; The base of VPlan's def-use relations class hierarchy. When instantiated, it; models a constant or a live-in Value in VPlan. It has users, which are of type; VPUser, but no operands. :VPUser:; A VPUser represents an entity that uses a number of VPValues as operands.; VPUser is similar in some aspects to LLVM's User class. :VPDef:; A VPDef represents an entity that defines zero, one or multiple VPValues.; It is used to model the fact that recipes in VPlan can define multiple; VPValues. :VPInstruction:; A VPInstruction is both a VPRecipe and a VPUser. It models a single; VPlan-level instruction to be generated if the VPlan is executed, including; its opcode and possibly additional characteristics. It is the basis for; writing instruction-level analyses and optimizations in VPlan as creating,; replacing or moving VPInstructions record both def-use and scheduling; decisions. VPInstructions also extend LLVM IR's opcodes with idiomatic; operations that enrich the Vectorizer's semantics. :VPTransformState:; Stores information used for generating output IR, passed from; LoopVectorizationPlanner to its selected VPlan for execution, and used to pass; additional information down to VPBlocks and VPRecipes. The Planning Process and VPlan Roadmap; ======================================. Transforming the Loop Vectorizer to use VPlan follows a staged approach. First,; VPlan is used to record the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analys",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:9314,Performance,load,load,9314," the final vectorization decisions, and to execute them:; the Hierarchical CFG models the planned control-flow, and Recipes capture; decisions taken inside basic-blocks. Next, VPlan will be used also as the basis; for taking these decisions, effectively turning them into a series of; VPlan-to-VPlan algorithms. Finally, VPlan will support the planning process; itself including cost-based analyses for making these decisions, to fully; support compositional and iterative decision making. Some decisions are local to an instruction in the loop, such as whether to widen; it into a vector instruction or replicate it, keeping the generated instructions; in place. Other decisions, however, involve moving instructions, replacing them; with other instructions, and/or introducing new instructions. For example, a; cast may sink past a later instruction and be widened to handle first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:11470,Performance,optimiz,optimizing,11470,"ach Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited for short SIMD architectures"", Dorit; Nuzman and Ayal Zaks, PACT 2008. .. [2] ""Proposal for function vectorization and loop vectorization with function; calls"", Xinmin Tian, [`cfe-dev; <http://lists.llvm.org/pipermail/cfe-dev/2016-March/047732.html>`_].,; March 2, 2016.; See also `review <https://reviews.llvm.org/D22792>`_. .. [3] ""Throttling Automatic Vectorization: When Less is More"", Vasileios; Porpodas and Tim Jones, PACT 2015 and LLVM Developers' Meeting 2015. .. [4] ""Exploiting mixed SIMD parallelism by reducing data reorganization; overhead"", Hao Zhou and Jingling Xue, CGO 2016. .. [5] ""Register Allocation via Hierarchical Graph Coloring"", David Callahan and; Brian Koblenz, PLDI 1991. .. [6] ""Structural analysis: A new approach to flow analysis in optimizing; compilers"", M. Sharir, Journal of Computer Languages, Jan. 1980. .. [7] ""Enabling Polyhedral Optimizations in LLVM"", Tobias Grosser, Diploma; thesis, 2011. .. [8] ""Introducing VPlan to the Loop Vectorizer"", Gil Rapaport and Ayal Zaks,; European LLVM Developers' Meeting 2017. .. [9] ""Extending LoopVectorizer: OpenMP4.5 SIMD and Outer Loop; Auto-Vectorization"", Intel Vectorizer Team, LLVM Developers' Meeting 2016.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:467,Safety,avoid,avoiding,467,"==================; Vectorization Plan; ==================. .. contents::; :local:. Abstract; ========; The vectorization transformation can be rather complicated, involving several; potential alternatives, especially for outer-loops [1]_ but also possibly for; innermost loops. These alternatives may have significant performance impact,; both positive and negative. A cost model is therefore employed to identify the; best alternative, including the alternative of avoiding any transformation; altogether. The Vectorization Plan is an explicit model for describing vectorization; candidates. It serves for both optimizing candidates including estimating their; cost reliably, and for performing their final translation into IR. This; facilitates dealing with multiple vectorization candidates. High-level Design; =================. Vectorization Workflow; ----------------------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:3868,Safety,detect,detection,3868,"ctorization [2]_. 4. Support multiple candidates efficiently. In particular, similar candidates; related to a range of possible VF's and UF's must be represented efficiently.; Potential versioning needs to be supported efficiently. 5. Support vectorizing idioms, such as interleaved groups of strided loads or; stores. This is achieved by modeling a sequence of output instructions using; a ""Recipe"", which is responsible for computing its cost and generating its; code. 6. Encapsulate Single-Entry Single-Exit regions (SESE). During vectorization; such regions may need to be, for example, predicated and linearized, or; replicated VF*UF times to handle scalarized and predicated instructions.; Innerloops are also modelled as SESE regions. 7. Support instruction-level analysis and transformation, as part of Planning; Step 2.b: During vectorization instructions may need to be traversed, moved,; replaced by other instructions or be created. For example, vector idiom; detection and formation involves searching for and optimizing instruction; patterns. Definitions; ===========; The low-level design of VPlan comprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It can construct, optimize and discard one or more VPlans,; each VPlan modelling a distinct way to vectorize the loop or the loop nest.; Once the best VPlan is determined, including the best VF and UF, this VPlan; drives the generation of output IR. :VPlan:; A model of a vectorized candidate for a given input IR loop or loop nest. This; candidate is represented using a Hierarchical CFG. VPlan supports estimating; the cost and driving the generation of the output IR code it represents. :Hierarchical CFG:; A control-flow graph whose nodes are basic-blocks or Hierarchical CFG's. The; Hierarchical CFG data structure is similar to the Tile Tree [5]_, where; cross-Tile edges are lifted to connect Tiles instead of the original",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:5026,Safety,avoid,avoid,5026,"mprises of the following classes. :LoopVectorizationPlanner:; A LoopVectorizationPlanner is designed to handle the vectorization of a loop; or a loop nest. It can construct, optimize and discard one or more VPlans,; each VPlan modelling a distinct way to vectorize the loop or the loop nest.; Once the best VPlan is determined, including the best VF and UF, this VPlan; drives the generation of output IR. :VPlan:; A model of a vectorized candidate for a given input IR loop or loop nest. This; candidate is represented using a Hierarchical CFG. VPlan supports estimating; the cost and driving the generation of the output IR code it represents. :Hierarchical CFG:; A control-flow graph whose nodes are basic-blocks or Hierarchical CFG's. The; Hierarchical CFG data structure is similar to the Tile Tree [5]_, where; cross-Tile edges are lifted to connect Tiles instead of the original; basic-blocks as in Sharir [6]_, promoting the Tile encapsulation. The terms; Region and Block are used rather than Tile [5]_ to avoid confusion with loop; tiling. :VPBlockBase:; The building block of the Hierarchical CFG. A pure-virtual base-class of; VPBasicBlock and VPRegionBlock, see below. VPBlockBase models the hierarchical; control-flow relations with other VPBlocks. Note that in contrast to the IR; BasicBlock, a VPBlockBase models its control-flow successors and predecessors; directly, rather than through a Terminator branch or through predecessor; branches that ""use"" the VPBlockBase. :VPBasicBlock:; VPBasicBlock is a subclass of VPBlockBase, and serves as the leaves of the; Hierarchical CFG. It represents a sequence of output IR instructions that will; appear consecutively in an output IR basic-block. The instructions of this; basic-block originate from one or more VPBasicBlocks. VPBasicBlock holds a; sequence of zero or more VPRecipes that model the cost and generation of the; output IR instructions. :VPRegionBlock:; VPRegionBlock is a subclass of VPBlockBase. It models a collection of; V",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:9876,Testability,log,logic,9876,"ve moving instructions, replacing them; with other instructions, and/or introducing new instructions. For example, a; cast may sink past a later instruction and be widened to handle first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited for short SIMD architectures"", Dorit; Nuzman and Ayal Zaks, PACT 2008. .. [2] ""Proposal for function vectorization and loop vectorization with function; calls"", Xinmin Tian, [`cfe-dev; <http://lists.llvm.org/pipermail/cfe-dev/2016-March/047732.html>`_].",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:10066,Testability,log,logic,10066,"e first-order; recurrence; an interleave group of strided gathers or scatters may effectively; move to one place where they are replaced with shuffles and a common wide vector; load or store; new instructions may be introduced to compute masks, shuffle the; elements of vectors, and pack scalar values into vectors or vice-versa. In order for VPlan to support making instruction-level decisions and analyses,; it needs to model the relevant instructions along with their def/use relations.; This too follows a staged approach: first, the new instructions that compute; masks are modeled as VPInstructions, along with their induced def/use subgraph.; This effectively models masks in VPlan, facilitating VPlan-based predication.; Next, the logic embedded within each Recipe for generating its instructions at; VPlan execution time, will instead take part in the planning process by modeling; them as VPInstructions. Finally, only logic that applies to instructions as a; group will remain in Recipes, such as interleave groups and potentially other; idiom groups having synergistic cost. Related LLVM components; -----------------------; 1. SLP Vectorizer: one can compare the VPlan model with LLVM's existing SLP; tree, where TSLP [3]_ adds Plan Step 2.b. 2. RegionInfo: one can compare VPlan's H-CFG with the Region Analysis as used by; Polly [7]_. 3. Loop Vectorizer: the Vectorization Plan aims to upgrade the infrastructure of; the Loop Vectorizer and extend it to handle outer loops [8]_, [9]_. References; ----------; .. [1] ""Outer-loop vectorization: revisited for short SIMD architectures"", Dorit; Nuzman and Ayal Zaks, PACT 2008. .. [2] ""Proposal for function vectorization and loop vectorization with function; calls"", Xinmin Tian, [`cfe-dev; <http://lists.llvm.org/pipermail/cfe-dev/2016-March/047732.html>`_].,; March 2, 2016.; See also `review <https://reviews.llvm.org/D22792>`_. .. [3] ""Throttling Automatic Vectorization: When Less is More"", Vasileios; Porpodas and Tim Jones, PACT 20",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst:1892,Usability,guid,guidelines,1892,"-------; VPlan-based vectorization involves three major steps, taking a ""scenario-based; approach"" to vectorization planning:. 1. Legal Step: check if a loop can be legally vectorized; encode constraints and; artifacts if so.; 2. Plan Step:. a. Build initial VPlans following the constraints and decisions taken by; Legal Step 1, and compute their cost.; b. Apply optimizations to the VPlans, possibly forking additional VPlans.; Prune sub-optimal VPlans having relatively high cost.; 3. Execute Step: materialize the best VPlan. Note that this is the only step; that modifies the IR. Design Guidelines; -----------------; In what follows, the term ""input IR"" refers to code that is fed into the; vectorizer whereas the term ""output IR"" refers to code that is generated by the; vectorizer. The output IR contains code that has been vectorized or ""widened""; according to a loop Vectorization Factor (VF), and/or loop unroll-and-jammed; according to an Unroll Factor (UF).; The design of VPlan follows several high-level guidelines:. 1. Analysis-like: building and manipulating VPlans must not modify the input IR.; In particular, if the best option is not to vectorize at all, the; vectorization process terminates before reaching Step 3, and compilation; should proceed as if VPlans had not been built. 2. Align Cost & Execute: each VPlan must support both estimating the cost and; generating the output IR code, such that the cost estimation evaluates the; to-be-generated code reliably. 3. Support vectorizing additional constructs:. a. Outer-loop vectorization. In particular, VPlan must be able to model the; control-flow of the output IR which may include multiple basic-blocks and; nested loops.; b. SLP vectorization.; c. Combinations of the above, including nested vectorization: vectorizing; both an inner loop and an outer-loop at the same time (each with its own; VF and UF), mixed vectorization: vectorizing a loop with SLP patterns; inside [4]_, (re)vectorizing input IR containing vector",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/VectorizationPlan.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/VectorizationPlan.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:3242,Availability,failure,failure,3242," count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed=loop-vectorize]. And the command line ``-Rpass-analysis=loop-vectorize`` indicates that the; switch statement cannot be vectorized. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: loop contains a switch statement [-Rpass-analysis=loop-vectorize]; switch(A[i]) {; ^. To ensure line and column numbers are produced include the command line options; ``-gline-tables-only`` and ``-gcolumn-info``. See the Clang `user manual; <https://clang.llvm.org/docs/UsersManual.html#options-to-e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:10161,Availability,avail,available,10161,"i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient because only a single execution port can be used by the processor.; By unrolling the code the Loop Vectorizer allows two or more execution ports; to be used simultaneously. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i];; return sum;; }. The Loop Vectorizer uses a cost model to decide when it is profitable to unroll loops.; The decision to unroll the loop depen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12929,Deployability,configurat,configuration,12929," vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combine these; into vector operations. .. code-block:: c++. void foo(int a1, int a2, int b1, int b2, int *A) {; A[0] = a1*(a1 + b1);; A[1] = a2*(a2 + b2);; A[2] = a1*(a1 + b1);; A[3] = a2*(a2 + b2);; }. The SLP-vectorizer ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:11148,Integrability,depend,depends,11148,"available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient because only a single execution port can be used by the processor.; By unrolling the code the Loop Vectorizer allows two or more execution ports; to be used simultaneously. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i];; return sum;; }. The Loop Vectorizer uses a cost model to decide when it is profitable to unroll loops.; The decision to unroll the loop depends on the register pressure and the generated code size. Epilogue Vectorization; ^^^^^^^^^^^^^^^^^^^^^^. When vectorizing a loop, often a scalar remainder (epilogue) loop is necessary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:5861,Modifiability,variab,variable,5861,".. code-block:: c++. void bar(float *A, float* B, float K, int start, int end) {; for (int i = start; i < end; ++i); A[i] *= B[i] + K;; }. Runtime Checks of Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In the example below, if the pointers A and B point to consecutive addresses,; then it is illegal to vectorize the code because some elements of A will be; written before they are read from array B. Some programmers use the 'restrict' keyword to notify the compiler that the; pointers are disjointed, but in our example, the Loop Vectorizer has no way of; knowing that the pointers A and B are unique. The Loop Vectorizer handles this; loop by placing code that checks, at runtime, if the arrays A and B point to; disjointed memory locations. If arrays A and B overlap, then the scalar version; of the loop is executed. .. code-block:: c++. void bar(float *A, float* B, float K, int n) {; for (int i = 0; i < n; ++i); A[i] *= B[i] + K;; }. Reductions; ^^^^^^^^^^. In this example the ``sum`` variable is used by consecutive iterations of; the loop. Normally, this would prevent vectorization, but the vectorizer can; detect that 'sum' is a reduction variable. The variable 'sum' becomes a vector; of integers, and at the end of the loop the elements of the array are added; together to create the correct result. We support a number of different; reduction operations, such as addition, multiplication, XOR, AND and OR. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i] + 5;; return sum;; }. We support floating point reduction operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:6019,Modifiability,variab,variable,6019,"rt; i < end; ++i); A[i] *= B[i] + K;; }. Runtime Checks of Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In the example below, if the pointers A and B point to consecutive addresses,; then it is illegal to vectorize the code because some elements of A will be; written before they are read from array B. Some programmers use the 'restrict' keyword to notify the compiler that the; pointers are disjointed, but in our example, the Loop Vectorizer has no way of; knowing that the pointers A and B are unique. The Loop Vectorizer handles this; loop by placing code that checks, at runtime, if the arrays A and B point to; disjointed memory locations. If arrays A and B overlap, then the scalar version; of the loop is executed. .. code-block:: c++. void bar(float *A, float* B, float K, int n) {; for (int i = 0; i < n; ++i); A[i] *= B[i] + K;; }. Reductions; ^^^^^^^^^^. In this example the ``sum`` variable is used by consecutive iterations of; the loop. Normally, this would prevent vectorization, but the vectorizer can; detect that 'sum' is a reduction variable. The variable 'sum' becomes a vector; of integers, and at the end of the loop the elements of the array are added; together to create the correct result. We support a number of different; reduction operations, such as addition, multiplication, XOR, AND and OR. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i] + 5;; return sum;; }. We support floating point reduction operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:6033,Modifiability,variab,variable,6033,"rs A and B point to consecutive addresses,; then it is illegal to vectorize the code because some elements of A will be; written before they are read from array B. Some programmers use the 'restrict' keyword to notify the compiler that the; pointers are disjointed, but in our example, the Loop Vectorizer has no way of; knowing that the pointers A and B are unique. The Loop Vectorizer handles this; loop by placing code that checks, at runtime, if the arrays A and B point to; disjointed memory locations. If arrays A and B overlap, then the scalar version; of the loop is executed. .. code-block:: c++. void bar(float *A, float* B, float K, int n) {; for (int i = 0; i < n; ++i); A[i] *= B[i] + K;; }. Reductions; ^^^^^^^^^^. In this example the ``sum`` variable is used by consecutive iterations of; the loop. Normally, this would prevent vectorization, but the vectorizer can; detect that 'sum' is a reduction variable. The variable 'sum' becomes a vector; of integers, and at the end of the loop the elements of the array are added; together to create the correct result. We support a number of different; reduction operations, such as addition, multiplication, XOR, AND and OR. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i] + 5;; return sum;; }. We support floating point reduction operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The innermost loop may contain complex; nesting of IFs, ELSEs and even GOTOs. .. code-block:: c++. int foo(int *A, int *B, int n) {; un",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:6560,Modifiability,variab,variable,6560," arrays A and B point to; disjointed memory locations. If arrays A and B overlap, then the scalar version; of the loop is executed. .. code-block:: c++. void bar(float *A, float* B, float K, int n) {; for (int i = 0; i < n; ++i); A[i] *= B[i] + K;; }. Reductions; ^^^^^^^^^^. In this example the ``sum`` variable is used by consecutive iterations of; the loop. Normally, this would prevent vectorization, but the vectorizer can; detect that 'sum' is a reduction variable. The variable 'sum' becomes a vector; of integers, and at the end of the loop the elements of the array are added; together to create the correct result. We support a number of different; reduction operations, such as addition, multiplication, XOR, AND and OR. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i] + 5;; return sum;; }. We support floating point reduction operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The innermost loop may contain complex; nesting of IFs, ELSEs and even GOTOs. .. code-block:: c++. int foo(int *A, int *B, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); if (A[i] > B[i]); sum += A[i] + 5;; return sum;; }. Pointer Induction Variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. This example uses the ""accumulate"" function of the standard c++ library. This; loop uses C++ iterators, which are pointers, and not integer indices.; The Loop Vectorizer detects pointer induction variables and can vectorize; this loop. This feature is important because many C++ programs use itera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:6649,Modifiability,variab,variables,6649," overlap, then the scalar version; of the loop is executed. .. code-block:: c++. void bar(float *A, float* B, float K, int n) {; for (int i = 0; i < n; ++i); A[i] *= B[i] + K;; }. Reductions; ^^^^^^^^^^. In this example the ``sum`` variable is used by consecutive iterations of; the loop. Normally, this would prevent vectorization, but the vectorizer can; detect that 'sum' is a reduction variable. The variable 'sum' becomes a vector; of integers, and at the end of the loop the elements of the array are added; together to create the correct result. We support a number of different; reduction operations, such as addition, multiplication, XOR, AND and OR. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i] + 5;; return sum;; }. We support floating point reduction operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The innermost loop may contain complex; nesting of IFs, ELSEs and even GOTOs. .. code-block:: c++. int foo(int *A, int *B, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); if (A[i] > B[i]); sum += A[i] + 5;; return sum;; }. Pointer Induction Variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. This example uses the ""accumulate"" function of the standard c++ library. This; loop uses C++ iterators, which are pointers, and not integer indices.; The Loop Vectorizer detects pointer induction variables and can vectorize; this loop. This feature is important because many C++ programs use iterators. .. code-block:: c++. int baz(int *A, int n) {; return std::accumu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:7457,Modifiability,variab,variables,7457,"n operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The innermost loop may contain complex; nesting of IFs, ELSEs and even GOTOs. .. code-block:: c++. int foo(int *A, int *B, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); if (A[i] > B[i]); sum += A[i] + 5;; return sum;; }. Pointer Induction Variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. This example uses the ""accumulate"" function of the standard c++ library. This; loop uses C++ iterators, which are pointers, and not integer indices.; The Loop Vectorizer detects pointer induction variables and can vectorize; this loop. This feature is important because many C++ programs use iterators. .. code-block:: c++. int baz(int *A, int n) {; return std::accumulate(A, A + n, 0);; }. Reverse Iterators; ^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize loops that count backwards. .. code-block:: c++. void foo(int *A, int n) {; for (int i = n; i > 0; --i); A[i] +=1;; }. Scatter / Gather; ^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize code that becomes a sequence of scalar instructions; that scatter/gathers memory. .. code-block:: c++. void foo(int * A, int * B, int n) {; for (intptr_t i = 0; i < n; ++i); A[i] += B[i * 4];; }. In many situations the cost model will inform LLVM that this is not beneficial; and LLVM will only vectorize such code if forced with ""-mllvm -force-vector-width=#"". Vectorization of Mixed Types; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize programs with mixed types. The Vectorizer; cost model can estimate the cost of the t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:10693,Modifiability,variab,variable,10693,"izer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient because only a single execution port can be used by the processor.; By unrolling the code the Loop Vectorizer allows two or more execution ports; to be used simultaneously. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i];; return sum;; }. The Loop Vectorizer uses a cost model to decide when it is profitable to unroll loops.; The decision to unroll the loop depends on the register pressure and the generated code size. Epilogue Vectorization; ^^^^^^^^^^^^^^^^^^^^^^. When vectorizing a loop, often a scalar remainder (epilogue) loop is necessary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:11729,Modifiability,enhance,enhanced,11729,"nrolling the code the Loop Vectorizer allows two or more execution ports; to be used simultaneously. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i];; return sum;; }. The Loop Vectorizer uses a cost model to decide when it is profitable to unroll loops.; The decision to unroll the loop depends on the register pressure and the generated code size. Epilogue Vectorization; ^^^^^^^^^^^^^^^^^^^^^^. When vectorizing a loop, often a scalar remainder (epilogue) loop is necessary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12929,Modifiability,config,configuration,12929," vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combine these; into vector operations. .. code-block:: c++. void foo(int a1, int a2, int b1, int b2, int *A) {; A[0] = a1*(a1 + b1);; A[1] = a2*(a2 + b2);; A[2] = a1*(a1 + b1);; A[3] = a2*(a2 + b2);; }. The SLP-vectorizer ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:293,Performance,optimiz,optimization,293,"==========================; Auto-Vectorization in LLVM; ==========================. .. contents::; :local:. LLVM has two vectorizers: The :ref:`Loop Vectorizer <loop-vectorizer>`,; which operates on Loops, and the :ref:`SLP Vectorizer; <slp-vectorizer>`. These vectorizers; focus on different optimization opportunities and use different techniques.; The SLP vectorizer merges multiple scalars that are found in the code into; vectors while the Loop Vectorizer widens instructions in loops; to operate on multiple consecutive iterations. Both the Loop Vectorizer and the SLP Vectorizer are enabled by default. .. _loop-vectorizer:. The Loop Vectorizer; ===================. Usage; -----. The Loop Vectorizer is enabled by default, but it can be disabled; through clang using the command line flag:. .. code-block:: console. $ clang ... -fno-vectorize file.c. Command line flags; ^^^^^^^^^^^^^^^^^^. The loop vectorizer uses a cost model to decide on the optimal vectorization factor; and unroll factor. However, users of the vectorizer can force the vectorizer to use; specific values. Both 'clang' and 'opt' support the flags below. Users can control the vectorization SIMD width using the command line flag ""-force-vector-width"". .. code-block:: console. $ clang -mllvm -force-vector-width=8 ...; $ opt -loop-vectorize -force-vector-width=8 ... Users can control the unroll factor using the command line flag ""-force-vector-interleave"". .. code-block:: console. $ clang -mllvm -force-vector-interleave=2 ...; $ opt -loop-vectorize -force-vector-interleave=2 ... Pragma loop hint directives; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``#pragma clang loop`` directive allows loop vectorization hints to be; specified for the subsequent for, while, do-while, or c++11 range-based for; loop. The directive allows vectorization and interleaving to be enabled or; disabled. Vector width as well as interleave count can also be manually; specified. The following example explicitly enables vectorization and; interl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:2452,Performance,optimiz,optimizations,2452,":: console. $ clang -mllvm -force-vector-interleave=2 ...; $ opt -loop-vectorize -force-vector-interleave=2 ... Pragma loop hint directives; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``#pragma clang loop`` directive allows loop vectorization hints to be; specified for the subsequent for, while, do-while, or c++11 range-based for; loop. The directive allows vectorization and interleaving to be enabled or; disabled. Vector width as well as interleave count can also be manually; specified. The following example explicitly enables vectorization and; interleaving:. .. code-block:: c++. #pragma clang loop vectorize(enable) interleave(enable); while(...) {; ...; }. The following example implicitly enables vectorization and interleaving by; specifying a vector width and interleaving count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:2668,Performance,optimiz,optimization,2668,"uent for, while, do-while, or c++11 range-based for; loop. The directive allows vectorization and interleaving to be enabled or; disabled. Vector width as well as interleave count can also be manually; specified. The following example explicitly enables vectorization and; interleaving:. .. code-block:: c++. #pragma clang loop vectorize(enable) interleave(enable); while(...) {; ...; }. The following example implicitly enables vectorization and interleaving by; specifying a vector width and interleaving count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:3173,Performance,optimiz,optimization-record,3173," count:. .. code-block:: c++. #pragma clang loop vectorize_width(2) interleave_count(2); for(...) {; ...; }. See the Clang; `language extensions; <https://clang.llvm.org/docs/LanguageExtensions.html#extensions-for-loop-hint-optimizations>`_; for details. Diagnostics; -----------. Many loops cannot be vectorized including loops with complicated control flow,; unvectorizable types, and unvectorizable calls. The loop vectorizer generates; optimization remarks which can be queried using command line options to identify; and diagnose loops that are skipped by the loop-vectorizer. Optimization remarks are enabled using:. ``-Rpass=loop-vectorize`` identifies loops that were successfully vectorized. ``-Rpass-missed=loop-vectorize`` identifies loops that failed vectorization and; indicates if vectorization was specified. ``-Rpass-analysis=loop-vectorize`` identifies the statements that caused; vectorization to fail. If in addition ``-fsave-optimization-record`` is; provided, multiple causes of vectorization failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed=loop-vectorize]. And the command line ``-Rpass-analysis=loop-vectorize`` indicates that the; switch statement cannot be vectorized. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: loop contains a switch statement [-Rpass-analysis=loop-vectorize]; switch(A[i]) {; ^. To ensure line and column numbers are produced include the command line options; ``-gline-tables-only`` and ``-gcolumn-info``. See the Clang `user manual; <https://clang.llvm.org/docs/UsersManual.html#options-to-e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:4232,Performance,optimiz,optimization-reports,4232,"n failure may be listed (this behavior; might change in the future). Consider the following loop:. .. code-block:: c++. #pragma clang loop vectorize(enable); for (int i = 0; i < Length; i++) {; switch(A[i]) {; case 0: A[i] = i*2; break;; case 1: A[i] = i; break;; default: A[i] = 0;; }; }. The command line ``-Rpass-missed=loop-vectorize`` prints the remark:. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: vectorization is explicitly enabled [-Rpass-missed=loop-vectorize]. And the command line ``-Rpass-analysis=loop-vectorize`` indicates that the; switch statement cannot be vectorized. .. code-block:: console. no_switch.cpp:4:5: remark: loop not vectorized: loop contains a switch statement [-Rpass-analysis=loop-vectorize]; switch(A[i]) {; ^. To ensure line and column numbers are produced include the command line options; ``-gline-tables-only`` and ``-gcolumn-info``. See the Clang `user manual; <https://clang.llvm.org/docs/UsersManual.html#options-to-emit-optimization-reports>`_; for details. Features; --------. The LLVM Loop Vectorizer has a number of features that allow it to vectorize; complex loops. Loops with unknown trip count; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer supports loops with an unknown trip count.; In the loop below, the iteration ``start`` and ``finish`` points are unknown,; and the Loop Vectorizer has a mechanism to vectorize loops that do not start; at zero. In this example, 'n' may not be a multiple of the vector width, and; the vectorizer has to execute the last few iterations as scalar code. Keeping; a scalar copy of the loop increases the code size. .. code-block:: c++. void bar(float *A, float* B, float K, int start, int end) {; for (int i = start; i < end; ++i); A[i] *= B[i] + K;; }. Runtime Checks of Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In the example below, if the pointers A and B point to consecutive addresses,; then it is illegal to vectorize the code because some elements of A will be; written before ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:9664,Performance,optimiz,optimizer,9664,"ed, with alias analysis being; used to make sure accesses don't alias. Run-time checks can also be added on; pointer access to structure members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient becaus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:9840,Performance,optimiz,optimization,9840,"ucture members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient because only a single execution port can be used by the processor.; By unrolling the code the Loop Vectorizer allows two or more executi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:10592,Performance,perform,performing,10592,"arbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient because only a single execution port can be used by the processor.; By unrolling the code the Loop Vectorizer allows two or more execution ports; to be used simultaneously. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i];; return sum;; }. The Loop Vectorizer uses a cost model to decide when it is profitable to unroll loops.; The decision to unroll the loop depends on the register pressure and the generated code size. Epilogue Vectorization; ^^^^^^^^^^^^^^^^^^^^^^. When vectorizing a loop, often a scalar remainder (epilogue) loop is necessary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; tr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12144,Performance,optimiz,optimizes,12144,"cision to unroll the loop depends on the register pressure and the generated code size. Epilogue Vectorization; ^^^^^^^^^^^^^^^^^^^^^^. When vectorizing a loop, often a scalar remainder (epilogue) loop is necessary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`Vec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12712,Performance,tune,tuned,12712,"nner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:13597,Performance,perform,performs,13597,"very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combine these; into vector operations. .. code-block:: c++. void foo(int a1, int a2, int b1, int b2, int *A) {; A[0] = a1*(a1 + b1);; A[1] = a2*(a2 + b2);; A[2] = a1*(a1 + b1);; A[3] = a2*(a2 + b2);; }. The SLP-vectorizer processes the code bottom-up, across basic blocks, in search of scalars to combine. Usage; ------. The SLP Vectorizer is enabled by default, but it can be disabled; through clang using the command line flag:. .. code-block:: console. $ clang -fno-slp-vectorize file.c; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:5986,Safety,detect,detect,5986,"rt; i < end; ++i); A[i] *= B[i] + K;; }. Runtime Checks of Pointers; ^^^^^^^^^^^^^^^^^^^^^^^^^^. In the example below, if the pointers A and B point to consecutive addresses,; then it is illegal to vectorize the code because some elements of A will be; written before they are read from array B. Some programmers use the 'restrict' keyword to notify the compiler that the; pointers are disjointed, but in our example, the Loop Vectorizer has no way of; knowing that the pointers A and B are unique. The Loop Vectorizer handles this; loop by placing code that checks, at runtime, if the arrays A and B point to; disjointed memory locations. If arrays A and B overlap, then the scalar version; of the loop is executed. .. code-block:: c++. void bar(float *A, float* B, float K, int n) {; for (int i = 0; i < n; ++i); A[i] *= B[i] + K;; }. Reductions; ^^^^^^^^^^. In this example the ``sum`` variable is used by consecutive iterations of; the loop. Normally, this would prevent vectorization, but the vectorizer can; detect that 'sum' is a reduction variable. The variable 'sum' becomes a vector; of integers, and at the end of the loop the elements of the array are added; together to create the correct result. We support a number of different; reduction operations, such as addition, multiplication, XOR, AND and OR. .. code-block:: c++. int foo(int *A, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); sum += A[i] + 5;; return sum;; }. We support floating point reduction operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:7431,Safety,detect,detects,7431,"n operations when `-ffast-math` is used. Inductions; ^^^^^^^^^^. In this example the value of the induction variable ``i`` is saved into an; array. The Loop Vectorizer knows to vectorize induction variables. .. code-block:: c++. void bar(float *A, int n) {; for (int i = 0; i < n; ++i); A[i] = i;; }. If Conversion; ^^^^^^^^^^^^^. The Loop Vectorizer is able to ""flatten"" the IF statement in the code and; generate a single stream of instructions. The Loop Vectorizer supports any; control flow in the innermost loop. The innermost loop may contain complex; nesting of IFs, ELSEs and even GOTOs. .. code-block:: c++. int foo(int *A, int *B, int n) {; unsigned sum = 0;; for (int i = 0; i < n; ++i); if (A[i] > B[i]); sum += A[i] + 5;; return sum;; }. Pointer Induction Variables; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. This example uses the ""accumulate"" function of the standard c++ library. This; loop uses C++ iterators, which are pointers, and not integer indices.; The Loop Vectorizer detects pointer induction variables and can vectorize; this loop. This feature is important because many C++ programs use iterators. .. code-block:: c++. int baz(int *A, int n) {; return std::accumulate(A, A + n, 0);; }. Reverse Iterators; ^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize loops that count backwards. .. code-block:: c++. void foo(int *A, int n) {; for (int i = n; i > 0; --i); A[i] +=1;; }. Scatter / Gather; ^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize code that becomes a sequence of scalar instructions; that scatter/gathers memory. .. code-block:: c++. void foo(int * A, int * B, int n) {; for (intptr_t i = 0; i < n; ++i); A[i] += B[i * 4];; }. In many situations the cost model will inform LLVM that this is not beneficial; and LLVM will only vectorize such code if forced with ""-mllvm -force-vector-width=#"". Vectorization of Mixed Types; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize programs with mixed types. The Vectorizer; cost model can estimate the cost of the t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12093,Safety,avoid,avoids,12093,"cision to unroll the loop depends on the register pressure and the generated code size. Epilogue Vectorization; ^^^^^^^^^^^^^^^^^^^^^^. When vectorizing a loop, often a scalar remainder (epilogue) loop is necessary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`Vec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:8785,Security,access,accesses,8785,"ards. .. code-block:: c++. void foo(int *A, int n) {; for (int i = n; i > 0; --i); A[i] +=1;; }. Scatter / Gather; ^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize code that becomes a sequence of scalar instructions; that scatter/gathers memory. .. code-block:: c++. void foo(int * A, int * B, int n) {; for (intptr_t i = 0; i < n; ++i); A[i] += B[i * 4];; }. In many situations the cost model will inform LLVM that this is not beneficial; and LLVM will only vectorize such code if forced with ""-mllvm -force-vector-width=#"". Vectorization of Mixed Types; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize programs with mixed types. The Vectorizer; cost model can estimate the cost of the type conversion and decide if; vectorization is profitable. .. code-block:: c++. void foo(int *A, char *B, int n) {; for (int i = 0; i < n; ++i); A[i] += 4 * B[i];; }. Global Structures Alias Analysis; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Access to global structures can also be vectorized, with alias analysis being; used to make sure accesses don't alias. Run-time checks can also be added on; pointer access to structure members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:8853,Security,access,access,8853,"Scatter / Gather; ^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize code that becomes a sequence of scalar instructions; that scatter/gathers memory. .. code-block:: c++. void foo(int * A, int * B, int n) {; for (intptr_t i = 0; i < n; ++i); A[i] += B[i * 4];; }. In many situations the cost model will inform LLVM that this is not beneficial; and LLVM will only vectorize such code if forced with ""-mllvm -force-vector-width=#"". Vectorization of Mixed Types; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize programs with mixed types. The Vectorizer; cost model can estimate the cost of the type conversion and decide if; vectorization is profitable. .. code-block:: c++. void foo(int *A, char *B, int n) {; for (int i = 0; i < n; ++i); A[i] += 4 * B[i];; }. Global Structures Alias Analysis; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Access to global structures can also be vectorized, with alias analysis being; used to make sure accesses don't alias. Run-time checks can also be added on; pointer access to structure members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better opti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:9784,Security,access,access,9784,"ed, with alias analysis being; used to make sure accesses don't alias. Run-time checks can also be added on; pointer access to structure members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire width of the machine.; The Loop Vectorizer increases the instruction level parallelism (ILP) by; performing partial-unrolling of loops. In the example below the entire array is accumulated into the variable 'sum'.; This is inefficient becaus",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:13449,Security,access,accesses,13449,"very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operations, PHI-nodes, can all be vectorized using this technique. For example, the following function performs very similar operations on its; inputs (a1, b1) and (a2, b2). The basic-block vectorizer may combine these; into vector operations. .. code-block:: c++. void foo(int a1, int a2, int b1, int b2, int *A) {; A[0] = a1*(a1 + b1);; A[1] = a2*(a2 + b2);; A[2] = a1*(a1 + b1);; A[3] = a2*(a2 + b2);; }. The SLP-vectorizer processes the code bottom-up, across basic blocks, in search of scalars to combine. Usage; ------. The SLP Vectorizer is enabled by default, but it can be disabled; through clang using the command line flag:. .. code-block:: console. $ clang -fno-slp-vectorize file.c; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:9466,Testability,log,log,9466," is profitable. .. code-block:: c++. void foo(int *A, char *B, int n) {; for (int i = 0; i < n; ++i); A[i] += 4 * B[i];; }. Global Structures Alias Analysis; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Access to global structures can also be vectorized, with alias analysis being; used to make sure accesses don't alias. Run-time checks can also be added on; pointer access to structure members. Many variations are supported, but some that rely on undefined behaviour being; ignored (as other compilers do) are still being left un-vectorized. .. code-block:: c++. struct { int A[100], K, B[100]; } Foo;. void foo() {; for (int i = 0; i < 100; ++i); Foo.A[i] = Foo.B[i] + 100;; }. Vectorization of function calls; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The Loop Vectorizer can vectorize intrinsic math functions.; See the table below for a list of these functions. +-----+-----+---------+; | pow | exp | exp2 |; +-----+-----+---------+; | sin | cos | sqrt |; +-----+-----+---------+; | log |log2 | log10 |; +-----+-----+---------+; |fabs |floor| ceil |; +-----+-----+---------+; |fma |trunc|nearbyint|; +-----+-----+---------+; | | | fmuladd |; +-----+-----+---------+. Note that the optimizer may not be able to vectorize math library functions; that correspond to these intrinsics if the library calls access external state; such as ""errno"". To allow better optimization of C/C++ math library functions,; use ""-fno-math-errno"". The loop vectorizer knows about special instructions on the target and will; vectorize a loop containing a function call that maps to the instructions. For; example, the loop below will be vectorized on Intel x86 if the SSE4.1 roundps; instruction is available. .. code-block:: c++. void foo(float *f) {; for (int i = 0; i != 1024; ++i); f[i] = floorf(f[i]);; }. Partial unrolling during vectorization; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. Modern processors feature multiple execution units, and only programs that contain a; high degree of parallelism can fully utilize the entire wi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12343,Testability,benchmark,benchmark,12343,"sary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12396,Testability,test,test-suite,12396,"does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12461,Testability,benchmark,benchmarks,12461,"on and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.k.a. superword-level parallelism) is; to combine similar independent instructions; into vector instructions. Memory accesses, arithmetic operations, comparison; operati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst:12336,Usability,simpl,simple,12336,"sary; to execute tail iterations of the loop if the loop trip count is unknown or it; does not evenly divide the vectorization and unroll factors. When the; vectorization and unroll factors are large, it's possible for loops with smaller; trip counts to end up spending most of their time in the scalar (rather than; the vector) code. In order to address this issue, the inner loop vectorizer is; enhanced with a feature that allows it to vectorize epilogue loops with a; vectorization and unroll factor combination that makes it more likely for small; trip count loops to still execute in vectorized code. The diagram below shows; the CFG for a typical epilogue vectorized loop with runtime checks. As; illustrated the control flow is structured in a way that avoids duplicating the; runtime pointer checks and optimizes the path length for loops that have very; small trip counts. .. image:: epilogue-vectorization-cfg.png. Performance; -----------. This section shows the execution time of Clang on a simple benchmark:; `gcc-loops <https://github.com/llvm/llvm-test-suite/tree/main/SingleSource/UnitTests/Vectorizer>`_.; This benchmarks is a collection of loops from the GCC autovectorization; `page <http://gcc.gnu.org/projects/tree-ssa/vectorization.html>`_ by Dorit Nuzman. The chart below compares GCC-4.7, ICC-13, and Clang-SVN with and without loop vectorization at -O3, tuned for ""corei7-avx"", running on a Sandybridge iMac.; The Y-axis shows the time in msec. Lower is better. The last column shows the geomean of all the kernels. .. image:: gcc-loops.png. And Linpack-pc with the same configuration. Result is Mflops, higher is better. .. image:: linpack-pc.png. Ongoing Development Directions; ------------------------------. .. toctree::; :hidden:. VectorizationPlan. :doc:`VectorizationPlan`; Modeling the process and upgrading the infrastructure of LLVM's Loop Vectorizer. .. _slp-vectorizer:. The SLP Vectorizer; ==================. Details; -------. The goal of SLP vectorization (a.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/Vectorizers.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/Vectorizers.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:873,Availability,down,downloaded,873,"=======================; Writing an LLVM Backend; =======================. .. toctree::; :hidden:. HowToUseInstrMappings. .. contents::; :local:. Introduction; ============. This document describes techniques for writing compiler backends that convert; the LLVM Intermediate Representation (IR) to code for a specified machine or; other languages. Code intended for a specific machine can take the form of; either assembly code or binary code (usable for a JIT compiler). The backend of LLVM features a target-independent code generator that may; create output for several types of target CPUs --- including X86, PowerPC,; ARM, and SPARC. The backend may also be used to generate code targeted at SPUs; of the Cell processor or GPUs to support the execution of compute kernels. The document focuses on existing examples found in subdirectories of; ``llvm/lib/Target`` in a downloaded LLVM release. In particular, this document; focuses on the example of creating a static compiler (one that emits text; assembly) for a SPARC target, because SPARC has fairly standard; characteristics, such as a RISC instruction set and straightforward calling; conventions. Audience; --------. The audience for this document is anyone who needs to write an LLVM backend to; generate code for a specific hardware or software target. Prerequisite Reading; --------------------. These essential documents must be read before reading this document:. * `LLVM Language Reference Manual <LangRef.html>`_ --- a reference manual for; the LLVM assembly language. * :doc:`CodeGenerator` --- a guide to the components (classes and code; generation algorithms) for translating the LLVM internal representation into; machine code for a specified target. Pay particular attention to the; descriptions of code generation stages: Instruction Selection, Scheduling and; Formation, SSA-based Optimization, Register Allocation, Prolog/Epilog Code; Insertion, Late Machine Code Optimizations, and Code Emission. * :doc:`TableGen/index` --",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:7068,Availability,error,errors,7068,"ctually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Generator <CodeGenerator>` document. First, you should create a subdirectory under ``lib/Target`` to hold all the; files related to your target. If your target is called ""Dummy"", create the; directory ``lib/Target/Dummy``. In this new directory, create a ``CMakeLists.txt``. It is easiest to copy a; ``CMakeLists.txt`` of another target and modify it. It should at least contain; the ``LLVM_TARGET_DEFINITIONS`` variable. The library can be named ``LLVMDummy``; (for example, see the MIPS target). Alternatively, you can split the library; into ``LLVMDummyCodeGen`` and ``LLVMDummyAsmPrinter``, the latter of which; should be implemented in a subdirectory below ``lib/Target/Dummy`` (for example,; see the PowerPC target). Note that these two naming schemes are hardcoded into ``llvm-config``. Using; any other naming scheme will confuse ``llvm-config`` and produce a lot of; (seemingly unrelated) linker errors when linking ``llc``. To make your target actually do something, you need to implement a subclass of; ``TargetMachine``. This implementation should typically be in the file; ``lib/Target/DummyTargetMachine.cpp``, but any file in the ``lib/Target``; directory will be built and should work. To use LLVM's target independent code; generator, you should do what all current machine backends do: create a; subclass of ``LLVMTargetMachine``. (To create a target from scratch, create a; subclass of ``TargetMachine``.). To get LLVM to actually build and link your target, you need to run ``cmake``; with ``-DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=Dummy``. This will build your; target without needing to add it to the list of all the targets. Once your target is stable, you can add it to the ``LLVM_ALL_TARGETS`` variable; located in the main ``CMakeLists.txt``. Target Machine; ==============. ``LLVMTargetMachine`` is designed as a base class for targets imp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:10838,Availability,mask,masked,10838,"fo() const;. public:; SparcTargetMachine(const Module &M, const std::string &FS);. virtual const SparcInstrInfo *getInstrInfo() const {return &InstrInfo; }; virtual const TargetFrameInfo *getFrameInfo() const {return &FrameInfo; }; virtual const TargetSubtarget *getSubtargetImpl() const{return &Subtarget; }; virtual const TargetRegisterInfo *getRegisterInfo() const {; return &InstrInfo.getRegisterInfo();; }; virtual const DataLayout *getDataLayout() const { return &DataLayout; }. // Pass Pipeline Configuration; virtual bool addInstSelector(PassManagerBase &PM, bool Fast);; virtual bool addPreEmitPass(PassManagerBase &PM, bool Fast);; };. } // end namespace llvm. * ``getInstrInfo()``; * ``getRegisterInfo()``; * ``getFrameInfo()``; * ``getDataLayout()``; * ``getSubtargetImpl()``. For some targets, you also need to support the following methods:. * ``getTargetLowering()``; * ``getJITInfo()``. Some architectures, such as GPUs, do not support jumping to an arbitrary; program location and implement branching using masked execution and loop using; special instructions around the loop body. In order to avoid CFG modifications; that introduce irreducible control flow not handled by such hardware, a target; must call `setRequiresStructuredCFG(true)` when being initialized. In addition, the ``XXXTargetMachine`` constructor should specify a; ``TargetDescription`` string that determines the data layout for the target; machine, including characteristics such as pointer size, alignment, and; endianness. For example, the constructor for ``SparcTargetMachine`` contains; the following:. .. code-block:: c++. SparcTargetMachine::SparcTargetMachine(const Module &M, const std::string &FS); : DataLayout(""E-p:32:32-f128:128:128""),; Subtarget(M, FS), InstrInfo(Subtarget),; FrameInfo(TargetFrameInfo::StackGrowsDown, 8, 0) {; }. Hyphens separate portions of the ``TargetDescription`` string. * An upper-case ""``E``"" in the string indicates a big-endian target data model.; A lower-case ""``e``"" in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:13463,Availability,avail,available,13463," Target Registration; ===================. You must also register your target with the ``TargetRegistry``, which is what; other LLVM tools use to be able to lookup and use your target at runtime. The; ``TargetRegistry`` can be used directly, but for most targets there are helper; templates which should take care of the work for you. All targets should declare a global ``Target`` object which is used to; represent the target during registration. Then, in the target's ``TargetInfo``; library, the target should define that object and use the ``RegisterTarget``; template to register the target. For example, the Sparc registration code; looks like this:. .. code-block:: c++. Target llvm::getTheSparcTarget();. extern ""C"" void LLVMInitializeSparcTargetInfo() {; RegisterTarget<Triple::sparc, /*HasJIT=*/false>; X(getTheSparcTarget(), ""sparc"", ""Sparc"");; }. This allows the ``TargetRegistry`` to look up the target by name or by target; triple. In addition, most targets will also register additional features which; are available in separate libraries. These registration steps are separate,; because some clients may wish to only link in some parts of the target --- the; JIT code generator does not require the use of the assembler printer, for; example. Here is an example of registering the Sparc assembly printer:. .. code-block:: c++. extern ""C"" void LLVMInitializeSparcAsmPrinter() {; RegisterAsmPrinter<SparcAsmPrinter> X(getTheSparcTarget());; }. For more information, see ""`llvm/Target/TargetRegistry.h; </doxygen/TargetRegistry_8h-source.html>`_"". Register Set and Register Classes; =================================. You should describe a concrete target-specific class that represents the; register file of a target machine. This class is called ``XXXRegisterInfo``; (where ``XXX`` identifies the target) and represents the class register file; data that is used for register allocation. It also describes the interactions; between registers. You also need to define register classes t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22685,Availability,avail,available,22685,"include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs``; defines a group of 32 single-precision floating-point registers (``F0`` to; ``F31``); ``DFPRegs`` defines a group of 16 double-precision registers; (``D0-D15``). .. code-block:: text. // F0, F1, F2, ..., F31; def FPRegs : RegisterClass<""SP"", [f32], 32, (sequence ""F%u"", 0, 31)>;. def DFPRegs : RegisterClass<""SP"", [f64], 64,; (add D0, D1, D2, D3, D4, D5, D6, D7, D8,; D9, D10, D11, D12, D13, D14, D15)>;. def IntRegs : RegisterClass<""SP"", [i32], 32,; (add L0, L1, L2, L3, L4, L5, L6, L7,; I0, I1, I2, I3, I4, I5,; O0, O1, O2, O3, O4, O5, O7,; G1,; // Non-allocatable regs:; G2, G3, G4,; O6, // stack ptr; I6, // frame ptr; I7, // return address; G0, // constant zero; G5, G6, G7 // res",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:41862,Availability,avail,available,41862,"ableGen definitions,; so operands with lowercase names will have lower case entries in the enum. To include the getNamedOperandIdx() function in your backend, you will need; to define a few preprocessor macros in XXXInstrInfo.cpp and XXXInstrInfo.h.; For example:. XXXInstrInfo.cpp:. .. code-block:: c++. #define GET_INSTRINFO_NAMED_OPS // For getNamedOperandIdx() function; #include ""XXXGenInstrInfo.inc"". XXXInstrInfo.h:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_ENUM // For OpName enum; #include ""XXXGenInstrInfo.inc"". namespace XXX {; int16_t getNamedOperandIdx(uint16_t Opcode, uint16_t NamedIndex);; } // End namespace XXX. Instruction Operand Types; ^^^^^^^^^^^^^^^^^^^^^^^^^. TableGen will also generate an enumeration consisting of all named Operand; types defined in the backend, in the llvm::XXX::OpTypes namespace.; Some common immediate Operand types (for instance i8, i32, i64, f32, f64); are defined for all targets in ``include/llvm/Target/Target.td``, and are; available in each Target's OpTypes enum. Also, only named Operand types appear; in the enumeration: anonymous types are ignored.; For example, the X86 backend defines ``brtarget`` and ``brtarget8``, both; instances of the TableGen ``Operand`` class, which represent branch target; operands:. .. code-block:: text. def brtarget : Operand<OtherVT>;; def brtarget8 : Operand<OtherVT>;. This results in:. .. code-block:: c++. namespace X86 {; namespace OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace gen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:59112,Availability,down,down,59112,"; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatment, or an operation; may require spilling and restoring registers in the stack and working with; register allocators. As seen in ``SparcISelLowering.cpp`` code below, to perform a type conversion; from a floating point value to a signed integer, first the; ``setOperationAction`` should be called with ``C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:62617,Availability,avail,available,62617,"al);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``TargetCallingConv.td`` to specify:. * The order of parameter allocation. * Where parameters and return values are placed (that is, on the stack or in; registers). * Which registers may be used. * Whether the caller or callee unwinds the stack. The following example demonstrates the use of the ``CCIfType`` and; ``CCAssignToReg`` interfaces. If the ``CCIfType`` predicate is true (that is,; if the current argument is of type ``f32`` or ``f64``), then the action is; performed. In this case, the ``CCAssignToReg`` action assigns the argument; value to the first available register: either ``R0`` or ``R1``. .. code-block:: text. CCIfType<[f32,f64], CCAssignToReg<[R0, R1]>>. ``SparcCallingConv.td`` contains definitions for a target-specific return-value; calling convention (``RetCC_Sparc32``) and a basic 32-bit C calling convention; (``CC_Sparc32``). The definition of ``RetCC_Sparc32`` (shown below) indicates; which registers are used for specified scalar return types. A single-precision; float is returned to register ``F0``, and a double-precision float goes to; register ``D0``. A 32-bit integer is returned in register ``I0`` or ``I1``. .. code-block:: text. def RetCC_Sparc32 : CallingConv<[; CCIfType<[i32], CCAssignToReg<[I0, I1]>>,; CCIfType<[f32], CCAssignToReg<[F0]>>,; CCIfType<[f64], CCAssignToReg<[D0]>>; ]>;. The definition of ``CC_Sparc32`` in ``SparcCallingConv.td`` introduces; ``CCAssignToStack``, which assigns the value to a stack slot with the specified; size and alignment. In the example below, the first paramete",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:71113,Availability,down,down,71113,"XXGenAsmWriter.inc`` contains an implementation of the ``printInstruction``; method that may call these methods:. * ``printOperand``; * ``printMemOperand``; * ``printCCOperand`` (for conditional statements); * ``printDataDirective``; * ``printDeclare``; * ``printImplicitDef``; * ``printInlineAsm``. The implementations of ``printDeclare``, ``printImplicitDef``,; ``printInlineAsm``, and ``printLabel`` in ``AsmPrinter.cpp`` are generally; adequate for printing assembly and do not need to be overridden. The ``printOperand`` method is implemented with a long ``switch``/``case``; statement for the type of operand: register, immediate, basic block, external; symbol, global address, constant pool index, or jump table index. For an; instruction with a memory address operand, the ``printMemOperand`` method; should be implemented to generate the proper output. Similarly,; ``printCCOperand`` should be used to print a conditional operand. ``doFinalization`` should be overridden in ``XXXAsmPrinter``, and it should be; called to shut down the assembly printer. During ``doFinalization``, global; variables and constants are printed to output. Subtarget Support; =================. Subtarget support is used to inform the code generation process of instruction; set variations for a given chip set. For example, the LLVM SPARC; implementation provided covers three major versions of the SPARC microprocessor; architecture: Version 8 (V8, which is a 32-bit architecture), Version 9 (V9, a; 64-bit architecture), and the UltraSPARC architecture. V8 has 16; double-precision floating-point registers that are also usable as either 32; single-precision or 8 quad-precision registers. V8 is also purely big-endian.; V9 has 32 double-precision floating-point registers that are also usable as 16; quad-precision registers, but cannot be used as single-precision registers.; The UltraSPARC architecture combines V9 with UltraSPARC Visual Instruction Set; extensions. If subtarget support is needed, you shou",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:889,Deployability,release,release,889,"=======================; Writing an LLVM Backend; =======================. .. toctree::; :hidden:. HowToUseInstrMappings. .. contents::; :local:. Introduction; ============. This document describes techniques for writing compiler backends that convert; the LLVM Intermediate Representation (IR) to code for a specified machine or; other languages. Code intended for a specific machine can take the form of; either assembly code or binary code (usable for a JIT compiler). The backend of LLVM features a target-independent code generator that may; create output for several types of target CPUs --- including X86, PowerPC,; ARM, and SPARC. The backend may also be used to generate code targeted at SPUs; of the Cell processor or GPUs to support the execution of compute kernels. The document focuses on existing examples found in subdirectories of; ``llvm/lib/Target`` in a downloaded LLVM release. In particular, this document; focuses on the example of creating a static compiler (one that emits text; assembly) for a SPARC target, because SPARC has fairly standard; characteristics, such as a RISC instruction set and straightforward calling; conventions. Audience; --------. The audience for this document is anyone who needs to write an LLVM backend to; generate code for a specific hardware or software target. Prerequisite Reading; --------------------. These essential documents must be read before reading this document:. * `LLVM Language Reference Manual <LangRef.html>`_ --- a reference manual for; the LLVM assembly language. * :doc:`CodeGenerator` --- a guide to the components (classes and code; generation algorithms) for translating the LLVM internal representation into; machine code for a specified target. Pay particular attention to the; descriptions of code generation stages: Instruction Selection, Scheduling and; Formation, SSA-based Optimization, Register Allocation, Prolog/Epilog Code; Insertion, Late Machine Code Optimizations, and Code Emission. * :doc:`TableGen/index` --",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22038,Deployability,configurat,configurations,22038,"n pick the size; int Alignment = alignment;. // CopyCost is the cost of copying a value between two registers; // default value 1 means a single instruction; // A negative value means copying is extremely expensive or impossible; int CopyCost = 1;; dag MemberList = regList;. // for register classes that are subregisters of this class; list<RegisterClass> SubRegClassList = [];. code MethodProtos = [{}]; // to insert arbitrary code; code MethodBodies = [{}];; }. To define a ``RegisterClass``, use the following 4 arguments:. * The first argument of the definition is the name of the namespace. * The second argument is a list of ``ValueType`` register type values that are; defined in ``include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58050,Deployability,release,releases,58050,"gisterClass(MVT::i32, SP::IntRegsRegisterClass);; addRegisterClass(MVT::f32, SP::FPRegsRegisterClass);; addRegisterClass(MVT::f64, SP::DFPRegsRegisterClass);. You should examine the node types in the ``ISD`` namespace; (``include/llvm/CodeGen/SelectionDAGNodes.h``) and determine which operations; the target natively supports. For operations that do **not** have native; support, add a callback to the constructor for the ``XXXTargetLowering`` class,; so the instruction selection process knows what to do. The ``TargetLowering``; class callback methods (declared in ``llvm/Target/TargetLowering.h``) are:. * ``setOperationAction`` --- General operation.; * ``setLoadExtAction`` --- Load with extension.; * ``setTruncStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native supp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58136,Deployability,release,releases,58136,"P::FPRegsRegisterClass);; addRegisterClass(MVT::f64, SP::DFPRegsRegisterClass);. You should examine the node types in the ``ISD`` namespace; (``include/llvm/CodeGen/SelectionDAGNodes.h``) and determine which operations; the target natively supports. For operations that do **not** have native; support, add a callback to the constructor for the ``XXXTargetLowering`` class,; so the instruction selection process knows what to do. The ``TargetLowering``; class callback methods (declared in ``llvm/Target/TargetLowering.h``) are:. * ``setOperationAction`` --- General operation.; * ``setLoadExtAction`` --- Load with extension.; * ``setTruncStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58204,Deployability,release,release,58204,"erClass);. You should examine the node types in the ``ISD`` namespace; (``include/llvm/CodeGen/SelectionDAGNodes.h``) and determine which operations; the target natively supports. For operations that do **not** have native; support, add a callback to the constructor for the ``XXXTargetLowering`` class,; so the instruction selection process knows what to do. The ``TargetLowering``; class callback methods (declared in ``llvm/Target/TargetLowering.h``) are:. * ``setOperationAction`` --- General operation.; * ``setLoadExtAction`` --- Load with extension.; * ``setTruncStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:14837,Energy Efficiency,allocate,allocate,14837,"ation, see ""`llvm/Target/TargetRegistry.h; </doxygen/TargetRegistry_8h-source.html>`_"". Register Set and Register Classes; =================================. You should describe a concrete target-specific class that represents the; register file of a target machine. This class is called ``XXXRegisterInfo``; (where ``XXX`` identifies the target) and represents the class register file; data that is used for register allocation. It also describes the interactions; between registers. You also need to define register classes to categorize related registers. A; register class should be added for groups of registers that are all treated the; same way for some instruction. Typical examples are register classes for; integer, floating-point, or vector registers. A register allocator allows an; instruction to use any register in a specified register class to perform the; instruction in a similar manner. Register classes allocate virtual registers; to instructions from these sets, and register classes let the; target-independent register allocator automatically choose the actual; registers. Much of the code for registers, including register definition, register; aliases, and register classes, is generated by TableGen from; ``XXXRegisterInfo.td`` input files and placed in ``XXXGenRegisterInfo.h.inc``; and ``XXXGenRegisterInfo.inc`` output files. Some of the code in the; implementation of ``XXXRegisterInfo`` requires hand-coding. Defining a Register; -------------------. The ``XXXRegisterInfo.td`` file typically starts with register definitions for; a target machine. The ``Register`` class (specified in ``Target.td``) is used; to define an object for each register. The specified string ``n`` becomes the; ``Name`` of the register. The basic ``Register`` object does not have any; subregisters and does not specify any aliases. .. code-block:: text. class Register<string n> {; string Namespace = """";; string AsmName = n;; string Name = n;; int SpillSize = 0;; int SpillAlignment = 0;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:42935,Energy Efficiency,schedul,schedule,42935,"ation: anonymous types are ignored.; For example, the X86 backend defines ``brtarget`` and ``brtarget8``, both; instances of the TableGen ``Operand`` class, which represent branch target; operands:. .. code-block:: text. def brtarget : Operand<OtherVT>;; def brtarget8 : Operand<OtherVT>;. This results in:. .. code-block:: c++. namespace X86 {; namespace OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace generated; by TableGen in XXXGenInstrInfo.inc. The name of the schedule classes are; the same as provided in XXXSchedule.td plus a default NoItinerary class. The schedule models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43034,Energy Efficiency,schedul,schedule,43034,"ableGen ``Operand`` class, which represent branch target; operands:. .. code-block:: text. def brtarget : Operand<OtherVT>;; def brtarget8 : Operand<OtherVT>;. This results in:. .. code-block:: c++. namespace X86 {; namespace OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace generated; by TableGen in XXXGenInstrInfo.inc. The name of the schedule classes are; the same as provided in XXXSchedule.td plus a default NoItinerary class. The schedule models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43326,Energy Efficiency,schedul,schedule,43326," OpTypes {; enum OperandType {; ...; brtarget,; brtarget8,; ...; i32imm,; i64imm,; ...; OPERAND_TYPE_LIST_END; } // End namespace OpTypes; } // End namespace X86. In typical TableGen fashion, to use the enum, you will need to define a; preprocessor macro:. .. code-block:: c++. #define GET_INSTRINFO_OPERAND_TYPES_ENUM // For OpTypes enum; #include ""XXXGenInstrInfo.inc"". Instruction Scheduling; ----------------------. Instruction itineraries can be queried using MCDesc::getSchedClass(). The; value can be named by an enumeration in llvm::XXX::Sched namespace generated; by TableGen in XXXGenInstrInfo.inc. The name of the schedule classes are; the same as provided in XXXSchedule.td plus a default NoItinerary class. The schedule models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; command with the ``subtarget-emitter`` debug option:. .. code-block:: shell. $ <build>/bin/llvm-tblgen -debug-only=subtarget-emitter -gen-subtarget \; -I <src>/lib/Target/<target> -I <src>/include \; -I <src>/lib/Target <src>/l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:43992,Energy Efficiency,schedul,schedule,43992,"e models are generated by TableGen by the SubtargetEmitter,; using the ``CodeGenSchedModels`` class. This is distinct from the itinerary; method of specifying machine resource use. The tool ``utils/schedcover.py``; can be used to determine which instructions have been covered by the; schedule model description and which haven't. The first step is to use the; instructions below to create an output file. Then run ``schedcover.py`` on the; output file:. .. code-block:: shell. $ <src>/utils/schedcover.py <build>/lib/Target/AArch64/tblGenSubtarget.with; instruction, default, CortexA53Model, CortexA57Model, CycloneModel, ExynosM3Model, FalkorModel, KryoModel, ThunderX2T99Model, ThunderXT8XModel; ABSv16i8, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_2VXVY_2cyc, KryoWrite_2cyc_XY_XY_150ln, ,; ABSv1i64, WriteV, , , CyWriteV3, M3WriteNMISC1, FalkorWr_1VXVY_2cyc, KryoWrite_2cyc_XY_noRSV_67ln, ,; ... To capture the debug output from generating a schedule model, change to the; appropriate target directory and use the following command:; command with the ``subtarget-emitter`` debug option:. .. code-block:: shell. $ <build>/bin/llvm-tblgen -debug-only=subtarget-emitter -gen-subtarget \; -I <src>/lib/Target/<target> -I <src>/include \; -I <src>/lib/Target <src>/lib/Target/<target>/<target>.td \; -o <build>/lib/Target/<target>/<target>GenSubtargetInfo.inc.tmp \; > tblGenSubtarget.dbg 2>&1. Where ``<build>`` is the build directory, ``src`` is the source directory,; and ``<target>`` is the name of the target.; To double check that the above command is what is needed, one can capture the; exact TableGen command from a build by using:. .. code-block:: shell. $ VERBOSE=1 make ... and search for ``llvm-tblgen`` commands in the output. Instruction Relation Mapping; ----------------------------. This TableGen feature is used to relate instructions with each other. It is; particularly useful when you have multiple instruction formats and need to; switch between them after instruction sele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:65336,Energy Efficiency,allocate,allocates,65336,". After the current value is; assigned to the register ``ST0`` or ``ST1``, the ``RetCC_X86Common`` is; invoked. .. code-block:: text. def RetCC_X86_32_C : CallingConv<[; CCIfType<[f32], CCAssignToReg<[ST0, ST1]>>,; CCIfType<[f64], CCAssignToReg<[ST0, ST1]>>,; CCDelegateTo<RetCC_X86Common>; ]>;. ``CCIfCC`` is an interface that attempts to match the given name to the current; calling convention. If the name identifies the current calling convention,; then a specified action is invoked. In the following example (in; ``X86CallingConv.td``), if the ``Fast`` calling convention is in use, then; ``RetCC_X86_32_Fast`` is invoked. If the ``SSECall`` calling convention is in; use, then ``RetCC_X86_32_SSE`` is invoked. .. code-block:: text. def RetCC_X86_32 : CallingConv<[; CCIfCC<""CallingConv::Fast"", CCDelegateTo<RetCC_X86_32_Fast>>,; CCIfCC<""CallingConv::X86_SSECall"", CCDelegateTo<RetCC_X86_32_SSE>>,; CCDelegateTo<RetCC_X86_32_C>; ]>;. ``CCAssignToRegAndStack`` is the same as ``CCAssignToReg``, but also allocates; a stack slot, when some register is used. Basically, it works like:; ``CCIf<CCAssignToReg<regList>, CCAssignToStack<size, align>>``. .. code-block:: text. class CCAssignToRegAndStack<list<Register> regList, int size, int align>; : CCAssignToReg<regList> {; int Size = size;; int Align = align;; }. Other calling convention interfaces include:. * ``CCIf <predicate, action>`` --- If the predicate matches, apply the action. * ``CCIfInReg <action>`` --- If the argument is marked with the ""``inreg``""; attribute, then apply the action. * ``CCIfNest <action>`` --- If the argument is marked with the ""``nest``""; attribute, then apply the action. * ``CCIfNotVarArg <action>`` --- If the current function does not take a; variable number of arguments, apply the action. * ``CCAssignToRegWithShadow <registerList, shadowList>`` --- similar to; ``CCAssignToReg``, but with a shadow list of registers. * ``CCPassByVal <size, align>`` --- Assign value to a stack slot with the; minimum spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:2897,Integrability,depend,dependent,2897,"cation, Prolog/Epilog Code; Insertion, Late Machine Code Optimizations, and Code Emission. * :doc:`TableGen/index` --- a document that describes the TableGen; (``tblgen``) application that manages domain-specific information to support; LLVM code generation. TableGen processes input from a target description; file (``.td`` suffix) and generates C++ code that can be used for code; generation. * :doc:`WritingAnLLVMPass` --- The assembly printer is a ``FunctionPass``, as; are several ``SelectionDAG`` processing steps. To follow the SPARC examples in this document, have a copy of `The SPARC; Architecture Manual, Version 8 <http://www.sparc.org/standards/V8.pdf>`_ for; reference. For details about the ARM instruction set, refer to the `ARM; Architecture Reference Manual <http://infocenter.arm.com/>`_. For more about; the GNU Assembler format (``GAS``), see `Using As; <http://sourceware.org/binutils/docs/as/index.html>`_, especially for the; assembly printer. ""Using As"" contains a list of target machine dependent; features. Basic Steps; -----------. To write a compiler backend for LLVM that converts the LLVM IR to code for a; specified target (machine or other language), follow these steps:. * Create a subclass of the ``TargetMachine`` class that describes; characteristics of your target machine. Copy existing examples of specific; ``TargetMachine`` class and header files; for example, start with; ``SparcTargetMachine.cpp`` and ``SparcTargetMachine.h``, but change the file; names for your target. Similarly, change code that references ""``Sparc``"" to; reference your target. * Describe the register set of the target. Use TableGen to generate code for; register definition, register aliases, and register classes from a; target-specific ``RegisterInfo.td`` input file. You should also write; additional code for a subclass of the ``TargetRegisterInfo`` class that; represents the class register file data used for register allocation and also; describes the interactions between re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:26453,Integrability,interface,interface,26453," ...; // IntRegs Super-register Classes..; static const TargetRegisterClass* const IntRegsSuperRegClasses [] = {; NULL; };; ...; // IntRegs Register Class sub-classes...; static const TargetRegisterClass* const IntRegsSubclasses [] = {; NULL; };; ...; // IntRegs Register Class super-classes...; static const TargetRegisterClass* const IntRegsSuperclasses [] = {; NULL; };. IntRegsClass::IntRegsClass() : TargetRegisterClass(IntRegsRegClassID,; IntRegsVTs, IntRegsSubclasses, IntRegsSuperclasses, IntRegsSubRegClasses,; IntRegsSuperRegClasses, 4, 4, 1, IntRegs, IntRegs + 32) {}; }. The register allocators will avoid using reserved registers, and callee saved; registers are not used until all the volatile registers have been used. That; is usually good enough, but in some cases it may be necessary to provide custom; allocation orders. Implement a subclass of ``TargetRegisterInfo``; ----------------------------------------------. The final step is to hand code portions of ``XXXRegisterInfo``, which; implements the interface described in ``TargetRegisterInfo.h`` (see; :ref:`TargetRegisterInfo`). These functions return ``0``, ``NULL``, or; ``false``, unless overridden. Here is a list of functions that are overridden; for the SPARC implementation in ``SparcRegisterInfo.cpp``:. * ``getCalleeSavedRegs`` --- Returns a list of callee-saved registers in the; order of the desired callee-save stack frame offset. * ``getReservedRegs`` --- Returns a bitset indexed by physical register; numbers, indicating if a particular register is unavailable. * ``hasFP`` --- Return a Boolean indicating if a function should have a; dedicated frame pointer register. * ``eliminateCallFramePseudoInstr`` --- If call frame setup or destroy pseudo; instructions are used, this can be called to eliminate them. * ``eliminateFrameIndex`` --- Eliminate abstract frame indices from; instructions that may use them. * ``emitPrologue`` --- Insert prologue code into the function. * ``emitEpilogue`` --- Insert epilogue",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:30785,Integrability,depend,depending,30785," Instruction class (defined in ``Target.td``) is mostly used as a base for; more complex instruction classes. .. code-block:: text. class Instruction {; string Namespace = """";; dag OutOperandList; // A dag containing the MI def operand list.; dag InOperandList; // A dag containing the MI use operand list.; string AsmString = """"; // The .s format to print the instruction with.; list<dag> Pattern; // Set to the DAG pattern for this instruction.; list<Register> Uses = [];; list<Register> Defs = [];; list<Predicate> Predicates = []; // predicates turned into isel match code; ... remainder not shown for space ...; }. A ``SelectionDAG`` node (``SDNode``) should contain an object representing a; target-specific instruction that is defined in ``XXXInstrInfo.td``. The; instruction objects should represent instructions from the architecture manual; of the target machine (such as the SPARC Architecture Manual for the SPARC; target). A single instruction from the architecture manual is often modeled as multiple; target instructions, depending upon its operands. For example, a manual might; describe an add instruction that takes a register or an immediate operand. An; LLVM target could model this with two instructions named ``ADDri`` and; ``ADDrr``. You should define a class for each instruction category and define each opcode; as a subclass of the category with appropriate parameters such as the fixed; binary encoding of opcodes and extended opcodes. You should map the register; bits to the bits of the instruction in which they are encoded (for the JIT).; Also you should specify how the instruction should be printed when the; automatic assembly printer is used. As is described in the SPARC Architecture Manual, Version 8, there are three; major 32-bit formats for instructions. Format 1 is only for the ``CALL``; instruction. Format 2 is for branch on condition codes and ``SETHI`` (set high; bits of a register) instructions. Format 3 is for other instructions. Each of these format",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:33511,Integrability,interface,interface,33511,"try, ``LDrr``, defines the Load Integer instruction for a; Word (the ``LD`` SPARC opcode) from a memory address to a register. The first; parameter, the value 3 (``11``\ :sub:`2`), is the operation value for this; category of operation. The second parameter (``000000``\ :sub:`2`) is the; specific operation value for ``LD``/Load Word. The third parameter is the; output destination, which is a register operand and defined in the ``Register``; target description file (``IntRegs``). .. code-block:: text. def LDrr : F3_1 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMrr $rs1, $rs2):$addr),; ""ld [$addr], $dst"",; [(set i32:$dst, (load ADDRrr:$addr))]>;. The fourth parameter is the input source, which uses the address operand; ``MEMrr`` that is defined earlier in ``SparcInstrInfo.td``:. .. code-block:: text. def MEMrr : Operand<i32> {; let PrintMethod = ""printMemOperand"";; let MIOperandInfo = (ops IntRegs, IntRegs);; }. The fifth parameter is a string that is used by the assembly printer and can be; left as an empty string until the assembly printer interface is implemented.; The sixth and final parameter is the pattern used to match the instruction; during the SelectionDAG Select Phase described in :doc:`CodeGenerator`.; This parameter is detailed in the next section, :ref:`instruction-selector`. Instruction class definitions are not overloaded for different operand types,; so separate versions of instructions are needed for register, memory, or; immediate value operands. For example, to perform a Load Integer instruction; for a Word from an immediate operand to a register, the following instruction; class is defined:. .. code-block:: text. def LDri : F3_2 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMri $rs1, $simm13):$addr),; ""ld [$addr], $dst"",; [(set i32:$rd, (load ADDRri:$addr))]>;. Writing these definitions for so many similar instructions can involve a lot of; cut and paste. In ``.td`` files, the ``multiclass`` directive enables the; creation of templates to define several",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:45764,Integrability,interface,interface,45764,"for ``llvm-tblgen`` commands in the output. Instruction Relation Mapping; ----------------------------. This TableGen feature is used to relate instructions with each other. It is; particularly useful when you have multiple instruction formats and need to; switch between them after instruction selection. This entire feature is driven; by relation models which can be defined in ``XXXInstrInfo.td`` files; according to the target-specific instruction set. Relation models are defined; using ``InstrMapping`` class as a base. TableGen parses all the models; and generates instruction relation maps using the specified information.; Relation maps are emitted as tables in the ``XXXGenInstrInfo.inc`` file; along with the functions to query them. For the detailed information on how to; use this feature, please refer to :doc:`HowToUseInstrMappings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:61723,Integrability,interface,interfaces,61723,"c++. static SDValue LowerFP_TO_SINT(SDValue Op, SelectionDAG &DAG) {; assert(Op.getValueType() == MVT::i32);; Op = DAG.getNode(SPISD::FTOI, MVT::f32, Op.getOperand(0));; return DAG.getNode(ISD::BITCAST, MVT::i32, Op);; }. Legal; ^^^^^. The ``Legal`` ``LegalizeAction`` enum value simply indicates that an operation; **is** natively supported. ``Legal`` represents the default condition, so it; is rarely used. In ``SparcISelLowering.cpp``, the action for ``CTPOP`` (an; operation to count the bits set in an integer) is natively supported only for; SPARC v9. The following code enables the ``Expand`` conversion technique for; non-v9 SPARC implementations. .. code-block:: c++. setOperationAction(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``TargetCallingConv.td`` to specify:. * The order of parameter allocation. * Where parameters and return values are placed (that is, on the stack or in; registers). * Which registers may be used. * Whether the caller or callee unwinds the stack. The following example demonstrates the use of the ``CCIfType`` and; ``CCAssignToReg`` interfaces. If the ``CCIfType`` predicate is true (that is,; if the current argument is of type ``f32`` or ``f64``), then the action is; performed. In this case, the ``CCAssignToReg`` action assigns the argument; value to the first available register: either ``R0`` or ``R1``. .. code-block:: text. CCIfType<[f32,f64], CCAssignToReg<[R0, R1]>>. ``SparcCallingConv.td`` contains definitio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:62038,Integrability,interface,interfaces,62038,"lue simply indicates that an operation; **is** natively supported. ``Legal`` represents the default condition, so it; is rarely used. In ``SparcISelLowering.cpp``, the action for ``CTPOP`` (an; operation to count the bits set in an integer) is natively supported only for; SPARC v9. The following code enables the ``Expand`` conversion technique for; non-v9 SPARC implementations. .. code-block:: c++. setOperationAction(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``TargetCallingConv.td`` to specify:. * The order of parameter allocation. * Where parameters and return values are placed (that is, on the stack or in; registers). * Which registers may be used. * Whether the caller or callee unwinds the stack. The following example demonstrates the use of the ``CCIfType`` and; ``CCAssignToReg`` interfaces. If the ``CCIfType`` predicate is true (that is,; if the current argument is of type ``f32`` or ``f64``), then the action is; performed. In this case, the ``CCAssignToReg`` action assigns the argument; value to the first available register: either ``R0`` or ``R1``. .. code-block:: text. CCIfType<[f32,f64], CCAssignToReg<[R0, R1]>>. ``SparcCallingConv.td`` contains definitions for a target-specific return-value; calling convention (``RetCC_Sparc32``) and a basic 32-bit C calling convention; (``CC_Sparc32``). The definition of ``RetCC_Sparc32`` (shown below) indicates; which registers are used for specified scalar return types. A single-precisio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:62385,Integrability,interface,interfaces,62385,"e enables the ``Expand`` conversion technique for; non-v9 SPARC implementations. .. code-block:: c++. setOperationAction(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``TargetCallingConv.td`` to specify:. * The order of parameter allocation. * Where parameters and return values are placed (that is, on the stack or in; registers). * Which registers may be used. * Whether the caller or callee unwinds the stack. The following example demonstrates the use of the ``CCIfType`` and; ``CCAssignToReg`` interfaces. If the ``CCIfType`` predicate is true (that is,; if the current argument is of type ``f32`` or ``f64``), then the action is; performed. In this case, the ``CCAssignToReg`` action assigns the argument; value to the first available register: either ``R0`` or ``R1``. .. code-block:: text. CCIfType<[f32,f64], CCAssignToReg<[R0, R1]>>. ``SparcCallingConv.td`` contains definitions for a target-specific return-value; calling convention (``RetCC_Sparc32``) and a basic 32-bit C calling convention; (``CC_Sparc32``). The definition of ``RetCC_Sparc32`` (shown below) indicates; which registers are used for specified scalar return types. A single-precision; float is returned to register ``F0``, and a double-precision float goes to; register ``D0``. A 32-bit integer is returned in register ``I0`` or ``I1``. .. code-block:: text. def RetCC_Sparc32 : CallingConv<[; CCIfType<[i32], CCAssignToReg<[I0, I1]>>,; CCIfType<[f32], CCAssignToReg<[F0]>>,; CCIfTy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:64100,Integrability,interface,interface,64100,"er ``D0``. A 32-bit integer is returned in register ``I0`` or ``I1``. .. code-block:: text. def RetCC_Sparc32 : CallingConv<[; CCIfType<[i32], CCAssignToReg<[I0, I1]>>,; CCIfType<[f32], CCAssignToReg<[F0]>>,; CCIfType<[f64], CCAssignToReg<[D0]>>; ]>;. The definition of ``CC_Sparc32`` in ``SparcCallingConv.td`` introduces; ``CCAssignToStack``, which assigns the value to a stack slot with the specified; size and alignment. In the example below, the first parameter, 4, indicates; the size of the slot, and the second parameter, also 4, indicates the stack; alignment along 4-byte units. (Special cases: if size is zero, then the ABI; size is used; if alignment is zero, then the ABI alignment is used.). .. code-block:: text. def CC_Sparc32 : CallingConv<[; // All arguments get passed in integer registers if there is space.; CCIfType<[i32, f32, f64], CCAssignToReg<[I0, I1, I2, I3, I4, I5]>>,; CCAssignToStack<4, 4>; ]>;. ``CCDelegateTo`` is another commonly used interface, which tries to find a; specified sub-calling convention, and, if a match is found, it is invoked. In; the following example (in ``X86CallingConv.td``), the definition of; ``RetCC_X86_32_C`` ends with ``CCDelegateTo``. After the current value is; assigned to the register ``ST0`` or ``ST1``, the ``RetCC_X86Common`` is; invoked. .. code-block:: text. def RetCC_X86_32_C : CallingConv<[; CCIfType<[f32], CCAssignToReg<[ST0, ST1]>>,; CCIfType<[f64], CCAssignToReg<[ST0, ST1]>>,; CCDelegateTo<RetCC_X86Common>; ]>;. ``CCIfCC`` is an interface that attempts to match the given name to the current; calling convention. If the name identifies the current calling convention,; then a specified action is invoked. In the following example (in; ``X86CallingConv.td``), if the ``Fast`` calling convention is in use, then; ``RetCC_X86_32_Fast`` is invoked. If the ``SSECall`` calling convention is in; use, then ``RetCC_X86_32_SSE`` is invoked. .. code-block:: text. def RetCC_X86_32 : CallingConv<[; CCIfCC<""CallingConv::Fast"", CCDel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:64640,Integrability,interface,interface,64640,"dicates the stack; alignment along 4-byte units. (Special cases: if size is zero, then the ABI; size is used; if alignment is zero, then the ABI alignment is used.). .. code-block:: text. def CC_Sparc32 : CallingConv<[; // All arguments get passed in integer registers if there is space.; CCIfType<[i32, f32, f64], CCAssignToReg<[I0, I1, I2, I3, I4, I5]>>,; CCAssignToStack<4, 4>; ]>;. ``CCDelegateTo`` is another commonly used interface, which tries to find a; specified sub-calling convention, and, if a match is found, it is invoked. In; the following example (in ``X86CallingConv.td``), the definition of; ``RetCC_X86_32_C`` ends with ``CCDelegateTo``. After the current value is; assigned to the register ``ST0`` or ``ST1``, the ``RetCC_X86Common`` is; invoked. .. code-block:: text. def RetCC_X86_32_C : CallingConv<[; CCIfType<[f32], CCAssignToReg<[ST0, ST1]>>,; CCIfType<[f64], CCAssignToReg<[ST0, ST1]>>,; CCDelegateTo<RetCC_X86Common>; ]>;. ``CCIfCC`` is an interface that attempts to match the given name to the current; calling convention. If the name identifies the current calling convention,; then a specified action is invoked. In the following example (in; ``X86CallingConv.td``), if the ``Fast`` calling convention is in use, then; ``RetCC_X86_32_Fast`` is invoked. If the ``SSECall`` calling convention is in; use, then ``RetCC_X86_32_SSE`` is invoked. .. code-block:: text. def RetCC_X86_32 : CallingConv<[; CCIfCC<""CallingConv::Fast"", CCDelegateTo<RetCC_X86_32_Fast>>,; CCIfCC<""CallingConv::X86_SSECall"", CCDelegateTo<RetCC_X86_32_SSE>>,; CCDelegateTo<RetCC_X86_32_C>; ]>;. ``CCAssignToRegAndStack`` is the same as ``CCAssignToReg``, but also allocates; a stack slot, when some register is used. Basically, it works like:; ``CCIf<CCAssignToReg<regList>, CCAssignToStack<size, align>>``. .. code-block:: text. class CCAssignToRegAndStack<list<Register> regList, int size, int align>; : CCAssignToReg<regList> {; int Size = size;; int Align = align;; }. Other calling convention int",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:65670,Integrability,interface,interfaces,65670,"match the given name to the current; calling convention. If the name identifies the current calling convention,; then a specified action is invoked. In the following example (in; ``X86CallingConv.td``), if the ``Fast`` calling convention is in use, then; ``RetCC_X86_32_Fast`` is invoked. If the ``SSECall`` calling convention is in; use, then ``RetCC_X86_32_SSE`` is invoked. .. code-block:: text. def RetCC_X86_32 : CallingConv<[; CCIfCC<""CallingConv::Fast"", CCDelegateTo<RetCC_X86_32_Fast>>,; CCIfCC<""CallingConv::X86_SSECall"", CCDelegateTo<RetCC_X86_32_SSE>>,; CCDelegateTo<RetCC_X86_32_C>; ]>;. ``CCAssignToRegAndStack`` is the same as ``CCAssignToReg``, but also allocates; a stack slot, when some register is used. Basically, it works like:; ``CCIf<CCAssignToReg<regList>, CCAssignToStack<size, align>>``. .. code-block:: text. class CCAssignToRegAndStack<list<Register> regList, int size, int align>; : CCAssignToReg<regList> {; int Size = size;; int Align = align;; }. Other calling convention interfaces include:. * ``CCIf <predicate, action>`` --- If the predicate matches, apply the action. * ``CCIfInReg <action>`` --- If the argument is marked with the ""``inreg``""; attribute, then apply the action. * ``CCIfNest <action>`` --- If the argument is marked with the ""``nest``""; attribute, then apply the action. * ``CCIfNotVarArg <action>`` --- If the current function does not take a; variable number of arguments, apply the action. * ``CCAssignToRegWithShadow <registerList, shadowList>`` --- similar to; ``CCAssignToReg``, but with a shadow list of registers. * ``CCPassByVal <size, align>`` --- Assign value to a stack slot with the; minimum specified size and alignment. * ``CCPromoteToType <type>`` --- Promote the current value to the specified; type. * ``CallingConv <[actions]>`` --- Define each calling convention that is; supported. Assembly Printer; ================. During the code emission stage, the code generator may utilize an LLVM pass to; produce assembly output. To d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:72411,Integrability,interface,interface,72411,"SPARC; implementation provided covers three major versions of the SPARC microprocessor; architecture: Version 8 (V8, which is a 32-bit architecture), Version 9 (V9, a; 64-bit architecture), and the UltraSPARC architecture. V8 has 16; double-precision floating-point registers that are also usable as either 32; single-precision or 8 quad-precision registers. V8 is also purely big-endian.; V9 has 32 double-precision floating-point registers that are also usable as 16; quad-precision registers, but cannot be used as single-precision registers.; The UltraSPARC architecture combines V9 with UltraSPARC Visual Instruction Set; extensions. If subtarget support is needed, you should implement a target-specific; ``XXXSubtarget`` class for your architecture. This class should process the; command-line options ``-mcpu=`` and ``-mattr=``. TableGen uses definitions in the ``Target.td`` and ``Sparc.td`` files to; generate code in ``SparcGenSubtarget.inc``. In ``Target.td``, shown below, the; ``SubtargetFeature`` interface is defined. The first 4 string parameters of; the ``SubtargetFeature`` interface are a feature name, a XXXSubtarget field set; by the feature, the value of the XXXSubtarget field, and a description of the; feature. (The fifth parameter is a list of features whose presence is implied,; and its default value is an empty array.). If the value for the field is the string ""true"" or ""false"", the field; is assumed to be a bool and only one SubtargetFeature should refer to it.; Otherwise, it is assumed to be an integer. The integer value may be the name; of an enum constant. If multiple features use the same integer field, the; field will be set to the maximum value of all enabled features that share; the field. .. code-block:: text. class SubtargetFeature<string n, string f, string v, string d,; list<SubtargetFeature> i = []> {; string Name = n;; string FieldName = f;; string Value = v;; string Desc = d;; list<SubtargetFeature> Implies = i;; }. In the ``Sparc.td`` file, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:72492,Integrability,interface,interface,72492," architecture), Version 9 (V9, a; 64-bit architecture), and the UltraSPARC architecture. V8 has 16; double-precision floating-point registers that are also usable as either 32; single-precision or 8 quad-precision registers. V8 is also purely big-endian.; V9 has 32 double-precision floating-point registers that are also usable as 16; quad-precision registers, but cannot be used as single-precision registers.; The UltraSPARC architecture combines V9 with UltraSPARC Visual Instruction Set; extensions. If subtarget support is needed, you should implement a target-specific; ``XXXSubtarget`` class for your architecture. This class should process the; command-line options ``-mcpu=`` and ``-mattr=``. TableGen uses definitions in the ``Target.td`` and ``Sparc.td`` files to; generate code in ``SparcGenSubtarget.inc``. In ``Target.td``, shown below, the; ``SubtargetFeature`` interface is defined. The first 4 string parameters of; the ``SubtargetFeature`` interface are a feature name, a XXXSubtarget field set; by the feature, the value of the XXXSubtarget field, and a description of the; feature. (The fifth parameter is a list of features whose presence is implied,; and its default value is an empty array.). If the value for the field is the string ""true"" or ""false"", the field; is assumed to be a bool and only one SubtargetFeature should refer to it.; Otherwise, it is assumed to be an integer. The integer value may be the name; of an enum constant. If multiple features use the same integer field, the; field will be set to the maximum value of all enabled features that share; the field. .. code-block:: text. class SubtargetFeature<string n, string f, string v, string d,; list<SubtargetFeature> i = []> {; string Name = n;; string FieldName = f;; string Value = v;; string Desc = d;; list<SubtargetFeature> Implies = i;; }. In the ``Sparc.td`` file, the ``SubtargetFeature`` is used to define the; following features. .. code-block:: text. def FeatureV9 : SubtargetFeature<""v9"", ""IsV9""",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:75956,Integrability,interface,interfaces,75956,"ould be included in the ``SparcSubtarget.cpp``. The target-specific; implementation of the ``XXXSubtarget`` method should follow this pseudocode:. .. code-block:: c++. XXXSubtarget::XXXSubtarget(const Module &M, const std::string &FS) {; // Set the default features; // Determine default and user specified characteristics of the CPU; // Call ParseSubtargetFeatures(FS, CPU) to parse the features string; // Perform any additional operations; }. JIT Support; ===========. The implementation of a target machine optionally includes a Just-In-Time (JIT); code generator that emits machine code and auxiliary structures as binary; output that can be written directly to memory. To do this, implement JIT code; generation by performing the following steps:. * Write an ``XXXCodeEmitter.cpp`` file that contains a machine function pass; that transforms target-machine instructions into relocatable machine; code. * Write an ``XXXJITInfo.cpp`` file that implements the JIT interfaces for; target-specific code-generation activities, such as emitting machine code and; stubs. * Modify ``XXXTargetMachine`` so that it provides a ``TargetJITInfo`` object; through its ``getJITInfo`` method. There are several different approaches to writing the JIT support code. For; instance, TableGen and target descriptor files may be used for creating a JIT; code generator, but are not mandatory. For the Alpha and PowerPC target; machines, TableGen is used to generate ``XXXGenCodeEmitter.inc``, which; contains the binary coding of machine instructions and the; ``getBinaryCodeForInstr`` method to access those codes. Other JIT; implementations do not. Both ``XXXJITInfo.cpp`` and ``XXXCodeEmitter.cpp`` must include the; ``llvm/CodeGen/MachineCodeEmitter.h`` header file that defines the; ``MachineCodeEmitter`` class containing code for several callback functions; that write data (in bytes, words, strings, etc.) to the output stream. Machine Code Emitter; --------------------. In ``XXXCodeEmitter.cpp``, a target-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:79249,Integrability,depend,depending,79249,"e (register); break;; case X86II::MRMSrcMem: // for instructions that use the Mod/RM byte; ... // to specify a source (memory); break;; case X86II::MRM0r: case X86II::MRM1r: // for instructions that operate on; case X86II::MRM2r: case X86II::MRM3r: // a REGISTER r/m operand and; case X86II::MRM4r: case X86II::MRM5r: // use the Mod/RM byte and a field; case X86II::MRM6r: case X86II::MRM7r: // to hold extended opcode data; ...; break;; case X86II::MRM0m: case X86II::MRM1m: // for instructions that operate on; case X86II::MRM2m: case X86II::MRM3m: // a MEMORY r/m operand and; case X86II::MRM4m: case X86II::MRM5m: // use the Mod/RM byte and a field; case X86II::MRM6m: case X86II::MRM7m: // to hold extended opcode data; ...; break;; case X86II::MRMInitReg: // for instructions whose source and; ... // destination are the same register; break;; }. The implementations of these case statements often first emit the opcode and; then get the operand(s). Then depending upon the operand, helper methods may; be called to process the operand(s). For example, in ``X86CodeEmitter.cpp``,; for the ``X86II::AddRegFrm`` case, the first data emitted (by ``emitByte``) is; the opcode added to the register operand. Then an object representing the; machine operand, ``MO1``, is extracted. The helper methods such as; ``isImmediate``, ``isGlobalAddress``, ``isExternalSymbol``,; ``isConstantPoolIndex``, and ``isJumpTableIndex`` determine the operand type.; (``X86CodeEmitter.cpp`` also has private methods such as ``emitConstant``,; ``emitGlobalAddress``, ``emitExternalSymbolAddress``, ``emitConstPoolAddress``,; and ``emitJumpTableAddress`` that emit the data into the output stream.). .. code-block:: c++. case X86II::AddRegFrm:; MCE.emitByte(BaseOpcode + getX86RegNum(MI.getOperand(CurOp++).getReg()));. if (CurOp != NumOps) {; const MachineOperand &MO1 = MI.getOperand(CurOp++);; unsigned Size = X86InstrInfo::sizeOfImm(Desc);; if (MO1.isImmediate()); emitConstant(MO1.getImm(), Size);; else {; unsigne",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:82106,Integrability,interface,interfaces,82106,"base offset). The ``RelocationType`` enum; for that target is defined in the short target-specific ``XXXRelocations.h``; file. The ``RelocationType`` is used by the ``relocate`` method defined in; ``XXXJITInfo.cpp`` to rewrite addresses for referenced global symbols. For example, ``X86Relocations.h`` specifies the following relocation types for; the X86 addresses. In all four cases, the relocated value is added to the; value already in memory. For ``reloc_pcrel_word`` and ``reloc_picrel_word``,; there is an additional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:82630,Integrability,wrap,wrappers,82630,"ditional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; JITCompilerFunction = F;; return AlphaCompilationCallback;; }. For the X86 target, the ``getLazyResolverFunction`` implementation is a little; more complicated, because it returns a different callback function for; processors with SSE instructions and XMM registers. The callback function initially saves and later restores the callee register; values, incoming arguments, and frame and return address. The callback; function needs low-level access to the registers or stack, so it is typically; implemented with a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:82915,Integrability,wrap,wrapper,82915,"itial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; JITCompilerFunction = F;; return AlphaCompilationCallback;; }. For the X86 target, the ``getLazyResolverFunction`` implementation is a little; more complicated, because it returns a different callback function for; processors with SSE instructions and XMM registers. The callback function initially saves and later restores the callee register; values, incoming arguments, and frame and return address. The callback; function needs low-level access to the registers or stack, so it is typically; implemented with assembler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:6575,Modifiability,variab,variable,6575," (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``. files, initially stub up these methods and then; implement them later. Initially, you may not know which private members that; the class will need and which components will need to be subclassed. Preliminaries; -------------. To actually create your compiler backend, you need to create and modify a few; files. The absolute minimum is discussed here. But to actually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Generator <CodeGenerator>` document. First, you should create a subdirectory under ``lib/Target`` to hold all the; files related to your target. If your target is called ""Dummy"", create the; directory ``lib/Target/Dummy``. In this new directory, create a ``CMakeLists.txt``. It is easiest to copy a; ``CMakeLists.txt`` of another target and modify it. It should at least contain; the ``LLVM_TARGET_DEFINITIONS`` variable. The library can be named ``LLVMDummy``; (for example, see the MIPS target). Alternatively, you can split the library; into ``LLVMDummyCodeGen`` and ``LLVMDummyAsmPrinter``, the latter of which; should be implemented in a subdirectory below ``lib/Target/Dummy`` (for example,; see the PowerPC target). Note that these two naming schemes are hardcoded into ``llvm-config``. Using; any other naming scheme will confuse ``llvm-config`` and produce a lot of; (seemingly unrelated) linker errors when linking ``llc``. To make your target actually do something, you need to implement a subclass of; ``TargetMachine``. This implementation should typically be in the file; ``lib/Target/DummyTargetMachine.cpp``, but any file in the ``lib/Target``; directory will be built and should work. To use LLVM's target independent code; generator, you should do what all current machine backends do: create a; subclass of ``LLVMTargetMachine``. (To create a target from scratch, cre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:6947,Modifiability,config,config,6947,"iler backend, you need to create and modify a few; files. The absolute minimum is discussed here. But to actually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Generator <CodeGenerator>` document. First, you should create a subdirectory under ``lib/Target`` to hold all the; files related to your target. If your target is called ""Dummy"", create the; directory ``lib/Target/Dummy``. In this new directory, create a ``CMakeLists.txt``. It is easiest to copy a; ``CMakeLists.txt`` of another target and modify it. It should at least contain; the ``LLVM_TARGET_DEFINITIONS`` variable. The library can be named ``LLVMDummy``; (for example, see the MIPS target). Alternatively, you can split the library; into ``LLVMDummyCodeGen`` and ``LLVMDummyAsmPrinter``, the latter of which; should be implemented in a subdirectory below ``lib/Target/Dummy`` (for example,; see the PowerPC target). Note that these two naming schemes are hardcoded into ``llvm-config``. Using; any other naming scheme will confuse ``llvm-config`` and produce a lot of; (seemingly unrelated) linker errors when linking ``llc``. To make your target actually do something, you need to implement a subclass of; ``TargetMachine``. This implementation should typically be in the file; ``lib/Target/DummyTargetMachine.cpp``, but any file in the ``lib/Target``; directory will be built and should work. To use LLVM's target independent code; generator, you should do what all current machine backends do: create a; subclass of ``LLVMTargetMachine``. (To create a target from scratch, create a; subclass of ``TargetMachine``.). To get LLVM to actually build and link your target, you need to run ``cmake``; with ``-DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=Dummy``. This will build your; target without needing to add it to the list of all the targets. Once your target is stable, you can add it to the ``LLVM_ALL_TARGETS`` variable; located in the main ``CMakeLists",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:7008,Modifiability,config,config,7008,"ctually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Generator <CodeGenerator>` document. First, you should create a subdirectory under ``lib/Target`` to hold all the; files related to your target. If your target is called ""Dummy"", create the; directory ``lib/Target/Dummy``. In this new directory, create a ``CMakeLists.txt``. It is easiest to copy a; ``CMakeLists.txt`` of another target and modify it. It should at least contain; the ``LLVM_TARGET_DEFINITIONS`` variable. The library can be named ``LLVMDummy``; (for example, see the MIPS target). Alternatively, you can split the library; into ``LLVMDummyCodeGen`` and ``LLVMDummyAsmPrinter``, the latter of which; should be implemented in a subdirectory below ``lib/Target/Dummy`` (for example,; see the PowerPC target). Note that these two naming schemes are hardcoded into ``llvm-config``. Using; any other naming scheme will confuse ``llvm-config`` and produce a lot of; (seemingly unrelated) linker errors when linking ``llc``. To make your target actually do something, you need to implement a subclass of; ``TargetMachine``. This implementation should typically be in the file; ``lib/Target/DummyTargetMachine.cpp``, but any file in the ``lib/Target``; directory will be built and should work. To use LLVM's target independent code; generator, you should do what all current machine backends do: create a; subclass of ``LLVMTargetMachine``. (To create a target from scratch, create a; subclass of ``TargetMachine``.). To get LLVM to actually build and link your target, you need to run ``cmake``; with ``-DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=Dummy``. This will build your; target without needing to add it to the list of all the targets. Once your target is stable, you can add it to the ``LLVM_ALL_TARGETS`` variable; located in the main ``CMakeLists.txt``. Target Machine; ==============. ``LLVMTargetMachine`` is designed as a base class for targets imp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:7879,Modifiability,variab,variable,7879," the PowerPC target). Note that these two naming schemes are hardcoded into ``llvm-config``. Using; any other naming scheme will confuse ``llvm-config`` and produce a lot of; (seemingly unrelated) linker errors when linking ``llc``. To make your target actually do something, you need to implement a subclass of; ``TargetMachine``. This implementation should typically be in the file; ``lib/Target/DummyTargetMachine.cpp``, but any file in the ``lib/Target``; directory will be built and should work. To use LLVM's target independent code; generator, you should do what all current machine backends do: create a; subclass of ``LLVMTargetMachine``. (To create a target from scratch, create a; subclass of ``TargetMachine``.). To get LLVM to actually build and link your target, you need to run ``cmake``; with ``-DLLVM_EXPERIMENTAL_TARGETS_TO_BUILD=Dummy``. This will build your; target without needing to add it to the list of all the targets. Once your target is stable, you can add it to the ``LLVM_ALL_TARGETS`` variable; located in the main ``CMakeLists.txt``. Target Machine; ==============. ``LLVMTargetMachine`` is designed as a base class for targets implemented with; the LLVM target-independent code generator. The ``LLVMTargetMachine`` class; should be specialized by a concrete target class that implements the various; virtual methods. ``LLVMTargetMachine`` is defined as a subclass of; ``TargetMachine`` in ``include/llvm/Target/TargetMachine.h``. The; ``TargetMachine`` class implementation (``TargetMachine.cpp``) also processes; numerous command-line options. To create a concrete target-specific subclass of ``LLVMTargetMachine``, start; by copying an existing ``TargetMachine`` class and header. You should name the; files that you create to reflect your specific target. For instance, for the; SPARC target, name the files ``SparcTargetMachine.h`` and; ``SparcTargetMachine.cpp``. For a target machine ``XXX``, the implementation of ``XXXTargetMachine`` must; have access methods t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22038,Modifiability,config,configurations,22038,"n pick the size; int Alignment = alignment;. // CopyCost is the cost of copying a value between two registers; // default value 1 means a single instruction; // A negative value means copying is extremely expensive or impossible; int CopyCost = 1;; dag MemberList = regList;. // for register classes that are subregisters of this class; list<RegisterClass> SubRegClassList = [];. code MethodProtos = [{}]; // to insert arbitrary code; code MethodBodies = [{}];; }. To define a ``RegisterClass``, use the following 4 arguments:. * The first argument of the definition is the name of the namespace. * The second argument is a list of ``ValueType`` register type values that are; defined in ``include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:31193,Modifiability,extend,extended,31193,"e instruction with.; list<dag> Pattern; // Set to the DAG pattern for this instruction.; list<Register> Uses = [];; list<Register> Defs = [];; list<Predicate> Predicates = []; // predicates turned into isel match code; ... remainder not shown for space ...; }. A ``SelectionDAG`` node (``SDNode``) should contain an object representing a; target-specific instruction that is defined in ``XXXInstrInfo.td``. The; instruction objects should represent instructions from the architecture manual; of the target machine (such as the SPARC Architecture Manual for the SPARC; target). A single instruction from the architecture manual is often modeled as multiple; target instructions, depending upon its operands. For example, a manual might; describe an add instruction that takes a register or an immediate operand. An; LLVM target could model this with two instructions named ``ADDri`` and; ``ADDrr``. You should define a class for each instruction category and define each opcode; as a subclass of the category with appropriate parameters such as the fixed; binary encoding of opcodes and extended opcodes. You should map the register; bits to the bits of the instruction in which they are encoded (for the JIT).; Also you should specify how the instruction should be printed when the; automatic assembly printer is used. As is described in the SPARC Architecture Manual, Version 8, there are three; major 32-bit formats for instructions. Format 1 is only for the ``CALL``; instruction. Format 2 is for branch on condition codes and ``SETHI`` (set high; bits of a register) instructions. Format 3 is for other instructions. Each of these formats has corresponding classes in ``SparcInstrFormat.td``.; ``InstSP`` is a base class for other instruction classes. Additional base; classes are specified for more precise formats: for example in; ``SparcInstrFormat.td``, ``F2_1`` is for ``SETHI``, and ``F2_2`` is for; branches. There are three other base classes: ``F3_1`` for register/register; operations, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58776,Modifiability,extend,extending,58776,"runcStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:66064,Modifiability,variab,variable,66064,"e-block:: text. def RetCC_X86_32 : CallingConv<[; CCIfCC<""CallingConv::Fast"", CCDelegateTo<RetCC_X86_32_Fast>>,; CCIfCC<""CallingConv::X86_SSECall"", CCDelegateTo<RetCC_X86_32_SSE>>,; CCDelegateTo<RetCC_X86_32_C>; ]>;. ``CCAssignToRegAndStack`` is the same as ``CCAssignToReg``, but also allocates; a stack slot, when some register is used. Basically, it works like:; ``CCIf<CCAssignToReg<regList>, CCAssignToStack<size, align>>``. .. code-block:: text. class CCAssignToRegAndStack<list<Register> regList, int size, int align>; : CCAssignToReg<regList> {; int Size = size;; int Align = align;; }. Other calling convention interfaces include:. * ``CCIf <predicate, action>`` --- If the predicate matches, apply the action. * ``CCIfInReg <action>`` --- If the argument is marked with the ""``inreg``""; attribute, then apply the action. * ``CCIfNest <action>`` --- If the argument is marked with the ""``nest``""; attribute, then apply the action. * ``CCIfNotVarArg <action>`` --- If the current function does not take a; variable number of arguments, apply the action. * ``CCAssignToRegWithShadow <registerList, shadowList>`` --- similar to; ``CCAssignToReg``, but with a shadow list of registers. * ``CCPassByVal <size, align>`` --- Assign value to a stack slot with the; minimum specified size and alignment. * ``CCPromoteToType <type>`` --- Promote the current value to the specified; type. * ``CallingConv <[actions]>`` --- Define each calling convention that is; supported. Assembly Printer; ================. During the code emission stage, the code generator may utilize an LLVM pass to; produce assembly output. To do this, you want to implement the code for a; printer that converts LLVM IR to a GAS-format assembly language for your target; machine, using the following steps:. * Define all the assembly strings for your target, adding them to the; instructions defined in the ``XXXInstrInfo.td`` file. (See; :ref:`instruction-set`.) TableGen will produce an output file; (``XXXGenAsmWriter.inc``)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:69096,Modifiability,variab,variable,69096,"= ""\t.word\t"";; Data64bitsDirective = 0; // .xword is only supported by V9.; ZeroDirective = ""\t.skip\t"";; CommentString = ""!"";; ConstantPoolSection = ""\t.section \"".rodata\"",#alloc\n"";; }. The X86 assembly printer implementation (``X86TargetAsmInfo``) is an example; where the target specific ``TargetAsmInfo`` class uses an overridden methods:; ``ExpandInlineAsm``. A target-specific implementation of ``AsmPrinter`` is written in; ``XXXAsmPrinter.cpp``, which implements the ``AsmPrinter`` class that converts; the LLVM to printable assembly. The implementation must include the following; headers that have declarations for the ``AsmPrinter`` and; ``MachineFunctionPass`` classes. The ``MachineFunctionPass`` is a subclass of; ``FunctionPass``. .. code-block:: c++. #include ""llvm/CodeGen/AsmPrinter.h""; #include ""llvm/CodeGen/MachineFunctionPass.h"". As a ``FunctionPass``, ``AsmPrinter`` first calls ``doInitialization`` to set; up the ``AsmPrinter``. In ``SparcAsmPrinter``, a ``Mangler`` object is; instantiated to process variable names. In ``XXXAsmPrinter.cpp``, the ``runOnMachineFunction`` method (declared in; ``MachineFunctionPass``) must be implemented for ``XXXAsmPrinter``. In; ``MachineFunctionPass``, the ``runOnFunction`` method invokes; ``runOnMachineFunction``. Target-specific implementations of; ``runOnMachineFunction`` differ, but generally do the following to process each; machine function:. * Call ``SetupMachineFunction`` to perform initialization. * Call ``EmitConstantPool`` to print out (to the output stream) constants which; have been spilled to memory. * Call ``EmitJumpTableInfo`` to print out jump tables used by the current; function. * Print out the label for the current function. * Print out the code for the function, including basic block labels and the; assembly for the instruction (using ``printInstruction``). The ``XXXAsmPrinter`` implementation must also include the code generated by; TableGen that is output in the ``XXXGenAsmWriter.inc`` file. The c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:71175,Modifiability,variab,variables,71175,"e methods:. * ``printOperand``; * ``printMemOperand``; * ``printCCOperand`` (for conditional statements); * ``printDataDirective``; * ``printDeclare``; * ``printImplicitDef``; * ``printInlineAsm``. The implementations of ``printDeclare``, ``printImplicitDef``,; ``printInlineAsm``, and ``printLabel`` in ``AsmPrinter.cpp`` are generally; adequate for printing assembly and do not need to be overridden. The ``printOperand`` method is implemented with a long ``switch``/``case``; statement for the type of operand: register, immediate, basic block, external; symbol, global address, constant pool index, or jump table index. For an; instruction with a memory address operand, the ``printMemOperand`` method; should be implemented to generate the proper output. Similarly,; ``printCCOperand`` should be used to print a conditional operand. ``doFinalization`` should be overridden in ``XXXAsmPrinter``, and it should be; called to shut down the assembly printer. During ``doFinalization``, global; variables and constants are printed to output. Subtarget Support; =================. Subtarget support is used to inform the code generation process of instruction; set variations for a given chip set. For example, the LLVM SPARC; implementation provided covers three major versions of the SPARC microprocessor; architecture: Version 8 (V8, which is a 32-bit architecture), Version 9 (V9, a; 64-bit architecture), and the UltraSPARC architecture. V8 has 16; double-precision floating-point registers that are also usable as either 32; single-precision or 8 quad-precision registers. V8 is also purely big-endian.; V9 has 32 double-precision floating-point registers that are also usable as 16; quad-precision registers, but cannot be used as single-precision registers.; The UltraSPARC architecture combines V9 with UltraSPARC Visual Instruction Set; extensions. If subtarget support is needed, you should implement a target-specific; ``XXXSubtarget`` class for your architecture. This class should proces",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:78691,Modifiability,extend,extended,78691,"nd the following ``switch``/``case`` statements:. .. code-block:: c++. switch (Desc->TSFlags & X86::FormMask) {; case X86II::Pseudo: // for not yet implemented instructions; ... // or pseudo-instructions; break;; case X86II::RawFrm: // for instructions with a fixed opcode value; ...; break;; case X86II::AddRegFrm: // for instructions that have one register operand; ... // added to their opcode; break;; case X86II::MRMDestReg:// for instructions that use the Mod/RM byte; ... // to specify a destination (register); break;; case X86II::MRMDestMem:// for instructions that use the Mod/RM byte; ... // to specify a destination (memory); break;; case X86II::MRMSrcReg: // for instructions that use the Mod/RM byte; ... // to specify a source (register); break;; case X86II::MRMSrcMem: // for instructions that use the Mod/RM byte; ... // to specify a source (memory); break;; case X86II::MRM0r: case X86II::MRM1r: // for instructions that operate on; case X86II::MRM2r: case X86II::MRM3r: // a REGISTER r/m operand and; case X86II::MRM4r: case X86II::MRM5r: // use the Mod/RM byte and a field; case X86II::MRM6r: case X86II::MRM7r: // to hold extended opcode data; ...; break;; case X86II::MRM0m: case X86II::MRM1m: // for instructions that operate on; case X86II::MRM2m: case X86II::MRM3m: // a MEMORY r/m operand and; case X86II::MRM4m: case X86II::MRM5m: // use the Mod/RM byte and a field; case X86II::MRM6m: case X86II::MRM7m: // to hold extended opcode data; ...; break;; case X86II::MRMInitReg: // for instructions whose source and; ... // destination are the same register; break;; }. The implementations of these case statements often first emit the opcode and; then get the operand(s). Then depending upon the operand, helper methods may; be called to process the operand(s). For example, in ``X86CodeEmitter.cpp``,; for the ``X86II::AddRegFrm`` case, the first data emitted (by ``emitByte``) is; the opcode added to the register operand. Then an object representing the; machine operand, `",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:78991,Modifiability,extend,extended,78991,"/ for instructions that have one register operand; ... // added to their opcode; break;; case X86II::MRMDestReg:// for instructions that use the Mod/RM byte; ... // to specify a destination (register); break;; case X86II::MRMDestMem:// for instructions that use the Mod/RM byte; ... // to specify a destination (memory); break;; case X86II::MRMSrcReg: // for instructions that use the Mod/RM byte; ... // to specify a source (register); break;; case X86II::MRMSrcMem: // for instructions that use the Mod/RM byte; ... // to specify a source (memory); break;; case X86II::MRM0r: case X86II::MRM1r: // for instructions that operate on; case X86II::MRM2r: case X86II::MRM3r: // a REGISTER r/m operand and; case X86II::MRM4r: case X86II::MRM5r: // use the Mod/RM byte and a field; case X86II::MRM6r: case X86II::MRM7r: // to hold extended opcode data; ...; break;; case X86II::MRM0m: case X86II::MRM1m: // for instructions that operate on; case X86II::MRM2m: case X86II::MRM3m: // a MEMORY r/m operand and; case X86II::MRM4m: case X86II::MRM5m: // use the Mod/RM byte and a field; case X86II::MRM6m: case X86II::MRM7m: // to hold extended opcode data; ...; break;; case X86II::MRMInitReg: // for instructions whose source and; ... // destination are the same register; break;; }. The implementations of these case statements often first emit the opcode and; then get the operand(s). Then depending upon the operand, helper methods may; be called to process the operand(s). For example, in ``X86CodeEmitter.cpp``,; for the ``X86II::AddRegFrm`` case, the first data emitted (by ``emitByte``) is; the opcode added to the register operand. Then an object representing the; machine operand, ``MO1``, is extracted. The helper methods such as; ``isImmediate``, ``isGlobalAddress``, ``isExternalSymbol``,; ``isConstantPoolIndex``, and ``isJumpTableIndex`` determine the operand type.; (``X86CodeEmitter.cpp`` also has private methods such as ``emitConstant``,; ``emitGlobalAddress``, ``emitExternalSymbolAddress`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:81008,Modifiability,variab,variable,81008,").getReg()));. if (CurOp != NumOps) {; const MachineOperand &MO1 = MI.getOperand(CurOp++);; unsigned Size = X86InstrInfo::sizeOfImm(Desc);; if (MO1.isImmediate()); emitConstant(MO1.getImm(), Size);; else {; unsigned rt = Is64BitMode ? X86::reloc_pcrel_word; : (IsPIC ? X86::reloc_picrel_word : X86::reloc_absolute_word);; if (Opcode == X86::MOV64ri); rt = X86::reloc_absolute_dword; // FIXME: add X86II flag?; if (MO1.isGlobalAddress()) {; bool NeedStub = isa<Function>(MO1.getGlobal());; bool isLazy = gvNeedsLazyPtr(MO1.getGlobal());; emitGlobalAddress(MO1.getGlobal(), rt, MO1.getOffset(), 0,; NeedStub, isLazy);; } else if (MO1.isExternalSymbol()); emitExternalSymbolAddress(MO1.getSymbolName(), rt);; else if (MO1.isConstantPoolIndex()); emitConstPoolAddress(MO1.getIndex(), rt);; else if (MO1.isJumpTableIndex()); emitJumpTableAddress(MO1.getIndex(), rt);; }; }; break;. In the previous example, ``XXXCodeEmitter.cpp`` uses the variable ``rt``, which; is a ``RelocationType`` enum that may be used to relocate addresses (for; example, a global address with a PIC base offset). The ``RelocationType`` enum; for that target is defined in the short target-specific ``XXXRelocations.h``; file. The ``RelocationType`` is used by the ``relocate`` method defined in; ``XXXJITInfo.cpp`` to rewrite addresses for referenced global symbols. For example, ``X86Relocations.h`` specifies the following relocation types for; the X86 addresses. In all four cases, the relocated value is added to the; value already in memory. For ``reloc_pcrel_word`` and ``reloc_picrel_word``,; there is an additional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:81362,Modifiability,rewrite,rewrite,81362,"solute_word);; if (Opcode == X86::MOV64ri); rt = X86::reloc_absolute_dword; // FIXME: add X86II flag?; if (MO1.isGlobalAddress()) {; bool NeedStub = isa<Function>(MO1.getGlobal());; bool isLazy = gvNeedsLazyPtr(MO1.getGlobal());; emitGlobalAddress(MO1.getGlobal(), rt, MO1.getOffset(), 0,; NeedStub, isLazy);; } else if (MO1.isExternalSymbol()); emitExternalSymbolAddress(MO1.getSymbolName(), rt);; else if (MO1.isConstantPoolIndex()); emitConstPoolAddress(MO1.getIndex(), rt);; else if (MO1.isJumpTableIndex()); emitJumpTableAddress(MO1.getIndex(), rt);; }; }; break;. In the previous example, ``XXXCodeEmitter.cpp`` uses the variable ``rt``, which; is a ``RelocationType`` enum that may be used to relocate addresses (for; example, a global address with a PIC base offset). The ``RelocationType`` enum; for that target is defined in the short target-specific ``XXXRelocations.h``; file. The ``RelocationType`` is used by the ``relocate`` method defined in; ``XXXJITInfo.cpp`` to rewrite addresses for referenced global symbols. For example, ``X86Relocations.h`` specifies the following relocation types for; the X86 addresses. In all four cases, the relocated value is added to the; value already in memory. For ``reloc_pcrel_word`` and ``reloc_picrel_word``,; there is an additional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:4662,Performance,perform,perform,4662," file. You should also write; additional code for a subclass of the ``TargetRegisterInfo`` class that; represents the class register file data used for register allocation and also; describes the interactions between registers. * Describe the instruction set of the target. Use TableGen to generate code; for target-specific instructions from target-specific versions of; ``TargetInstrFormats.td`` and ``TargetInstrInfo.td``. You should write; additional code for a subclass of the ``TargetInstrInfo`` class to represent; machine instructions supported by the target machine. * Describe the selection and conversion of the LLVM IR from a Directed Acyclic; Graph (DAG) representation of instructions to native target-specific; instructions. Use TableGen to generate code that matches patterns and; selects instructions based on additional information in a target-specific; version of ``TargetInstrInfo.td``. Write code for ``XXXISelDAGToDAG.cpp``,; where ``XXX`` identifies the specific target, to perform pattern matching and; DAG-to-DAG instruction selection. Also write code in ``XXXISelLowering.cpp``; to replace or remove operations and data types that are not supported; natively in a SelectionDAG. * Write code for an assembly printer that converts LLVM IR to a GAS format for; your target machine. You should add assembly strings to the instructions; defined in your target-specific version of ``TargetInstrInfo.td``. You; should also write code for a subclass of ``AsmPrinter`` that performs the; LLVM-to-assembly conversion and a trivial subclass of ``TargetAsmInfo``. * Optionally, add support for subtargets (i.e., variants with different; capabilities). You should also write code for a subclass of the; ``TargetSubtarget`` class, which allows you to use the ``-mcpu=`` and; ``-mattr=`` command-line options. * Optionally, add JIT support and create a machine code emitter (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:5156,Performance,perform,performs,5156,"` class to represent; machine instructions supported by the target machine. * Describe the selection and conversion of the LLVM IR from a Directed Acyclic; Graph (DAG) representation of instructions to native target-specific; instructions. Use TableGen to generate code that matches patterns and; selects instructions based on additional information in a target-specific; version of ``TargetInstrInfo.td``. Write code for ``XXXISelDAGToDAG.cpp``,; where ``XXX`` identifies the specific target, to perform pattern matching and; DAG-to-DAG instruction selection. Also write code in ``XXXISelLowering.cpp``; to replace or remove operations and data types that are not supported; natively in a SelectionDAG. * Write code for an assembly printer that converts LLVM IR to a GAS format for; your target machine. You should add assembly strings to the instructions; defined in your target-specific version of ``TargetInstrInfo.td``. You; should also write code for a subclass of ``AsmPrinter`` that performs the; LLVM-to-assembly conversion and a trivial subclass of ``TargetAsmInfo``. * Optionally, add support for subtargets (i.e., variants with different; capabilities). You should also write code for a subclass of the; ``TargetSubtarget`` class, which allows you to use the ``-mcpu=`` and; ``-mattr=`` command-line options. * Optionally, add JIT support and create a machine code emitter (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``. files, initially stub up these methods and then; implement them later. Initially, you may not know which private members that; the class will need and which components will need to be subclassed. Preliminaries; -------------. To actually create your compiler backend, you need to create and modify a few; files. The absolute minimum is discussed here. But to actually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Gen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:6092,Performance,perform,perform,6092,"rite code for a subclass of ``AsmPrinter`` that performs the; LLVM-to-assembly conversion and a trivial subclass of ``TargetAsmInfo``. * Optionally, add support for subtargets (i.e., variants with different; capabilities). You should also write code for a subclass of the; ``TargetSubtarget`` class, which allows you to use the ``-mcpu=`` and; ``-mattr=`` command-line options. * Optionally, add JIT support and create a machine code emitter (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``. files, initially stub up these methods and then; implement them later. Initially, you may not know which private members that; the class will need and which components will need to be subclassed. Preliminaries; -------------. To actually create your compiler backend, you need to create and modify a few; files. The absolute minimum is discussed here. But to actually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Generator <CodeGenerator>` document. First, you should create a subdirectory under ``lib/Target`` to hold all the; files related to your target. If your target is called ""Dummy"", create the; directory ``lib/Target/Dummy``. In this new directory, create a ``CMakeLists.txt``. It is easiest to copy a; ``CMakeLists.txt`` of another target and modify it. It should at least contain; the ``LLVM_TARGET_DEFINITIONS`` variable. The library can be named ``LLVMDummy``; (for example, see the MIPS target). Alternatively, you can split the library; into ``LLVMDummyCodeGen`` and ``LLVMDummyAsmPrinter``, the latter of which; should be implemented in a subdirectory below ``lib/Target/Dummy`` (for example,; see the PowerPC target). Note that these two naming schemes are hardcoded into ``llvm-config``. Using; any other naming scheme will confuse ``llvm-config`` and produce a lot of; (seemingly unrelated) linker errors when linking ``llc``. To make you",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:14774,Performance,perform,perform,14774,"embly printer:. .. code-block:: c++. extern ""C"" void LLVMInitializeSparcAsmPrinter() {; RegisterAsmPrinter<SparcAsmPrinter> X(getTheSparcTarget());; }. For more information, see ""`llvm/Target/TargetRegistry.h; </doxygen/TargetRegistry_8h-source.html>`_"". Register Set and Register Classes; =================================. You should describe a concrete target-specific class that represents the; register file of a target machine. This class is called ``XXXRegisterInfo``; (where ``XXX`` identifies the target) and represents the class register file; data that is used for register allocation. It also describes the interactions; between registers. You also need to define register classes to categorize related registers. A; register class should be added for groups of registers that are all treated the; same way for some instruction. Typical examples are register classes for; integer, floating-point, or vector registers. A register allocator allows an; instruction to use any register in a specified register class to perform the; instruction in a similar manner. Register classes allocate virtual registers; to instructions from these sets, and register classes let the; target-independent register allocator automatically choose the actual; registers. Much of the code for registers, including register definition, register; aliases, and register classes, is generated by TableGen from; ``XXXRegisterInfo.td`` input files and placed in ``XXXGenRegisterInfo.h.inc``; and ``XXXGenRegisterInfo.inc`` output files. Some of the code in the; implementation of ``XXXRegisterInfo`` requires hand-coding. Defining a Register; -------------------. The ``XXXRegisterInfo.td`` file typically starts with register definitions for; a target machine. The ``Register`` class (specified in ``Target.td``) is used; to define an object for each register. The specified string ``n`` becomes the; ``Name`` of the register. The basic ``Register`` object does not have any; subregisters and does not specify any a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22343,Performance,load,loaded,22343," are subregisters of this class; list<RegisterClass> SubRegClassList = [];. code MethodProtos = [{}]; // to insert arbitrary code; code MethodBodies = [{}];; }. To define a ``RegisterClass``, use the following 4 arguments:. * The first argument of the definition is the name of the namespace. * The second argument is a list of ``ValueType`` register type values that are; defined in ``include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs``; defines a group of 32 single-precision floating-point registers (``F0`` to; ``F31``); ``DFPRegs`` defines a group of 16 double-precision registers; (``D0-D15``). .. code-block:: text. // F0, F1, F2, ..., F31; def FPRegs : RegisterClass<""SP"", [f32], 32, (sequence ""F%u"", 0, 31)>;. def DFPRegs : Regist",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:27843,Performance,load,load,27843,"lee-save stack frame offset. * ``getReservedRegs`` --- Returns a bitset indexed by physical register; numbers, indicating if a particular register is unavailable. * ``hasFP`` --- Return a Boolean indicating if a function should have a; dedicated frame pointer register. * ``eliminateCallFramePseudoInstr`` --- If call frame setup or destroy pseudo; instructions are used, this can be called to eliminate them. * ``eliminateFrameIndex`` --- Eliminate abstract frame indices from; instructions that may use them. * ``emitPrologue`` --- Insert prologue code into the function. * ``emitEpilogue`` --- Insert epilogue code into the function. .. _instruction-set:. Instruction Set; ===============. During the early stages of code generation, the LLVM IR code is converted to a; ``SelectionDAG`` with nodes that are instances of the ``SDNode`` class; containing target instructions. An ``SDNode`` has an opcode, operands, type; requirements, and operation properties. For example, is an operation; commutative, does an operation load from memory. The various operation node; types are described in the ``include/llvm/CodeGen/SelectionDAGNodes.h`` file; (values of the ``NodeType`` enum in the ``ISD`` namespace). TableGen uses the following target description (``.td``) input files to; generate much of the code for instruction definition:. * ``Target.td`` --- Where the ``Instruction``, ``Operand``, ``InstrInfo``, and; other fundamental classes are defined. * ``TargetSelectionDAG.td`` --- Used by ``SelectionDAG`` instruction selection; generators, contains ``SDTC*`` classes (selection DAG type constraint),; definitions of ``SelectionDAG`` nodes (such as ``imm``, ``cond``, ``bb``,; ``add``, ``fadd``, ``sub``), and pattern support (``Pattern``, ``Pat``,; ``PatFrag``, ``PatLeaf``, ``ComplexPattern``. * ``XXXInstrFormats.td`` --- Patterns for definitions of target-specific; instructions. * ``XXXInstrInfo.td`` --- Target-specific definitions of instruction templates,; condition codes, and instructio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:33084,Performance,load,load,33084,"re three other base classes: ``F3_1`` for register/register; operations, ``F3_2`` for register/immediate operations, and ``F3_3`` for; floating-point operations. ``SparcInstrInfo.td`` also adds the base class; ``Pseudo`` for synthetic SPARC instructions. ``SparcInstrInfo.td`` largely consists of operand and instruction definitions; for the SPARC target. In ``SparcInstrInfo.td``, the following target; description file entry, ``LDrr``, defines the Load Integer instruction for a; Word (the ``LD`` SPARC opcode) from a memory address to a register. The first; parameter, the value 3 (``11``\ :sub:`2`), is the operation value for this; category of operation. The second parameter (``000000``\ :sub:`2`) is the; specific operation value for ``LD``/Load Word. The third parameter is the; output destination, which is a register operand and defined in the ``Register``; target description file (``IntRegs``). .. code-block:: text. def LDrr : F3_1 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMrr $rs1, $rs2):$addr),; ""ld [$addr], $dst"",; [(set i32:$dst, (load ADDRrr:$addr))]>;. The fourth parameter is the input source, which uses the address operand; ``MEMrr`` that is defined earlier in ``SparcInstrInfo.td``:. .. code-block:: text. def MEMrr : Operand<i32> {; let PrintMethod = ""printMemOperand"";; let MIOperandInfo = (ops IntRegs, IntRegs);; }. The fifth parameter is a string that is used by the assembly printer and can be; left as an empty string until the assembly printer interface is implemented.; The sixth and final parameter is the pattern used to match the instruction; during the SelectionDAG Select Phase described in :doc:`CodeGenerator`.; This parameter is detailed in the next section, :ref:`instruction-selector`. Instruction class definitions are not overloaded for different operand types,; so separate versions of instructions are needed for register, memory, or; immediate value operands. For example, to perform a Load Integer instruction; for a Word from an immediate operand to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:33959,Performance,perform,perform,33959," (MEMrr $rs1, $rs2):$addr),; ""ld [$addr], $dst"",; [(set i32:$dst, (load ADDRrr:$addr))]>;. The fourth parameter is the input source, which uses the address operand; ``MEMrr`` that is defined earlier in ``SparcInstrInfo.td``:. .. code-block:: text. def MEMrr : Operand<i32> {; let PrintMethod = ""printMemOperand"";; let MIOperandInfo = (ops IntRegs, IntRegs);; }. The fifth parameter is a string that is used by the assembly printer and can be; left as an empty string until the assembly printer interface is implemented.; The sixth and final parameter is the pattern used to match the instruction; during the SelectionDAG Select Phase described in :doc:`CodeGenerator`.; This parameter is detailed in the next section, :ref:`instruction-selector`. Instruction class definitions are not overloaded for different operand types,; so separate versions of instructions are needed for register, memory, or; immediate value operands. For example, to perform a Load Integer instruction; for a Word from an immediate operand to a register, the following instruction; class is defined:. .. code-block:: text. def LDri : F3_2 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMri $rs1, $simm13):$addr),; ""ld [$addr], $dst"",; [(set i32:$rd, (load ADDRri:$addr))]>;. Writing these definitions for so many similar instructions can involve a lot of; cut and paste. In ``.td`` files, the ``multiclass`` directive enables the; creation of templates to define several instruction classes at once (using the; ``defm`` directive). For example in ``SparcInstrInfo.td``, the ``multiclass``; pattern ``F3_12`` is defined to create 2 instruction classes each time; ``F3_12`` is invoked:. .. code-block:: text. multiclass F3_12 <string OpcStr, bits<6> Op3Val, SDNode OpNode> {; def rr : F3_1 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, IntRegs:$rs1),; !strconcat(OpcStr, "" $rs1, $rs2, $rd""),; [(set i32:$rd, (OpNode i32:$rs1, i32:$rs2))]>;; def ri : F3_2 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, i32imm:$simm13),; !",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:34238,Performance,load,load,34238,"rr`` that is defined earlier in ``SparcInstrInfo.td``:. .. code-block:: text. def MEMrr : Operand<i32> {; let PrintMethod = ""printMemOperand"";; let MIOperandInfo = (ops IntRegs, IntRegs);; }. The fifth parameter is a string that is used by the assembly printer and can be; left as an empty string until the assembly printer interface is implemented.; The sixth and final parameter is the pattern used to match the instruction; during the SelectionDAG Select Phase described in :doc:`CodeGenerator`.; This parameter is detailed in the next section, :ref:`instruction-selector`. Instruction class definitions are not overloaded for different operand types,; so separate versions of instructions are needed for register, memory, or; immediate value operands. For example, to perform a Load Integer instruction; for a Word from an immediate operand to a register, the following instruction; class is defined:. .. code-block:: text. def LDri : F3_2 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMri $rs1, $simm13):$addr),; ""ld [$addr], $dst"",; [(set i32:$rd, (load ADDRri:$addr))]>;. Writing these definitions for so many similar instructions can involve a lot of; cut and paste. In ``.td`` files, the ``multiclass`` directive enables the; creation of templates to define several instruction classes at once (using the; ``defm`` directive). For example in ``SparcInstrInfo.td``, the ``multiclass``; pattern ``F3_12`` is defined to create 2 instruction classes each time; ``F3_12`` is invoked:. .. code-block:: text. multiclass F3_12 <string OpcStr, bits<6> Op3Val, SDNode OpNode> {; def rr : F3_1 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, IntRegs:$rs1),; !strconcat(OpcStr, "" $rs1, $rs2, $rd""),; [(set i32:$rd, (OpNode i32:$rs1, i32:$rs2))]>;; def ri : F3_2 <2, Op3Val,; (outs IntRegs:$rd), (ins IntRegs:$rs1, i32imm:$simm13),; !strconcat(OpcStr, "" $rs1, $simm13, $rd""),; [(set i32:$rd, (OpNode i32:$rs1, simm13:$simm13))]>;; }. So when the ``defm`` directive is used for the ``XOR`` and ``ADD``; ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:39202,Performance,load,load,39202,"> asi = 0; // asi not currently used; bits<5> rs2;; let op = opVal;; let op3 = op3val;; let Inst{13} = 0; // i field = 0; let Inst{12-5} = asi; // address space identifier; let Inst{4-0} = rs2;; }. ``F3_1`` assigns a value to ``op`` and ``op3`` fields, and defines the ``rs2``; field. Therefore, a ``F3_1`` format instruction will require a definition for; ``rd``, ``rs1``, and ``rs2`` in order to fully specify the instruction encoding. The ``XNORrr`` instruction then provides those three operands in its; OutOperandList and InOperandList, which bind to the corresponding fields, and; thus complete the instruction encoding. For some instructions, a single operand may contain sub-operands. As shown; earlier, the instruction ``LDrr`` uses an input operand of type ``MEMrr``. This; operand type contains two register sub-operands, defined by the; ``MIOperandInfo`` value to be ``(ops IntRegs, IntRegs)``. .. code-block:: text. def LDrr : F3_1 <3, 0b000000, (outs IntRegs:$rd), (ins (MEMrr $rs1, $rs2):$addr),; ""ld [$addr], $dst"",; [(set i32:$dst, (load ADDRrr:$addr))]>;. As this instruction is also the ``F3_1`` format, it will expect operands named; ``rd``, ``rs1``, and ``rs2`` as well. In order to allow this, a complex operand; can optionally give names to each of its sub-operands. In this example; ``MEMrr``'s first sub-operand is named ``$rs1``, the second ``$rs2``, and the; operand as a whole is also given the name ``$addr``. When a particular instruction doesn't use all the operands that the instruction; format defines, a constant value may instead be bound to one or all. For; example, the ``RDASR`` instruction only takes a single register operand, so we; assign a constant zero to ``rs2``:. .. code-block:: text. let rs2 = 0 in; def RDASR : F3_1<2, 0b101000,; (outs IntRegs:$rd), (ins ASRRegs:$rs1),; ""rd $rs1, $rd"", []>;. Instruction Operand Name Mapping; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. TableGen will also generate a function called getNamedOperandIdx() which; can be used to lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46103,Performance,load,load,46103," in ``XXXInstrInfo.td`` files; according to the target-specific instruction set. Relation models are defined; using ``InstrMapping`` class as a base. TableGen parses all the models; and generates instruction relation maps using the specified information.; Relation maps are emitted as tables in the ``XXXGenInstrInfo.inc`` file; along with the functions to query them. For the detailed information on how to; use this feature, please refer to :doc:`HowToUseInstrMappings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to exam",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46553,Performance,load,loadRegFromStackSlot,46553,"ings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to examine conditional instructions and; remove unnecessary instructions. ``analyzeBranch`` looks at the end of a; machine basic block (MBB) for opportunities for improvement, such as branch; folding and if conversion. The ``BranchFolder`` and ``IfConverter`` machine; function passes (see the source files ``BranchFolding.cpp`` and; ``IfConversion.cpp`` in the ``lib/CodeGen`` directory) call ``analyzeBranch``; to improve the control flow graph that represents the instr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46684,Performance,load,loadRegFromAddr,46684,"de portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to examine conditional instructions and; remove unnecessary instructions. ``analyzeBranch`` looks at the end of a; machine basic block (MBB) for opportunities for improvement, such as branch; folding and if conversion. The ``BranchFolder`` and ``IfConverter`` machine; function passes (see the source files ``BranchFolding.cpp`` and; ``IfConversion.cpp`` in the ``lib/CodeGen`` directory) call ``analyzeBranch``; to improve the control flow graph that represents the instructions. Several implementations of ``analyzeBranch`` (for ARM, Alpha, and X86) can be; examined as models for your own ``anal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:46808,Performance,load,load,46808,"fo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Folding and If Conversion; --------------------------------. Performance can be improved by combining instructions or by eliminating; instructions that are never reached. The ``analyzeBranch`` method in; ``XXXInstrInfo`` may be implemented to examine conditional instructions and; remove unnecessary instructions. ``analyzeBranch`` looks at the end of a; machine basic block (MBB) for opportunities for improvement, such as branch; folding and if conversion. The ``BranchFolder`` and ``IfConverter`` machine; function passes (see the source files ``BranchFolding.cpp`` and; ``IfConversion.cpp`` in the ``lib/CodeGen`` directory) call ``analyzeBranch``; to improve the control flow graph that represents the instructions. Several implementations of ``analyzeBranch`` (for ARM, Alpha, and X86) can be; examined as models for your own ``analyzeBranch`` implementation. Since SPARC; does not implement a useful ``analyzeBranch``, the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:51485,Performance,perform,perform,51485,"a block ends with both a conditional branch and an ensuing unconditional; branch, then ``analyzeBranch`` (shown below) should return the conditional; branch destination (assuming it corresponds to a conditional evaluation of; ""``true``"") in the ``TBB`` parameter and the unconditional branch destination; in the ``FBB`` (corresponding to a conditional evaluation of ""``false``""). A; list of operands to evaluate the condition should be returned in the ``Cond``; parameter. .. code-block:: c++. unsigned SecondLastOpc = SecondLastInst->getOpcode();. if ((SecondLastOpc == ARM::Bcc && LastOpc == ARM::B) ||; (SecondLastOpc == ARM::tBcc && LastOpc == ARM::tB)) {; TBB = SecondLastInst->getOperand(0).getMBB();; Cond.push_back(SecondLastInst->getOperand(1));; Cond.push_back(SecondLastInst->getOperand(2));; FBB = LastInst->getOperand(0).getMBB();; return false;; }. For the last two cases (ending with a single conditional branch or ending with; one conditional and one unconditional branch), the operands returned in the; ``Cond`` parameter can be passed to methods of other instructions to create new; branches or perform other operations. An implementation of ``analyzeBranch``; requires the helper methods ``removeBranch`` and ``insertBranch`` to manage; subsequent operations. ``analyzeBranch`` should return false indicating success in most circumstances.; ``analyzeBranch`` should only return true when the method is stumped about what; to do, for example, if a block has three terminating branches.; ``analyzeBranch`` may return true if it encounters a terminator it cannot; handle, such as an indirect branch. .. _instruction-selector:. Instruction Selector; ====================. LLVM uses a ``SelectionDAG`` to represent LLVM IR instructions, and nodes of; the ``SelectionDAG`` ideally represent native target instructions. During code; generation, instruction selection passes are performed to convert non-native; DAG instructions into native target-specific instructions. The pass described",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:52262,Performance,perform,performed,52262,"e conditional branch or ending with; one conditional and one unconditional branch), the operands returned in the; ``Cond`` parameter can be passed to methods of other instructions to create new; branches or perform other operations. An implementation of ``analyzeBranch``; requires the helper methods ``removeBranch`` and ``insertBranch`` to manage; subsequent operations. ``analyzeBranch`` should return false indicating success in most circumstances.; ``analyzeBranch`` should only return true when the method is stumped about what; to do, for example, if a block has three terminating branches.; ``analyzeBranch`` may return true if it encounters a terminator it cannot; handle, such as an indirect branch. .. _instruction-selector:. Instruction Selector; ====================. LLVM uses a ``SelectionDAG`` to represent LLVM IR instructions, and nodes of; the ``SelectionDAG`` ideally represent native target instructions. During code; generation, instruction selection passes are performed to convert non-native; DAG instructions into native target-specific instructions. The pass described; in ``XXXISelDAGToDAG.cpp`` is used to match patterns and perform DAG-to-DAG; instruction selection. Optionally, a pass may be defined (in; ``XXXBranchSelector.cpp``) to perform similar DAG-to-DAG operations for branch; instructions. Later, the code in ``XXXISelLowering.cpp`` replaces or removes; operations and data types not supported natively (legalizes) in a; ``SelectionDAG``. TableGen generates code for instruction selection using the following target; description input files:. * ``XXXInstrInfo.td`` --- Contains definitions of instructions in a; target-specific instruction set, generates ``XXXGenDAGISel.inc``, which is; included in ``XXXISelDAGToDAG.cpp``. * ``XXXCallingConv.td`` --- Contains the calling and return value conventions; for the target architecture, and it generates ``XXXGenCallingConv.inc``,; which is included in ``XXXISelLowering.cpp``. The implementation of an instruction ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:52431,Performance,perform,perform,52431,"s of other instructions to create new; branches or perform other operations. An implementation of ``analyzeBranch``; requires the helper methods ``removeBranch`` and ``insertBranch`` to manage; subsequent operations. ``analyzeBranch`` should return false indicating success in most circumstances.; ``analyzeBranch`` should only return true when the method is stumped about what; to do, for example, if a block has three terminating branches.; ``analyzeBranch`` may return true if it encounters a terminator it cannot; handle, such as an indirect branch. .. _instruction-selector:. Instruction Selector; ====================. LLVM uses a ``SelectionDAG`` to represent LLVM IR instructions, and nodes of; the ``SelectionDAG`` ideally represent native target instructions. During code; generation, instruction selection passes are performed to convert non-native; DAG instructions into native target-specific instructions. The pass described; in ``XXXISelDAGToDAG.cpp`` is used to match patterns and perform DAG-to-DAG; instruction selection. Optionally, a pass may be defined (in; ``XXXBranchSelector.cpp``) to perform similar DAG-to-DAG operations for branch; instructions. Later, the code in ``XXXISelLowering.cpp`` replaces or removes; operations and data types not supported natively (legalizes) in a; ``SelectionDAG``. TableGen generates code for instruction selection using the following target; description input files:. * ``XXXInstrInfo.td`` --- Contains definitions of instructions in a; target-specific instruction set, generates ``XXXGenDAGISel.inc``, which is; included in ``XXXISelDAGToDAG.cpp``. * ``XXXCallingConv.td`` --- Contains the calling and return value conventions; for the target architecture, and it generates ``XXXGenCallingConv.inc``,; which is included in ``XXXISelLowering.cpp``. The implementation of an instruction selection pass must include a header that; declares the ``FunctionPass`` class or a subclass of ``FunctionPass``. In; ``XXXTargetMachine.cpp``, a Pass Manag",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:52543,Performance,perform,perform,52543,"r methods ``removeBranch`` and ``insertBranch`` to manage; subsequent operations. ``analyzeBranch`` should return false indicating success in most circumstances.; ``analyzeBranch`` should only return true when the method is stumped about what; to do, for example, if a block has three terminating branches.; ``analyzeBranch`` may return true if it encounters a terminator it cannot; handle, such as an indirect branch. .. _instruction-selector:. Instruction Selector; ====================. LLVM uses a ``SelectionDAG`` to represent LLVM IR instructions, and nodes of; the ``SelectionDAG`` ideally represent native target instructions. During code; generation, instruction selection passes are performed to convert non-native; DAG instructions into native target-specific instructions. The pass described; in ``XXXISelDAGToDAG.cpp`` is used to match patterns and perform DAG-to-DAG; instruction selection. Optionally, a pass may be defined (in; ``XXXBranchSelector.cpp``) to perform similar DAG-to-DAG operations for branch; instructions. Later, the code in ``XXXISelLowering.cpp`` replaces or removes; operations and data types not supported natively (legalizes) in a; ``SelectionDAG``. TableGen generates code for instruction selection using the following target; description input files:. * ``XXXInstrInfo.td`` --- Contains definitions of instructions in a; target-specific instruction set, generates ``XXXGenDAGISel.inc``, which is; included in ``XXXISelDAGToDAG.cpp``. * ``XXXCallingConv.td`` --- Contains the calling and return value conventions; for the target architecture, and it generates ``XXXGenCallingConv.inc``,; which is included in ``XXXISelLowering.cpp``. The implementation of an instruction selection pass must include a header that; declares the ``FunctionPass`` class or a subclass of ``FunctionPass``. In; ``XXXTargetMachine.cpp``, a Pass Manager (PM) should add each instruction; selection pass into the queue of passes to run. The LLVM static compiler (``llc``) is an excellent ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:53495,Performance,queue,queue,53495,"ection. Optionally, a pass may be defined (in; ``XXXBranchSelector.cpp``) to perform similar DAG-to-DAG operations for branch; instructions. Later, the code in ``XXXISelLowering.cpp`` replaces or removes; operations and data types not supported natively (legalizes) in a; ``SelectionDAG``. TableGen generates code for instruction selection using the following target; description input files:. * ``XXXInstrInfo.td`` --- Contains definitions of instructions in a; target-specific instruction set, generates ``XXXGenDAGISel.inc``, which is; included in ``XXXISelDAGToDAG.cpp``. * ``XXXCallingConv.td`` --- Contains the calling and return value conventions; for the target architecture, and it generates ``XXXGenCallingConv.inc``,; which is included in ``XXXISelLowering.cpp``. The implementation of an instruction selection pass must include a header that; declares the ``FunctionPass`` class or a subclass of ``FunctionPass``. In; ``XXXTargetMachine.cpp``, a Pass Manager (PM) should add each instruction; selection pass into the queue of passes to run. The LLVM static compiler (``llc``) is an excellent tool for visualizing the; contents of DAGs. To display the ``SelectionDAG`` before or after specific; processing phases, use the command line options for ``llc``, described at; :ref:`SelectionDAG-Process`. To describe instruction selector behavior, you should add patterns for lowering; LLVM code into a ``SelectionDAG`` as the last parameter of the instruction; definitions in ``XXXInstrInfo.td``. For example, in ``SparcInstrInfo.td``,; this entry defines a register store operation, and the last parameter describes; a pattern with the store DAG operator. .. code-block:: text. def STrr : F3_1< 3, 0b000100, (outs), (ins MEMrr:$addr, IntRegs:$src),; ""st $src, [$addr]"", [(store i32:$src, ADDRrr:$addr)]>;. ``ADDRrr`` is a memory mode that is also defined in ``SparcInstrInfo.td``:. .. code-block:: text. def ADDRrr : ComplexPattern<i32, 2, ""SelectADDRrr"", [], []>;. The definition of ``ADDRrr``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:57871,Performance,load,load,57871,"` and placed in; ``XXXGenRegisterInfo.h.inc``. For example, the implementation of the; constructor for the SparcTargetLowering class (in ``SparcISelLowering.cpp``); starts with the following code:. .. code-block:: c++. addRegisterClass(MVT::i32, SP::IntRegsRegisterClass);; addRegisterClass(MVT::f32, SP::FPRegsRegisterClass);; addRegisterClass(MVT::f64, SP::DFPRegsRegisterClass);. You should examine the node types in the ``ISD`` namespace; (``include/llvm/CodeGen/SelectionDAGNodes.h``) and determine which operations; the target natively supports. For operations that do **not** have native; support, add a callback to the constructor for the ``XXXTargetLowering`` class,; so the instruction selection process knows what to do. The ``TargetLowering``; class callback methods (declared in ``llvm/Target/TargetLowering.h``) are:. * ``setOperationAction`` --- General operation.; * ``setLoadExtAction`` --- Load with extension.; * ``setTruncStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58786,Performance,load,load,58786,"runcStoreAction`` --- Truncating store.; * ``setIndexedLoadAction`` --- Indexed load.; * ``setIndexedStoreAction`` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:58949,Performance,load,loading,58949,"` --- Indexed store.; * ``setConvertAction`` --- Type conversion.; * ``setCondCodeAction`` --- Support for a given condition code. Note: on older releases, ``setLoadXAction`` is used instead of; ``setLoadExtAction``. Also, on older releases, ``setCondCodeAction`` may not; be supported. Examine your release to see what methods are specifically; supported. These callbacks are used to determine that an operation does or does not work; with a specified type (or types). And in all cases, the third parameter is a; ``LegalAction`` type enum value: ``Promote``, ``Expand``, ``Custom``, or; ``Legal``. ``SparcISelLowering.cpp`` contains examples of all four; ``LegalAction`` values. Promote; ^^^^^^^. For an operation without native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatment, or an operation; may require spilling and restoring registers in the stack and working with; register allocat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:59962,Performance,perform,perform,59962,"nd; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatment, or an operation; may require spilling and restoring registers in the stack and working with; register allocators. As seen in ``SparcISelLowering.cpp`` code below, to perform a type conversion; from a floating point value to a signed integer, first the; ``setOperationAction`` should be called with ``Custom`` as the third parameter:. .. code-block:: c++. setOperationAction(ISD::FP_TO_SINT, MVT::i32, Custom);. In the ``LowerOperation`` method, for each ``Custom`` operation, a case; statement should be added to indicate what function to call. In the following; code, an ``FP_TO_SINT`` opcode will call the ``LowerFP_TO_SINT`` method:. .. code-block:: c++. SDValue SparcTargetLowering::LowerOperation(SDValue Op, SelectionDAG &DAG) {; switch (Op.getOpcode()) {; case ISD::FP_TO_SINT: return LowerFP_TO_SINT(Op, DAG);; ...; }; }. Finally, the ``LowerFP_TO_SINT`` method is implemented, using an FP register to; convert the floating-point value to an integer. .. code-block:: c++. static SDValue LowerFP_TO_SINT(SDValue Op, SelectionDAG &DAG) {; assert(Op.getValueType() == MVT::i32);; Op = DAG.getNode(SPISD::FTOI, MVT::f32, Op.getOperand(0));; return DAG.getNode(ISD::BITCAST, MVT::i32, Op);; }. Legal; ^^^^^. The ``Legal`` ``LegalizeActi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:62522,Performance,perform,performed,62522,"ion(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``TargetCallingConv.td`` to specify:. * The order of parameter allocation. * Where parameters and return values are placed (that is, on the stack or in; registers). * Which registers may be used. * Whether the caller or callee unwinds the stack. The following example demonstrates the use of the ``CCIfType`` and; ``CCAssignToReg`` interfaces. If the ``CCIfType`` predicate is true (that is,; if the current argument is of type ``f32`` or ``f64``), then the action is; performed. In this case, the ``CCAssignToReg`` action assigns the argument; value to the first available register: either ``R0`` or ``R1``. .. code-block:: text. CCIfType<[f32,f64], CCAssignToReg<[R0, R1]>>. ``SparcCallingConv.td`` contains definitions for a target-specific return-value; calling convention (``RetCC_Sparc32``) and a basic 32-bit C calling convention; (``CC_Sparc32``). The definition of ``RetCC_Sparc32`` (shown below) indicates; which registers are used for specified scalar return types. A single-precision; float is returned to register ``F0``, and a double-precision float goes to; register ``D0``. A 32-bit integer is returned in register ``I0`` or ``I1``. .. code-block:: text. def RetCC_Sparc32 : CallingConv<[; CCIfType<[i32], CCAssignToReg<[I0, I1]>>,; CCIfType<[f32], CCAssignToReg<[F0]>>,; CCIfType<[f64], CCAssignToReg<[D0]>>; ]>;. The definition of ``CC_Sparc32`` in ``SparcCallingConv.td`` introduces; ``CCAssi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:67519,Performance,perform,performs,67519,"upported. Assembly Printer; ================. During the code emission stage, the code generator may utilize an LLVM pass to; produce assembly output. To do this, you want to implement the code for a; printer that converts LLVM IR to a GAS-format assembly language for your target; machine, using the following steps:. * Define all the assembly strings for your target, adding them to the; instructions defined in the ``XXXInstrInfo.td`` file. (See; :ref:`instruction-set`.) TableGen will produce an output file; (``XXXGenAsmWriter.inc``) with an implementation of the ``printInstruction``; method for the ``XXXAsmPrinter`` class. * Write ``XXXTargetAsmInfo.h``, which contains the bare-bones declaration of; the ``XXXTargetAsmInfo`` class (a subclass of ``TargetAsmInfo``). * Write ``XXXTargetAsmInfo.cpp``, which contains target-specific values for; ``TargetAsmInfo`` properties and sometimes new implementations for methods. * Write ``XXXAsmPrinter.cpp``, which implements the ``AsmPrinter`` class that; performs the LLVM-to-assembly conversion. The code in ``XXXTargetAsmInfo.h`` is usually a trivial declaration of the; ``XXXTargetAsmInfo`` class for use in ``XXXTargetAsmInfo.cpp``. Similarly,; ``XXXTargetAsmInfo.cpp`` usually has a few declarations of ``XXXTargetAsmInfo``; replacement values that override the default values in ``TargetAsmInfo.cpp``.; For example in ``SparcTargetAsmInfo.cpp``:. .. code-block:: c++. SparcTargetAsmInfo::SparcTargetAsmInfo(const SparcTargetMachine &TM) {; Data16bitsDirective = ""\t.half\t"";; Data32bitsDirective = ""\t.word\t"";; Data64bitsDirective = 0; // .xword is only supported by V9.; ZeroDirective = ""\t.skip\t"";; CommentString = ""!"";; ConstantPoolSection = ""\t.section \"".rodata\"",#alloc\n"";; }. The X86 assembly printer implementation (``X86TargetAsmInfo``) is an example; where the target specific ``TargetAsmInfo`` class uses an overridden methods:; ``ExpandInlineAsm``. A target-specific implementation of ``AsmPrinter`` is written in; ``XXXAsmPrin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:69520,Performance,perform,perform,69520,"er.cpp``, which implements the ``AsmPrinter`` class that converts; the LLVM to printable assembly. The implementation must include the following; headers that have declarations for the ``AsmPrinter`` and; ``MachineFunctionPass`` classes. The ``MachineFunctionPass`` is a subclass of; ``FunctionPass``. .. code-block:: c++. #include ""llvm/CodeGen/AsmPrinter.h""; #include ""llvm/CodeGen/MachineFunctionPass.h"". As a ``FunctionPass``, ``AsmPrinter`` first calls ``doInitialization`` to set; up the ``AsmPrinter``. In ``SparcAsmPrinter``, a ``Mangler`` object is; instantiated to process variable names. In ``XXXAsmPrinter.cpp``, the ``runOnMachineFunction`` method (declared in; ``MachineFunctionPass``) must be implemented for ``XXXAsmPrinter``. In; ``MachineFunctionPass``, the ``runOnFunction`` method invokes; ``runOnMachineFunction``. Target-specific implementations of; ``runOnMachineFunction`` differ, but generally do the following to process each; machine function:. * Call ``SetupMachineFunction`` to perform initialization. * Call ``EmitConstantPool`` to print out (to the output stream) constants which; have been spilled to memory. * Call ``EmitJumpTableInfo`` to print out jump tables used by the current; function. * Print out the label for the current function. * Print out the code for the function, including basic block labels and the; assembly for the instruction (using ``printInstruction``). The ``XXXAsmPrinter`` implementation must also include the code generated by; TableGen that is output in the ``XXXGenAsmWriter.inc`` file. The code in; ``XXXGenAsmWriter.inc`` contains an implementation of the ``printInstruction``; method that may call these methods:. * ``printOperand``; * ``printMemOperand``; * ``printCCOperand`` (for conditional statements); * ``printDataDirective``; * ``printDeclare``; * ``printImplicitDef``; * ``printInlineAsm``. The implementations of ``printDeclare``, ``printImplicitDef``,; ``printInlineAsm``, and ``printLabel`` in ``AsmPrinter.cpp`` are general",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:75710,Performance,perform,performing,75710,".inc`` specifies enum values to identify the features,; arrays of constants to represent the CPU features and CPU subtypes, and the; ``ParseSubtargetFeatures`` method that parses the features string that sets; specified subtarget options. The generated ``SparcGenSubtarget.inc`` file; should be included in the ``SparcSubtarget.cpp``. The target-specific; implementation of the ``XXXSubtarget`` method should follow this pseudocode:. .. code-block:: c++. XXXSubtarget::XXXSubtarget(const Module &M, const std::string &FS) {; // Set the default features; // Determine default and user specified characteristics of the CPU; // Call ParseSubtargetFeatures(FS, CPU) to parse the features string; // Perform any additional operations; }. JIT Support; ===========. The implementation of a target machine optionally includes a Just-In-Time (JIT); code generator that emits machine code and auxiliary structures as binary; output that can be written directly to memory. To do this, implement JIT code; generation by performing the following steps:. * Write an ``XXXCodeEmitter.cpp`` file that contains a machine function pass; that transforms target-machine instructions into relocatable machine; code. * Write an ``XXXJITInfo.cpp`` file that implements the JIT interfaces for; target-specific code-generation activities, such as emitting machine code and; stubs. * Modify ``XXXTargetMachine`` so that it provides a ``TargetJITInfo`` object; through its ``getJITInfo`` method. There are several different approaches to writing the JIT support code. For; instance, TableGen and target descriptor files may be used for creating a JIT; code generator, but are not mandatory. For the Alpha and PowerPC target; machines, TableGen is used to generate ``XXXGenCodeEmitter.inc``, which; contains the binary coding of machine instructions and the; ``getBinaryCodeForInstr`` method to access those codes. Other JIT; implementations do not. Both ``XXXJITInfo.cpp`` and ``XXXCodeEmitter.cpp`` must include the; ``llvm/Cod",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:10926,Safety,avoid,avoid,10926,"FrameInfo() const {return &FrameInfo; }; virtual const TargetSubtarget *getSubtargetImpl() const{return &Subtarget; }; virtual const TargetRegisterInfo *getRegisterInfo() const {; return &InstrInfo.getRegisterInfo();; }; virtual const DataLayout *getDataLayout() const { return &DataLayout; }. // Pass Pipeline Configuration; virtual bool addInstSelector(PassManagerBase &PM, bool Fast);; virtual bool addPreEmitPass(PassManagerBase &PM, bool Fast);; };. } // end namespace llvm. * ``getInstrInfo()``; * ``getRegisterInfo()``; * ``getFrameInfo()``; * ``getDataLayout()``; * ``getSubtargetImpl()``. For some targets, you also need to support the following methods:. * ``getTargetLowering()``; * ``getJITInfo()``. Some architectures, such as GPUs, do not support jumping to an arbitrary; program location and implement branching using masked execution and loop using; special instructions around the loop body. In order to avoid CFG modifications; that introduce irreducible control flow not handled by such hardware, a target; must call `setRequiresStructuredCFG(true)` when being initialized. In addition, the ``XXXTargetMachine`` constructor should specify a; ``TargetDescription`` string that determines the data layout for the target; machine, including characteristics such as pointer size, alignment, and; endianness. For example, the constructor for ``SparcTargetMachine`` contains; the following:. .. code-block:: c++. SparcTargetMachine::SparcTargetMachine(const Module &M, const std::string &FS); : DataLayout(""E-p:32:32-f128:128:128""),; Subtarget(M, FS), InstrInfo(Subtarget),; FrameInfo(TargetFrameInfo::StackGrowsDown, 8, 0) {; }. Hyphens separate portions of the ``TargetDescription`` string. * An upper-case ""``E``"" in the string indicates a big-endian target data model.; A lower-case ""``e``"" indicates little-endian. * ""``p:``"" is followed by pointer information: size, ABI alignment, and; preferred alignment. If only two figures follow ""``p:``"", then the first; value is pointer siz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:26043,Safety,avoid,avoid,26043," Value Types...; static const MVT::ValueType IntRegsVTs[] = {; MVT::i32, MVT::Other; };. namespace SP { // Register class instances; DFPRegsClass DFPRegsRegClass;; FPRegsClass FPRegsRegClass;; IntRegsClass IntRegsRegClass;; ...; // IntRegs Sub-register Classes...; static const TargetRegisterClass* const IntRegsSubRegClasses [] = {; NULL; };; ...; // IntRegs Super-register Classes..; static const TargetRegisterClass* const IntRegsSuperRegClasses [] = {; NULL; };; ...; // IntRegs Register Class sub-classes...; static const TargetRegisterClass* const IntRegsSubclasses [] = {; NULL; };; ...; // IntRegs Register Class super-classes...; static const TargetRegisterClass* const IntRegsSuperclasses [] = {; NULL; };. IntRegsClass::IntRegsClass() : TargetRegisterClass(IntRegsRegClassID,; IntRegsVTs, IntRegsSubclasses, IntRegsSuperclasses, IntRegsSubRegClasses,; IntRegsSuperRegClasses, 4, 4, 1, IntRegs, IntRegs + 32) {}; }. The register allocators will avoid using reserved registers, and callee saved; registers are not used until all the volatile registers have been used. That; is usually good enough, but in some cases it may be necessary to provide custom; allocation orders. Implement a subclass of ``TargetRegisterInfo``; ----------------------------------------------. The final step is to hand code portions of ``XXXRegisterInfo``, which; implements the interface described in ``TargetRegisterInfo.h`` (see; :ref:`TargetRegisterInfo`). These functions return ``0``, ``NULL``, or; ``false``, unless overridden. Here is a list of functions that are overridden; for the SPARC implementation in ``SparcRegisterInfo.cpp``:. * ``getCalleeSavedRegs`` --- Returns a list of callee-saved registers in the; order of the desired callee-save stack frame offset. * ``getReservedRegs`` --- Returns a bitset indexed by physical register; numbers, indicating if a particular register is unavailable. * ``hasFP`` --- Return a Boolean indicating if a function should have a; dedicated frame pointer register.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:8849,Security,access,access,8849," can add it to the ``LLVM_ALL_TARGETS`` variable; located in the main ``CMakeLists.txt``. Target Machine; ==============. ``LLVMTargetMachine`` is designed as a base class for targets implemented with; the LLVM target-independent code generator. The ``LLVMTargetMachine`` class; should be specialized by a concrete target class that implements the various; virtual methods. ``LLVMTargetMachine`` is defined as a subclass of; ``TargetMachine`` in ``include/llvm/Target/TargetMachine.h``. The; ``TargetMachine`` class implementation (``TargetMachine.cpp``) also processes; numerous command-line options. To create a concrete target-specific subclass of ``LLVMTargetMachine``, start; by copying an existing ``TargetMachine`` class and header. You should name the; files that you create to reflect your specific target. For instance, for the; SPARC target, name the files ``SparcTargetMachine.h`` and; ``SparcTargetMachine.cpp``. For a target machine ``XXX``, the implementation of ``XXXTargetMachine`` must; have access methods to obtain objects that represent target components. These; methods are named ``get*Info``, and are intended to obtain the instruction set; (``getInstrInfo``), register set (``getRegisterInfo``), stack frame layout; (``getFrameInfo``), and similar information. ``XXXTargetMachine`` must also; implement the ``getDataLayout`` method to access an object with target-specific; data characteristics, such as data type size and alignment requirements. For instance, for the SPARC target, the header file ``SparcTargetMachine.h``; declares prototypes for several ``get*Info`` and ``getDataLayout`` methods that; simply return a class member. .. code-block:: c++. namespace llvm {. class Module;. class SparcTargetMachine : public LLVMTargetMachine {; const DataLayout DataLayout; // Calculates type size & alignment; SparcSubtarget Subtarget;; SparcInstrInfo InstrInfo;; TargetFrameInfo FrameInfo;. protected:; virtual const TargetAsmInfo *createTargetAsmInfo() const;. public:; Spar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:9198,Security,access,access,9198,"LVMTargetMachine`` is defined as a subclass of; ``TargetMachine`` in ``include/llvm/Target/TargetMachine.h``. The; ``TargetMachine`` class implementation (``TargetMachine.cpp``) also processes; numerous command-line options. To create a concrete target-specific subclass of ``LLVMTargetMachine``, start; by copying an existing ``TargetMachine`` class and header. You should name the; files that you create to reflect your specific target. For instance, for the; SPARC target, name the files ``SparcTargetMachine.h`` and; ``SparcTargetMachine.cpp``. For a target machine ``XXX``, the implementation of ``XXXTargetMachine`` must; have access methods to obtain objects that represent target components. These; methods are named ``get*Info``, and are intended to obtain the instruction set; (``getInstrInfo``), register set (``getRegisterInfo``), stack frame layout; (``getFrameInfo``), and similar information. ``XXXTargetMachine`` must also; implement the ``getDataLayout`` method to access an object with target-specific; data characteristics, such as data type size and alignment requirements. For instance, for the SPARC target, the header file ``SparcTargetMachine.h``; declares prototypes for several ``get*Info`` and ``getDataLayout`` methods that; simply return a class member. .. code-block:: c++. namespace llvm {. class Module;. class SparcTargetMachine : public LLVMTargetMachine {; const DataLayout DataLayout; // Calculates type size & alignment; SparcSubtarget Subtarget;; SparcInstrInfo InstrInfo;; TargetFrameInfo FrameInfo;. protected:; virtual const TargetAsmInfo *createTargetAsmInfo() const;. public:; SparcTargetMachine(const Module &M, const std::string &FS);. virtual const SparcInstrInfo *getInstrInfo() const {return &InstrInfo; }; virtual const TargetFrameInfo *getFrameInfo() const {return &FrameInfo; }; virtual const TargetSubtarget *getSubtargetImpl() const{return &Subtarget; }; virtual const TargetRegisterInfo *getRegisterInfo() const {; return &InstrInfo.getRegisterIn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:29696,Security,access,access,29696,"Patterns for definitions of target-specific; instructions. * ``XXXInstrInfo.td`` --- Target-specific definitions of instruction templates,; condition codes, and instructions of an instruction set. For architecture; modifications, a different file name may be used. For example, for Pentium; with SSE instruction, this file is ``X86InstrSSE.td``, and for Pentium with; MMX, this file is ``X86InstrMMX.td``. There is also a target-specific ``XXX.td`` file, where ``XXX`` is the name of; the target. The ``XXX.td`` file includes the other ``.td`` input files, but; its contents are only directly important for subtargets. You should describe a concrete target-specific class ``XXXInstrInfo`` that; represents machine instructions supported by a target machine.; ``XXXInstrInfo`` contains an array of ``XXXInstrDescriptor`` objects, each of; which describes one instruction. An instruction descriptor defines:. * Opcode mnemonic; * Number of operands; * List of implicit register definitions and uses; * Target-independent properties (such as memory access, is commutable); * Target-specific flags. The Instruction class (defined in ``Target.td``) is mostly used as a base for; more complex instruction classes. .. code-block:: text. class Instruction {; string Namespace = """";; dag OutOperandList; // A dag containing the MI def operand list.; dag InOperandList; // A dag containing the MI use operand list.; string AsmString = """"; // The .s format to print the instruction with.; list<dag> Pattern; // Set to the DAG pattern for this instruction.; list<Register> Uses = [];; list<Register> Defs = [];; list<Predicate> Predicates = []; // predicates turned into isel match code; ... remainder not shown for space ...; }. A ``SelectionDAG`` node (``SDNode``) should contain an object representing a; target-specific instruction that is defined in ``XXXInstrInfo.td``. The; instruction objects should represent instructions from the architecture manual; of the target machine (such as the SPARC Architectu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:76569,Security,access,access,76569,"ust-In-Time (JIT); code generator that emits machine code and auxiliary structures as binary; output that can be written directly to memory. To do this, implement JIT code; generation by performing the following steps:. * Write an ``XXXCodeEmitter.cpp`` file that contains a machine function pass; that transforms target-machine instructions into relocatable machine; code. * Write an ``XXXJITInfo.cpp`` file that implements the JIT interfaces for; target-specific code-generation activities, such as emitting machine code and; stubs. * Modify ``XXXTargetMachine`` so that it provides a ``TargetJITInfo`` object; through its ``getJITInfo`` method. There are several different approaches to writing the JIT support code. For; instance, TableGen and target descriptor files may be used for creating a JIT; code generator, but are not mandatory. For the Alpha and PowerPC target; machines, TableGen is used to generate ``XXXGenCodeEmitter.inc``, which; contains the binary coding of machine instructions and the; ``getBinaryCodeForInstr`` method to access those codes. Other JIT; implementations do not. Both ``XXXJITInfo.cpp`` and ``XXXCodeEmitter.cpp`` must include the; ``llvm/CodeGen/MachineCodeEmitter.h`` header file that defines the; ``MachineCodeEmitter`` class containing code for several callback functions; that write data (in bytes, words, strings, etc.) to the output stream. Machine Code Emitter; --------------------. In ``XXXCodeEmitter.cpp``, a target-specific of the ``Emitter`` class is; implemented as a function pass (subclass of ``MachineFunctionPass``). The; target-specific implementation of ``runOnMachineFunction`` (invoked by; ``runOnFunction`` in ``MachineFunctionPass``) iterates through the; ``MachineBasicBlock`` calls ``emitInstruction`` to process each instruction and; emit binary code. ``emitInstruction`` is largely implemented with case; statements on the instruction types defined in ``XXXInstrInfo.h``. For; example, in ``X86CodeEmitter.cpp``, the ``emitInstruction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:83586,Security,access,access,83586,"itial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; JITCompilerFunction = F;; return AlphaCompilationCallback;; }. For the X86 target, the ``getLazyResolverFunction`` implementation is a little; more complicated, because it returns a different callback function for; processors with SSE instructions and XMM registers. The callback function initially saves and later restores the callee register; values, incoming arguments, and frame and return address. The callback; function needs low-level access to the registers or stack, so it is typically; implemented with assembler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:5683,Testability,stub,stub,5683,"AG instruction selection. Also write code in ``XXXISelLowering.cpp``; to replace or remove operations and data types that are not supported; natively in a SelectionDAG. * Write code for an assembly printer that converts LLVM IR to a GAS format for; your target machine. You should add assembly strings to the instructions; defined in your target-specific version of ``TargetInstrInfo.td``. You; should also write code for a subclass of ``AsmPrinter`` that performs the; LLVM-to-assembly conversion and a trivial subclass of ``TargetAsmInfo``. * Optionally, add support for subtargets (i.e., variants with different; capabilities). You should also write code for a subclass of the; ``TargetSubtarget`` class, which allows you to use the ``-mcpu=`` and; ``-mattr=`` command-line options. * Optionally, add JIT support and create a machine code emitter (subclass of; ``TargetJITInfo``) that is used to emit binary code directly into memory. In the ``.cpp`` and ``.h``. files, initially stub up these methods and then; implement them later. Initially, you may not know which private members that; the class will need and which components will need to be subclassed. Preliminaries; -------------. To actually create your compiler backend, you need to create and modify a few; files. The absolute minimum is discussed here. But to actually use the LLVM; target-independent code generator, you must perform the steps described in the; :doc:`LLVM Target-Independent Code Generator <CodeGenerator>` document. First, you should create a subdirectory under ``lib/Target`` to hold all the; files related to your target. If your target is called ""Dummy"", create the; directory ``lib/Target/Dummy``. In this new directory, create a ``CMakeLists.txt``. It is easiest to copy a; ``CMakeLists.txt`` of another target and modify it. It should at least contain; the ``LLVM_TARGET_DEFINITIONS`` variable. The library can be named ``LLVMDummy``; (for example, see the MIPS target). Alternatively, you can split the library",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:45890,Testability,assert,assert,45890,"o relate instructions with each other. It is; particularly useful when you have multiple instruction formats and need to; switch between them after instruction selection. This entire feature is driven; by relation models which can be defined in ``XXXInstrInfo.td`` files; according to the target-specific instruction set. Relation models are defined; using ``InstrMapping`` class as a base. TableGen parses all the models; and generates instruction relation maps using the specified information.; Relation maps are emitted as tables in the ``XXXGenInstrInfo.inc`` file; along with the functions to query them. For the detailed information on how to; use this feature, please refer to :doc:`HowToUseInstrMappings`. Implement a subclass of ``TargetInstrInfo``; -------------------------------------------. The final step is to hand code portions of ``XXXInstrInfo``, which implements; the interface described in ``TargetInstrInfo.h`` (see :ref:`TargetInstrInfo`).; These functions return ``0`` or a Boolean or they assert, unless overridden.; Here's a list of functions that are overridden for the SPARC implementation in; ``SparcInstrInfo.cpp``:. * ``isLoadFromStackSlot`` --- If the specified machine instruction is a direct; load from a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``isStoreToStackSlot`` --- If the specified machine instruction is a direct; store to a stack slot, return the register number of the destination and the; ``FrameIndex`` of the stack slot. * ``copyPhysReg`` --- Copy values between a pair of physical registers. * ``storeRegToStackSlot`` --- Store a register value to a stack slot. * ``loadRegFromStackSlot`` --- Load a register value from a stack slot. * ``storeRegToAddr`` --- Store a register value to memory. * ``loadRegFromAddr`` --- Load a register value from memory. * ``foldMemoryOperand`` --- Attempt to combine instructions of any load or; store instruction for the specified operand(s). Branch Foldi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:60841,Testability,assert,assert,60841,"may require spilling and restoring registers in the stack and working with; register allocators. As seen in ``SparcISelLowering.cpp`` code below, to perform a type conversion; from a floating point value to a signed integer, first the; ``setOperationAction`` should be called with ``Custom`` as the third parameter:. .. code-block:: c++. setOperationAction(ISD::FP_TO_SINT, MVT::i32, Custom);. In the ``LowerOperation`` method, for each ``Custom`` operation, a case; statement should be added to indicate what function to call. In the following; code, an ``FP_TO_SINT`` opcode will call the ``LowerFP_TO_SINT`` method:. .. code-block:: c++. SDValue SparcTargetLowering::LowerOperation(SDValue Op, SelectionDAG &DAG) {; switch (Op.getOpcode()) {; case ISD::FP_TO_SINT: return LowerFP_TO_SINT(Op, DAG);; ...; }; }. Finally, the ``LowerFP_TO_SINT`` method is implemented, using an FP register to; convert the floating-point value to an integer. .. code-block:: c++. static SDValue LowerFP_TO_SINT(SDValue Op, SelectionDAG &DAG) {; assert(Op.getValueType() == MVT::i32);; Op = DAG.getNode(SPISD::FTOI, MVT::f32, Op.getOperand(0));; return DAG.getNode(ISD::BITCAST, MVT::i32, Op);; }. Legal; ^^^^^. The ``Legal`` ``LegalizeAction`` enum value simply indicates that an operation; **is** natively supported. ``Legal`` represents the default condition, so it; is rarely used. In ``SparcISelLowering.cpp``, the action for ``CTPOP`` (an; operation to count the bits set in an integer) is natively supported only for; SPARC v9. The following code enables the ``Expand`` conversion technique for; non-v9 SPARC implementations. .. code-block:: c++. setOperationAction(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:76051,Testability,stub,stubs,76051,"ould be included in the ``SparcSubtarget.cpp``. The target-specific; implementation of the ``XXXSubtarget`` method should follow this pseudocode:. .. code-block:: c++. XXXSubtarget::XXXSubtarget(const Module &M, const std::string &FS) {; // Set the default features; // Determine default and user specified characteristics of the CPU; // Call ParseSubtargetFeatures(FS, CPU) to parse the features string; // Perform any additional operations; }. JIT Support; ===========. The implementation of a target machine optionally includes a Just-In-Time (JIT); code generator that emits machine code and auxiliary structures as binary; output that can be written directly to memory. To do this, implement JIT code; generation by performing the following steps:. * Write an ``XXXCodeEmitter.cpp`` file that contains a machine function pass; that transforms target-machine instructions into relocatable machine; code. * Write an ``XXXJITInfo.cpp`` file that implements the JIT interfaces for; target-specific code-generation activities, such as emitting machine code and; stubs. * Modify ``XXXTargetMachine`` so that it provides a ``TargetJITInfo`` object; through its ``getJITInfo`` method. There are several different approaches to writing the JIT support code. For; instance, TableGen and target descriptor files may be used for creating a JIT; code generator, but are not mandatory. For the Alpha and PowerPC target; machines, TableGen is used to generate ``XXXGenCodeEmitter.inc``, which; contains the binary coding of machine instructions and the; ``getBinaryCodeForInstr`` method to access those codes. Other JIT; implementations do not. Both ``XXXJITInfo.cpp`` and ``XXXCodeEmitter.cpp`` must include the; ``llvm/CodeGen/MachineCodeEmitter.h`` header file that defines the; ``MachineCodeEmitter`` class containing code for several callback functions; that write data (in bytes, words, strings, etc.) to the output stream. Machine Code Emitter; --------------------. In ``XXXCodeEmitter.cpp``, a target-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:82200,Testability,stub,stubs,82200,"base offset). The ``RelocationType`` enum; for that target is defined in the short target-specific ``XXXRelocations.h``; file. The ``RelocationType`` is used by the ``relocate`` method defined in; ``XXXJITInfo.cpp`` to rewrite addresses for referenced global symbols. For example, ``X86Relocations.h`` specifies the following relocation types for; the X86 addresses. In all four cases, the relocated value is added to the; value already in memory. For ``reloc_pcrel_word`` and ``reloc_picrel_word``,; there is an additional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:82653,Testability,stub,stub,82653,"ditional initial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; JITCompilerFunction = F;; return AlphaCompilationCallback;; }. For the X86 target, the ``getLazyResolverFunction`` implementation is a little; more complicated, because it returns a different callback function for; processors with SSE instructions and XMM registers. The callback function initially saves and later restores the callee register; values, incoming arguments, and frame and return address. The callback; function needs low-level access to the registers or stack, so it is typically; implemented with a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:444,Usability,usab,usable,444,"=======================; Writing an LLVM Backend; =======================. .. toctree::; :hidden:. HowToUseInstrMappings. .. contents::; :local:. Introduction; ============. This document describes techniques for writing compiler backends that convert; the LLVM Intermediate Representation (IR) to code for a specified machine or; other languages. Code intended for a specific machine can take the form of; either assembly code or binary code (usable for a JIT compiler). The backend of LLVM features a target-independent code generator that may; create output for several types of target CPUs --- including X86, PowerPC,; ARM, and SPARC. The backend may also be used to generate code targeted at SPUs; of the Cell processor or GPUs to support the execution of compute kernels. The document focuses on existing examples found in subdirectories of; ``llvm/lib/Target`` in a downloaded LLVM release. In particular, this document; focuses on the example of creating a static compiler (one that emits text; assembly) for a SPARC target, because SPARC has fairly standard; characteristics, such as a RISC instruction set and straightforward calling; conventions. Audience; --------. The audience for this document is anyone who needs to write an LLVM backend to; generate code for a specific hardware or software target. Prerequisite Reading; --------------------. These essential documents must be read before reading this document:. * `LLVM Language Reference Manual <LangRef.html>`_ --- a reference manual for; the LLVM assembly language. * :doc:`CodeGenerator` --- a guide to the components (classes and code; generation algorithms) for translating the LLVM internal representation into; machine code for a specified target. Pay particular attention to the; descriptions of code generation stages: Instruction Selection, Scheduling and; Formation, SSA-based Optimization, Register Allocation, Prolog/Epilog Code; Insertion, Late Machine Code Optimizations, and Code Emission. * :doc:`TableGen/index` --",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:1566,Usability,guid,guide,1566,"nd SPARC. The backend may also be used to generate code targeted at SPUs; of the Cell processor or GPUs to support the execution of compute kernels. The document focuses on existing examples found in subdirectories of; ``llvm/lib/Target`` in a downloaded LLVM release. In particular, this document; focuses on the example of creating a static compiler (one that emits text; assembly) for a SPARC target, because SPARC has fairly standard; characteristics, such as a RISC instruction set and straightforward calling; conventions. Audience; --------. The audience for this document is anyone who needs to write an LLVM backend to; generate code for a specific hardware or software target. Prerequisite Reading; --------------------. These essential documents must be read before reading this document:. * `LLVM Language Reference Manual <LangRef.html>`_ --- a reference manual for; the LLVM assembly language. * :doc:`CodeGenerator` --- a guide to the components (classes and code; generation algorithms) for translating the LLVM internal representation into; machine code for a specified target. Pay particular attention to the; descriptions of code generation stages: Instruction Selection, Scheduling and; Formation, SSA-based Optimization, Register Allocation, Prolog/Epilog Code; Insertion, Late Machine Code Optimizations, and Code Emission. * :doc:`TableGen/index` --- a document that describes the TableGen; (``tblgen``) application that manages domain-specific information to support; LLVM code generation. TableGen processes input from a target description; file (``.td`` suffix) and generates C++ code that can be used for code; generation. * :doc:`WritingAnLLVMPass` --- The assembly printer is a ``FunctionPass``, as; are several ``SelectionDAG`` processing steps. To follow the SPARC examples in this document, have a copy of `The SPARC; Architecture Manual, Version 8 <http://www.sparc.org/standards/V8.pdf>`_ for; reference. For details about the ARM instruction set, refer to the `ARM; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:9469,Usability,simpl,simply,9469," To create a concrete target-specific subclass of ``LLVMTargetMachine``, start; by copying an existing ``TargetMachine`` class and header. You should name the; files that you create to reflect your specific target. For instance, for the; SPARC target, name the files ``SparcTargetMachine.h`` and; ``SparcTargetMachine.cpp``. For a target machine ``XXX``, the implementation of ``XXXTargetMachine`` must; have access methods to obtain objects that represent target components. These; methods are named ``get*Info``, and are intended to obtain the instruction set; (``getInstrInfo``), register set (``getRegisterInfo``), stack frame layout; (``getFrameInfo``), and similar information. ``XXXTargetMachine`` must also; implement the ``getDataLayout`` method to access an object with target-specific; data characteristics, such as data type size and alignment requirements. For instance, for the SPARC target, the header file ``SparcTargetMachine.h``; declares prototypes for several ``get*Info`` and ``getDataLayout`` methods that; simply return a class member. .. code-block:: c++. namespace llvm {. class Module;. class SparcTargetMachine : public LLVMTargetMachine {; const DataLayout DataLayout; // Calculates type size & alignment; SparcSubtarget Subtarget;; SparcInstrInfo InstrInfo;; TargetFrameInfo FrameInfo;. protected:; virtual const TargetAsmInfo *createTargetAsmInfo() const;. public:; SparcTargetMachine(const Module &M, const std::string &FS);. virtual const SparcInstrInfo *getInstrInfo() const {return &InstrInfo; }; virtual const TargetFrameInfo *getFrameInfo() const {return &FrameInfo; }; virtual const TargetSubtarget *getSubtargetImpl() const{return &Subtarget; }; virtual const TargetRegisterInfo *getRegisterInfo() const {; return &InstrInfo.getRegisterInfo();; }; virtual const DataLayout *getDataLayout() const { return &DataLayout; }. // Pass Pipeline Configuration; virtual bool addInstSelector(PassManagerBase &PM, bool Fast);; virtual bool addPreEmitPass(PassManagerBase &PM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:22599,Usability,simpl,simply,22599,"lueType`` register type values that are; defined in ``include/llvm/CodeGen/ValueTypes.td``. Defined values include; integer types (such as ``i16``, ``i32``, and ``i1`` for Boolean),; floating-point types (``f32``, ``f64``), and vector types (for example,; ``v8i16`` for an ``8 x i16`` vector). All registers in a ``RegisterClass``; must have the same ``ValueType``, but some registers may store vector data in; different configurations. For example a register that can process a 128-bit; vector may be able to handle 16 8-bit integer elements, 8 16-bit integers, 4; 32-bit integers, and so on. * The third argument of the ``RegisterClass`` definition specifies the; alignment required of the registers when they are stored or loaded to; memory. * The final argument, ``regList``, specifies which registers are in this class.; If an alternative allocation order method is not specified, then ``regList``; also defines the order of allocation used by the register allocator. Besides; simply listing registers with ``(add R0, R1, ...)``, more advanced set; operators are available. See ``include/llvm/Target/Target.td`` for more; information. In ``SparcRegisterInfo.td``, three ``RegisterClass`` objects are defined:; ``FPRegs``, ``DFPRegs``, and ``IntRegs``. For all three register classes, the; first argument defines the namespace with the string ""``SP``"". ``FPRegs``; defines a group of 32 single-precision floating-point registers (``F0`` to; ``F31``); ``DFPRegs`` defines a group of 16 double-precision registers; (``D0-D15``). .. code-block:: text. // F0, F1, F2, ..., F31; def FPRegs : RegisterClass<""SP"", [f32], 32, (sequence ""F%u"", 0, 31)>;. def DFPRegs : RegisterClass<""SP"", [f64], 64,; (add D0, D1, D2, D3, D4, D5, D6, D7, D8,; D9, D10, D11, D12, D13, D14, D15)>;. def IntRegs : RegisterClass<""SP"", [i32], 32,; (add L0, L1, L2, L3, L4, L5, L6, L7,; I0, I1, I2, I3, I4, I5,; O0, O1, O2, O3, O4, O5, O7,; G1,; // Non-allocatable regs:; G2, G3, G4,; O6, // stack ptr; I6, // frame ptr; I7, // r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:48377,Usability,simpl,simplest,48377,"`BranchFolding.cpp`` and; ``IfConversion.cpp`` in the ``lib/CodeGen`` directory) call ``analyzeBranch``; to improve the control flow graph that represents the instructions. Several implementations of ``analyzeBranch`` (for ARM, Alpha, and X86) can be; examined as models for your own ``analyzeBranch`` implementation. Since SPARC; does not implement a useful ``analyzeBranch``, the ARM target implementation is; shown below. ``analyzeBranch`` returns a Boolean value and takes four parameters:. * ``MachineBasicBlock &MBB`` --- The incoming block to be examined. * ``MachineBasicBlock *&TBB`` --- A destination block that is returned. For a; conditional branch that evaluates to true, ``TBB`` is the destination. * ``MachineBasicBlock *&FBB`` --- For a conditional branch that evaluates to; false, ``FBB`` is returned as the destination. * ``std::vector<MachineOperand> &Cond`` --- List of operands to evaluate a; condition for a conditional branch. In the simplest case, if a block ends without a branch, then it falls through; to the successor block. No destination blocks are specified for either ``TBB``; or ``FBB``, so both parameters return ``NULL``. The start of the; ``analyzeBranch`` (see code below for the ARM target) shows the function; parameters and the code for the simplest case. .. code-block:: c++. bool ARMInstrInfo::analyzeBranch(MachineBasicBlock &MBB,; MachineBasicBlock *&TBB,; MachineBasicBlock *&FBB,; std::vector<MachineOperand> &Cond) const; {; MachineBasicBlock::iterator I = MBB.end();; if (I == MBB.begin() || !isUnpredicatedTerminator(--I)); return false;. If a block ends with a single unconditional branch instruction, then; ``analyzeBranch`` (shown below) should return the destination of that branch in; the ``TBB`` parameter. .. code-block:: c++. if (LastOpc == ARM::B || LastOpc == ARM::tB) {; TBB = LastInst->getOperand(0).getMBB();; return false;; }. If a block ends with two unconditional branches, then the second branch is; never reached. In that situation, a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:48701,Usability,simpl,simplest,48701,"M, Alpha, and X86) can be; examined as models for your own ``analyzeBranch`` implementation. Since SPARC; does not implement a useful ``analyzeBranch``, the ARM target implementation is; shown below. ``analyzeBranch`` returns a Boolean value and takes four parameters:. * ``MachineBasicBlock &MBB`` --- The incoming block to be examined. * ``MachineBasicBlock *&TBB`` --- A destination block that is returned. For a; conditional branch that evaluates to true, ``TBB`` is the destination. * ``MachineBasicBlock *&FBB`` --- For a conditional branch that evaluates to; false, ``FBB`` is returned as the destination. * ``std::vector<MachineOperand> &Cond`` --- List of operands to evaluate a; condition for a conditional branch. In the simplest case, if a block ends without a branch, then it falls through; to the successor block. No destination blocks are specified for either ``TBB``; or ``FBB``, so both parameters return ``NULL``. The start of the; ``analyzeBranch`` (see code below for the ARM target) shows the function; parameters and the code for the simplest case. .. code-block:: c++. bool ARMInstrInfo::analyzeBranch(MachineBasicBlock &MBB,; MachineBasicBlock *&TBB,; MachineBasicBlock *&FBB,; std::vector<MachineOperand> &Cond) const; {; MachineBasicBlock::iterator I = MBB.end();; if (I == MBB.begin() || !isUnpredicatedTerminator(--I)); return false;. If a block ends with a single unconditional branch instruction, then; ``analyzeBranch`` (shown below) should return the destination of that branch in; the ``TBB`` parameter. .. code-block:: c++. if (LastOpc == ARM::B || LastOpc == ARM::tB) {; TBB = LastInst->getOperand(0).getMBB();; return false;; }. If a block ends with two unconditional branches, then the second branch is; never reached. In that situation, as shown below, remove the last branch; instruction and return the penultimate branch in the ``TBB`` parameter. .. code-block:: c++. if ((SecondLastOpc == ARM::B || SecondLastOpc == ARM::tB) &&; (LastOpc == ARM::B || LastOpc =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:59603,Usability,simpl,simple,59603,"t native support for a given type, the specified type; may be promoted to a larger type that is supported. For example, SPARC does; not support a sign-extending load for Boolean values (``i1`` type), so in; ``SparcISelLowering.cpp`` the third parameter below, ``Promote``, changes; ``i1`` type values to a large type before loading. .. code-block:: c++. setLoadExtAction(ISD::SEXTLOAD, MVT::i1, Promote);. Expand; ^^^^^^. For a type without native support, a value may need to be broken down further,; rather than promoted. For an operation without native support, a combination; of other operations may be used to similar effect. In SPARC, the; floating-point sine and cosine trig operations are supported by expansion to; other operations, as indicated by the third parameter, ``Expand``, to; ``setOperationAction``:. .. code-block:: c++. setOperationAction(ISD::FSIN, MVT::f32, Expand);; setOperationAction(ISD::FCOS, MVT::f32, Expand);. Custom; ^^^^^^. For some operations, simple type promotion or operation expansion may be; insufficient. In some cases, a special intrinsic function must be implemented. For example, a constant value may require special treatment, or an operation; may require spilling and restoring registers in the stack and working with; register allocators. As seen in ``SparcISelLowering.cpp`` code below, to perform a type conversion; from a floating point value to a signed integer, first the; ``setOperationAction`` should be called with ``Custom`` as the third parameter:. .. code-block:: c++. setOperationAction(ISD::FP_TO_SINT, MVT::i32, Custom);. In the ``LowerOperation`` method, for each ``Custom`` operation, a case; statement should be added to indicate what function to call. In the following; code, an ``FP_TO_SINT`` opcode will call the ``LowerFP_TO_SINT`` method:. .. code-block:: c++. SDValue SparcTargetLowering::LowerOperation(SDValue Op, SelectionDAG &DAG) {; switch (Op.getOpcode()) {; case ISD::FP_TO_SINT: return LowerFP_TO_SINT(Op, DAG);; ...; }; }.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:61051,Usability,simpl,simply,61051,"tionAction`` should be called with ``Custom`` as the third parameter:. .. code-block:: c++. setOperationAction(ISD::FP_TO_SINT, MVT::i32, Custom);. In the ``LowerOperation`` method, for each ``Custom`` operation, a case; statement should be added to indicate what function to call. In the following; code, an ``FP_TO_SINT`` opcode will call the ``LowerFP_TO_SINT`` method:. .. code-block:: c++. SDValue SparcTargetLowering::LowerOperation(SDValue Op, SelectionDAG &DAG) {; switch (Op.getOpcode()) {; case ISD::FP_TO_SINT: return LowerFP_TO_SINT(Op, DAG);; ...; }; }. Finally, the ``LowerFP_TO_SINT`` method is implemented, using an FP register to; convert the floating-point value to an integer. .. code-block:: c++. static SDValue LowerFP_TO_SINT(SDValue Op, SelectionDAG &DAG) {; assert(Op.getValueType() == MVT::i32);; Op = DAG.getNode(SPISD::FTOI, MVT::f32, Op.getOperand(0));; return DAG.getNode(ISD::BITCAST, MVT::i32, Op);; }. Legal; ^^^^^. The ``Legal`` ``LegalizeAction`` enum value simply indicates that an operation; **is** natively supported. ``Legal`` represents the default condition, so it; is rarely used. In ``SparcISelLowering.cpp``, the action for ``CTPOP`` (an; operation to count the bits set in an integer) is natively supported only for; SPARC v9. The following code enables the ``Expand`` conversion technique for; non-v9 SPARC implementations. .. code-block:: c++. setOperationAction(ISD::CTPOP, MVT::i32, Expand);; ...; if (TM.getSubtarget<SparcSubtarget>().isV9()); setOperationAction(ISD::CTPOP, MVT::i32, Legal);. Calling Conventions; -------------------. To support target-specific calling conventions, ``XXXGenCallingConv.td`` uses; interfaces (such as ``CCIfType`` and ``CCAssignToReg``) that are defined in; ``lib/Target/TargetCallingConv.td``. TableGen can take the target descriptor; file ``XXXGenCallingConv.td`` and generate the header file; ``XXXGenCallingConv.inc``, which is typically included in; ``XXXISelLowering.cpp``. You can use the interfaces in; ``Targe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:71689,Usability,usab,usable,71689,"and: register, immediate, basic block, external; symbol, global address, constant pool index, or jump table index. For an; instruction with a memory address operand, the ``printMemOperand`` method; should be implemented to generate the proper output. Similarly,; ``printCCOperand`` should be used to print a conditional operand. ``doFinalization`` should be overridden in ``XXXAsmPrinter``, and it should be; called to shut down the assembly printer. During ``doFinalization``, global; variables and constants are printed to output. Subtarget Support; =================. Subtarget support is used to inform the code generation process of instruction; set variations for a given chip set. For example, the LLVM SPARC; implementation provided covers three major versions of the SPARC microprocessor; architecture: Version 8 (V8, which is a 32-bit architecture), Version 9 (V9, a; 64-bit architecture), and the UltraSPARC architecture. V8 has 16; double-precision floating-point registers that are also usable as either 32; single-precision or 8 quad-precision registers. V8 is also purely big-endian.; V9 has 32 double-precision floating-point registers that are also usable as 16; quad-precision registers, but cannot be used as single-precision registers.; The UltraSPARC architecture combines V9 with UltraSPARC Visual Instruction Set; extensions. If subtarget support is needed, you should implement a target-specific; ``XXXSubtarget`` class for your architecture. This class should process the; command-line options ``-mcpu=`` and ``-mattr=``. TableGen uses definitions in the ``Target.td`` and ``Sparc.td`` files to; generate code in ``SparcGenSubtarget.inc``. In ``Target.td``, shown below, the; ``SubtargetFeature`` interface is defined. The first 4 string parameters of; the ``SubtargetFeature`` interface are a feature name, a XXXSubtarget field set; by the feature, the value of the XXXSubtarget field, and a description of the; feature. (The fifth parameter is a list of features whose pres",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:71855,Usability,usab,usable,71855,"tMemOperand`` method; should be implemented to generate the proper output. Similarly,; ``printCCOperand`` should be used to print a conditional operand. ``doFinalization`` should be overridden in ``XXXAsmPrinter``, and it should be; called to shut down the assembly printer. During ``doFinalization``, global; variables and constants are printed to output. Subtarget Support; =================. Subtarget support is used to inform the code generation process of instruction; set variations for a given chip set. For example, the LLVM SPARC; implementation provided covers three major versions of the SPARC microprocessor; architecture: Version 8 (V8, which is a 32-bit architecture), Version 9 (V9, a; 64-bit architecture), and the UltraSPARC architecture. V8 has 16; double-precision floating-point registers that are also usable as either 32; single-precision or 8 quad-precision registers. V8 is also purely big-endian.; V9 has 32 double-precision floating-point registers that are also usable as 16; quad-precision registers, but cannot be used as single-precision registers.; The UltraSPARC architecture combines V9 with UltraSPARC Visual Instruction Set; extensions. If subtarget support is needed, you should implement a target-specific; ``XXXSubtarget`` class for your architecture. This class should process the; command-line options ``-mcpu=`` and ``-mattr=``. TableGen uses definitions in the ``Target.td`` and ``Sparc.td`` files to; generate code in ``SparcGenSubtarget.inc``. In ``Target.td``, shown below, the; ``SubtargetFeature`` interface is defined. The first 4 string parameters of; the ``SubtargetFeature`` interface are a feature name, a XXXSubtarget field set; by the feature, the value of the XXXSubtarget field, and a description of the; feature. (The fifth parameter is a list of features whose presence is implied,; and its default value is an empty array.). If the value for the field is the string ""true"" or ""false"", the field; is assumed to be a bool and only one Subtarge",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst:83024,Usability,simpl,simply,83024,"itial adjustment. .. code-block:: c++. enum RelocationType {; reloc_pcrel_word = 0, // add reloc value after adjusting for the PC loc; reloc_picrel_word = 1, // add reloc value after adjusting for the PIC base; reloc_absolute_word = 2, // absolute relocation; no additional adjustment; reloc_absolute_dword = 3 // absolute relocation; no additional adjustment; };. Target JIT Info; ---------------. ``XXXJITInfo.cpp`` implements the JIT interfaces for target-specific; code-generation activities, such as emitting machine code and stubs. At; minimum, a target-specific version of ``XXXJITInfo`` implements the following:. * ``getLazyResolverFunction`` --- Initializes the JIT, gives the target a; function that is used for compilation. * ``emitFunctionStub`` --- Returns a native function with a specified address; for a callback function. * ``relocate`` --- Changes the addresses of referenced globals, based on; relocation types. * Callback function that are wrappers to a function stub that is used when the; real target is not initially known. ``getLazyResolverFunction`` is generally trivial to implement. It makes the; incoming parameter as the global ``JITCompilerFunction`` and returns the; callback function that will be used a function wrapper. For the Alpha target; (in ``AlphaJITInfo.cpp``), the ``getLazyResolverFunction`` implementation is; simply:. .. code-block:: c++. TargetJITInfo::LazyResolverFn AlphaJITInfo::getLazyResolverFunction(; JITCompilerFn F) {; JITCompilerFunction = F;; return AlphaCompilationCallback;; }. For the X86 target, the ``getLazyResolverFunction`` implementation is a little; more complicated, because it returns a different callback function for; processors with SSE instructions and XMM registers. The callback function initially saves and later restores the callee register; values, incoming arguments, and frame and return address. The callback; function needs low-level access to the registers or stack, so it is typically; implemented with assembler.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMBackend.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:1449,Deployability,pipeline,pipeline,1449,"sis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-npm-pass-build:. Setting up the build; --------------------. First, configure and build LLVM as described in :doc:`GettingStarted`. Next, we will reuse an existing directory (creating a new directory involves; messing around with more CMake files than we want). For this example, we'll use; ``llvm/lib/Transforms/Utils/HelloWorld.cpp``, which has already been created.; If you'd like to create your own pass, add a new source f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7519,Deployability,pipeline,pipelines,7519,"true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:607,Integrability,interface,interface,607,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:746,Integrability,interface,interface,746,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:633,Modifiability,inherit,inheritance,633,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:703,Modifiability,polymorphi,polymorphism,703,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:827,Modifiability,inherit,inherit,827,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:2069,Modifiability,config,configure,2069,"ion &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-npm-pass-build:. Setting up the build; --------------------. First, configure and build LLVM as described in :doc:`GettingStarted`. Next, we will reuse an existing directory (creating a new directory involves; messing around with more CMake files than we want). For this example, we'll use; ``llvm/lib/Transforms/Utils/HelloWorld.cpp``, which has already been created.; If you'd like to create your own pass, add a new source file into; ``llvm/lib/Transforms/Utils/CMakeLists.txt`` (assuming you want your pass in; the ``Transforms/Utils`` directory. Now that we have the build set up for a new pass, we need to write the code; for the pass itself. .. _writing-an-llvm-npm-pass-basiccode:. Basic code required; -------------------. Now that the build is setup for a new pass, we just have to write it. First we need to define the pass in a header file. We'll create; ``llvm/include/llvm/Transforms/Utils/HelloWorld.h``. The file should; contain the following boilerplate:. .. code-block:: c++. #ifndef LLVM_TRANSFORMS_HELLONEW_HELLOWORLD_H; #define LLVM_TRANSFORMS_HELLONEW_HELLOWORLD_H. #include",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7325,Modifiability,plugin,plugins,7325,"build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7408,Modifiability,plugin,plugins,7408,"===. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7472,Modifiability,plugin,plugin,7472,"true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8049,Modifiability,plugin,plugins,8049,"ntain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamical",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8217,Modifiability,plugin,plugins,8217,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8488,Modifiability,plugin,plugins,8488,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8530,Modifiability,plugin,plugin,8530,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8709,Modifiability,plugin,plugin,8709,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8928,Modifiability,plugin,plugins,8928,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8967,Modifiability,plugin,plugin,8967,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:9078,Modifiability,plugin,plugin,9078,"nction. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamically.; auto Plugin = PassPlugin::Load(PathToPlugin);; if (!Plugin); report_error();; // Register plugin extensions in PassBuilder.; Plugin.registerPassBuilderCallbacks(PB);; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:333,Performance,perform,perform,333,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:365,Performance,optimiz,optimizations,365,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM pass framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7113,Performance,optimiz,optimizations,7113,"s/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:7505,Performance,optimiz,optimization,7505,"true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:8042,Performance,load,loaded,8042,"ntain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------. LLVM provides a mechanism to register pass plugins within various tools like; ``clang`` or ``opt``. A pass plugin can add passes to default optimization; pipelines or to be manually run via tools like ``opt``. For more information,; see :doc:`NewPassManager`. Create a CMake project at the root of the repo alongside; other projects. This project must contain the following minimal; ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_pass_plugin(MyPassName source.cpp). See the definition of ``add_llvm_pass_plugin`` for more CMake details. The pass must provide at least one of two entry points for the new pass manager,; one for static registration and one for dynamically loaded plugins:. - ``llvm::PassPluginLibraryInfo get##Name##PluginInfo();``; - ``extern ""C"" ::llvm::PassPluginLibraryInfo llvmGetPassPluginInfo() LLVM_ATTRIBUTE_WEAK;``. Pass plugins are compiled and linked dynamically by default. Setting; ``LLVM_${NAME}_LINK_INTO_TOOLS`` to ``ON`` turns the project into a statically; linked extension. For an in-tree example, see ``llvm/examples/Bye/``. To make ``PassBuilder`` aware of statically linked pass plugins:. .. code-block:: c++. // Declare plugin extension function declarations.; #define HANDLE_EXTENSION(Ext) llvm::PassPluginLibraryInfo get##Ext##PluginInfo();; #include ""llvm/Support/Extension.def"". ... // Register plugin extensions in PassBuilder.; #define HANDLE_EXTENSION(Ext) get##Ext##PluginInfo().RegisterPassBuilderCallbacks(PB);; #include ""llvm/Support/Extension.def"". To make ``PassBuilder`` aware of dynamically linked pass plugins:. .. code-block:: c++. // Load plugin dynamical",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:1257,Testability,test,testing,1257," important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-npm-pass-build:. Setting up the build; --------------------. First, configure and build LLVM as described in :doc:`GettingStarted`. Next, we will reuse an existing directory (creating a new directory invol",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:5927,Testability,test,test,5927," into; ``llvm/lib/Passes/PassBuilder.cpp`` multiple times for various reasons. Since; it constructs our pass, we need to also add the proper #include in; ``llvm/lib/Passes/PassBuilder.cpp``:. .. code-block:: c++. #include ""llvm/Transforms/Utils/HelloWorld.h"". This should be all the code necessary for our pass, now it's time to compile; and run it. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny pass, we can build :program:`opt` and use; it to run some LLVM IR through the pass. .. code-block:: console. $ ninja -C build/ opt; # or whatever build system/build directory you are using. $ cat /tmp/a.ll; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. define void @bar() {; ret void; }. $ build/bin/opt -disable-output /tmp/a.ll -passes=helloworld; foo; bar. Our pass ran and printed the names of functions as expected!. Testing a pass; --------------. Testing our pass is important to prevent future regressions. We'll add a lit; test at ``llvm/test/Transforms/Utils/helloworld.ll``. See; :doc:`TestingGuide` for more information on testing. .. code-block:: llvm. $ cat llvm/test/Transforms/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:5942,Testability,test,test,5942," into; ``llvm/lib/Passes/PassBuilder.cpp`` multiple times for various reasons. Since; it constructs our pass, we need to also add the proper #include in; ``llvm/lib/Passes/PassBuilder.cpp``:. .. code-block:: c++. #include ""llvm/Transforms/Utils/HelloWorld.h"". This should be all the code necessary for our pass, now it's time to compile; and run it. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny pass, we can build :program:`opt` and use; it to run some LLVM IR through the pass. .. code-block:: console. $ ninja -C build/ opt; # or whatever build system/build directory you are using. $ cat /tmp/a.ll; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. define void @bar() {; ret void; }. $ build/bin/opt -disable-output /tmp/a.ll -passes=helloworld; foo; bar. Our pass ran and printed the names of functions as expected!. Testing a pass; --------------. Testing our pass is important to prevent future regressions. We'll add a lit; test at ``llvm/test/Transforms/Utils/helloworld.ll``. See; :doc:`TestingGuide` for more information on testing. .. code-block:: llvm. $ cat llvm/test/Transforms/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:6030,Testability,test,testing,6030,"us reasons. Since; it constructs our pass, we need to also add the proper #include in; ``llvm/lib/Passes/PassBuilder.cpp``:. .. code-block:: c++. #include ""llvm/Transforms/Utils/HelloWorld.h"". This should be all the code necessary for our pass, now it's time to compile; and run it. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny pass, we can build :program:`opt` and use; it to run some LLVM IR through the pass. .. code-block:: console. $ ninja -C build/ opt; # or whatever build system/build directory you are using. $ cat /tmp/a.ll; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. define void @bar() {; ret void; }. $ build/bin/opt -disable-output /tmp/a.ll -passes=helloworld; foo; bar. Our pass ran and printed the names of functions as expected!. Testing a pass; --------------. Testing our pass is important to prevent future regressions. We'll add a lit; test at ``llvm/test/Transforms/Utils/helloworld.ll``. See; :doc:`TestingGuide` for more information on testing. .. code-block:: llvm. $ cat llvm/test/Transforms/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:6072,Testability,test,test,6072," #include in; ``llvm/lib/Passes/PassBuilder.cpp``:. .. code-block:: c++. #include ""llvm/Transforms/Utils/HelloWorld.h"". This should be all the code necessary for our pass, now it's time to compile; and run it. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny pass, we can build :program:`opt` and use; it to run some LLVM IR through the pass. .. code-block:: console. $ ninja -C build/ opt; # or whatever build system/build directory you are using. $ cat /tmp/a.ll; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. define void @bar() {; ret void; }. $ build/bin/opt -disable-output /tmp/a.ll -passes=helloworld; foo; bar. Our pass ran and printed the names of functions as expected!. Testing a pass; --------------. Testing our pass is important to prevent future regressions. We'll add a lit; test at ``llvm/test/Transforms/Utils/helloworld.ll``. See; :doc:`TestingGuide` for more information on testing. .. code-block:: llvm. $ cat llvm/test/Transforms/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:6366,Testability,test,test,6366,"have a brand new shiny pass, we can build :program:`opt` and use; it to run some LLVM IR through the pass. .. code-block:: console. $ ninja -C build/ opt; # or whatever build system/build directory you are using. $ cat /tmp/a.ll; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. define void @bar() {; ret void; }. $ build/bin/opt -disable-output /tmp/a.ll -passes=helloworld; foo; bar. Our pass ran and printed the names of functions as expected!. Testing a pass; --------------. Testing our pass is important to prevent future regressions. We'll add a lit; test at ``llvm/test/Transforms/Utils/helloworld.ll``. See; :doc:`TestingGuide` for more information on testing. .. code-block:: llvm. $ cat llvm/test/Transforms/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:6400,Testability,test,tests,6400,"have a brand new shiny pass, we can build :program:`opt` and use; it to run some LLVM IR through the pass. .. code-block:: console. $ ninja -C build/ opt; # or whatever build system/build directory you are using. $ cat /tmp/a.ll; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. define void @bar() {; ret void; }. $ build/bin/opt -disable-output /tmp/a.ll -passes=helloworld; foo; bar. Our pass ran and printed the names of functions as expected!. Testing a pass; --------------. Testing our pass is important to prevent future regressions. We'll add a lit; test at ``llvm/test/Transforms/Utils/helloworld.ll``. See; :doc:`TestingGuide` for more information on testing. .. code-block:: llvm. $ cat llvm/test/Transforms/Utils/helloworld.ll; ; RUN: opt -disable-output -passes=helloworld %s 2>&1 | FileCheck %s. ; CHECK: {{^}}foo{{$}}; define i32 @foo() {; %a = add i32 2, 3; ret i32 %a; }. ; CHECK-NEXT: {{^}}bar{{$}}; define void @bar() {; ret void; }. $ ninja -C build check-llvm; # runs our new test alongside all other llvm lit tests. FAQs; ====. Required passes; ---------------. A pass that defines a static ``isRequired()`` method that returns true is a required pass. For example:. .. code-block:: c++. class HelloWorldPass : public PassInfoMixin<HelloWorldPass> {; public:; PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);. static bool isRequired() { return true; }; };. A required pass is a pass that may not be skipped. An example of a required; pass is ``AlwaysInlinerPass``, which must always be run to preserve; ``alwaysinline`` semantics. Pass managers are required since they may contain; other required passes. An example of how a pass can be skipped is the ``optnone`` function; attribute, which specifies that optimizations should not be run on the; function. Required passes will still be run on ``optnone`` functions. For more implementation details, see; ``PassInstrumentation::runBeforePass()``. Registering passes as plugins; -----------------------------.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:1322,Usability,learn,learn,1322,"of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. Unlike passes under the legacy pass manager where the pass interface is; defined via inheritance, passes under the new pass manager rely on; concept-based polymorphism, meaning there is no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-npm-pass-build:. Setting up the build; --------------------. First, configure and build LLVM as described in :doc:`GettingStarted`. Next, we will reuse an existing directory (creating a new directory involves; messing around with more CMake files than we want). For this example, we'll use; ``llvm/lib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:1705,Usability,simpl,simply,1705,"s no explicit interface (see; comments in ``PassManager.h`` for more details). All LLVM passes inherit from; the CRTP mix-in ``PassInfoMixin<PassT>``. The pass should have a ``run()``; method which returns a ``PreservedAnalyses`` and takes in some unit of IR; along with an analysis manager. For example, a function pass would have a; ``PreservedAnalyses run(Function &F, FunctionAnalysisManager &AM);`` method. We start by showing you how to construct a pass, from setting up the build,; creating the pass, to executing and testing it. Looking at existing passes is; always a great way to learn details. .. warning::; This document deals with the new pass manager. LLVM uses the legacy pass; manager for the codegen pipeline. For more details, see; :doc:`WritingAnLLVMPass` and :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""HelloWorld""; pass is designed to simply print out the name of non-external functions that; exist in the program being compiled. It does not modify the program at all,; it just inspects it. The code below already exists; feel free to create a pass with a different; name alongside the HelloWorld source files. .. _writing-an-llvm-npm-pass-build:. Setting up the build; --------------------. First, configure and build LLVM as described in :doc:`GettingStarted`. Next, we will reuse an existing directory (creating a new directory involves; messing around with more CMake files than we want). For this example, we'll use; ``llvm/lib/Transforms/Utils/HelloWorld.cpp``, which has already been created.; If you'd like to create your own pass, add a new source file into; ``llvm/lib/Transforms/Utils/CMakeLists.txt`` (assuming you want your pass in; the ``Transforms/Utils`` directory. Now that we have the build set up for a new pass, we need to write the code; for the pass itself. .. _writing-an-llvm-npm-pass-basiccode:. Basic code required; -------------------. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst:4274,Usability,simpl,simply,4274," llvm. #endif // LLVM_TRANSFORMS_HELLONEW_HELLOWORLD_H. This creates the class for the pass with a declaration of the ``run()``; method which actually runs the pass. Inheriting from ``PassInfoMixin<PassT>``; sets up some more boilerplate so that we don't have to write it ourselves. Our class is in the ``llvm`` namespace so that we don't pollute the global; namespace. Next we'll create ``llvm/lib/Transforms/Utils/HelloWorld.cpp``, starting; with. .. code-block:: c++. #include ""llvm/Transforms/Utils/HelloWorld.h"". ... to include the header file we just created. .. code-block:: c++. using namespace llvm;. ... is required because the functions from the include files live in the llvm; namespace. This should only be done in non-header files. Next we have the pass's ``run()`` definition:. .. code-block:: c++. PreservedAnalyses HelloWorldPass::run(Function &F,; FunctionAnalysisManager &AM) {; errs() << F.getName() << ""\n"";; return PreservedAnalyses::all();; }. ... which simply prints out the name of the function to stderr. The pass; manager will ensure that the pass will be run on every function in a module.; The ``PreservedAnalyses`` return value says that all analyses (e.g. dominator; tree) are still valid after this pass since we didn't modify any functions. That's it for the pass itself. Now in order to ""register"" the pass, we need; to add it to a couple places. Add the following to; ``llvm/lib/Passes/PassRegistry.def`` in the ``FUNCTION_PASS`` section. .. code-block:: c++. FUNCTION_PASS(""helloworld"", HelloWorldPass()). ... which adds the pass under the name ""helloworld"". ``llvm/lib/Passes/PassRegistry.def`` is #include'd into; ``llvm/lib/Passes/PassBuilder.cpp`` multiple times for various reasons. Since; it constructs our pass, we need to also add the proper #include in; ``llvm/lib/Passes/PassBuilder.cpp``:. .. code-block:: c++. #include ""llvm/Transforms/Utils/HelloWorld.h"". This should be all the code necessary for our pass, now it's time to compile; and run it. Runni",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMNewPMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1573,Availability,down,down,1573,"e `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:2293,Availability,avail,available,2293,"fficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; copy the following into ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_library( LLVMHello MODULE; Hello.cpp. PLUGIN_TOOL; opt; ). and the following line into ``lib/Transforms/CMakeLists.txt``:. .. code-block:: cmake. add_subdirectory(Hello). (Note that there is already a directory named ``Hello`` with a sample ""Hello""; pass; you may play with it -- in which case you don't need to modify any; ``CMakeLists.txt`` files -- or, if you want to create everything from scratch,; use another name.). This build script specifies that ``Hello.cpp`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:9079,Availability,avail,available,9079,"VM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello -time-passes < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main; ===----------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:11489,Availability,avail,available,11489,"( 0.0%) 0.0000 ( 0.0%) 0.0001 ( 10.7%) Module Verifier; 0.0007 (100.0%) 0.0007 (100.0%) 0.0005 (100.0%) Total. As you can see, our implementation above is pretty fast. The additional; passes listed are automatically inserted by the :program:`opt` tool to verify; that the LLVM emitted by your pass is still valid and well formed LLVM, which; hasn't been broken somehow. Now that you have seen the basics of the mechanics behind passes, we can talk; about some more details of how they work and how to use them. .. _writing-an-llvm-pass-pass-classes:. Pass classes and requirements; =============================. One of the first things that you should do when designing a new pass is to; decide what class you should subclass for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various tran",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:31088,Availability,alive,alive,31088,"sage::addRequired<>`` and ``AnalysisUsage::addRequiredTransitive<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. If your pass requires a previous pass to be executed (an analysis for example),; it can use one of these methods to arrange for it to be run before your pass.; LLVM has many different types of analyses and passes that can be required,; spanning the range from ``DominatorSet`` to ``BreakCriticalEdges``. Requiring; ``BreakCriticalEdges``, for example, guarantees that there will be no critical; edges in the CFG when your pass has been run. Some analyses chain to other analyses to do their job. For example, an; `AliasAnalysis <AliasAnalysis>` implementation is required to :ref:`chain; <aliasanalysis-chaining>` to other alias analysis passes. In cases where; analyses chain, the ``addRequiredTransitive`` method should be used instead of; the ``addRequired`` method. This informs the ``PassManager`` that the; transitively required pass should be alive as long as the requiring pass is. The ``AnalysisUsage::addPreserved<>`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One of the jobs of the ``PassManager`` is to optimize how and when analyses are; run. In particular, it attempts to avoid recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transforma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:31506,Availability,avail,available,31506,"the range from ``DominatorSet`` to ``BreakCriticalEdges``. Requiring; ``BreakCriticalEdges``, for example, guarantees that there will be no critical; edges in the CFG when your pass has been run. Some analyses chain to other analyses to do their job. For example, an; `AliasAnalysis <AliasAnalysis>` implementation is required to :ref:`chain; <aliasanalysis-chaining>` to other alias analysis passes. In cases where; analyses chain, the ``addRequiredTransitive`` method should be used instead of; the ``addRequired`` method. This informs the ``PassManager`` that the; transitively required pass should be alive as long as the requiring pass is. The ``AnalysisUsage::addPreserved<>`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One of the jobs of the ``PassManager`` is to optimize how and when analyses are; run. In particular, it attempts to avoid recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses if they exist, so it can preserve them, despite the; fact that it hacks on the CFG. Example implementations of ``getAnalysisUsage``; ^^^^^^^^^^",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:33497,Availability,failure,failure,33497,"fies the program, but does not modify the CFG; void LICM::getAnalysisUsage(AnalysisUsage &AU) const {; AU.setPreservesCFG();; AU.addRequired<LoopInfoWrapperPass>();; }. .. _writing-an-llvm-pass-getAnalysis:. The ``getAnalysis<>`` and ``getAnalysisIfAvailable<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &LI = getAnalysis<LoopInfoWrapperPass>().getLoopInfo();; //...; }. This method call returns a reference to the pass desired. You may get a; runtime assertion failure if you attempt to get an analysis that you did not; declare as required in your :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` implementation. This method can be; called by your ``run*`` method implementation, or by any other local method; invoked by your ``run*`` method. A module level pass can use function level analysis info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func);; //...; }. In above example, ``runOnFunction`` for ``DominatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Ana",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:36264,Availability,avail,available,36264," alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes are: the; ``AnalysisUsage::addRequired()`` and ``Pass::getAnalysis()`` methods. In order; to resolve this requirement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:36338,Availability,avail,available,36338," alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes are: the; ``AnalysisUsage::addRequired()`` and ``Pass::getAnalysis()`` methods. In order; to resolve this requirement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:36360,Availability,avail,available,36360,"mount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes are: the; ``AnalysisUsage::addRequired()`` and ``Pass::getAnalysis()`` methods. In order; to resolve this requirement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass); just does a few simple checks that don't require significant analysis to; compute (such as: two different ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:39932,Availability,avail,available,39932,"ement the AliasAnalysis interface; INITIALIZE_AG_PASS(FancyAA, AliasAnalysis , ""somefancyaa"",; ""A more complex alias analysis implementation"",; false, // Is CFG Only?; true, // Is Analysis?; false); // Is default Analysis Group implementation?; }. This just shows a class ``FancyAA`` that uses the ``INITIALIZE_AG_PASS`` macro; both to register and to ""join"" the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ analysis group.; Every implementation of an analysis group should join using this macro. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(BasicAA, AliasAnalysis, ""basic-aa"",; ""Basic Alias Analysis (default AA impl)"",; false, // Is CFG Only?; true, // Is Analysis?; true); // Is default Analysis Group implementation?; }. Here we show how the default implementation is specified (using the final; argument to the ``INITIALIZE_AG_PASS`` template). There must be exactly one; default implementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41363,Availability,avail,available,41363,"om passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:54284,Availability,down,down,54284," we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After following the information; above, you have succeeded in getting some breakpoints planted in your pass.; Next thing you know, you restart the program (i.e., you type ""``run``"" again),; and you start getting errors about breakpoints being unsettable. The only; way I have found to ""fix"" this problem is to delete the breakpoints that are; already set in your pass, run the program, and re-set the breakpoints once; execution stops in ``PassManager::run``. Hopefully these tips will help with common case debugging situations. If you'd; like to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:54978,Availability,error,errors,54978," it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After following the information; above, you have succeeded in getting some breakpoints planted in your pass.; Next thing you know, you restart the program (i.e., you type ""``run``"" again),; and you start getting errors about breakpoints being unsettable. The only; way I have found to ""fix"" this problem is to delete the breakpoints that are; already set in your pass, run the program, and re-set the breakpoints once; execution stops in ``PassManager::run``. Hopefully these tips will help with common case debugging situations. If you'd; like to contribute some tips of your own, just contact `Chris; <mailto:sabre@nondot.org>`_.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1735,Deployability,pipeline,pipeline,1735,"ss works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1757,Deployability,pipeline,pipeline,1757,"ss works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:12153,Deployability,update,updated,12153,"=======. One of the first things that you should do when designing a new pass is to; decide what class you should subclass for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:12275,Deployability,configurat,configuration,12275," for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:20533,Deployability,update,update,20533,"(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. .. _writing-an-llvm-pass-doFinalization-mod:. The ``doFinalization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(Module &M);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` for every function in the program being; compiled. .. _writing-an-llvm-pass-LoopPass:. The ``LoopPass`` class; ----------------------. All ``LoopPass`` execute on each :ref:`loop <loop-terminology>` in the function; independent of all of the other loops in the function. ``LoopPass`` processes; loops in loop nest order such that outer most loop is processed last. ``LoopPass`` subclasses are allowed to update loop nest using ``LPPassManager``; interface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:20892,Deployability,pipeline,pipeline,20892,"rtual bool doFinalization(Module &M);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` for every function in the program being; compiled. .. _writing-an-llvm-pass-LoopPass:. The ``LoopPass`` class; ----------------------. All ``LoopPass`` execute on each :ref:`loop <loop-terminology>` in the function; independent of all of the other loops in the function. ``LoopPass`` processes; loops in loop nest order such that outer most loop is processed last. ``LoopPass`` subclasses are allowed to update loop nest using ``LPPassManager``; interface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:20990,Deployability,pipeline,pipeline,20990,"rtual bool doFinalization(Module &M);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` for every function in the program being; compiled. .. _writing-an-llvm-pass-LoopPass:. The ``LoopPass`` class; ----------------------. All ``LoopPass`` execute on each :ref:`loop <loop-terminology>` in the function; independent of all of the other loops in the function. ``LoopPass`` processes; loops in loop nest order such that outer most loop is processed last. ``LoopPass`` subclasses are allowed to update loop nest using ``LPPassManager``; interface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:22297,Deployability,update,update,22297,"his set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23035,Deployability,update,update,23035,"M) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:24295,Deployability,update,update,24295,"f they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; ---------------------------------. A ``MachineFunctionPass`` is a part of the LLVM code generator that executes on; the machine-dependent representation of each LLVM function in the program. Code generator passes are registered and initialized specially by; ``TargetMachine::addPassesToEmitFile`` and similar routines, so they cannot; generally be run from the :program:`opt` or :program:`bugpoint` commands. A ``MachineFunctionPass`` is also a ``FunctionPass``, so all the restrictions; that apply to a ``FunctionPass`` also apply to it. ``MachineFunctionPass``\ es; also have addition",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:32282,Deployability,update,update,32282," recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses if they exist, so it can preserve them, despite the; fact that it hacks on the CFG. Example implementations of ``getAnalysisUsage``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. // This example modifies the program, but does not modify the CFG; void LICM::getAnalysisUsage(AnalysisUsage &AU) const {; AU.setPreservesCFG();; AU.addRequired<LoopInfoWrapperPass>();; }. .. _writing-an-llvm-pass-getAnalysis:. The ``getAnalysis<>`` and ``getAnalysisIfAvailable<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:34533,Deployability,update,update,34533,"analysis that you did not; declare as required in your :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` implementation. This method can be; called by your ``run*`` method implementation, or by any other local method; invoked by your ``run*`` method. A module level pass can use function level analysis info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func);; //...; }. In above example, ``runOnFunction`` for ``DominatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Analysis Groups; ----------------------------. Now that we understand the basics of how passes are defined, how they are used,; and how they are required from other passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41630,Deployability,release,releaseMemory,41630,"r's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46861,Deployability,release,releaseMemory,46861,"y the program, so we preserve all analyses; void getAnalysisUsage(AnalysisUsage &AU) const override {; AU.setPreservesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; ===================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46883,Deployability,release,releaseMemory,46883,"getAnalysisUsage(AnalysisUsage &AU) const override {; AU.setPreservesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when construct",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46971,Deployability,release,releaseMemory,46971,"vesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:47300,Deployability,release,releaseMemory,47300,"s Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:47599,Deployability,release,releaseMemory,47599,"mpl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:47625,Deployability,release,release,47625,"mpl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:48192,Deployability,configurat,configurations,48192,"object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50052,Deployability,install,installing,50052,"try``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1278,Energy Efficiency,schedul,schedules,1278,"exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1308,Energy Efficiency,efficient,efficient,1308,"exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; so",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16254,Energy Efficiency,schedul,scheduled,16254,"to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global data). Implementing a ``CallGraphSCCPass`` is slightly tricky in some cases because it; has to handle SCCs with more than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, loca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:18874,Energy Efficiency,schedul,scheduled,18874,"ns of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). A good example of how this method should be used is the `LowerAllocations; <https://llvm.org/doxygen/LowerAllocations_8cpp-source.html>`_ pass. This pass; converts ``malloc`` and ``free`` instructions into platform dependent; ``malloc()`` and ``free()`` function calls. It uses the ``doInitialization``; method to get a reference to the ``malloc`` and ``free`` functions that it; needs, adding prototypes to the module if necessary. .. _writing-an-llvm-pass-runOnFunction:. The ``runOnFunction`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnFunction(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. .. _writing-an-llvm-pass-doFinalization-mod:. The ``doFinalization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:21695,Energy Efficiency,schedul,scheduled,21695,"; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` clas",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23687,Energy Efficiency,schedul,scheduled,23687,"ss`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; -----------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:40970,Energy Efficiency,schedul,schedules,40970,"lementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:40994,Energy Efficiency,efficient,efficiently,40994,"lementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41144,Energy Efficiency,reduce,reduce,41144,"lysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41646,Energy Efficiency,allocate,allocated,41646,"r's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42485,Energy Efficiency,reduce,reduces,42485,"act lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42504,Energy Efficiency,consumption,consumption,42504,"act lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42807,Energy Efficiency,schedul,scheduling,42807,"cution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example, we can see how our; :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass interacts with other; passes. Lets try it out with the gvn and licm passes:. .. code-block:: console. $ opt -load lib/LLVMHello.s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:47644,Energy Efficiency,allocate,allocated,47644,"mpl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:49368,Energy Efficiency,schedul,scheduling,49368," the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Registe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50710,Energy Efficiency,schedul,schedulers,50710,"o in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:5846,Integrability,message,message,5846,". struct Hello : public FunctionPass {. This declares a ""``Hello``"" class that is a subclass of :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. The different builtin pass subclasses; are described in detail :ref:`later <writing-an-llvm-pass-pass-classes>`, but; for now, know that ``FunctionPass`` operates on a function at a time. .. code-block:: c++. static char ID;; Hello() : FunctionPass(ID) {}. This declares pass identifier used by LLVM to identify pass. This allows LLVM; to avoid using expensive C++ runtime information. .. code-block:: c++. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. We declare a :ref:`runOnFunction <writing-an-llvm-pass-runOnFunction>` method,; which overrides an abstract virtual method inherited from :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. This is where we are supposed to do our; thing, so we just print out our message with the name of each function. .. code-block:: c++. char Hello::ID = 0;. We initialize pass ID here. LLVM uses ID's address to identify a pass, so; initialization value is not important. .. code-block:: c++. static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Lastly, we :ref:`register our class <writing-an-llvm-pass-registration>`; ``Hello``, giving it a command line argument ""``hello``"", and a name ""Hello; World Pass"". The last two arguments describe its behavior: if a pass walks CFG; without modifying it then the third argument is set to ``true``; if a pass is; an analysis pass, for example dominator tree pass, then ``true`` is supplied as; the fourth argument. As a whole, the ``.cpp`` file looks like:. .. code-block:: c++. #include ""llvm/Pass.h""; #include ""llvm/IR/Function.h""; #include ""llvm/Support/raw_ostream.h"". #include ""llvm/IR/LegacyPassManager.h"". using namespace llvm;. namespace {; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:7587,Integrability,interface,interfaces,7587,"r tree pass, then ``true`` is supplied as; the fourth argument. As a whole, the ``.cpp`` file looks like:. .. code-block:: c++. #include ""llvm/Pass.h""; #include ""llvm/IR/Function.h""; #include ""llvm/Support/raw_ostream.h"". #include ""llvm/IR/LegacyPassManager.h"". using namespace llvm;. namespace {; struct Hello : public FunctionPass {; static char ID;; Hello() : FunctionPass(ID) {}. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. char Hello::ID = 0;; static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Now that it's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:13242,Integrability,interface,interface,13242,"is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the; ``getAnalysis`` interface ``getAnalysis<DominatorTree>(llvm::Function *)`` to; provide the function to retrieve analysis result for, if the function pass does; not require any module or immutable passes. Note that this can only be done; for functions for which the analysis ran, e.g. in the case of dominators you; should only ask for the ``DominatorTree`` for function definitions, not; declarations. To write a correct ``ModulePass`` subclass, derive from ``ModulePass`` and; override the ``runOnModule`` method with the following signature:. The ``runOnModule`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnModule(Module &M) = 0;. The ``runOnModule`` method performs the interesting work of the pass. It; should return ``true`` if the module was modified by the transformation and; ``false`` otherwise. .. _writing-an-llvm-pass-CallGraphSCCPass:. The ``CallGraphSCCPass`` class; ------------------------------. The `CallGraphSCCPass; <https://llvm.org/doxygen/classllvm_1_1CallGraphSCCPass.html>`_ is used by; passes that need to traverse the program bottom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16173,Integrability,depend,depend,16173," ... *not allowed* to add or remove SCC's from the current Module, though; they may change the contents of an SCC.; #. ... *allowed* to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global data). Implementing a ``CallGraphSCCPass`` is slightly tricky in some cases because it; has to handle SCCs with more than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:18788,Integrability,depend,depend,18788,"on``\ s from the current ``Module``.; #. Add or remove global variables from the current ``Module``.; #. Maintain state across invocations of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). A good example of how this method should be used is the `LowerAllocations; <https://llvm.org/doxygen/LowerAllocations_8cpp-source.html>`_ pass. This pass; converts ``malloc`` and ``free`` instructions into platform dependent; ``malloc()`` and ``free()`` function calls. It uses the ``doInitialization``; method to get a reference to the ``malloc`` and ``free`` functions that it; needs, adding prototypes to the module if necessary. .. _writing-an-llvm-pass-runOnFunction:. The ``runOnFunction`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnFunction(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:19173,Integrability,depend,dependent,19173,"virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). A good example of how this method should be used is the `LowerAllocations; <https://llvm.org/doxygen/LowerAllocations_8cpp-source.html>`_ pass. This pass; converts ``malloc`` and ``free`` instructions into platform dependent; ``malloc()`` and ``free()`` function calls. It uses the ``doInitialization``; method to get a reference to the ``malloc`` and ``free`` functions that it; needs, adding prototypes to the module if necessary. .. _writing-an-llvm-pass-runOnFunction:. The ``runOnFunction`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnFunction(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. .. _writing-an-llvm-pass-doFinalization-mod:. The ``doFinalization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(Module &M);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` for every function in the program b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:20575,Integrability,interface,interface,20575,"(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. .. _writing-an-llvm-pass-doFinalization-mod:. The ``doFinalization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(Module &M);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` for every function in the program being; compiled. .. _writing-an-llvm-pass-LoopPass:. The ``LoopPass`` class; ----------------------. All ``LoopPass`` execute on each :ref:`loop <loop-terminology>` in the function; independent of all of the other loops in the function. ``LoopPass`` processes; loops in loop nest order such that outer most loop is processed last. ``LoopPass`` subclasses are allowed to update loop nest using ``LPPassManager``; interface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:21609,Integrability,depend,depend,21609,"erface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:21797,Integrability,interface,interface,21797,"ass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but execute",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:22268,Integrability,interface,interface,22268,"his set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23090,Integrability,interface,interface,23090,"M) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23601,Integrability,depend,depend,23601,"p; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnReg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23789,Integrability,interface,interface,23789,"t executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; ---------------------------------. A ``MachineFunctionPass`` is a part of the LLVM code generator that executes on; the machine-de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:24266,Integrability,interface,interface,24266,"f they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; ---------------------------------. A ``MachineFunctionPass`` is a part of the LLVM code generator that executes on; the machine-dependent representation of each LLVM function in the program. Code generator passes are registered and initialized specially by; ``TargetMachine::addPassesToEmitFile`` and similar routines, so they cannot; generally be run from the :program:`opt` or :program:`bugpoint` commands. A ``MachineFunctionPass`` is also a ``FunctionPass``, so all the restrictions; that apply to a ``FunctionPass`` also apply to it. ``MachineFunctionPass``\ es; also have addition",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:24823,Integrability,depend,dependent,24823,"be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; ---------------------------------. A ``MachineFunctionPass`` is a part of the LLVM code generator that executes on; the machine-dependent representation of each LLVM function in the program. Code generator passes are registered and initialized specially by; ``TargetMachine::addPassesToEmitFile`` and similar routines, so they cannot; generally be run from the :program:`opt` or :program:`bugpoint` commands. A ``MachineFunctionPass`` is also a ``FunctionPass``, so all the restrictions; that apply to a ``FunctionPass`` also apply to it. ``MachineFunctionPass``\ es; also have additional restrictions. In particular, ``MachineFunctionPass``\ es; are not allowed to do any of the following:. #. Modify or create any LLVM IR ``Instruction``\ s, ``BasicBlock``\ s,; ``Argument``\ s, ``Function``\ s, ``GlobalVariable``\ s,; ``GlobalAlias``\ es, or ``Module``\ s.; #. Modify a ``MachineFunction`` other than the one currently being processed.; #. Maintain state across invocations of :ref:`runOnMachineFunction; <writing-an-llvm-pass-runOnMachineFunction>` (including global data). .. _writing-an-llvm-pass-runOnMac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:25004,Integrability,rout,routines,25004,". virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; ---------------------------------. A ``MachineFunctionPass`` is a part of the LLVM code generator that executes on; the machine-dependent representation of each LLVM function in the program. Code generator passes are registered and initialized specially by; ``TargetMachine::addPassesToEmitFile`` and similar routines, so they cannot; generally be run from the :program:`opt` or :program:`bugpoint` commands. A ``MachineFunctionPass`` is also a ``FunctionPass``, so all the restrictions; that apply to a ``FunctionPass`` also apply to it. ``MachineFunctionPass``\ es; also have additional restrictions. In particular, ``MachineFunctionPass``\ es; are not allowed to do any of the following:. #. Modify or create any LLVM IR ``Instruction``\ s, ``BasicBlock``\ s,; ``Argument``\ s, ``Function``\ s, ``GlobalVariable``\ s,; ``GlobalAlias``\ es, or ``Module``\ s.; #. Modify a ``MachineFunction`` other than the one currently being processed.; #. Maintain state across invocations of :ref:`runOnMachineFunction; <writing-an-llvm-pass-runOnMachineFunction>` (including global data). .. _writing-an-llvm-pass-runOnMachineFunction:. The ``runOnMachineFunction(MachineFunction &MF)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnMachineFunction(M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:26376,Integrability,depend,dependent,26376,"r, ``MachineFunctionPass``\ es; are not allowed to do any of the following:. #. Modify or create any LLVM IR ``Instruction``\ s, ``BasicBlock``\ s,; ``Argument``\ s, ``Function``\ s, ``GlobalVariable``\ s,; ``GlobalAlias``\ es, or ``Module``\ s.; #. Modify a ``MachineFunction`` other than the one currently being processed.; #. Maintain state across invocations of :ref:`runOnMachineFunction; <writing-an-llvm-pass-runOnMachineFunction>` (including global data). .. _writing-an-llvm-pass-runOnMachineFunction:. The ``runOnMachineFunction(MachineFunction &MF)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnMachineFunction(MachineFunction &MF) = 0;. ``runOnMachineFunction`` can be considered the main entry point of a; ``MachineFunctionPass``; that is, you should override this method to do the; work of your ``MachineFunctionPass``. The ``runOnMachineFunction`` method is called on every ``MachineFunction`` in a; ``Module``, so that the ``MachineFunctionPass`` may perform optimizations on; the machine-dependent representation of the function. If you want to get at; the LLVM ``Function`` for the ``MachineFunction`` you're working on, use; ``MachineFunction``'s ``getFunction()`` accessor method --- but remember, you; may not modify the LLVM ``Function`` or its contents from a; ``MachineFunctionPass``. .. _writing-an-llvm-pass-registration:. Pass registration; -----------------. In the :ref:`Hello World <writing-an-llvm-pass-basiccode>` example pass we; illustrated how pass registration works, and discussed some of the reasons that; it is used and what it does. Here we discuss how and why passes are; registered. As we saw above, passes are registered with the ``RegisterPass`` template. The; template parameter is the name of the pass that is to be used on the command; line to specify that the pass should be added to a program (for example, with; :program:`opt` or :program:`bugpoint`). The first argument is the name of the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:28364,Integrability,depend,depended,28364,"). The first argument is the name of the; pass, which is to be used for the :option:`-help` output of programs, as well; as for debug output generated by the `--debug-pass` option. If you want your pass to be easily dumpable, you should implement the virtual; print method:. The ``print`` method; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void print(llvm::raw_ostream &O, const Module *M) const;. The ``print`` method must be implemented by ""analyses"" in order to print a; human readable version of the analysis results. This is useful for debugging; an analysis itself, as well as for other people to figure out how an analysis; works. Use the opt ``-analyze`` argument to invoke this method. The ``llvm::raw_ostream`` parameter specifies the stream to write the results; on, and the ``Module`` parameter gives a pointer to the top level module of the; program that has been analyzed. Note however that this pointer may be ``NULL``; in certain circumstances (such as calling the ``Pass::dump()`` from a; debugger), so it should only be used to enhance debug output, it should not be; depended on. .. _writing-an-llvm-pass-interaction:. Specifying interactions between passes; --------------------------------------. One of the main responsibilities of the ``PassManager`` is to make sure that; passes interact with each other correctly. Because ``PassManager`` tries to; :ref:`optimize the execution of passes <writing-an-llvm-pass-passmanager>` it; must know how the passes interact with each other and what dependencies exist; between the various passes. To track this, each pass can declare the set of; passes that are required to be executed before the current pass, and the passes; which are invalidated by the current pass. Typically this functionality is used to require that analysis results are; computed before your pass is run. Running arbitrary transformation passes can; invalidate the computed analysis results, which is what the invalidation set; specifies. If a pass does no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:28789,Integrability,depend,dependencies,28789,"ses"" in order to print a; human readable version of the analysis results. This is useful for debugging; an analysis itself, as well as for other people to figure out how an analysis; works. Use the opt ``-analyze`` argument to invoke this method. The ``llvm::raw_ostream`` parameter specifies the stream to write the results; on, and the ``Module`` parameter gives a pointer to the top level module of the; program that has been analyzed. Note however that this pointer may be ``NULL``; in certain circumstances (such as calling the ``Pass::dump()`` from a; debugger), so it should only be used to enhance debug output, it should not be; depended on. .. _writing-an-llvm-pass-interaction:. Specifying interactions between passes; --------------------------------------. One of the main responsibilities of the ``PassManager`` is to make sure that; passes interact with each other correctly. Because ``PassManager`` tries to; :ref:`optimize the execution of passes <writing-an-llvm-pass-passmanager>` it; must know how the passes interact with each other and what dependencies exist; between the various passes. To track this, each pass can declare the set of; passes that are required to be executed before the current pass, and the passes; which are invalidated by the current pass. Typically this functionality is used to require that analysis results are; computed before your pass is run. Running arbitrary transformation passes can; invalidate the computed analysis results, which is what the invalidation set; specifies. If a pass does not implement the :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` method, it defaults to not having any; prerequisite passes, and invalidating **all** other passes. .. _writing-an-llvm-pass-getAnalysisUsage:. The ``getAnalysisUsage`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void getAnalysisUsage(AnalysisUsage &Info) const;. By implementing the ``getAnalysisUsage`` method, the required and invalidated; sets ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:33864,Integrability,interface,interface,33864,"; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &LI = getAnalysis<LoopInfoWrapperPass>().getLoopInfo();; //...; }. This method call returns a reference to the pass desired. You may get a; runtime assertion failure if you attempt to get an analysis that you did not; declare as required in your :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` implementation. This method can be; called by your ``run*`` method implementation, or by any other local method; invoked by your ``run*`` method. A module level pass can use function level analysis info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func);; //...; }. In above example, ``runOnFunction`` for ``DominatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Analysis Groups; ----------------------------. Now that we understand the basics of how passes are defined, how they are used,; and how they are required from other passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are ve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:34856,Integrability,depend,depends,34856,"s info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func);; //...; }. In above example, ``runOnFunction`` for ``DominatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Analysis Groups; ----------------------------. Now that we understand the basics of how passes are defined, how they are used,; and how they are required from other passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:35079,Integrability,interface,interface,35079,"inatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Analysis Groups; ----------------------------. Now that we understand the basics of how passes are defined, how they are used,; and how they are required from other passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:35708,Integrability,interface,interface,35708,"ther passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes are: the; ``AnalysisUsage::addRequired()`` and ``Pass::getAnalysis()`` methods. In order; to resolve this requirement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`IN",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:36866,Integrability,interface,interface,36866,"ass. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes are: the; ``AnalysisUsage::addRequired()`` and ``Pass::getAnalysis()`` methods. In order; to resolve this requirement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass); just does a few simple checks that don't require significant analysis to; compute (such as: two different globals can never alias each other, etc).; Passes that use the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ interface (for; example the `gvn <https://llvm.org/doxygen/classllvm_1_1GVN.html>`_ pass), do not; care which implementation of alias analysis is actually provided, they just use; the designated interface. From the user's perspective, commands work just like normal. Issuing the; command ``opt -gvn ...`` will cause the ``basic-aa`` class to be instantiated; and added to the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:37191,Integrability,interface,interface,37191,"irement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass); just does a few simple checks that don't require significant analysis to; compute (such as: two different globals can never alias each other, etc).; Passes that use the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ interface (for; example the `gvn <https://llvm.org/doxygen/classllvm_1_1GVN.html>`_ pass), do not; care which implementation of alias analysis is actually provided, they just use; the designated interface. From the user's perspective, commands work just like normal. Issuing the; command ``opt -gvn ...`` will cause the ``basic-aa`` class to be instantiated; and added to the pass sequence. Issuing the command ``opt -somefancyaa -gvn; ...`` will cause the ``gvn`` pass to use the ``somefancyaa`` alias analysis; (which doesn't actually exist, it's just a hypothetical example) instead. .. _writing-an-llvm-pass-RegisterAnalysisGroup:. Using ``RegisterAnaly",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:37529,Integrability,interface,interface,37529,"ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass); just does a few simple checks that don't require significant analysis to; compute (such as: two different globals can never alias each other, etc).; Passes that use the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ interface (for; example the `gvn <https://llvm.org/doxygen/classllvm_1_1GVN.html>`_ pass), do not; care which implementation of alias analysis is actually provided, they just use; the designated interface. From the user's perspective, commands work just like normal. Issuing the; command ``opt -gvn ...`` will cause the ``basic-aa`` class to be instantiated; and added to the pass sequence. Issuing the command ``opt -somefancyaa -gvn; ...`` will cause the ``gvn`` pass to use the ``somefancyaa`` alias analysis; (which doesn't actually exist, it's just a hypothetical example) instead. .. _writing-an-llvm-pass-RegisterAnalysisGroup:. Using ``RegisterAnalysisGroup``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``RegisterAnalysisGroup`` template is used to register the analysis group; itself, while the ``INITIALIZE_AG_PASS`` is used to add pass implementations to; the analysis group. First, an analysis group should be registered, with a; human readable name provided for it. Unlike registration of passes, there is; no co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:37724,Integrability,interface,interface,37724,"tions must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass); just does a few simple checks that don't require significant analysis to; compute (such as: two different globals can never alias each other, etc).; Passes that use the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ interface (for; example the `gvn <https://llvm.org/doxygen/classllvm_1_1GVN.html>`_ pass), do not; care which implementation of alias analysis is actually provided, they just use; the designated interface. From the user's perspective, commands work just like normal. Issuing the; command ``opt -gvn ...`` will cause the ``basic-aa`` class to be instantiated; and added to the pass sequence. Issuing the command ``opt -somefancyaa -gvn; ...`` will cause the ``gvn`` pass to use the ``somefancyaa`` alias analysis; (which doesn't actually exist, it's just a hypothetical example) instead. .. _writing-an-llvm-pass-RegisterAnalysisGroup:. Using ``RegisterAnalysisGroup``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``RegisterAnalysisGroup`` template is used to register the analysis group; itself, while the ``INITIALIZE_AG_PASS`` is used to add pass implementations to; the analysis group. First, an analysis group should be registered, with a; human readable name provided for it. Unlike registration of passes, there is; no command line argument to be specified for the Analysis Group Interface; itself, because it is ""abstract"":. .. code-block:: ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:38837,Integrability,interface,interface,38837," command ``opt -gvn ...`` will cause the ``basic-aa`` class to be instantiated; and added to the pass sequence. Issuing the command ``opt -somefancyaa -gvn; ...`` will cause the ``gvn`` pass to use the ``somefancyaa`` alias analysis; (which doesn't actually exist, it's just a hypothetical example) instead. .. _writing-an-llvm-pass-RegisterAnalysisGroup:. Using ``RegisterAnalysisGroup``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``RegisterAnalysisGroup`` template is used to register the analysis group; itself, while the ``INITIALIZE_AG_PASS`` is used to add pass implementations to; the analysis group. First, an analysis group should be registered, with a; human readable name provided for it. Unlike registration of passes, there is; no command line argument to be specified for the Analysis Group Interface; itself, because it is ""abstract"":. .. code-block:: c++. static RegisterAnalysisGroup<AliasAnalysis> A(""Alias Analysis"");. Once the analysis is registered, passes can declare that they are valid; implementations of the interface by using the following code:. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(FancyAA, AliasAnalysis , ""somefancyaa"",; ""A more complex alias analysis implementation"",; false, // Is CFG Only?; true, // Is Analysis?; false); // Is default Analysis Group implementation?; }. This just shows a class ``FancyAA`` that uses the ``INITIALIZE_AG_PASS`` macro; both to register and to ""join"" the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ analysis group.; Every implementation of an analysis group should join using this macro. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(BasicAA, AliasAnalysis, ""basic-aa"",; ""Basic Alias Analysis (default AA impl)"",; false, // Is CFG Only?; true, // Is Analysis?; true); // Is default Analysis Group implementation?; }. Here we show how the default implementation is spec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:38958,Integrability,interface,interface,38958,"s; (which doesn't actually exist, it's just a hypothetical example) instead. .. _writing-an-llvm-pass-RegisterAnalysisGroup:. Using ``RegisterAnalysisGroup``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``RegisterAnalysisGroup`` template is used to register the analysis group; itself, while the ``INITIALIZE_AG_PASS`` is used to add pass implementations to; the analysis group. First, an analysis group should be registered, with a; human readable name provided for it. Unlike registration of passes, there is; no command line argument to be specified for the Analysis Group Interface; itself, because it is ""abstract"":. .. code-block:: c++. static RegisterAnalysisGroup<AliasAnalysis> A(""Alias Analysis"");. Once the analysis is registered, passes can declare that they are valid; implementations of the interface by using the following code:. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(FancyAA, AliasAnalysis , ""somefancyaa"",; ""A more complex alias analysis implementation"",; false, // Is CFG Only?; true, // Is Analysis?; false); // Is default Analysis Group implementation?; }. This just shows a class ``FancyAA`` that uses the ``INITIALIZE_AG_PASS`` macro; both to register and to ""join"" the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ analysis group.; Every implementation of an analysis group should join using this macro. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(BasicAA, AliasAnalysis, ""basic-aa"",; ""Basic Alias Analysis (default AA impl)"",; false, // Is CFG Only?; true, // Is Analysis?; true); // Is default Analysis Group implementation?; }. Here we show how the default implementation is specified (using the final; argument to the ``INITIALIZE_AG_PASS`` template). There must be exactly one; default implementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``Imm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:39544,Integrability,interface,interface,39544,"itself, because it is ""abstract"":. .. code-block:: c++. static RegisterAnalysisGroup<AliasAnalysis> A(""Alias Analysis"");. Once the analysis is registered, passes can declare that they are valid; implementations of the interface by using the following code:. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(FancyAA, AliasAnalysis , ""somefancyaa"",; ""A more complex alias analysis implementation"",; false, // Is CFG Only?; true, // Is Analysis?; false); // Is default Analysis Group implementation?; }. This just shows a class ``FancyAA`` that uses the ``INITIALIZE_AG_PASS`` macro; both to register and to ""join"" the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ analysis group.; Every implementation of an analysis group should join using this macro. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(BasicAA, AliasAnalysis, ""basic-aa"",; ""Basic Alias Analysis (default AA impl)"",; false, // Is CFG Only?; true, // Is Analysis?; true); // Is default Analysis Group implementation?; }. Here we show how the default implementation is specified (using the final; argument to the ``INITIALIZE_AG_PASS`` template). There must be exactly one; default implementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. ..",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:40203,Integrability,interface,interface,40203,"This just shows a class ``FancyAA`` that uses the ``INITIALIZE_AG_PASS`` macro; both to register and to ""join"" the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ analysis group.; Every implementation of an analysis group should join using this macro. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(BasicAA, AliasAnalysis, ""basic-aa"",; ""Basic Alias Analysis (default AA impl)"",; false, // Is CFG Only?; true, // Is Analysis?; true); // Is default Analysis Group implementation?; }. Here we show how the default implementation is specified (using the final; argument to the ``INITIALIZE_AG_PASS`` template). There must be exactly one; default implementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:48675,Integrability,interface,interface,48675," the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` fil",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:52536,Integrability,depend,depends,52536,"y is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator. Using GDB with dynamically loaded passes; ----------------------------------------. Unfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:713,Modifiability,inherit,inherited,713,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM Pass Framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:784,Modifiability,inherit,inherit,784,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM Pass Framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:2482,Modifiability,config,configure,2482,"etting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; copy the following into ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_library( LLVMHello MODULE; Hello.cpp. PLUGIN_TOOL; opt; ). and the following line into ``lib/Transforms/CMakeLists.txt``:. .. code-block:: cmake. add_subdirectory(Hello). (Note that there is already a directory named ``Hello`` with a sample ""Hello""; pass; you may play with it -- in which case you don't need to modify any; ``CMakeLists.txt`` files -- or, if you want to create everything from scratch,; use another name.). This build script specifies that ``Hello.cpp`` file in the current directory; is to be compiled and linked into a shared object ``$(LEVEL)/lib/LLVMHello.so`` that; can be dynamically loaded by the :program:`opt` tool via its :o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:5700,Modifiability,inherit,inherited,5700,"e current file.; If you're not familiar with them, consult a decent C++ book for more; information. Next, we declare our pass itself:. .. code-block:: c++. struct Hello : public FunctionPass {. This declares a ""``Hello``"" class that is a subclass of :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. The different builtin pass subclasses; are described in detail :ref:`later <writing-an-llvm-pass-pass-classes>`, but; for now, know that ``FunctionPass`` operates on a function at a time. .. code-block:: c++. static char ID;; Hello() : FunctionPass(ID) {}. This declares pass identifier used by LLVM to identify pass. This allows LLVM; to avoid using expensive C++ runtime information. .. code-block:: c++. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. We declare a :ref:`runOnFunction <writing-an-llvm-pass-runOnFunction>` method,; which overrides an abstract virtual method inherited from :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. This is where we are supposed to do our; thing, so we just print out our message with the name of each function. .. code-block:: c++. char Hello::ID = 0;. We initialize pass ID here. LLVM uses ID's address to identify a pass, so; initialization value is not important. .. code-block:: c++. static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Lastly, we :ref:`register our class <writing-an-llvm-pass-registration>`; ``Hello``, giving it a command line argument ""``hello``"", and a name ""Hello; World Pass"". The last two arguments describe its behavior: if a pass walks CFG; without modifying it then the third argument is set to ``true``; if a pass is; an analysis pass, for example dominator tree pass, then ``true`` is supplied as; the fourth argument. As a whole, the ``.cpp`` file looks like:. .. code-block:: c++. #include ""llvm/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:12275,Modifiability,config,configuration,12275," for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:15297,Modifiability,variab,variables,15297,"e the program bottom-up on the call graph (callees; before callers). Deriving from ``CallGraphSCCPass`` provides some mechanics; for building and traversing the ``CallGraph``, but also allows the system to; optimize execution of ``CallGraphSCCPass``\ es. If your pass meets the; requirements outlined below, and doesn't meet the requirements of a; :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, you should derive from; ``CallGraphSCCPass``. ``TODO``: explain briefly what SCC, Tarjan's algo, and B-U mean. To be explicit, CallGraphSCCPass subclasses are:. #. ... *not allowed* to inspect or modify any ``Function``\ s other than those; in the current SCC and the direct callers and direct callees of the SCC.; #. ... *required* to preserve the current ``CallGraph`` object, updating it to; reflect any changes made to the program.; #. ... *not allowed* to add or remove SCC's from the current Module, though; they may change the contents of an SCC.; #. ... *allowed* to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global data). Implementing a ``CallGraphSCCPass`` is slightly tricky in some cases because it; has to handle SCCs with more than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:17819,Modifiability,variab,variables,17819,"zation`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, local behavior that can be expected by the system. All; ``FunctionPass`` execute on each function in the program independent of all of; the other functions in the program. ``FunctionPass``\ es do not require that; they are executed in a particular order, and ``FunctionPass``\ es do not modify; external functions. To be explicit, ``FunctionPass`` subclasses are not allowed to:. #. Inspect or modify a ``Function`` other than the one currently being processed.; #. Add or remove ``Function``\ s from the current ``Module``.; #. Add or remove global variables from the current ``Module``.; #. Maintain state across invocations of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:28324,Modifiability,enhance,enhance,28324,"). The first argument is the name of the; pass, which is to be used for the :option:`-help` output of programs, as well; as for debug output generated by the `--debug-pass` option. If you want your pass to be easily dumpable, you should implement the virtual; print method:. The ``print`` method; ^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void print(llvm::raw_ostream &O, const Module *M) const;. The ``print`` method must be implemented by ""analyses"" in order to print a; human readable version of the analysis results. This is useful for debugging; an analysis itself, as well as for other people to figure out how an analysis; works. Use the opt ``-analyze`` argument to invoke this method. The ``llvm::raw_ostream`` parameter specifies the stream to write the results; on, and the ``Module`` parameter gives a pointer to the top level module of the; program that has been analyzed. Note however that this pointer may be ``NULL``; in certain circumstances (such as calling the ``Pass::dump()`` from a; debugger), so it should only be used to enhance debug output, it should not be; depended on. .. _writing-an-llvm-pass-interaction:. Specifying interactions between passes; --------------------------------------. One of the main responsibilities of the ``PassManager`` is to make sure that; passes interact with each other correctly. Because ``PassManager`` tries to; :ref:`optimize the execution of passes <writing-an-llvm-pass-passmanager>` it; must know how the passes interact with each other and what dependencies exist; between the various passes. To track this, each pass can declare the set of; passes that are required to be executed before the current pass, and the passes; which are invalidated by the current pass. Typically this functionality is used to require that analysis results are; computed before your pass is run. Running arbitrary transformation passes can; invalidate the computed analysis results, which is what the invalidation set; specifies. If a pass does no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:32952,Modifiability,inherit,inherited,32952,"setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses if they exist, so it can preserve them, despite the; fact that it hacks on the CFG. Example implementations of ``getAnalysisUsage``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. // This example modifies the program, but does not modify the CFG; void LICM::getAnalysisUsage(AnalysisUsage &AU) const {; AU.setPreservesCFG();; AU.addRequired<LoopInfoWrapperPass>();; }. .. _writing-an-llvm-pass-getAnalysis:. The ``getAnalysis<>`` and ``getAnalysisIfAvailable<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &LI = getAnalysis<LoopInfoWrapperPass>().getLoopInfo();; //...; }. This method call returns a reference to the pass desired. You may get a; runtime assertion failure if you attempt to get an analysis that you did not; declare as required in your :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` implementation. This method can be; called by your ``run*`` method implementation, or by any other local method; invoked by your ``run*`` method. A module level pass can use function level analysis info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:48192,Modifiability,config,configurations,48192,"object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53063,Modifiability,config,configured,53063,"nfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:333,Performance,perform,perform,333,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM Pass Framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:365,Performance,optimiz,optimizations,365,"====================; Writing an LLVM Pass; ====================. .. program:: opt. .. contents::; :local:. Introduction --- What is a pass?; ================================. The LLVM Pass Framework is an important part of the LLVM system, because LLVM; passes are where most of the interesting parts of the compiler exist. Passes; perform the transformations and optimizations that make up the compiler, they; build the analysis results that are used by these transformations, and they; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1525,Performance,load,loading,1525,"; are, above all, a structuring technique for compiler code. All LLVM passes are subclasses of the `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ class, which implement; functionality by overriding virtual methods inherited from ``Pass``. Depending; on how your pass works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, confi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:1722,Performance,optimiz,optimization,1722,"ss works, you should inherit from the :ref:`ModulePass; <writing-an-llvm-pass-ModulePass>` , :ref:`CallGraphSCCPass; <writing-an-llvm-pass-CallGraphSCCPass>`, :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` , or :ref:`LoopPass; <writing-an-llvm-pass-LoopPass>`, or :ref:`RegionPass; <writing-an-llvm-pass-RegionPass>` classes, which gives the system more; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:3447,Performance,load,loaded,3447,"--------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; copy the following into ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_library( LLVMHello MODULE; Hello.cpp. PLUGIN_TOOL; opt; ). and the following line into ``lib/Transforms/CMakeLists.txt``:. .. code-block:: cmake. add_subdirectory(Hello). (Note that there is already a directory named ``Hello`` with a sample ""Hello""; pass; you may play with it -- in which case you don't need to modify any; ``CMakeLists.txt`` files -- or, if you want to create everything from scratch,; use another name.). This build script specifies that ``Hello.cpp`` file in the current directory; is to be compiled and linked into a shared object ``$(LEVEL)/lib/LLVMHello.so`` that; can be dynamically loaded by the :program:`opt` tool via its :option:`-load`; option. If your operating system uses a suffix other than ``.so`` (such as; Windows or macOS), the appropriate extension will be used. Now that we have the build scripts set up, we just need to write the code for; the pass itself. .. _writing-an-llvm-pass-basiccode:. Basic code required; -------------------. Now that we have a way to compile our new pass, we just have to write it.; Start out with:. .. code-block:: c++. #include ""llvm/Pass.h""; #include ""llvm/IR/Function.h""; #include ""llvm/Support/raw_ostream.h"". Which are needed because we are writing a `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_, we are operating on; `Function <https://llvm.org/doxygen/classllvm_1_1Function.html>`_\ s, and we will; be doing some printing. Next we have:. .. code-block:: c++. using namespace llvm;. ... which is required because the functions from the include files live in the; llvm namespace. Next we have:. .. code-block:: c++. namespace {. ... whic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:3499,Performance,load,load,3499,"--------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; copy the following into ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_library( LLVMHello MODULE; Hello.cpp. PLUGIN_TOOL; opt; ). and the following line into ``lib/Transforms/CMakeLists.txt``:. .. code-block:: cmake. add_subdirectory(Hello). (Note that there is already a directory named ``Hello`` with a sample ""Hello""; pass; you may play with it -- in which case you don't need to modify any; ``CMakeLists.txt`` files -- or, if you want to create everything from scratch,; use another name.). This build script specifies that ``Hello.cpp`` file in the current directory; is to be compiled and linked into a shared object ``$(LEVEL)/lib/LLVMHello.so`` that; can be dynamically loaded by the :program:`opt` tool via its :option:`-load`; option. If your operating system uses a suffix other than ``.so`` (such as; Windows or macOS), the appropriate extension will be used. Now that we have the build scripts set up, we just need to write the code for; the pass itself. .. _writing-an-llvm-pass-basiccode:. Basic code required; -------------------. Now that we have a way to compile our new pass, we just have to write it.; Start out with:. .. code-block:: c++. #include ""llvm/Pass.h""; #include ""llvm/IR/Function.h""; #include ""llvm/Support/raw_ostream.h"". Which are needed because we are writing a `Pass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_, we are operating on; `Function <https://llvm.org/doxygen/classllvm_1_1Function.html>`_\ s, and we will; be doing some printing. Next we have:. .. code-block:: c++. using namespace llvm;. ... which is required because the functions from the include files live in the; llvm namespace. Next we have:. .. code-block:: c++. namespace {. ... whic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:7963,Performance,load,loaded,7963,"ass(ID) {}. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. char Hello::ID = 0;; static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Now that it's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8249,Performance,load,load,8249,"t's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8357,Performance,load,load,8357," in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8407,Performance,load,load,8407," in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8904,Performance,load,load,8904,"le to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:8967,Performance,optimiz,optimizer,8967,"t it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello -time-passes ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:9879,Performance,queue,queue,9879,"ened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello -time-passes < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main; ===-------------------------------------------------------------------------===; ... Pass execution timing report ...; ===-------------------------------------------------------------------------===; Total Execution Time: 0.0007 seconds (0.0005 wall clock). ---User Time--- --User+System-- ---Wall Time--- --- Name ---; 0.0004 ( 55.3%) 0.0004 ( 55.3%) 0.0004 ( 75.7%) Bitcode Writer; 0.0003 ( 44.7%) 0.0003 ( 44.7%) 0.0001 ( 13.6%) Hello World Pass; 0.0000 ( 0.0%) 0.0000 ( 0.0%) 0.0001 ( 10.7%) Module Verifier; 0.0007 (100.0%) 0.0007 (100.0%) 0.0005 (100.0%) Total. As you can see, our implementation above is pretty fast. The additional; passes listed are automatically inserted by the :program:`opt` tool to verify; that the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:9935,Performance,load,load,9935,"W: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello -time-passes < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main; ===-------------------------------------------------------------------------===; ... Pass execution timing report ...; ===-------------------------------------------------------------------------===; Total Execution Time: 0.0007 seconds (0.0005 wall clock). ---User Time--- --User+System-- ---Wall Time--- --- Name ---; 0.0004 ( 55.3%) 0.0004 ( 55.3%) 0.0004 ( 75.7%) Bitcode Writer; 0.0003 ( 44.7%) 0.0003 ( 44.7%) 0.0001 ( 13.6%) Hello World Pass; 0.0000 ( 0.0%) 0.0000 ( 0.0%) 0.0001 ( 10.7%) Module Verifier; 0.0007 (100.0%) 0.0007 (100.0%) 0.0005 (100.0%) Total. As you can see, our implementation above is pretty fast. The additional; passes listed are automatically inserted by the :program:`opt` tool to verify; that the LLVM emitted by your pass is still valid and well formed LLVM, which; hasn't been broken somehow. Now that you have seen the basics of the mechanics behind passes, we can",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:11770,Performance,optimiz,optimize,11770,"tted by your pass is still valid and well formed LLVM, which; hasn't been broken somehow. Now that you have seen the basics of the mechanics behind passes, we can talk; about some more details of how they work and how to use them. .. _writing-an-llvm-pass-pass-classes:. Pass classes and requirements; =============================. One of the first things that you should do when designing a new pass is to; decide what class you should subclass for your pass. The :ref:`Hello World; <writing-an-llvm-pass-basiccode>` example uses the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` class for its implementation, but we did; not discuss why or when this should occur. Here we talk about the classes; available, from the most general to the most specific. When choosing a superclass for your ``Pass``, you should choose the **most; specific** class possible, while still being able to meet the requirements; listed. This gives the LLVM Pass Infrastructure information necessary to; optimize how passes are run, so that the resultant compiler isn't unnecessarily; slow. The ``ImmutablePass`` class; ---------------------------. The most plain and boring type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:13107,Performance,optimiz,optimization,13107,"not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the; ``getAnalysis`` interface ``getAnalysis<DominatorTree>(llvm::Function *)`` to; provide the function to retrieve analysis result for, if the function pass does; not require any module or immutable passes. Note that this can only be done; for functions for which the analysis ran, e.g. in the case of dominators you; should only ask for the ``DominatorTree`` for function definitions, not; declarations. To write a correct ``ModulePass`` subclass, derive from ``ModulePass`` and; override the ``runOnModule`` method with the following signature:. The ``runOnModule`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnModule(Module &M) = 0;. The ``runOnModule`` method performs the interesting work of the pass. It; should return ``true`` if the module was modified by the transformation and; ``false`` otherwise. .. _writing-an-llvm-pass-Cal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:13917,Performance,perform,performs,13917,"ram as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the; ``getAnalysis`` interface ``getAnalysis<DominatorTree>(llvm::Function *)`` to; provide the function to retrieve analysis result for, if the function pass does; not require any module or immutable passes. Note that this can only be done; for functions for which the analysis ran, e.g. in the case of dominators you; should only ask for the ``DominatorTree`` for function definitions, not; declarations. To write a correct ``ModulePass`` subclass, derive from ``ModulePass`` and; override the ``runOnModule`` method with the following signature:. The ``runOnModule`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnModule(Module &M) = 0;. The ``runOnModule`` method performs the interesting work of the pass. It; should return ``true`` if the module was modified by the transformation and; ``false`` otherwise. .. _writing-an-llvm-pass-CallGraphSCCPass:. The ``CallGraphSCCPass`` class; ------------------------------. The `CallGraphSCCPass; <https://llvm.org/doxygen/classllvm_1_1CallGraphSCCPass.html>`_ is used by; passes that need to traverse the program bottom-up on the call graph (callees; before callers). Deriving from ``CallGraphSCCPass`` provides some mechanics; for building and traversing the ``CallGraph``, but also allows the system to; optimize execution of ``CallGraphSCCPass``\ es. If your pass meets the; requirements outlined below, and doesn't meet the requirements of a; :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, you should derive from; ``CallGraphSCCPass``. ``TODO``: explain briefly what SCC, Tarjan's algo, and B-U mean. To be explicit, CallGraphSCCPass subclasses are:. #. ... *not allowed* to inspect or modify any ``Function``\ s ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:14503,Performance,optimiz,optimize,14503,"done; for functions for which the analysis ran, e.g. in the case of dominators you; should only ask for the ``DominatorTree`` for function definitions, not; declarations. To write a correct ``ModulePass`` subclass, derive from ``ModulePass`` and; override the ``runOnModule`` method with the following signature:. The ``runOnModule`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnModule(Module &M) = 0;. The ``runOnModule`` method performs the interesting work of the pass. It; should return ``true`` if the module was modified by the transformation and; ``false`` otherwise. .. _writing-an-llvm-pass-CallGraphSCCPass:. The ``CallGraphSCCPass`` class; ------------------------------. The `CallGraphSCCPass; <https://llvm.org/doxygen/classllvm_1_1CallGraphSCCPass.html>`_ is used by; passes that need to traverse the program bottom-up on the call graph (callees; before callers). Deriving from ``CallGraphSCCPass`` provides some mechanics; for building and traversing the ``CallGraph``, but also allows the system to; optimize execution of ``CallGraphSCCPass``\ es. If your pass meets the; requirements outlined below, and doesn't meet the requirements of a; :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, you should derive from; ``CallGraphSCCPass``. ``TODO``: explain briefly what SCC, Tarjan's algo, and B-U mean. To be explicit, CallGraphSCCPass subclasses are:. #. ... *not allowed* to inspect or modify any ``Function``\ s other than those; in the current SCC and the direct callers and direct callees of the SCC.; #. ... *required* to preserve the current ``CallGraph`` object, updating it to; reflect any changes made to the program.; #. ... *not allowed* to add or remove SCC's from the current Module, though; they may change the contents of an SCC.; #. ... *allowed* to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16516,Performance,perform,performs,16516,"than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, local behavior that can be expected by the system. All; ``FunctionPass`` execute on each function in the program independent of all of; the other functions in the program. ``FunctionPass``\ es do not require that; they are executed in a particular order, and ``FunctionPass``\ es do not modify; external fu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:26338,Performance,perform,perform,26338,"r, ``MachineFunctionPass``\ es; are not allowed to do any of the following:. #. Modify or create any LLVM IR ``Instruction``\ s, ``BasicBlock``\ s,; ``Argument``\ s, ``Function``\ s, ``GlobalVariable``\ s,; ``GlobalAlias``\ es, or ``Module``\ s.; #. Modify a ``MachineFunction`` other than the one currently being processed.; #. Maintain state across invocations of :ref:`runOnMachineFunction; <writing-an-llvm-pass-runOnMachineFunction>` (including global data). .. _writing-an-llvm-pass-runOnMachineFunction:. The ``runOnMachineFunction(MachineFunction &MF)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnMachineFunction(MachineFunction &MF) = 0;. ``runOnMachineFunction`` can be considered the main entry point of a; ``MachineFunctionPass``; that is, you should override this method to do the; work of your ``MachineFunctionPass``. The ``runOnMachineFunction`` method is called on every ``MachineFunction`` in a; ``Module``, so that the ``MachineFunctionPass`` may perform optimizations on; the machine-dependent representation of the function. If you want to get at; the LLVM ``Function`` for the ``MachineFunction`` you're working on, use; ``MachineFunction``'s ``getFunction()`` accessor method --- but remember, you; may not modify the LLVM ``Function`` or its contents from a; ``MachineFunctionPass``. .. _writing-an-llvm-pass-registration:. Pass registration; -----------------. In the :ref:`Hello World <writing-an-llvm-pass-basiccode>` example pass we; illustrated how pass registration works, and discussed some of the reasons that; it is used and what it does. Here we discuss how and why passes are; registered. As we saw above, passes are registered with the ``RegisterPass`` template. The; template parameter is the name of the pass that is to be used on the command; line to specify that the pass should be added to a program (for example, with; :program:`opt` or :program:`bugpoint`). The first argument is the name of the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:26346,Performance,optimiz,optimizations,26346,"r, ``MachineFunctionPass``\ es; are not allowed to do any of the following:. #. Modify or create any LLVM IR ``Instruction``\ s, ``BasicBlock``\ s,; ``Argument``\ s, ``Function``\ s, ``GlobalVariable``\ s,; ``GlobalAlias``\ es, or ``Module``\ s.; #. Modify a ``MachineFunction`` other than the one currently being processed.; #. Maintain state across invocations of :ref:`runOnMachineFunction; <writing-an-llvm-pass-runOnMachineFunction>` (including global data). .. _writing-an-llvm-pass-runOnMachineFunction:. The ``runOnMachineFunction(MachineFunction &MF)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnMachineFunction(MachineFunction &MF) = 0;. ``runOnMachineFunction`` can be considered the main entry point of a; ``MachineFunctionPass``; that is, you should override this method to do the; work of your ``MachineFunctionPass``. The ``runOnMachineFunction`` method is called on every ``MachineFunction`` in a; ``Module``, so that the ``MachineFunctionPass`` may perform optimizations on; the machine-dependent representation of the function. If you want to get at; the LLVM ``Function`` for the ``MachineFunction`` you're working on, use; ``MachineFunction``'s ``getFunction()`` accessor method --- but remember, you; may not modify the LLVM ``Function`` or its contents from a; ``MachineFunctionPass``. .. _writing-an-llvm-pass-registration:. Pass registration; -----------------. In the :ref:`Hello World <writing-an-llvm-pass-basiccode>` example pass we; illustrated how pass registration works, and discussed some of the reasons that; it is used and what it does. Here we discuss how and why passes are; registered. As we saw above, passes are registered with the ``RegisterPass`` template. The; template parameter is the name of the pass that is to be used on the command; line to specify that the pass should be added to a program (for example, with; :program:`opt` or :program:`bugpoint`). The first argument is the name of the;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:28657,Performance,optimiz,optimize,28657,"ses"" in order to print a; human readable version of the analysis results. This is useful for debugging; an analysis itself, as well as for other people to figure out how an analysis; works. Use the opt ``-analyze`` argument to invoke this method. The ``llvm::raw_ostream`` parameter specifies the stream to write the results; on, and the ``Module`` parameter gives a pointer to the top level module of the; program that has been analyzed. Note however that this pointer may be ``NULL``; in certain circumstances (such as calling the ``Pass::dump()`` from a; debugger), so it should only be used to enhance debug output, it should not be; depended on. .. _writing-an-llvm-pass-interaction:. Specifying interactions between passes; --------------------------------------. One of the main responsibilities of the ``PassManager`` is to make sure that; passes interact with each other correctly. Because ``PassManager`` tries to; :ref:`optimize the execution of passes <writing-an-llvm-pass-passmanager>` it; must know how the passes interact with each other and what dependencies exist; between the various passes. To track this, each pass can declare the set of; passes that are required to be executed before the current pass, and the passes; which are invalidated by the current pass. Typically this functionality is used to require that analysis results are; computed before your pass is run. Running arbitrary transformation passes can; invalidate the computed analysis results, which is what the invalidation set; specifies. If a pass does not implement the :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` method, it defaults to not having any; prerequisite passes, and invalidating **all** other passes. .. _writing-an-llvm-pass-getAnalysisUsage:. The ``getAnalysisUsage`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void getAnalysisUsage(AnalysisUsage &Info) const;. By implementing the ``getAnalysisUsage`` method, the required and invalidated; sets ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:31265,Performance,optimiz,optimize,31265,"previous pass to be executed (an analysis for example),; it can use one of these methods to arrange for it to be run before your pass.; LLVM has many different types of analyses and passes that can be required,; spanning the range from ``DominatorSet`` to ``BreakCriticalEdges``. Requiring; ``BreakCriticalEdges``, for example, guarantees that there will be no critical; edges in the CFG when your pass has been run. Some analyses chain to other analyses to do their job. For example, an; `AliasAnalysis <AliasAnalysis>` implementation is required to :ref:`chain; <aliasanalysis-chaining>` to other alias analysis passes. In cases where; analyses chain, the ``addRequiredTransitive`` method should be used instead of; the ``addRequired`` method. This informs the ``PassManager`` that the; transitively required pass should be alive as long as the requiring pass is. The ``AnalysisUsage::addPreserved<>`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One of the jobs of the ``PassManager`` is to optimize how and when analyses are; run. In particular, it attempts to avoid recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. Thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41823,Performance,cache,cache,41823,"es a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:42313,Performance,cache,cache,42313," analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:43724,Performance,load,load,43724,"ectly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example, we can see how our; :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass interacts with other; passes. Lets try it out with the gvn and licm passes:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -licm --debug-pass=Structure < hello.bc > /dev/null; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer. This output shows us when passes are constructed.; Here we see that GVN uses dominator tree information to do its job. The LICM pass; uses natural loop information, which uses dominator tree as well. After the LICM pass, the module verifier runs (which is automatically added by; the :program:`opt` tool), which uses the dominator tree to check that the; resultant LLVM code is well formed. Note that the dominator tree is computed; once, and shared by three passes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:44892,Performance,load,load,44892,"stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer. This output shows us when passes are constructed.; Here we see that GVN uses dominator tree information to do its job. The LICM pass; uses natural loop information, which uses dominator tree as well. After the LICM pass, the module verifier runs (which is automatically added by; the :program:`opt` tool), which uses the dominator tree to check that the; resultant LLVM code is well formed. Note that the dominator tree is computed; once, and shared by three passes. Lets see how this changes when we run the :ref:`Hello World; <writing-an-llvm-pass-basiccode>` pass in between the two passes:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Dominator Tree Construction; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Here we see that the :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass; has killed the Dominator Tree pass, even though it doesn't modify the code at; all! To fix this, we need to add the following :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` method to our pass:. .. code-block:: c++. // We don't modify the program, so we preserve all analyse",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:46065,Performance,load,load,46065," (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Dominator Tree Construction; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Here we see that the :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass; has killed the Dominator Tree pass, even though it doesn't modify the code at; all! To fix this, we need to add the following :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` method to our pass:. .. code-block:: c++. // We don't modify the program, so we preserve all analyses; void getAnalysisUsage(AnalysisUsage &AU) const override {; AU.setPreservesAll();; }. Now when we run our pass, we get this output:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -hello -licm --debug-pass=Structure < hello.bc > /dev/null; Pass Arguments: -gvn -hello -licm; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Hello World Pass; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bitcode Writer; Hello: __main; Hello: puts; Hello: main. Which shows that we don't accidentally invalidate dominator information; anymore, and therefore do not have to compute it twice. .. _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:47823,Performance,load,loaded,47823,". _writing-an-llvm-pass-releaseMemory:. The ``releaseMemory`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual void releaseMemory();. The ``PassManager`` automatically determines when to compute analysis results,; and how long to keep them around for. Because the lifetime of the pass object; itself is effectively the entire duration of the compilation process, we need; some way to free analysis results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:49200,Performance,load,loaded,49200,"ant to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAlloca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:49230,Performance,load,load,49230,"ant to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at unload. Using existing registries; -------------------------. There are predefined registries to track instruction scheduling; (``RegisterScheduler``) and register allocation (``RegisterRegAlloc``) machine; passes. Here we will describe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAlloca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50918,Performance,load,load,50918,"; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:52014,Performance,load,loaded,52014,"on's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator. Using GDB with dynamically loaded passes; ----------------------------------------. Unfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show wa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:52113,Performance,load,loaded,52113,"en/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator. Using GDB with dynamically loaded passes; ----------------------------------------. Unfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:52239,Performance,load,loaded,52239,"of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``RegisterMyPasses`` then define:. .. code-block:: c++. MachinePassRegistry<RegisterMyPasses::FunctionPassCtor> RegisterMyPasses::Registry;. And finally, declare the command line option for your passes. Example:. .. code-block:: c++. cl::opt<RegisterMyPasses::FunctionPassCtor, false,; RegisterPassParser<RegisterMyPasses> >; MyPassOpt(""mypass"",; cl::init(&createDefaultMyPass),; cl::desc(""my pass option help""));. Here the command option is ""``mypass``"", with ``createDefaultMyPass`` as the; default creator. Using GDB with dynamically loaded passes; ----------------------------------------. Unfortunately, using GDB with dynamically loaded passes is not as easy as it; should be. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53199,Performance,load,load,53199,"e. First of all, you can't set a breakpoint in a shared object that; has not been loaded yet, and second of all there are problems with inlined; functions in shared objects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace thr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53292,Performance,load,loaded,53292,"jects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53407,Performance,load,loaded,53407,"jects. Here are some suggestions to debugging your pass; with GDB. For sake of discussion, I'm going to assume that you are debugging a; transformation invoked by :program:`opt`, although nothing described here; depends on that. Setting a breakpoint in your pass; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. First thing you do is start gdb on the opt process:. .. code-block:: console. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53707,Performance,load,load,53707,"yright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restart",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53805,Performance,load,load,53805,"c License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After following the information; above, you have succeeded in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:54548,Performance,load,loaded,54548," it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After following the information; above, you have succeeded in getting some breakpoints planted in your pass.; Next thing you know, you restart the program (i.e., you type ""``run``"" again),; and you start getting errors about breakpoints being unsettable. The only; way I have found to ""fix"" this problem is to delete the breakpoints that are; already set in your pass, run the program, and re-set the breakpoints once; execution stops in ``PassManager::run``. Hopefully these tips will help with common case debugging situations. If you'd; like to contribute some tips of your own, just contact `Chris; <mailto:sabre@nondot.org>`_.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:5321,Safety,avoid,avoid,5321," because the functions from the include files live in the; llvm namespace. Next we have:. .. code-block:: c++. namespace {. ... which starts out an anonymous namespace. Anonymous namespaces are to C++; what the ""``static``"" keyword is to C (at global scope). It makes the things; declared inside of the anonymous namespace visible only to the current file.; If you're not familiar with them, consult a decent C++ book for more; information. Next, we declare our pass itself:. .. code-block:: c++. struct Hello : public FunctionPass {. This declares a ""``Hello``"" class that is a subclass of :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. The different builtin pass subclasses; are described in detail :ref:`later <writing-an-llvm-pass-pass-classes>`, but; for now, know that ``FunctionPass`` operates on a function at a time. .. code-block:: c++. static char ID;; Hello() : FunctionPass(ID) {}. This declares pass identifier used by LLVM to identify pass. This allows LLVM; to avoid using expensive C++ runtime information. .. code-block:: c++. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. We declare a :ref:`runOnFunction <writing-an-llvm-pass-runOnFunction>` method,; which overrides an abstract virtual method inherited from :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>`. This is where we are supposed to do our; thing, so we just print out our message with the name of each function. .. code-block:: c++. char Hello::ID = 0;. We initialize pass ID here. LLVM uses ID's address to identify a pass, so; initialization value is not important. .. code-block:: c++. static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Lastly, we :ref:`register our class <writing-an-llvm-pass-registration>`; ``Hello``, giving it a command line argument ""``hello``"", and a name ""Hello;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:12975,Safety,predict,predictable,12975,"ng type of pass is the ""`ImmutablePass; <https://llvm.org/doxygen/classllvm_1_1ImmutablePass.html>`_"" class. This pass; type is used for passes that do not have to be run, do not change state, and; never need to be updated. This is not a normal type of transformation or; analysis, but can provide information about the current compiler configuration. Although this pass class is very infrequently used, it is important for; providing information about the current target machine being compiled for, and; other static information that can affect the various transformations. ``ImmutablePass``\ es never invalidate other transformations, are never; invalidated, and are never ""run"". .. _writing-an-llvm-pass-ModulePass:. The ``ModulePass`` class; ------------------------. The `ModulePass <https://llvm.org/doxygen/classllvm_1_1ModulePass.html>`_ class; is the most general of all superclasses that you can use. Deriving from; ``ModulePass`` indicates that your pass uses the entire program as a unit,; referring to function bodies in no predictable order, or adding and removing; functions. Because nothing is known about the behavior of ``ModulePass``; subclasses, no optimization can be done for their execution. A module pass can use function level passes (e.g. dominators) using the; ``getAnalysis`` interface ``getAnalysis<DominatorTree>(llvm::Function *)`` to; provide the function to retrieve analysis result for, if the function pass does; not require any module or immutable passes. Note that this can only be done; for functions for which the analysis ran, e.g. in the case of dominators you; should only ask for the ``DominatorTree`` for function definitions, not; declarations. To write a correct ``ModulePass`` subclass, derive from ``ModulePass`` and; override the ``runOnModule`` method with the following signature:. The ``runOnModule`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnModule(Module &M) = 0;. The ``runOnModule`` method performs the interest",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:17256,Safety,predict,predictable,17256,"lap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ``ModulePass`` subclasses, `FunctionPass; <https://llvm.org/doxygen/classllvm_1_1Pass.html>`_ subclasses do have a; predictable, local behavior that can be expected by the system. All; ``FunctionPass`` execute on each function in the program independent of all of; the other functions in the program. ``FunctionPass``\ es do not require that; they are executed in a particular order, and ``FunctionPass``\ es do not modify; external functions. To be explicit, ``FunctionPass`` subclasses are not allowed to:. #. Inspect or modify a ``Function`` other than the one currently being processed.; #. Add or remove ``Function``\ s from the current ``Module``.; #. Add or remove global variables from the current ``Module``.; #. Maintain state across invocations of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:31336,Safety,avoid,avoid,31336,"e methods to arrange for it to be run before your pass.; LLVM has many different types of analyses and passes that can be required,; spanning the range from ``DominatorSet`` to ``BreakCriticalEdges``. Requiring; ``BreakCriticalEdges``, for example, guarantees that there will be no critical; edges in the CFG when your pass has been run. Some analyses chain to other analyses to do their job. For example, an; `AliasAnalysis <AliasAnalysis>` implementation is required to :ref:`chain; <aliasanalysis-chaining>` to other alias analysis passes. In cases where; analyses chain, the ``addRequiredTransitive`` method should be used instead of; the ``addRequired`` method. This informs the ``PassManager`` that the; transitively required pass should be alive as long as the requiring pass is. The ``AnalysisUsage::addPreserved<>`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One of the jobs of the ``PassManager`` is to optimize how and when analyses are; run. In particular, it attempts to avoid recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:41258,Safety,avoid,avoid,41258,"s://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analyses are available already, which analyses get invalidated, and; which analyses are needed to be run for a pass. An important part of work; is that the ``PassManager`` tracks the exact lifetime of all analysis; results, allowing it to :ref:`free memory; <writing-an-llvm-pass-releaseMemory>` allocated to holding analysis results; as soon as they are no longer needed. #. **Pipeline the execution of passes on the program.** The ``PassManager``; attempts to get better cache and memory usage behavior out of a series of; passes by pipelining the passes together. This means that, given a series; of consecutive :ref:`FunctionPass <writing-an-llvm-pass-FunctionPass>`, it; will execute all of the :ref:`FunctionPass; <writing-an-llvm-pass-FunctionPass>` on the first function, then all of the; :ref:`FunctionPasses <writing-an-llvm-pass-FunctionPass>` on the second; function, etc... until the entire program has bee",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:7947,Security,access,access,7947,"ass(ID) {}. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. char Hello::ID = 0;; static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Now that it's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:21826,Security,access,access,21826,"ass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but execute",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23818,Security,access,access,23818,"t executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnRegion; <writing-an-llvm-pass-runOnRegion>` for every region in the program being; compiled. The ``MachineFunctionPass`` class; ---------------------------------. A ``MachineFunctionPass`` is a part of the LLVM code generator that executes on; the machine-de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:26555,Security,access,accessor,26555,"e``\ s.; #. Modify a ``MachineFunction`` other than the one currently being processed.; #. Maintain state across invocations of :ref:`runOnMachineFunction; <writing-an-llvm-pass-runOnMachineFunction>` (including global data). .. _writing-an-llvm-pass-runOnMachineFunction:. The ``runOnMachineFunction(MachineFunction &MF)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnMachineFunction(MachineFunction &MF) = 0;. ``runOnMachineFunction`` can be considered the main entry point of a; ``MachineFunctionPass``; that is, you should override this method to do the; work of your ``MachineFunctionPass``. The ``runOnMachineFunction`` method is called on every ``MachineFunction`` in a; ``Module``, so that the ``MachineFunctionPass`` may perform optimizations on; the machine-dependent representation of the function. If you want to get at; the LLVM ``Function`` for the ``MachineFunction`` you're working on, use; ``MachineFunction``'s ``getFunction()`` accessor method --- but remember, you; may not modify the LLVM ``Function`` or its contents from a; ``MachineFunctionPass``. .. _writing-an-llvm-pass-registration:. Pass registration; -----------------. In the :ref:`Hello World <writing-an-llvm-pass-basiccode>` example pass we; illustrated how pass registration works, and discussed some of the reasons that; it is used and what it does. Here we discuss how and why passes are; registered. As we saw above, passes are registered with the ``RegisterPass`` template. The; template parameter is the name of the pass that is to be used on the command; line to specify that the pass should be added to a program (for example, with; :program:`opt` or :program:`bugpoint`). The first argument is the name of the; pass, which is to be used for the :option:`-help` output of programs, as well; as for debug output generated by the `--debug-pass` option. If you want your pass to be easily dumpable, you should implement the virtual; print method:. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:32997,Security,access,access,32997,"setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses if they exist, so it can preserve them, despite the; fact that it hacks on the CFG. Example implementations of ``getAnalysisUsage``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. // This example modifies the program, but does not modify the CFG; void LICM::getAnalysisUsage(AnalysisUsage &AU) const {; AU.setPreservesCFG();; AU.addRequired<LoopInfoWrapperPass>();; }. .. _writing-an-llvm-pass-getAnalysis:. The ``getAnalysis<>`` and ``getAnalysisIfAvailable<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &LI = getAnalysis<LoopInfoWrapperPass>().getLoopInfo();; //...; }. This method call returns a reference to the pass desired. You may get a; runtime assertion failure if you attempt to get an analysis that you did not; declare as required in your :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` implementation. This method can be; called by your ``run*`` method implementation, or by any other local method; invoked by your ``run*`` method. A module level pass can use function level analysis info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:40357,Security,expose,expose,40357,"iasAnalysis.html>`_ analysis group.; Every implementation of an analysis group should join using this macro. .. code-block:: c++. namespace {; // Declare that we implement the AliasAnalysis interface; INITIALIZE_AG_PASS(BasicAA, AliasAnalysis, ""basic-aa"",; ""Basic Alias Analysis (default AA impl)"",; false, // Is CFG Only?; true, // Is Analysis?; true); // Is default Analysis Group implementation?; }. Here we show how the default implementation is specified (using the final; argument to the ``INITIALIZE_AG_PASS`` template). There must be exactly one; default implementation available at all times for an Analysis Group to be used.; Only default implementation can derive from ``ImmutablePass``. Here we declare; that the `BasicAliasAnalysis; <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass is the default; implementation for the interface. Pass Statistics; ===============. The `Statistic <https://llvm.org/doxygen/Statistic_8h_source.html>`_ class is; designed to be an easy way to expose various success metrics from passes.; These statistics are printed at the end of a run, when the :option:`-stats`; command line option is enabled on the command line. See the :ref:`Statistics; section <Statistic>` in the Programmer's Manual for details. .. _writing-an-llvm-pass-passmanager:. What PassManager does; ---------------------. The `PassManager <https://llvm.org/doxygen/PassManager_8h_source.html>`_ `class; <https://llvm.org/doxygen/classllvm_1_1PassManager.html>`_ takes a list of; passes, ensures their :ref:`prerequisites <writing-an-llvm-pass-interaction>`; are set up correctly, and then schedules passes to run efficiently. All of the; LLVM tools that run passes use the PassManager for execution of these passes. The PassManager does two main things to try to reduce the execution time of a; series of passes:. #. **Share analysis results.** The ``PassManager`` attempts to avoid; recomputing analysis results as much as possible. This means keeping track; of which analy",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:43164,Security,expose,exposes,43164,"re program has been run through the passes. This improves the cache behavior of the compiler, because it is only; touching the LLVM program representation for a single function at a time,; instead of traversing the entire program. It reduces the memory consumption; of compiler, because, for example, only one `DominatorSet; <https://llvm.org/doxygen/classllvm_1_1DominatorSet.html>`_ needs to be; calculated at a time. The effectiveness of the ``PassManager`` is influenced directly by how much; information it has about the behaviors of the passes it is scheduling. For; example, the ""preserved"" set is intentionally conservative in the face of an; unimplemented :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. Not implementing when it should be implemented will have the effect of; not allowing any analysis results to live across the execution of your pass. The ``PassManager`` class exposes a ``--debug-pass`` command line options that; is useful for debugging pass execution, seeing how things work, and diagnosing; when you should be preserving more analyses than you currently are. (To get; information about all of the variants of the ``--debug-pass`` option, just type; ""``opt -help-hidden``""). By using the --debug-pass=Structure option, for example, we can see how our; :ref:`Hello World <writing-an-llvm-pass-basiccode>` pass interacts with other; passes. Lets try it out with the gvn and licm passes:. .. code-block:: console. $ opt -load lib/LLVMHello.so -gvn -licm --debug-pass=Structure < hello.bc > /dev/null; ModulePass Manager; FunctionPass Manager; Dominator Tree Construction; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Memory Dependence Analysis; Global Value Numbering; Natural Loop Information; Canonicalize natural loops; Loop-Closed SSA Form Pass; Basic Alias Analysis (stateless AA impl); Function Alias Analysis Results; Scalar Evolution Analysis; Loop Pass Manager; Loop Invariant Code Motion; Module Verifier; Bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:7974,Testability,test,test,7974,"; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. char Hello::ID = 0;; static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Now that it's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main. The :option:`-load` option specifies that :program:`opt` should load your pass; as a shared object, which makes ""``-hello``"" a valid command line argument; (which is one reason you need to :ref:`register your pass; <writing-an-llvm-pass-registration>`). Because the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:9587,Testability,test,tested,9587,"se the Hello pass does not modify; the program in any interesting way, we just throw away the result of; :program:`opt` (sending it to ``/dev/null``). To see what happened to the other string you registered, try running; :program:`opt` with the :option:`-help` option:. .. code-block:: console. $ opt -load lib/LLVMHello.so -help; OVERVIEW: llvm .bc -> .bc modular optimizer and analysis printer. USAGE: opt [subcommand] [options] <input bitcode file>. OPTIONS:; Optimizations available:; ...; -guard-widening - Widen guards; -gvn - Global Value Numbering; -gvn-hoist - Early GVN Hoisting of Expressions; -hello - Hello World Pass; -indvars - Induction Variable Simplification; -inferattrs - Infer set function attributes; ... The pass name gets added as the information string for your pass, giving some; documentation to users of :program:`opt`. Now that you have a working pass,; you would go ahead and make it do the cool transformations you want. Once you; get it all working and tested, it may become useful to find out how fast your; pass is. The :ref:`PassManager <writing-an-llvm-pass-passmanager>` provides a; nice command line option (:option:`-time-passes`) that allows you to get; information about the execution time of your pass along with the other passes; you queue up. For example:. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello -time-passes < hello.bc > /dev/null; Hello: __main; Hello: puts; Hello: main; ===-------------------------------------------------------------------------===; ... Pass execution timing report ...; ===-------------------------------------------------------------------------===; Total Execution Time: 0.0007 seconds (0.0005 wall clock). ---User Time--- --User+System-- ---Wall Time--- --- Name ---; 0.0004 ( 55.3%) 0.0004 ( 55.3%) 0.0004 ( 75.7%) Bitcode Writer; 0.0003 ( 44.7%) 0.0003 ( 44.7%) 0.0001 ( 13.6%) Hello World Pass; 0.0000 ( 0.0%) 0.0000 ( 0.0%) 0.0001 ( 10.7%) Module Verifier; 0.0007 (100.0%) 0.0007 (100.0%) 0.0005 (100.0%)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:33487,Testability,assert,assertion,33487,"fies the program, but does not modify the CFG; void LICM::getAnalysisUsage(AnalysisUsage &AU) const {; AU.setPreservesCFG();; AU.addRequired<LoopInfoWrapperPass>();; }. .. _writing-an-llvm-pass-getAnalysis:. The ``getAnalysis<>`` and ``getAnalysisIfAvailable<>`` methods; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``Pass::getAnalysis<>`` method is automatically inherited by your class,; providing you with access to the passes that you declared that you required; with the :ref:`getAnalysisUsage <writing-an-llvm-pass-getAnalysisUsage>`; method. It takes a single template argument that specifies which pass class; you want, and returns a reference to that pass. For example:. .. code-block:: c++. bool LICM::runOnFunction(Function &F) {; LoopInfo &LI = getAnalysis<LoopInfoWrapperPass>().getLoopInfo();; //...; }. This method call returns a reference to the pass desired. You may get a; runtime assertion failure if you attempt to get an analysis that you did not; declare as required in your :ref:`getAnalysisUsage; <writing-an-llvm-pass-getAnalysisUsage>` implementation. This method can be; called by your ``run*`` method implementation, or by any other local method; invoked by your ``run*`` method. A module level pass can use function level analysis info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func);; //...; }. In above example, ``runOnFunction`` for ``DominatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Ana",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53698,Testability,test,test,53698,"onsole. $ gdb opt; GNU gdb 5.0; Copyright 2000 Free Software Foundation, Inc.; GDB is free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:53796,Testability,test,test,53796,"s free software, covered by the GNU General Public License, and you are; welcome to change it and/or distribute copies of it under certain conditions.; Type ""show copying"" to see the conditions.; There is absolutely no warranty for GDB. Type ""show warranty"" for details.; This GDB was configured as ""sparc-sun-solaris2.6""...; (gdb). Note that :program:`opt` has a lot of debugging information in it, so it takes; time to load. Be patient. Since we cannot set a breakpoint in our pass yet; (the shared object isn't loaded until runtime), we must execute the process,; and have it stop before it invokes our pass, but after it has loaded the shared; object. The most foolproof way of doing this is to set a breakpoint in; ``PassManager::run`` and then run the process with the arguments you want:. .. code-block:: console. $ (gdb) break llvm::PassManager::run; Breakpoint 1 at 0x2413bc: file Pass.cpp, line 70.; (gdb) run test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Starting program: opt test.bc -load $(LLVMTOP)/llvm/Debug+Asserts/lib/[libname].so -[passoption]; Breakpoint 1, PassManager::run (this=0xffbef174, M=@0x70b298) at Pass.cpp:70; 70 bool PassManager::run(Module &M) { return PM->run(M); }; (gdb). Once the :program:`opt` stops in the ``PassManager::run`` method you are now; free to set breakpoints in your pass so that you can trace through execution or; do other standard debugging stuff. Miscellaneous Problems; ^^^^^^^^^^^^^^^^^^^^^^. Once you have the basics down, there are a couple of problems that GDB has,; some with solutions, some without. * Inline functions have bogus stack information. In general, GDB does a pretty; good job getting stack traces and stepping through inline functions. When a; pass is dynamically loaded however, it somehow completely loses this; capability. The only solution I know of is to de-inline a function (move it; from the body of a class to a ``.cpp`` file). * Restarting the program breaks breakpoints. After followi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:2093,Usability,simpl,simply,2093,"ore; information about what your pass does, and how it can be combined with other; passes. One of the main features of the LLVM Pass Framework is that it; schedules passes to run in an efficient way based on the constraints that your; pass meets (which are indicated by which class they derive from). We start by showing you how to construct a pass, everything from setting up the; code, to compiling, loading, and executing it. After the basics are down, more; advanced features are discussed. .. warning::; This document deals with the legacy pass manager. LLVM uses the new pass; manager for the optimization pipeline (the codegen pipeline; still uses the legacy pass manager), which has its own way of defining; passes. For more details, see :doc:`WritingAnLLVMNewPMPass` and; :doc:`NewPassManager`. Quick Start --- Writing hello world; ===================================. Here we describe how to write the ""hello world"" of passes. The ""Hello"" pass is; designed to simply print out the name of non-external functions that exist in; the program being compiled. It does not modify the program at all, it just; inspects it. The source code and files for this pass are available in the LLVM; source tree in the ``lib/Transforms/Hello`` directory. .. _writing-an-llvm-pass-makefile:. Setting up the build environment; --------------------------------. First, configure and build LLVM. Next, you need to create a new directory; somewhere in the LLVM source base. For this example, we'll assume that you; made ``lib/Transforms/Hello``. Finally, you must set up a build script; that will compile the source code for the new pass. To do this,; copy the following into ``CMakeLists.txt``:. .. code-block:: cmake. add_llvm_library( LLVMHello MODULE; Hello.cpp. PLUGIN_TOOL; opt; ). and the following line into ``lib/Transforms/CMakeLists.txt``:. .. code-block:: cmake. add_subdirectory(Hello). (Note that there is already a directory named ``Hello`` with a sample ""Hello""; pass; you may play with it -- in ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:7296,Usability,simpl,simple,7296,"llo; World Pass"". The last two arguments describe its behavior: if a pass walks CFG; without modifying it then the third argument is set to ``true``; if a pass is; an analysis pass, for example dominator tree pass, then ``true`` is supplied as; the fourth argument. As a whole, the ``.cpp`` file looks like:. .. code-block:: c++. #include ""llvm/Pass.h""; #include ""llvm/IR/Function.h""; #include ""llvm/Support/raw_ostream.h"". #include ""llvm/IR/LegacyPassManager.h"". using namespace llvm;. namespace {; struct Hello : public FunctionPass {; static char ID;; Hello() : FunctionPass(ID) {}. bool runOnFunction(Function &F) override {; errs() << ""Hello: "";; errs().write_escaped(F.getName()) << '\n';; return false;; }; }; // end of struct Hello; } // end of anonymous namespace. char Hello::ID = 0;; static RegisterPass<Hello> X(""hello"", ""Hello World Pass"",; false /* Only looks at CFG */,; false /* Analysis Pass */);. Now that it's all together, compile the file with a simple ""``gmake``"" command; from the top level of your build directory and you should get a new file; ""``lib/LLVMHello.so``"". Note that everything in this file is; contained in an anonymous namespace --- this reflects the fact that passes; are self contained units that do not need external interfaces (although they; can have them) to be useful. Running a pass with ``opt``; ---------------------------. Now that you have a brand new shiny shared object file, we can use the; :program:`opt` command to run an LLVM program through your pass. Because you; registered your pass with ``RegisterPass``, you will be able to use the; :program:`opt` tool to access it, once loaded. To test it, follow the example at the end of the :doc:`GettingStarted` to; compile ""Hello World"" to LLVM. We can now run the bitcode file (hello.bc) for; the program through our transformation like this (or course, any bitcode file; will work):. .. code-block:: console. $ opt -load lib/LLVMHello.so -hello < hello.bc > /dev/null; Hello: __main; Hello: puts;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:16123,Usability,simpl,simple,16123," ... *not allowed* to add or remove SCC's from the current Module, though; they may change the contents of an SCC.; #. ... *allowed* to add or remove global variables from the current Module.; #. ... *allowed* to maintain state across invocations of :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` (including global data). Implementing a ``CallGraphSCCPass`` is slightly tricky in some cases because it; has to handle SCCs with more than one node in it. All of the virtual methods; described below should return ``true`` if they modified the program, or; ``false`` if they didn't. The ``doInitialization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(CallGraph &CG);. The ``doInitialization`` method is allowed to do most of the things that; ``CallGraphSCCPass``\ es are not allowed to do. They can add and remove; functions, get pointers to functions, etc. The ``doInitialization`` method is; designed to do simple initialization type of stuff that does not depend on the; SCCs being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). .. _writing-an-llvm-pass-runOnSCC:. The ``runOnSCC`` method; ^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnSCC(CallGraphSCC &SCC) = 0;. The ``runOnSCC`` method performs the interesting work of the pass, and should; return ``true`` if the module was modified by the transformation, ``false``; otherwise. The ``doFinalization(CallGraph &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization(CallGraph &CG);. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnSCC; <writing-an-llvm-pass-runOnSCC>` for every SCC in the program being compiled. .. _writing-an-llvm-pass-FunctionPass:. The ``FunctionPass`` class; --------------------------. In contrast to ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:18738,Usability,simpl,simple,18738,"on``\ s from the current ``Module``.; #. Add or remove global variables from the current ``Module``.; #. Maintain state across invocations of :ref:`runOnFunction; <writing-an-llvm-pass-runOnFunction>` (including global data). Implementing a ``FunctionPass`` is usually straightforward (See the :ref:`Hello; World <writing-an-llvm-pass-basiccode>` pass for example).; ``FunctionPass``\ es may override three virtual methods to do their work. All; of these methods should return ``true`` if they modified the program, or; ``false`` if they didn't. .. _writing-an-llvm-pass-doInitialization-mod:. The ``doInitialization(Module &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Module &M);. The ``doInitialization`` method is allowed to do most of the things that; ``FunctionPass``\ es are not allowed to do. They can add and remove functions,; get pointers to functions, etc. The ``doInitialization`` method is designed to; do simple initialization type of stuff that does not depend on the functions; being processed. The ``doInitialization`` method call is not scheduled to; overlap with any other pass executions (thus it should be very fast). A good example of how this method should be used is the `LowerAllocations; <https://llvm.org/doxygen/LowerAllocations_8cpp-source.html>`_ pass. This pass; converts ``malloc`` and ``free`` instructions into platform dependent; ``malloc()`` and ``free()`` function calls. It uses the ``doInitialization``; method to get a reference to the ``malloc`` and ``free`` functions that it; needs, adding prototypes to the module if necessary. .. _writing-an-llvm-pass-runOnFunction:. The ``runOnFunction`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnFunction(Function &F) = 0;. The ``runOnFunction`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:21558,Usability,simpl,simple,21558,"erface. Implementing a loop pass is usually straightforward.; ``LoopPass``\ es may override three virtual methods to do their work. All; these methods should return ``true`` if they modified the program, or ``false``; if they didn't. A ``LoopPass`` subclass which is intended to run as part of the main loop pass; pipeline needs to preserve all of the same *function* analyses that the other; loop passes in its pipeline require. To make that easier,; a ``getLoopAnalysisUsage`` function is provided by ``LoopUtils.h``. It can be; called within the subclass's ``getAnalysisUsage`` override to get consistent; and correct behavior. Analogously, ``INITIALIZE_PASS_DEPENDENCY(LoopPass)``; will initialize this set of function analyses. The ``doInitialization(Loop *, LPPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Loop *, LPPassManager &LPM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``LPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnLoop:. The ``runOnLoop`` method; ^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnLoop(Loop *, LPPassManager &LPM) = 0;. The ``runOnLoop`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a ``true`` value; should be returned if the function is modified. ``LPPassManager`` interface; should be used to update loop nest. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnLoop; <writ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:23550,Usability,simpl,simple,23550,"p; <writing-an-llvm-pass-runOnLoop>` for every loop in the program being compiled. .. _writing-an-llvm-pass-RegionPass:. The ``RegionPass`` class; ------------------------. ``RegionPass`` is similar to :ref:`LoopPass <writing-an-llvm-pass-LoopPass>`,; but executes on each single entry single exit region in the function.; ``RegionPass`` processes regions in nested order such that the outer most; region is processed last. ``RegionPass`` subclasses are allowed to update the region tree by using the; ``RGPassManager`` interface. You may override three virtual methods of; ``RegionPass`` to implement your own region pass. All these methods should; return ``true`` if they modified the program, or ``false`` if they did not. The ``doInitialization(Region *, RGPassManager &)`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doInitialization(Region *, RGPassManager &RGM);. The ``doInitialization`` method is designed to do simple initialization type of; stuff that does not depend on the functions being processed. The; ``doInitialization`` method call is not scheduled to overlap with any other; pass executions (thus it should be very fast). ``RPPassManager`` interface; should be used to access ``Function`` or ``Module`` level analysis information. .. _writing-an-llvm-pass-runOnRegion:. The ``runOnRegion`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool runOnRegion(Region *, RGPassManager &RGM) = 0;. The ``runOnRegion`` method must be implemented by your subclass to do the; transformation or analysis work of your pass. As usual, a true value should be; returned if the region is modified. ``RGPassManager`` interface should be used to; update region tree. The ``doFinalization()`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. virtual bool doFinalization();. The ``doFinalization`` method is an infrequently used method that is called; when the pass framework has finished calling :ref:`runOnReg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:31533,Usability,simpl,simple,31533,"ample, guarantees that there will be no critical; edges in the CFG when your pass has been run. Some analyses chain to other analyses to do their job. For example, an; `AliasAnalysis <AliasAnalysis>` implementation is required to :ref:`chain; <aliasanalysis-chaining>` to other alias analysis passes. In cases where; analyses chain, the ``addRequiredTransitive`` method should be used instead of; the ``addRequired`` method. This informs the ``PassManager`` that the; transitively required pass should be alive as long as the requiring pass is. The ``AnalysisUsage::addPreserved<>`` method; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. One of the jobs of the ``PassManager`` is to optimize how and when analyses are; run. In particular, it attempts to avoid recomputing data unless it needs to.; For this reason, passes are allowed to declare that they preserve (i.e., they; don't invalidate) an existing analysis if it's available. For example, a; simple constant folding pass would not modify the CFG, so it can't possibly; affect the results of dominator analysis. By default, all passes are assumed; to invalidate all others. The ``AnalysisUsage`` class provides several methods which are useful in; certain circumstances that are related to ``addPreserved``. In particular, the; ``setPreservesAll`` method can be called to indicate that the pass does not; modify the LLVM program at all (which is true for analyses), and the; ``setPreservesCFG`` method can be used by transformations that change; instructions in the program but do not modify the CFG or terminator; instructions. ``addPreserved`` is particularly useful for transformations like; ``BreakCriticalEdges``. This pass knows how to update a small set of loop and; dominator related analyses if they exist, so it can preserve them, despite the; fact that it hacks on the CFG. Example implementations of ``getAnalysisUsage``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. code-block:: c++. // This example modifies the program, bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:34839,Usability,simpl,simple,34839,"s info using this interface.; For example:. .. code-block:: c++. bool ModuleLevelPass::runOnModule(Module &M) {; //...; DominatorTree &DT = getAnalysis<DominatorTree>(Func);; //...; }. In above example, ``runOnFunction`` for ``DominatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Analysis Groups; ----------------------------. Now that we understand the basics of how passes are defined, how they are used,; and how they are required from other passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:35071,Usability,simpl,simple,35071,"inatorTree`` is called by pass; manager before returning a reference to the desired pass. If your pass is capable of updating analyses if they exist (e.g.,; ``BreakCriticalEdges``, as described above), you can use the; ``getAnalysisIfAvailable`` method, which returns a pointer to the analysis if; it is active. For example:. .. code-block:: c++. if (DominatorSet *DS = getAnalysisIfAvailable<DominatorSet>()) {; // A DominatorSet is active. This code will update it.; }. Implementing Analysis Groups; ----------------------------. Now that we understand the basics of how passes are defined, how they are used,; and how they are required from other passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:35701,Usability,simpl,simple,35701,"ther passes, it's time to get a little bit; fancier. All of the pass relationships that we have seen so far are very; simple: one pass depends on one other specific pass to be run before it can; run. For many applications, this is great, for others, more flexibility is; required. In particular, some analyses are defined such that there is a single simple; interface to the analysis results, but multiple ways of calculating them.; Consider alias analysis for example. The most trivial alias analysis returns; ""may alias"" for any alias query. The most sophisticated analysis a; flow-sensitive, context-sensitive interprocedural analysis that can take a; significant amount of time to execute (and obviously, there is a lot of room; between these two extremes for other implementations). To cleanly support; situations like this, the LLVM Pass Infrastructure supports the notion of; Analysis Groups. Analysis Group Concepts; ^^^^^^^^^^^^^^^^^^^^^^^. An Analysis Group is a single simple interface that may be implemented by; multiple different passes. Analysis Groups can be given human readable names; just like passes, but unlike passes, they need not derive from the ``Pass``; class. An analysis group may have one or more implementations, one of which is; the ""default"" implementation. Analysis groups are used by client passes just like other passes are: the; ``AnalysisUsage::addRequired()`` and ``Pass::getAnalysis()`` methods. In order; to resolve this requirement, the :ref:`PassManager; <writing-an-llvm-pass-passmanager>` scans the available passes to see if any; implementations of the analysis group are available. If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`IN",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:37299,Usability,simpl,simple,37299,"If none is available, the; default implementation is created for the pass to use. All standard rules for; :ref:`interaction between passes <writing-an-llvm-pass-interaction>` still; apply. Although :ref:`Pass Registration <writing-an-llvm-pass-registration>` is; optional for normal passes, all analysis group implementations must be; registered, and must use the :ref:`INITIALIZE_AG_PASS; <writing-an-llvm-pass-RegisterAnalysisGroup>` template to join the; implementation pool. Also, a default implementation of the interface **must**; be registered with :ref:`RegisterAnalysisGroup; <writing-an-llvm-pass-RegisterAnalysisGroup>`. As a concrete example of an Analysis Group in action, consider the; `AliasAnalysis <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_; analysis group. The default implementation of the alias analysis interface; (the `basic-aa <https://llvm.org/doxygen/structBasicAliasAnalysis.html>`_ pass); just does a few simple checks that don't require significant analysis to; compute (such as: two different globals can never alias each other, etc).; Passes that use the `AliasAnalysis; <https://llvm.org/doxygen/classllvm_1_1AliasAnalysis.html>`_ interface (for; example the `gvn <https://llvm.org/doxygen/classllvm_1_1GVN.html>`_ pass), do not; care which implementation of alias analysis is actually provided, they just use; the designated interface. From the user's perspective, commands work just like normal. Issuing the; command ``opt -gvn ...`` will cause the ``basic-aa`` class to be instantiated; and added to the pass sequence. Issuing the command ``opt -somefancyaa -gvn; ...`` will cause the ``gvn`` pass to use the ``somefancyaa`` alias analysis; (which doesn't actually exist, it's just a hypothetical example) instead. .. _writing-an-llvm-pass-RegisterAnalysisGroup:. Using ``RegisterAnalysisGroup``; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The ``RegisterAnalysisGroup`` template is used to register the analysis group; itself, while the ``INITIALIZE_AG_PASS`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:48267,Usability,feedback,feedback,48267," results when they are no longer useful. The; ``releaseMemory`` virtual method is the way to do this. If you are writing an analysis or any other pass that retains a significant; amount of state (for use by another pass which ""requires"" your pass and uses; the :ref:`getAnalysis <writing-an-llvm-pass-getAnalysis>` method) you should; implement ``releaseMemory`` to, well, release the memory allocated to maintain; this internal state. This method is called after the ``run*`` method for the; class, before the next call of ``run*`` in your pass. Registering dynamically loaded passes; =====================================. *Size matters* when constructing production quality tools using LLVM, both for; the purposes of distribution, and for regulating the resident code size when; running on the target system. Therefore, it becomes desirable to selectively; use some passes, while omitting others and maintain the flexibility to change; configurations later on. You want to be able to do all this, and, provide; feedback to the user. This is where pass registration comes into play. The fundamental mechanisms for pass registration are the; ``MachinePassRegistry`` class and subclasses of ``MachinePassRegistryNode``. An instance of ``MachinePassRegistry`` is used to maintain a list of; ``MachinePassRegistryNode`` objects. This instance maintains the list and; communicates additions and deletions to the command line interface. An instance of ``MachinePassRegistryNode`` subclass is used to maintain; information provided about a particular pass. This information includes the; command line name, the command help string and the address of the function used; to create an instance of the pass. A global static constructor of one of these; instances *registers* with a corresponding ``MachinePassRegistry``, the static; destructor *unregisters*. Thus a pass that is statically linked in the tool; will be registered at start up. A dynamically loaded pass will register on; load and unregister at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50514,Usability,simpl,simple,50514,"ribe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``Regist",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst:50523,Usability,simpl,simple,50523,"ribe how to *register* a register allocator machine; pass. Implement your register allocator machine pass. In your register allocator; ``.cpp`` file add the following include:. .. code-block:: c++. #include ""llvm/CodeGen/RegAllocRegistry.h"". Also in your register allocator ``.cpp`` file, define a creator function in the; form:. .. code-block:: c++. FunctionPass *createMyRegisterAllocator() {; return new MyRegisterAllocator();; }. Note that the signature of this function should match the type of; ``RegisterRegAlloc::FunctionPassCtor``. In the same file add the ""installing""; declaration, in the form:. .. code-block:: c++. static RegisterRegAlloc myRegAlloc(""myregalloc"",; ""my register allocator help string"",; createMyRegisterAllocator);. Note the two spaces prior to the help string produces a tidy result on the; :option:`-help` query. .. code-block:: console. $ llc -help; ...; -regalloc - Register allocator to use (default=linearscan); =linearscan - linear scan register allocator; =local - local register allocator; =simple - simple register allocator; =myregalloc - my register allocator help string; ... And that's it. The user is now free to use ``-regalloc=myregalloc`` as an; option. Registering instruction schedulers is similar except use the; ``RegisterScheduler`` class. Note that the; ``RegisterScheduler::FunctionPassCtor`` is significantly different from; ``RegisterRegAlloc::FunctionPassCtor``. To force the load/linking of your register allocator into the; :program:`llc`/:program:`lli` tools, add your creator function's global; declaration to ``Passes.h`` and add a ""pseudo"" call line to; ``llvm/Codegen/LinkAllCodegenComponents.h``. Creating new registries; -----------------------. The easiest way to get started is to clone one of the existing registries; we; recommend ``llvm/CodeGen/RegAllocRegistry.h``. The key things to modify are; the class name and the ``FunctionPassCtor`` type. Then you need to declare the registry. Example: if your pass registry is; ``Regist",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/WritingAnLLVMPass.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:734,Availability,avail,available,734,"====================; XRay Instrumentation; ====================. :Version: 1 as of 2016-11-08. .. contents::; :local:. Introduction; ============. XRay is a function call tracing system which combines compiler-inserted; instrumentation points and a runtime library that can dynamically enable and; disable the instrumentation. More high level information about XRay can be found in the `XRay whitepaper`_. This document describes how to use XRay as implemented in LLVM. XRay in LLVM; ============. XRay consists of three main parts:. - Compiler-inserted instrumentation points.; - A runtime library for enabling/disabling tracing at runtime.; - A suite of tools for analysing the traces. **NOTE:** As of July 25, 2018 , XRay is only available for the following; architectures running Linux: x86_64, arm7 (no thumb), aarch64, powerpc64le,; mips, mipsel, mips64, mips64el, NetBSD: x86_64, FreeBSD: x86_64 and; OpenBSD: x86_64. The compiler-inserted instrumentation points come in the form of nop-sleds in; the final generated binary, and an ELF section named ``xray_instr_map`` which; contains entries pointing to these instrumentation points. The runtime library; relies on being able to access the entries of the ``xray_instr_map``, and; overwrite the instrumentation points at runtime. Using XRay; ==========. You can use XRay in a couple of ways:. - Instrumenting your C/C++/Objective-C/Objective-C++ application.; - Generating LLVM IR with the correct function attributes. The rest of this section covers these main ways and later on how to customize; what XRay does in an XRay-instrumented binary. Instrumenting your C/C++/Objective-C Application; ------------------------------------------------. The easiest way of getting XRay instrumentation for your application is by; enabling the ``-fxray-instrument`` flag in your clang invocation. For example:. ::. clang -fxray-instrument ... By default, functions that have at least 200 instructions (or contain a loop) will; get XRay instrumentation p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5406,Availability,down,down,5406,"nstrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+---",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9107,Availability,avail,available,9107,"y_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10099,Availability,error,errors,10099,"rs, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the develop",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:13576,Availability,avail,available,13576,"ed by the graph; subcommand to conveniently represent a function call graph with statistics; associated with edges and vertices.; - ``llvm/XRay/InstrumentationMap.h``: A convenient tool for analyzing the; instrumentation map in XRay-instrumented object files and binaries. The; ``extract`` and ``stack`` subcommands uses this particular library. Minimizing Binary Size; ----------------------. XRay supports several different instrumentation points including ``function-entry``,; ``function-exit``, ``custom``, and ``typed`` points. These can be enabled individually; using the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expande",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:4704,Deployability,patch,patching,4704,"; numeric string value for how many instructions should be in the function before; it gets instrumented. .. code-block:: llvm. define i32 @maybe_instrument() uwtable ""xray-instruction-threshold""=""2"" {; ; ...; }. Special Case File; -----------------. Attributes can be imbued through the use of special case files instead of; adding them to the original source files. You can use this to mark certain; functions and classes to be never, always, or instrumented with first-argument; logging from a file. The file's format is described below:. .. code-block:: bash. # Comments are supported; [always]; fun:always_instrument; fun:log_arg1=arg1 # Log the first argument for the function. [never]; fun:never_instrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5708,Deployability,patch,patch,5708," is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do thi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5925,Deployability,install,install,5925," in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7009,Deployability,install,install,7009,"-----------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7263,Deployability,install,installed,7263,"+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7375,Deployability,install,installation,7375,"+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8248,Deployability,install,installed,8248,"ntation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_O",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8471,Deployability,install,installed,8471,"implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9451,Deployability,configurat,configuration,9451,"e(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_statu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9525,Deployability,configurat,configuration,9525,"e(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_statu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9577,Deployability,install,installed,9577,"e(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_statu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10961,Deployability,update,update,10961,"ded below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from one format to another. We can; convert from binary XRay traces (both basic and FDR mode) to YAML,; `flame-graph <https://github.com/brendangregg/FlameGraph>`_ friendly text; formats, as well as `Chrome Trace Viewer (catapult); <https://github.com/catapult-project/catapult>` formats.; - ``graph``: Generates a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:14112,Deployability,patch,patch,14112," enabled individually; using the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented binary, the size of generated XRay traces can; quickly become unwieldy. We are working on integrating pruning techniques and; heuristics for the analysis tools to sift through the traces and surface only; relevant information. More Platforms; --------------. We're looking forward to contributions to port XRay to more architectures and; operating systems. .. References... .. _`XRay whitepaper`: http://research.google",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:14443,Deployability,integrat,integrate,14443,"ng the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented binary, the size of generated XRay traces can; quickly become unwieldy. We are working on integrating pruning techniques and; heuristics for the analysis tools to sift through the traces and surface only; relevant information. More Platforms; --------------. We're looking forward to contributions to port XRay to more architectures and; operating systems. .. References... .. _`XRay whitepaper`: http://research.google.com/pubs/pub45287.html. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:14783,Deployability,integrat,integrating,14783,"ng the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented binary, the size of generated XRay traces can; quickly become unwieldy. We are working on integrating pruning techniques and; heuristics for the analysis tools to sift through the traces and surface only; relevant information. More Platforms; --------------. We're looking forward to contributions to port XRay to more architectures and; operating systems. .. References... .. _`XRay whitepaper`: http://research.google.com/pubs/pub45287.html. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7561,Integrability,rout,routine,7561,"PIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:14443,Integrability,integrat,integrate,14443,"ng the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented binary, the size of generated XRay traces can; quickly become unwieldy. We are working on integrating pruning techniques and; heuristics for the analysis tools to sift through the traces and surface only; relevant information. More Platforms; --------------. We're looking forward to contributions to port XRay to more architectures and; operating systems. .. References... .. _`XRay whitepaper`: http://research.google.com/pubs/pub45287.html. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:14783,Integrability,integrat,integrating,14783,"ng the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented binary, the size of generated XRay traces can; quickly become unwieldy. We are working on integrating pruning techniques and; heuristics for the analysis tools to sift through the traces and surface only; relevant information. More Platforms; --------------. We're looking forward to contributions to port XRay to more architectures and; operating systems. .. References... .. _`XRay whitepaper`: http://research.google.com/pubs/pub45287.html. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5382,Modifiability,variab,variable,5382,"nstrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+---",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8339,Modifiability,variab,variable,8339,"ntation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_O",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8549,Modifiability,config,configured,8549,"tion routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8749,Modifiability,variab,variable,8749,"unction. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9248,Modifiability,variab,variable,9248,"nstalled/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9310,Modifiability,variab,variable,9310,"nstalled/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9428,Modifiability,variab,variable,9428,"=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9451,Modifiability,config,configuration,9451,"e(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_statu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9525,Modifiability,config,configuration,9525,"e(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_statu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:4494,Performance,load,loaded,4494,"; ...; }. define i32 @never_instrument() uwtable ""function-instrument""=""xray-never"" {; ; ...; }. You can also set the ``xray-instruction-threshold`` attribute and provide a; numeric string value for how many instructions should be in the function before; it gets instrumented. .. code-block:: llvm. define i32 @maybe_instrument() uwtable ""xray-instruction-threshold""=""2"" {; ; ...; }. Special Case File; -----------------. Attributes can be imbued through the use of special case files instead of; adding them to the original source files. You can use this to mark certain; functions and classes to be never, always, or instrumented with first-argument; logging from a file. The file's format is described below:. .. code-block:: bash. # Comments are supported; [always]; fun:always_instrument; fun:log_arg1=arg1 # Log the first argument for the function. [never]; fun:never_instrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+--------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:4692,Performance,perform,perform,4692,"; numeric string value for how many instructions should be in the function before; it gets instrumented. .. code-block:: llvm. define i32 @maybe_instrument() uwtable ""xray-instruction-threshold""=""2"" {; ; ...; }. Special Case File; -----------------. Attributes can be imbued through the use of special case files instead of; adding them to the original source files. You can use this to mark certain; functions and classes to be never, always, or instrumented with first-argument; logging from a file. The file's format is described below:. .. code-block:: bash. # Comments are supported; [always]; fun:always_instrument; fun:log_arg1=arg1 # Log the first argument for the function. [never]; fun:never_instrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9071,Performance,queue,queue,9071,"y_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10225,Performance,queue,queue,10225,"nd flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:12353,Performance,load,loading,12353,"nstrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from one format to another. We can; convert from binary XRay traces (both basic and FDR mode) to YAML,; `flame-graph <https://github.com/brendangregg/FlameGraph>`_ friendly text; formats, as well as `Chrome Trace Viewer (catapult); <https://github.com/catapult-project/catapult>` formats.; - ``graph``: Generates a DOT graph of the function call relationships between; functions found in an XRay trace.; - ``stack``: Reconstructs function call stacks from a timeline of function; calls in an XRay trace. These subcommands use various library components found as part of the XRay; libraries, distributed with the LLVM distribution. These are:. - ``llvm/XRay/Trace.h`` : A trace reading library for conveniently loading; an XRay trace of supported forms, into a convenient in-memory representation.; All the analysis tools that deal with traces use this implementation.; - ``llvm/XRay/Graph.h`` : A semi-generic graph type used by the graph; subcommand to conveniently represent a function call graph with statistics; associated with edges and vertices.; - ``llvm/XRay/InstrumentationMap.h``: A convenient tool for analyzing the; instrumentation map in XRay-instrumented object files and binaries. The; ``extract`` and ``stack`` subcommands uses this particular library. Minimizing Binary Size; ----------------------. XRay supports several different instrumentation points including ``function-entry``,; ``function-exit``, ``custom``, and ``typed`` points. These can be enabled individually; using the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:2160,Safety,detect,detection,2160,"ries of the ``xray_instr_map``, and; overwrite the instrumentation points at runtime. Using XRay; ==========. You can use XRay in a couple of ways:. - Instrumenting your C/C++/Objective-C/Objective-C++ application.; - Generating LLVM IR with the correct function attributes. The rest of this section covers these main ways and later on how to customize; what XRay does in an XRay-instrumented binary. Instrumenting your C/C++/Objective-C Application; ------------------------------------------------. The easiest way of getting XRay instrumentation for your application is by; enabling the ``-fxray-instrument`` flag in your clang invocation. For example:. ::. clang -fxray-instrument ... By default, functions that have at least 200 instructions (or contain a loop) will; get XRay instrumentation points. You can tweak that number through the; ``-fxray-instruction-threshold=`` flag:. ::. clang -fxray-instrument -fxray-instruction-threshold=1 ... The loop detection can be disabled with ``-fxray-ignore-loops`` to use only the; instruction threshold. You can also specifically instrument functions in your; binary to either always or never be instrumented using source-level attributes.; You can do it using the GCC-style attributes or C++11-style attributes. .. code-block:: c++. [[clang::xray_always_instrument]] void always_instrumented();. [[clang::xray_never_instrument]] void never_instrumented();. void alt_always_instrumented() __attribute__((xray_always_instrument));. void alt_never_instrumented() __attribute__((xray_never_instrument));. When linking a binary, you can either manually link in the `XRay Runtime; Library`_ or use ``clang`` to link it in automatically with the; ``-fxray-instrument`` flag. Alternatively, you can statically link-in the XRay; runtime library from compiler-rt -- those archive files will take the name of; `libclang_rt.xray-{arch}` where `{arch}` is the mnemonic supported by clang; (x86_64, arm7, etc.). LLVM Function Attribute; -----------------------. If",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:1188,Security,access,access,1188,"erted; instrumentation points and a runtime library that can dynamically enable and; disable the instrumentation. More high level information about XRay can be found in the `XRay whitepaper`_. This document describes how to use XRay as implemented in LLVM. XRay in LLVM; ============. XRay consists of three main parts:. - Compiler-inserted instrumentation points.; - A runtime library for enabling/disabling tracing at runtime.; - A suite of tools for analysing the traces. **NOTE:** As of July 25, 2018 , XRay is only available for the following; architectures running Linux: x86_64, arm7 (no thumb), aarch64, powerpc64le,; mips, mipsel, mips64, mips64el, NetBSD: x86_64, FreeBSD: x86_64 and; OpenBSD: x86_64. The compiler-inserted instrumentation points come in the form of nop-sleds in; the final generated binary, and an ELF section named ``xray_instr_map`` which; contains entries pointing to these instrumentation points. The runtime library; relies on being able to access the entries of the ``xray_instr_map``, and; overwrite the instrumentation points at runtime. Using XRay; ==========. You can use XRay in a couple of ways:. - Instrumenting your C/C++/Objective-C/Objective-C++ application.; - Generating LLVM IR with the correct function attributes. The rest of this section covers these main ways and later on how to customize; what XRay does in an XRay-instrumented binary. Instrumenting your C/C++/Objective-C Application; ------------------------------------------------. The easiest way of getting XRay instrumentation for your application is by; enabling the ``-fxray-instrument`` flag in your clang invocation. For example:. ::. clang -fxray-instrument ... By default, functions that have at least 200 instructions (or contain a loop) will; get XRay instrumentation points. You can tweak that number through the; ``-fxray-instruction-threshold=`` flag:. ::. clang -fxray-instrument -fxray-instruction-threshold=1 ... The loop detection can be disabled with ``-fxray-ignore-loops`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7828,Security,access,access,7828,"ging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; ------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:13706,Security,hash,hash,13706," - ``llvm/XRay/InstrumentationMap.h``: A convenient tool for analyzing the; instrumentation map in XRay-instrumented object files and binaries. The; ``extract`` and ``stack`` subcommands uses this particular library. Minimizing Binary Size; ----------------------. XRay supports several different instrumentation points including ``function-entry``,; ``function-exit``, ``custom``, and ``typed`` points. These can be enabled individually; using the ``-fxray-instrumentation-bundle=`` flag. For example if you only wanted to; instrument function entry and custom points you could specify:. ::. clang -fxray-instrument -fxray-instrumentation-bundle=function-entry,custom ... This will omit the other sled types entirely, reducing the binary size. You can also; instrument just a sampled subset of functions using instrumentation groups.; For example, to instrument only a quarter of available functions invoke:. ::. clang -fxray-instrument -fxray-function-groups=4. A subset will be chosen arbitrarily based on a hash of the function name. To sample a; different subset you can specify ``-fxray-selected-function-group=`` with a group number; in the range of 0 to ``xray-function-groups`` - 1. Together these options could be used; to produce multiple binaries with different instrumented subsets. If all you need is; runtime control over which functions are being traced at any given time it is better; to selectively patch and unpatch the individual functions you need using the XRay; Runtime Library's ``__xray_patch_function()`` method. Future Work; ===========. There are a number of ongoing efforts for expanding the toolset building around; the XRay instrumentation system. Trace Analysis Tools; --------------------. - Work is in progress to integrate with or develop tools to visualize findings; from an XRay trace. Particularly, the ``stack`` tool is being expanded to; output formats that allow graphing and exploring the duration of time in each; call stack.; - With a large instrumented bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:4155,Testability,log,logging,4155," supported by clang; (x86_64, arm7, etc.). LLVM Function Attribute; -----------------------. If you're using LLVM IR directly, you can add the ``function-instrument``; string attribute to your functions, to get the similar effect that the; C/C++/Objective-C source-level attributes would get:. .. code-block:: llvm. define i32 @always_instrument() uwtable ""function-instrument""=""xray-always"" {; ; ...; }. define i32 @never_instrument() uwtable ""function-instrument""=""xray-never"" {; ; ...; }. You can also set the ``xray-instruction-threshold`` attribute and provide a; numeric string value for how many instructions should be in the function before; it gets instrumented. .. code-block:: llvm. define i32 @maybe_instrument() uwtable ""xray-instruction-threshold""=""2"" {; ; ...; }. Special Case File; -----------------. Attributes can be imbued through the use of special case files instead of; adding them to the original source files. You can use this to mark certain; functions and classes to be never, always, or instrumented with first-argument; logging from a file. The file's format is described below:. .. code-block:: bash. # Comments are supported; [always]; fun:always_instrument; fun:log_arg1=arg1 # Log the first argument for the function. [never]; fun:never_instrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:5245,Testability,log,log,5245,"code-block:: bash. # Comments are supported; [always]; fun:always_instrument; fun:log_arg1=arg1 # Log the first argument for the function. [never]; fun:never_instrument. These files can be provided through the ``-fxray-attr-list=`` flag to clang.; You may have multiple files loaded through multiple instances of the flag. XRay Runtime Library; --------------------. The XRay Runtime Library is part of the compiler-rt project, which implements; the runtime components that perform the patching and unpatching of inserted; instrumentation points. When you use ``clang`` to link your binaries and the; ``-fxray-instrument`` flag, it will automatically link in the XRay runtime. The default implementation of the XRay runtime will enable XRay instrumentation; before ``main`` starts, which works for applications that have a short; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:6108,Testability,log,log,6108,"ort; lifetime. This implementation also records all function entry and exit events; which may result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:6155,Testability,log,logfile,6155,"result in a lot of records in the resulting trace. Also by default the filename of the XRay trace is ``xray-log.XXXXXX`` where the; ``XXXXXX`` part is randomly generated. These options can be controlled through the ``XRAY_OPTIONS`` environment; variable, where we list down the options and their defaults below. +-------------------+-----------------+---------------+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:6439,Testability,log,logging,6439,"---+------------------------+; | Option | Type | Default | Description |; +===================+=================+===============+========================+; | patch_premain | ``bool`` | ``false`` | Whether to patch |; | | | | instrumentation points |; | | | | before main. |; +-------------------+-----------------+---------------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation throug",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:6800,Testability,log,logging,6800,"---------+------------------------+; | xray_mode | ``const char*`` | ``""""`` | Default mode to |; | | | | install and initialize |; | | | | before ``main``. |; +-------------------+-----------------+---------------+------------------------+; | xray_logfile_base | ``const char*`` | ``xray-log.`` | Filename base for the |; | | | | XRay logfile. |; +-------------------+-----------------+---------------+------------------------+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7273,Testability,log,logging,7273,"+; | verbosity | ``int`` | ``0`` | Runtime verbosity |; | | | | level. |; +-------------------+-----------------+---------------+------------------------+. If you choose to not use the default logging implementation that comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7396,Testability,log,logging,7396,"t comes with the; XRay runtime and/or control when/how the XRay instrumentation runs, you may use; the XRay APIs directly for doing so. To do this, you'll need to include the; ``xray_log_interface.h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8129,Testability,log,logging,8129," - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8225,Testability,log,log,8225," - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:8829,Testability,log,logging,8829,"t_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. Basic-mode specific; defaults can be provided in the ``XRAY_BASIC_OPTIONS`` environment variable. Flight Data Recorder Mode; -------------------------. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:9799,Testability,log,logging,9799,"-----. XRay supports a logging mode which allows the application to only capture a; fixed amount of memory's worth of events. Flight Data Recorder (FDR) mode works; very much like a plane's ""black box"" which keeps recording data to memory in a; fixed-size circular queue of buffers, and have the data available; programmatically until the buffers are finalized and flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support al",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10136,Testability,log,log,10136,"nd flushed. To use FDR mode; on your application, you may set the ``xray_mode`` variable to ``xray-fdr`` in; the ``XRAY_OPTIONS`` environment variable. Additional options to the FDR mode; implementation can be provided in the ``XRAY_FDR_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10398,Testability,log,log,10398,"_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10447,Testability,log,log,10447,"_OPTIONS`` environment; variable. Programmatic configuration can be done by calling; ``__xray_log_init_mode(""xray-fdr"", <configuration string>)`` once it has been; selected/installed. When the buffers are flushed to disk, the result is a binary trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10636,Testability,log,logs,10636,"trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10671,Testability,log,log,10671,"trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10717,Testability,log,log,10717,"trace format; described by `XRay FDR format <XRayFDRFormat.html>`_. When FDR mode is on, it will keep writing and recycling memory buffers until; the logging implementation is finalized -- at which point it can be flushed and; re-initialised later. To do this programmatically, we follow the workflow; provided below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:10972,Testability,log,log,10972,"ded below:. .. code-block:: c++. // Patch the sleds, if we haven't yet.; auto patch_status = __xray_patch();. // Maybe handle the patch_status errors. // When we want to flush the log, we need to finalize it first, to give; // threads a chance to return buffers to the queue.; auto finalize_status = __xray_log_finalize();; if (finalize_status != XRAY_LOG_FINALIZED) {; // maybe retry, or bail out.; }. // At this point, we are sure that the log is finalized, so we may try; // flushing the log.; auto flush_status = __xray_log_flushLog();; if (flush_status != XRAY_LOG_FLUSHED) {; // maybe retry, or bail out.; }. The default settings for the FDR mode implementation will create logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from one format to another. We can; convert from binary XRay traces (both basic and FDR mode) to YAML,; `flame-graph <https://github.com/brendangregg/FlameGraph>`_ friendly text; formats, as well as `Chrome Trace Viewer (catapult); <https://github.com/catapult-project/catapult>` formats.; - ``graph``: Generates a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:11634,Testability,log,log,11634," logs named; similarly to the basic log implementation, but will have a different log; format. All the trace analysis tools (and the trace reading library) will; support all versions of the FDR mode format as we add more functionality and; record types in the future. **NOTE:** We do not promise perpetual support for when we update the log; versions we support going forward. Deprecation of the formats will be; announced and discussed on the developers mailing list. Trace Analysis Tools; --------------------. We currently have the beginnings of a trace analysis tool in LLVM, which can be; found in the ``tools/llvm-xray`` directory. The ``llvm-xray`` tool currently; supports the following subcommands:. - ``extract``: Extract the instrumentation map from a binary, and return it as; YAML.; - ``account``: Performs basic function call accounting statistics with various; options for sorting, and output formats (supports CSV, YAML, and; console-friendly TEXT).; - ``convert``: Converts an XRay log file from one format to another. We can; convert from binary XRay traces (both basic and FDR mode) to YAML,; `flame-graph <https://github.com/brendangregg/FlameGraph>`_ friendly text; formats, as well as `Chrome Trace Viewer (catapult); <https://github.com/catapult-project/catapult>` formats.; - ``graph``: Generates a DOT graph of the function call relationships between; functions found in an XRay trace.; - ``stack``: Reconstructs function call stacks from a timeline of function; calls in an XRay trace. These subcommands use various library components found as part of the XRay; libraries, distributed with the LLVM distribution. These are:. - ``llvm/XRay/Trace.h`` : A trace reading library for conveniently loading; an XRay trace of supported forms, into a convenient in-memory representation.; All the analysis tools that deal with traces use this implementation.; - ``llvm/XRay/Graph.h`` : A semi-generic graph type used by the graph; subcommand to conveniently represent a function call",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst:7657,Usability,clear,cleared,7657,"h`` from the compiler-rt ``xray`` directory. The important API; functions we list below:. - ``__xray_log_register_mode(...)``: Register a logging implementation against; a string Mode identifier. The implementation is an instance of; ``XRayLogImpl`` defined in ``xray/xray_log_interface.h``.; - ``__xray_log_select_mode(...)``: Select the mode to install, associated with; a string Mode identifier. Only implementations registered with; ``__xray_log_register_mode(...)`` can be chosen with this function.; - ``__xray_log_init_mode(...)``: This function allows for initializing and; re-initializing an installed logging implementation. See; ``xray/xray_log_interface.h`` for details, part of the XRay compiler-rt; installation. Once a logging implementation has been initialized, it can be ""stopped"" by; finalizing the implementation through the ``__xray_log_finalize()`` function.; The finalization routine is the opposite of the initialization. When finalized,; an implementation's data can be cleared out through the; ``__xray_log_flushLog()`` function. For implementations that support in-memory; processing, these should register an iterator function to provide access to the; data via the ``__xray_log_set_buffer_iterator(...)`` which allows code calling; the ``__xray_log_process_buffers(...)`` function to deal with the data in; memory. All of this is better explained in the ``xray/xray_log_interface.h`` header. Basic Mode; ----------. XRay supports a basic logging mode which will trace the application's; execution, and periodically append to a single log. This mode can be; installed/enabled by setting ``xray_mode=xray-basic`` in the ``XRAY_OPTIONS``; environment variable. Combined with ``patch_premain=true`` this can allow for; tracing applications from start to end. Like all the other modes installed through ``__xray_log_select_mode(...)``, the; implementation can be configured through the ``__xray_log_init_mode(...)``; function, providing the mode string and the flag options. B",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:12689,Availability,avail,available,12689,"PPassManager::runOnFunction(llvm::Function&) 6 39331465; #5 llvm::PMDataManager::verifyPreservedAnalysis(llvm::Pass*) 399 16628590; #6 llvm::PMTopLevelManager::findAnalysisPass(void const*) 4584 15155600; #7 llvm::PMDataManager::findAnalysisPass(void const*, bool) 32088 9633790. ..etc.. In the default mode, identical stacks on different threads are independently; aggregated. In a multithreaded program, you may end up having identical call; stacks fill your list of top calls. To address this, you may specify the ``--aggregate-threads`` or; ``--per-thread-stacks`` flags. ``--per-thread-stacks`` treats the thread id as an; implicit root in each call stack tree, while ``--aggregate-threads`` combines; identical stacks from all threads. Flame Graph Generation; ----------------------. The ``llvm-xray stack`` tool may also be used to generate flamegraphs for; visualizing your instrumented invocations. The tool does not generate the graphs; themselves, but instead generates a format that can be used with Brendan Gregg's; FlameGraph tool, currently available on `github; <https://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxk",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:15034,Availability,avail,available,15034,"and. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; ++i) {; std::cerr << '-';; }; }. int main(int argc, char* argv[]) {; std::thread t1([] {; for (int i = 0; i < 1 << 10; ++i); f();; });; std::thread t2([] {; g();; });; t1.join();; t2.join();; std::cerr << '\n';; }. We then build the above with XRay instrumentation:. ::. $ clang++ -o sample -O3 sample.cc -std=c++11 -fxray-instrument -fxray-instruction-threshold=1; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic"" ./sample. We can then explore the graph rendering of the trace generated by this sample; application. We assume you have the graphviz tools available in your system,; including both ``unflatten`` and ``dot``. If you prefer rendering or exploring; the graph using another tool, then that should be feasible as well. ``llvm-xray; graph`` will create DOT format graphs which should be usable in most graph; rendering applications. One example invocation of the ``llvm-xray graph``; command should yield some interesting insights to the workings of C++; applications:. ::. $ llvm-xray graph xray-log.sample.* -m sample --color-edges=sum --edge-label=sum \; | unflatten -f -l10 | dot -Tsvg -o sample.svg. Next Steps; ----------. If you have some interesting analyses you'd like to implement as part of the; llvm-xray tool, please feel free to propose them on the llvm-dev@ mailing list.; The following are some ideas to inspire you in getting involved and potentially; making things better. - Implement a query/filtering library that allows for finding patterns in the; XRay traces.; - Collecting function call stacks and how often they're encountered in the; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:1594,Deployability,patch,patch,1594," add ``-fxray-instrument`` to the list of flags; passed to Clang when building a binary. Note that we need to link with Clang as; well to get the XRay runtime linked in appropriately. For building ``llc`` with; XRay, we do something similar below for our LLVM build:. ::. $ mkdir -p llvm-build && cd llvm-build; # Assume that the LLVM sources are at ../llvm; $ cmake -GNinja ../llvm -DCMAKE_BUILD_TYPE=Release \; -DCMAKE_C_FLAGS_RELEASE=""-fxray-instrument"" -DCMAKE_CXX_FLAGS=""-fxray-instrument"" \; # Once this finishes, we should build llc; $ ninja llc. To verify that we have an XRay instrumented binary, we can use ``objdump`` to; look for the ``xray_instr_map`` section. ::. $ objdump -h -j xray_instr_map ./bin/llc; ./bin/llc: file format elf64-x86-64. Sections:; Idx Name Size VMA LMA File off Algn; 14 xray_instr_map 00002fc0 00000000041516c6 00000000041516c6 03d516c6 2**0; CONTENTS, ALLOC, LOAD, READONLY, DATA. Getting Traces; --------------. By default, XRay does not write out the trace files or patch the application; before main starts. If we run ``llc`` it should work like a normally built; binary. If we want to get a full trace of the application's operations (of the; functions we do end up instrumenting with XRay) then we need to enable XRay; at application start. To do this, XRay checks the ``XRAY_OPTIONS`` environment; variable. ::. # The following doesn't create an XRay trace by default.; $ ./bin/llc input.ll. # We need to set the XRAY_OPTIONS to enable some features.; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic verbosity=1"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.m35qPB'. At this point we now have an XRay trace we can start analysing. The ``llvm-xray`` Tool; ----------------------. Having a trace then allows us to do basic accounting of the functions that were; instrumented, and how much time we're spending in parts of the code. To make; sense of this data, we use the ``llvm-xray`` tool which has a few subcommands; to help us und",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:10015,Deployability,configurat,configuration,10015,"assManager.cpp:1564:0: (anonymous namespace)::MPPassManager::runOnModule(llvm::Module&); 139607 2 [ 0.147345, 0.315994, 0.315994, 0.315994, 0.315994] 0.463340 LegacyPassManager.cpp:1530:0: llvm::FPPassManager::runOnModule(llvm::Module&); 139605 21 [ 0.000002, 0.000002, 0.102593, 0.213336, 0.213336] 0.463331 LegacyPassManager.cpp:1491:0: llvm::FPPassManager::runOnFunction(llvm::Function&); 139563 26096 [ 0.000002, 0.000002, 0.000037, 0.000063, 0.000215] 0.225708 LegacyPassManager.cpp:1083:0: llvm::PMDataManager::findAnalysisPass(void const*, bool); 108055 188 [ 0.000002, 0.000120, 0.001375, 0.004523, 0.062624] 0.159279 MachineFunctionPass.cpp:38:0: llvm::MachineFunctionPass::runOnFunction(llvm::Function&); 62635 22 [ 0.000041, 0.000046, 0.000050, 0.126744, 0.126744] 0.127715 X86TargetMachine.cpp:242:0: llvm::X86TargetMachine::getSubtargetImpl(llvm::Function const&) const. Instrumentation Attributes; ``````````````````````````. The other way is to use configuration files for selecting which functions; should always be instrumented by the compiler. This gives us a way of ensuring; that certain functions are either always or never instrumented by not having to; add the attribute to the source. To use this feature, you can define one file for the functions to always; instrument, and another for functions to never instrument. The format of these; files are exactly the same as the SanitizerLists files that control similar; things for the sanitizer implementations. For example:. ::. # xray-attr-list.txt; # always instrument functions that match the following filters:; [always]; fun:main. # never instrument functions that match the following filters:; [never]; fun:__cxx_*. Given the file above we can re-build by providing it to the; ``-fxray-attr-list=`` flag to clang. You can have multiple files, each defining; different sets of attribute sets, to be combined into a single list by clang. The XRay stack tool; -------------------. Given a trace, and optionally an instrumentat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:1930,Modifiability,variab,variable,1930,"me that the LLVM sources are at ../llvm; $ cmake -GNinja ../llvm -DCMAKE_BUILD_TYPE=Release \; -DCMAKE_C_FLAGS_RELEASE=""-fxray-instrument"" -DCMAKE_CXX_FLAGS=""-fxray-instrument"" \; # Once this finishes, we should build llc; $ ninja llc. To verify that we have an XRay instrumented binary, we can use ``objdump`` to; look for the ``xray_instr_map`` section. ::. $ objdump -h -j xray_instr_map ./bin/llc; ./bin/llc: file format elf64-x86-64. Sections:; Idx Name Size VMA LMA File off Algn; 14 xray_instr_map 00002fc0 00000000041516c6 00000000041516c6 03d516c6 2**0; CONTENTS, ALLOC, LOAD, READONLY, DATA. Getting Traces; --------------. By default, XRay does not write out the trace files or patch the application; before main starts. If we run ``llc`` it should work like a normally built; binary. If we want to get a full trace of the application's operations (of the; functions we do end up instrumenting with XRay) then we need to enable XRay; at application start. To do this, XRay checks the ``XRAY_OPTIONS`` environment; variable. ::. # The following doesn't create an XRay trace by default.; $ ./bin/llc input.ll. # We need to set the XRAY_OPTIONS to enable some features.; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic verbosity=1"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.m35qPB'. At this point we now have an XRay trace we can start analysing. The ``llvm-xray`` Tool; ----------------------. Having a trace then allows us to do basic accounting of the functions that were; instrumented, and how much time we're spending in parts of the code. To make; sense of this data, we use the ``llvm-xray`` tool which has a few subcommands; to help us understand our trace. One of the things we can do is to get an accounting of the functions that have; been instrumented. We can see an example accounting with ``llvm-xray account``:. ::. $ llvm-xray account xray-log.llc.m35qPB --top=10 --sort=sum --sortorder=dsc --instr_map=./bin/llc; Functions with latencies: 29; funci",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:10015,Modifiability,config,configuration,10015,"assManager.cpp:1564:0: (anonymous namespace)::MPPassManager::runOnModule(llvm::Module&); 139607 2 [ 0.147345, 0.315994, 0.315994, 0.315994, 0.315994] 0.463340 LegacyPassManager.cpp:1530:0: llvm::FPPassManager::runOnModule(llvm::Module&); 139605 21 [ 0.000002, 0.000002, 0.102593, 0.213336, 0.213336] 0.463331 LegacyPassManager.cpp:1491:0: llvm::FPPassManager::runOnFunction(llvm::Function&); 139563 26096 [ 0.000002, 0.000002, 0.000037, 0.000063, 0.000215] 0.225708 LegacyPassManager.cpp:1083:0: llvm::PMDataManager::findAnalysisPass(void const*, bool); 108055 188 [ 0.000002, 0.000120, 0.001375, 0.004523, 0.062624] 0.159279 MachineFunctionPass.cpp:38:0: llvm::MachineFunctionPass::runOnFunction(llvm::Function&); 62635 22 [ 0.000041, 0.000046, 0.000050, 0.126744, 0.126744] 0.127715 X86TargetMachine.cpp:242:0: llvm::X86TargetMachine::getSubtargetImpl(llvm::Function const&) const. Instrumentation Attributes; ``````````````````````````. The other way is to use configuration files for selecting which functions; should always be instrumented by the compiler. This gives us a way of ensuring; that certain functions are either always or never instrumented by not having to; add the attribute to the source. To use this feature, you can define one file for the functions to always; instrument, and another for functions to never instrument. The format of these; files are exactly the same as the SanitizerLists files that control similar; things for the sanitizer implementations. For example:. ::. # xray-attr-list.txt; # always instrument functions that match the following filters:; [always]; fun:main. # never instrument functions that match the following filters:; [never]; fun:__cxx_*. Given the file above we can re-build by providing it to the; ``-fxray-attr-list=`` flag to clang. You can have multiple files, each defining; different sets of attribute sets, to be combined into a single list by clang. The XRay stack tool; -------------------. Given a trace, and optionally an instrumentat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13460,Performance,load,loaded,13460," generate flamegraphs for; visualizing your instrumented invocations. The tool does not generate the graphs; themselves, but instead generates a format that can be used with Brendan Gregg's; FlameGraph tool, currently available on `github; <https://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; +",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13738,Performance,load,load,13738,"tps://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; ++i) {; std::cerr << '-';; }; }. int main(int argc, char* argv[]) {; std::thread t1([] {; for (int i = 0; i < 1 << 10; ++i); f();; });; std::thread t2([] {; g();; });; t1.join();; t2.join();; std::cerr << '\n';; }. We then build the above with",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:10506,Security,sanitiz,sanitizer,10506,"0002, 0.000002, 0.000037, 0.000063, 0.000215] 0.225708 LegacyPassManager.cpp:1083:0: llvm::PMDataManager::findAnalysisPass(void const*, bool); 108055 188 [ 0.000002, 0.000120, 0.001375, 0.004523, 0.062624] 0.159279 MachineFunctionPass.cpp:38:0: llvm::MachineFunctionPass::runOnFunction(llvm::Function&); 62635 22 [ 0.000041, 0.000046, 0.000050, 0.126744, 0.126744] 0.127715 X86TargetMachine.cpp:242:0: llvm::X86TargetMachine::getSubtargetImpl(llvm::Function const&) const. Instrumentation Attributes; ``````````````````````````. The other way is to use configuration files for selecting which functions; should always be instrumented by the compiler. This gives us a way of ensuring; that certain functions are either always or never instrumented by not having to; add the attribute to the source. To use this feature, you can define one file for the functions to always; instrument, and another for functions to never instrument. The format of these; files are exactly the same as the SanitizerLists files that control similar; things for the sanitizer implementations. For example:. ::. # xray-attr-list.txt; # always instrument functions that match the following filters:; [always]; fun:main. # never instrument functions that match the following filters:; [never]; fun:__cxx_*. Given the file above we can re-build by providing it to the; ``-fxray-attr-list=`` flag to clang. You can have multiple files, each defining; different sets of attribute sets, to be combined into a single list by clang. The XRay stack tool; -------------------. Given a trace, and optionally an instrumentation map, the ``llvm-xray stack``; command can be used to analyze a call stack graph constructed from the function; call timeline. The way to use the command is to output the top stacks by call count and time spent. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc. Unique Stacks: 3069; Top 10 Stacks by leaf sum:. Sum: 9633790; lvl function count sum; #0 main 1 58421550; #1 compileModule(char**,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:2206,Testability,log,log,2206,"ry, we can use ``objdump`` to; look for the ``xray_instr_map`` section. ::. $ objdump -h -j xray_instr_map ./bin/llc; ./bin/llc: file format elf64-x86-64. Sections:; Idx Name Size VMA LMA File off Algn; 14 xray_instr_map 00002fc0 00000000041516c6 00000000041516c6 03d516c6 2**0; CONTENTS, ALLOC, LOAD, READONLY, DATA. Getting Traces; --------------. By default, XRay does not write out the trace files or patch the application; before main starts. If we run ``llc`` it should work like a normally built; binary. If we want to get a full trace of the application's operations (of the; functions we do end up instrumenting with XRay) then we need to enable XRay; at application start. To do this, XRay checks the ``XRAY_OPTIONS`` environment; variable. ::. # The following doesn't create an XRay trace by default.; $ ./bin/llc input.ll. # We need to set the XRAY_OPTIONS to enable some features.; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic verbosity=1"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.m35qPB'. At this point we now have an XRay trace we can start analysing. The ``llvm-xray`` Tool; ----------------------. Having a trace then allows us to do basic accounting of the functions that were; instrumented, and how much time we're spending in parts of the code. To make; sense of this data, we use the ``llvm-xray`` tool which has a few subcommands; to help us understand our trace. One of the things we can do is to get an accounting of the functions that have; been instrumented. We can see an example accounting with ``llvm-xray account``:. ::. $ llvm-xray account xray-log.llc.m35qPB --top=10 --sort=sum --sortorder=dsc --instr_map=./bin/llc; Functions with latencies: 29; funcid count [ min, med, 90p, 99p, max] sum function; 187 360 [ 0.000000, 0.000001, 0.000014, 0.000032, 0.000075] 0.001596 LLLexer.cpp:446:0: llvm::LLLexer::LexIdentifier(); 85 130 [ 0.000000, 0.000000, 0.000018, 0.000023, 0.000156] 0.000799 X86ISelDAGToDAG.cpp:1984:0: (anonymous namespace",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:2796,Testability,log,log,2796," do end up instrumenting with XRay) then we need to enable XRay; at application start. To do this, XRay checks the ``XRAY_OPTIONS`` environment; variable. ::. # The following doesn't create an XRay trace by default.; $ ./bin/llc input.ll. # We need to set the XRAY_OPTIONS to enable some features.; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic verbosity=1"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.m35qPB'. At this point we now have an XRay trace we can start analysing. The ``llvm-xray`` Tool; ----------------------. Having a trace then allows us to do basic accounting of the functions that were; instrumented, and how much time we're spending in parts of the code. To make; sense of this data, we use the ``llvm-xray`` tool which has a few subcommands; to help us understand our trace. One of the things we can do is to get an accounting of the functions that have; been instrumented. We can see an example accounting with ``llvm-xray account``:. ::. $ llvm-xray account xray-log.llc.m35qPB --top=10 --sort=sum --sortorder=dsc --instr_map=./bin/llc; Functions with latencies: 29; funcid count [ min, med, 90p, 99p, max] sum function; 187 360 [ 0.000000, 0.000001, 0.000014, 0.000032, 0.000075] 0.001596 LLLexer.cpp:446:0: llvm::LLLexer::LexIdentifier(); 85 130 [ 0.000000, 0.000000, 0.000018, 0.000023, 0.000156] 0.000799 X86ISelDAGToDAG.cpp:1984:0: (anonymous namespace)::X86DAGToDAGISel::Select(llvm::SDNode*); 138 130 [ 0.000000, 0.000000, 0.000017, 0.000155, 0.000155] 0.000774 SelectionDAGISel.cpp:2963:0: llvm::SelectionDAGISel::SelectCodeCommon(llvm::SDNode*, unsigned char const*, unsigned int); 188 103 [ 0.000000, 0.000000, 0.000003, 0.000123, 0.000214] 0.000737 LLParser.cpp:2692:0: llvm::LLParser::ParseValID(llvm::ValID&, llvm::LLParser::PerFunctionState*); 88 1 [ 0.000562, 0.000562, 0.000562, 0.000562, 0.000562] 0.000562 X86ISelLowering.cpp:83:0: llvm::X86TargetLowering::X86TargetLowering(llvm::X86TargetMachine const&, llvm::X86Subtarget const&); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:5301,Testability,log,log,5301,"n(llvm::Function const&); 123 1 [ 0.000302, 0.000302, 0.000302, 0.000302, 0.000302] 0.000302 LLVMContextImpl.cpp:54:0: llvm::LLVMContextImpl::~LLVMContextImpl(); 139 46 [ 0.000000, 0.000002, 0.000006, 0.000008, 0.000019] 0.000138 TargetLowering.cpp:506:0: llvm::TargetLowering::SimplifyDemandedBits(llvm::SDValue, llvm::APInt const&, llvm::APInt&, llvm::APInt&, llvm::TargetLowering::TargetLoweringOpt&, unsigned int, bool) const. This shows us that for our input file, ``llc`` spent the most cumulative time; in the lexer (a total of 1 millisecond). If we wanted for example to work with; this data in a spreadsheet, we can output the results as CSV using the; ``-format=csv`` option to the command for further analysis. If we want to get a textual representation of the raw trace we can use the; ``llvm-xray convert`` tool to get YAML output. The first few lines of that; output for an example trace would look like the following:. ::. $ llvm-xray convert -f yaml --symbolize --instr_map=./bin/llc xray-log.llc.m35qPB; ---; header:; version: 1; type: 0; constant-tsc: true; nonstop-tsc: true; cycle-frequency: 2601000000; records:; - { type: 0, func-id: 110, function: __cxx_global_var_init.8, cpu: 37, thread: 69819, kind: function-enter, tsc: 5434426023268520 }; - { type: 0, func-id: 110, function: __cxx_global_var_init.8, cpu: 37, thread: 69819, kind: function-exit, tsc: 5434426023523052 }; - { type: 0, func-id: 164, function: __cxx_global_var_init, cpu: 37, thread: 69819, kind: function-enter, tsc: 5434426029925386 }; - { type: 0, func-id: 164, function: __cxx_global_var_init, cpu: 37, thread: 69819, kind: function-exit, tsc: 5434426030031128 }; - { type: 0, func-id: 142, function: '(anonymous namespace)::CommandLineParser::ParseCommandLineOptions(int, char const* const*, llvm::StringRef, llvm::raw_ostream*)', cpu: 37, thread: 69819, kind: function-enter, tsc: 5434426046951388 }; - { type: 0, func-id: 142, function: '(anonymous namespace)::CommandLineParser::ParseCommandLineOptio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:8262,Testability,log,log,8262,"ction-exit, tsc: 5434426048067316 }. Controlling Fidelity; --------------------. So far in our examples, we haven't been getting full coverage of the functions; we have in the binary. To get that, we need to modify the compiler flags so; that we can instrument more (if not all) the functions we have in the binary.; We have two options for doing that, and we explore both of these below. Instruction Threshold; `````````````````````. The first ""blunt"" way of doing this is by setting the minimum threshold for; function bodies to 1. We can do that with the; ``-fxray-instruction-threshold=N`` flag when building our binary. We rebuild; ``llc`` with this option and observe the results:. ::. $ rm CMakeCache.txt; $ cmake -GNinja ../llvm -DCMAKE_BUILD_TYPE=Release \; -DCMAKE_C_FLAGS_RELEASE=""-fxray-instrument -fxray-instruction-threshold=1"" \; -DCMAKE_CXX_FLAGS=""-fxray-instrument -fxray-instruction-threshold=1""; $ ninja llc; $ XRAY_OPTIONS=""patch_premain=true"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.5rqxkU'. $ llvm-xray account xray-log.llc.5rqxkU --top=10 --sort=sum --sortorder=dsc --instr_map=./bin/llc; Functions with latencies: 36652; funcid count [ min, med, 90p, 99p, max] sum function; 75 1 [ 0.672368, 0.672368, 0.672368, 0.672368, 0.672368] 0.672368 llc.cpp:271:0: main; 78 1 [ 0.626455, 0.626455, 0.626455, 0.626455, 0.626455] 0.626455 llc.cpp:381:0: compileModule(char**, llvm::LLVMContext&); 139617 1 [ 0.472618, 0.472618, 0.472618, 0.472618, 0.472618] 0.472618 LegacyPassManager.cpp:1723:0: llvm::legacy::PassManager::run(llvm::Module&); 139610 1 [ 0.472618, 0.472618, 0.472618, 0.472618, 0.472618] 0.472618 LegacyPassManager.cpp:1681:0: llvm::legacy::PassManagerImpl::run(llvm::Module&); 139612 1 [ 0.470948, 0.470948, 0.470948, 0.470948, 0.470948] 0.470948 LegacyPassManager.cpp:1564:0: (anonymous namespace)::MPPassManager::runOnModule(llvm::Module&); 139607 2 [ 0.147345, 0.315994, 0.315994, 0.315994, 0.315994] 0.463340 LegacyPassManager.cpp:1530:0: llvm::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:8304,Testability,log,log,8304," Fidelity; --------------------. So far in our examples, we haven't been getting full coverage of the functions; we have in the binary. To get that, we need to modify the compiler flags so; that we can instrument more (if not all) the functions we have in the binary.; We have two options for doing that, and we explore both of these below. Instruction Threshold; `````````````````````. The first ""blunt"" way of doing this is by setting the minimum threshold for; function bodies to 1. We can do that with the; ``-fxray-instruction-threshold=N`` flag when building our binary. We rebuild; ``llc`` with this option and observe the results:. ::. $ rm CMakeCache.txt; $ cmake -GNinja ../llvm -DCMAKE_BUILD_TYPE=Release \; -DCMAKE_C_FLAGS_RELEASE=""-fxray-instrument -fxray-instruction-threshold=1"" \; -DCMAKE_CXX_FLAGS=""-fxray-instrument -fxray-instruction-threshold=1""; $ ninja llc; $ XRAY_OPTIONS=""patch_premain=true"" ./bin/llc input.ll; ==69819==XRay: Log file in 'xray-log.llc.5rqxkU'. $ llvm-xray account xray-log.llc.5rqxkU --top=10 --sort=sum --sortorder=dsc --instr_map=./bin/llc; Functions with latencies: 36652; funcid count [ min, med, 90p, 99p, max] sum function; 75 1 [ 0.672368, 0.672368, 0.672368, 0.672368, 0.672368] 0.672368 llc.cpp:271:0: main; 78 1 [ 0.626455, 0.626455, 0.626455, 0.626455, 0.626455] 0.626455 llc.cpp:381:0: compileModule(char**, llvm::LLVMContext&); 139617 1 [ 0.472618, 0.472618, 0.472618, 0.472618, 0.472618] 0.472618 LegacyPassManager.cpp:1723:0: llvm::legacy::PassManager::run(llvm::Module&); 139610 1 [ 0.472618, 0.472618, 0.472618, 0.472618, 0.472618] 0.472618 LegacyPassManager.cpp:1681:0: llvm::legacy::PassManagerImpl::run(llvm::Module&); 139612 1 [ 0.470948, 0.470948, 0.470948, 0.470948, 0.470948] 0.470948 LegacyPassManager.cpp:1564:0: (anonymous namespace)::MPPassManager::runOnModule(llvm::Module&); 139607 2 [ 0.147345, 0.315994, 0.315994, 0.315994, 0.315994] 0.463340 LegacyPassManager.cpp:1530:0: llvm::FPPassManager::runOnModule(llvm::Module&); 1396",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:11293,Testability,log,log,11293,"u can define one file for the functions to always; instrument, and another for functions to never instrument. The format of these; files are exactly the same as the SanitizerLists files that control similar; things for the sanitizer implementations. For example:. ::. # xray-attr-list.txt; # always instrument functions that match the following filters:; [always]; fun:main. # never instrument functions that match the following filters:; [never]; fun:__cxx_*. Given the file above we can re-build by providing it to the; ``-fxray-attr-list=`` flag to clang. You can have multiple files, each defining; different sets of attribute sets, to be combined into a single list by clang. The XRay stack tool; -------------------. Given a trace, and optionally an instrumentation map, the ``llvm-xray stack``; command can be used to analyze a call stack graph constructed from the function; call timeline. The way to use the command is to output the top stacks by call count and time spent. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc. Unique Stacks: 3069; Top 10 Stacks by leaf sum:. Sum: 9633790; lvl function count sum; #0 main 1 58421550; #1 compileModule(char**, llvm::LLVMContext&) 1 51440360; #2 llvm::legacy::PassManagerImpl::run(llvm::Module&) 1 40535375; #3 llvm::FPPassManager::runOnModule(llvm::Module&) 2 39337525; #4 llvm::FPPassManager::runOnFunction(llvm::Function&) 6 39331465; #5 llvm::PMDataManager::verifyPreservedAnalysis(llvm::Pass*) 399 16628590; #6 llvm::PMTopLevelManager::findAnalysisPass(void const*) 4584 15155600; #7 llvm::PMDataManager::findAnalysisPass(void const*, bool) 32088 9633790. ..etc.. In the default mode, identical stacks on different threads are independently; aggregated. In a multithreaded program, you may end up having identical call; stacks fill your list of top calls. To address this, you may specify the ``--aggregate-threads`` or; ``--per-thread-stacks`` flags. ``--per-thread-stacks`` treats the thread id as an; implicit root in each ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13116,Testability,log,log,13116,"calls. To address this, you may specify the ``--aggregate-threads`` or; ``--per-thread-stacks`` flags. ``--per-thread-stacks`` treats the thread id as an; implicit root in each call stack tree, while ``--aggregate-threads`` combines; identical stacks from all threads. Flame Graph Generation; ----------------------. The ``llvm-xray stack`` tool may also be used to generate flamegraphs for; visualizing your instrumented invocations. The tool does not generate the graphs; themselves, but instead generates a format that can be used with Brendan Gregg's; FlameGraph tool, currently available on `github; <https://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:13621,Testability,log,log,13621,"ead generates a format that can be used with Brendan Gregg's; FlameGraph tool, currently available on `github; <https://github.com/brendangregg/FlameGraph>`_. To generate output for a flamegraph, a few more options are necessary. - ``--all-stacks`` - Emits all of the stacks.; - ``--stack-format`` - Choose the flamegraph output format 'flame'.; - ``--aggregation-type`` - Choose the metric to graph. You may pipe the command output directly to the flamegraph tool to obtain an; svg file. ::. $ llvm-xray stack xray-log.llc.5rqxkU --instr_map=./bin/llc --stack-format=flame --aggregation-type=time --all-stacks | \; /path/to/FlameGraph/flamegraph.pl > flamegraph.svg. If you open the svg in a browser, mouse events allow exploring the call stacks. Chrome Trace Viewer Visualization; ---------------------------------. We can also generate a trace which can be loaded by the Chrome Trace Viewer; from the same generated trace:. ::. $ llvm-xray convert --symbolize --instr_map=./bin/llc \; --output-format=trace_event xray-log.llc.5rqxkU \; | gzip > llc-trace.txt.gz. From a Chrome browser, navigating to ``chrome:///tracing`` allows us to load; the ``sample-trace.txt.gz`` file to visualize the execution trace. Further Exploration; -------------------. The ``llvm-xray`` tool has a few other subcommands that are in various stages; of being developed. One interesting subcommand that can highlight a few; interesting things is the ``graph`` subcommand. Given for example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; ++i) {; std::cerr << '-';; }; }. int main(int argc, char* argv[]) {; std::thread t1([] {; for (int i = 0; i < 1 << 10; ++i); f();;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:15486,Testability,log,log,15486," example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; ++i) {; std::cerr << '-';; }; }. int main(int argc, char* argv[]) {; std::thread t1([] {; for (int i = 0; i < 1 << 10; ++i); f();; });; std::thread t2([] {; g();; });; t1.join();; t2.join();; std::cerr << '\n';; }. We then build the above with XRay instrumentation:. ::. $ clang++ -o sample -O3 sample.cc -std=c++11 -fxray-instrument -fxray-instruction-threshold=1; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic"" ./sample. We can then explore the graph rendering of the trace generated by this sample; application. We assume you have the graphviz tools available in your system,; including both ``unflatten`` and ``dot``. If you prefer rendering or exploring; the graph using another tool, then that should be feasible as well. ``llvm-xray; graph`` will create DOT format graphs which should be usable in most graph; rendering applications. One example invocation of the ``llvm-xray graph``; command should yield some interesting insights to the workings of C++; applications:. ::. $ llvm-xray graph xray-log.sample.* -m sample --color-edges=sum --edge-label=sum \; | unflatten -f -l10 | dot -Tsvg -o sample.svg. Next Steps; ----------. If you have some interesting analyses you'd like to implement as part of the; llvm-xray tool, please feel free to propose them on the llvm-dev@ mailing list.; The following are some ideas to inspire you in getting involved and potentially; making things better. - Implement a query/filtering library that allows for finding patterns in the; XRay traces.; - Collecting function call stacks and how often they're encountered in the; XRay trace.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst:15276,Usability,usab,usable,15276," example the following; toy program that we build with XRay instrumentation, we can see how the; generated graph may be a helpful indicator of where time is being spent for the; application. .. code-block:: c++. // sample.cc; #include <iostream>; #include <thread>. [[clang::xray_always_instrument]] void f() {; std::cerr << '.';; }. [[clang::xray_always_instrument]] void g() {; for (int i = 0; i < 1 << 10; ++i) {; std::cerr << '-';; }; }. int main(int argc, char* argv[]) {; std::thread t1([] {; for (int i = 0; i < 1 << 10; ++i); f();; });; std::thread t2([] {; g();; });; t1.join();; t2.join();; std::cerr << '\n';; }. We then build the above with XRay instrumentation:. ::. $ clang++ -o sample -O3 sample.cc -std=c++11 -fxray-instrument -fxray-instruction-threshold=1; $ XRAY_OPTIONS=""patch_premain=true xray_mode=xray-basic"" ./sample. We can then explore the graph rendering of the trace generated by this sample; application. We assume you have the graphviz tools available in your system,; including both ``unflatten`` and ``dot``. If you prefer rendering or exploring; the graph using another tool, then that should be feasible as well. ``llvm-xray; graph`` will create DOT format graphs which should be usable in most graph; rendering applications. One example invocation of the ``llvm-xray graph``; command should yield some interesting insights to the workings of C++; applications:. ::. $ llvm-xray graph xray-log.sample.* -m sample --color-edges=sum --edge-label=sum \; | unflatten -f -l10 | dot -Tsvg -o sample.svg. Next Steps; ----------. If you have some interesting analyses you'd like to implement as part of the; llvm-xray tool, please feel free to propose them on the llvm-dev@ mailing list.; The following are some ideas to inspire you in getting involved and potentially; making things better. - Implement a query/filtering library that allows for finding patterns in the; XRay traces.; - Collecting function call stacks and how often they're encountered in the; XRay trace.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayExample.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayExample.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:6566,Availability,mask,mask,6566,", or is a non-standard entry |; | | | or exit produced by optimizations. |; +---------------+--------------+-----------------------------------------------+; | function_id | ``28`` | A numeric ID for the function. Resolved to a |; | | | name via the xray instrumentation map. The |; | | | instrumentation map is built by xray at |; | | | compile time into an object file and pairs |; | | | the function ids to addresses. It is used for |; | | | patching and as a lookup into the binary's |; | | | symbols to obtain names. |; +---------------+--------------+-----------------------------------------------+; | tsc_delta | ``32`` | The number of ticks of the timestamp counter |; | | | since a previous record recorded a delta or |; | | | other TSC resetting event. |; +---------------+--------------+-----------------------------------------------+. On little-endian machines, the bitfields are ordered from least significant bit; bit to most significant bit. A reader can read an 8 bit value and apply the mask; ``0x01`` for the discriminant. Similarly, they can read 32 bits and unsigned; shift right by ``0x04`` to obtain the function_id field. On big-endian machine, the bitfields are written in order from most significant; bit to least significant bit. A reader would read an 8 bit value and unsigned; shift right by 7 bits for the discriminant. The function_id field could be; obtained by reading a 32 bit value and applying the mask ``0x0FFFFFFF``. Function action types are as follows. +---------------+--------------+-----------------------------------------------+; | Type | Number | Description |; +===============+==============+===============================================+; | Entry | ``0`` | Typical function entry. |; +---------------+--------------+-----------------------------------------------+; | Exit | ``1`` | Typical function exit. |; +---------------+--------------+-----------------------------------------------+; | Tail_Exit | ``2`` | An exit from a function due to tail",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:6995,Availability,mask,mask,6995," ids to addresses. It is used for |; | | | patching and as a lookup into the binary's |; | | | symbols to obtain names. |; +---------------+--------------+-----------------------------------------------+; | tsc_delta | ``32`` | The number of ticks of the timestamp counter |; | | | since a previous record recorded a delta or |; | | | other TSC resetting event. |; +---------------+--------------+-----------------------------------------------+. On little-endian machines, the bitfields are ordered from least significant bit; bit to most significant bit. A reader can read an 8 bit value and apply the mask; ``0x01`` for the discriminant. Similarly, they can read 32 bits and unsigned; shift right by ``0x04`` to obtain the function_id field. On big-endian machine, the bitfields are written in order from most significant; bit to least significant bit. A reader would read an 8 bit value and unsigned; shift right by 7 bits for the discriminant. The function_id field could be; obtained by reading a 32 bit value and applying the mask ``0x0FFFFFFF``. Function action types are as follows. +---------------+--------------+-----------------------------------------------+; | Type | Number | Description |; +===============+==============+===============================================+; | Entry | ``0`` | Typical function entry. |; +---------------+--------------+-----------------------------------------------+; | Exit | ``1`` | Typical function exit. |; +---------------+--------------+-----------------------------------------------+; | Tail_Exit | ``2`` | An exit from a function due to tail call |; | | | optimization. |; +---------------+--------------+-----------------------------------------------+; | Entry_Args | ``3`` | A function entry that records arguments. |; +---------------+--------------+-----------------------------------------------+. Entry_Args records do not contain the arguments themselves. Instead, metadata; records for each of the logged args follow the function recor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:6005,Deployability,patch,patching,6005,"durations. +---------------+--------------+-----------------------------------------------+; | Field | Size (bits) | Description |; +===============+==============+===============================================+; | discriminant | ``1`` | Indicates whether a reader should read a |; | | | Function or Metadata record. Set to ``0`` for |; | | | Function records. |; +---------------+--------------+-----------------------------------------------+; | action | ``3`` | Specifies whether the function is being |; | | | entered, exited, or is a non-standard entry |; | | | or exit produced by optimizations. |; +---------------+--------------+-----------------------------------------------+; | function_id | ``28`` | A numeric ID for the function. Resolved to a |; | | | name via the xray instrumentation map. The |; | | | instrumentation map is built by xray at |; | | | compile time into an object file and pairs |; | | | the function ids to addresses. It is used for |; | | | patching and as a lookup into the binary's |; | | | symbols to obtain names. |; +---------------+--------------+-----------------------------------------------+; | tsc_delta | ``32`` | The number of ticks of the timestamp counter |; | | | since a previous record recorded a delta or |; | | | other TSC resetting event. |; +---------------+--------------+-----------------------------------------------+. On little-endian machines, the bitfields are ordered from least significant bit; bit to most significant bit. A reader can read an 8 bit value and apply the mask; ``0x01`` for the discriminant. Similarly, they can read 32 bits and unsigned; shift right by ``0x04`` to obtain the function_id field. On big-endian machine, the bitfields are written in order from most significant; bit to least significant bit. A reader would read an 8 bit value and unsigned; shift right by 7 bits for the discriminant. The function_id field could be; obtained by reading a 32 bit value and applying the mask ``0x0FFFFFFF``. Function action",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:2947,Energy Efficiency,power,power,2947,"---------------+----------------------------------------+; | buffer_size | ``8`` | The size in bytes of the data portion |; | | | of the trace following the header. |; +-------------------+-----------------+----------------------------------------+; | reserved | ``8`` | Reserved for future use. |; +-------------------+-----------------+----------------------------------------+. The bitfield parameter of the file header is composed of the following fields. +-------------------+----------------+-----------------------------------------+; | Field | Size (bits) | Description |; +===================+================+=========================================+; | constant_tsc | ``1`` | Whether the platform's timestamp |; | | | counter used to record ticks between |; | | | events ticks at a constant frequency |; | | | despite CPU frequency changes. |; | | | 0 == non-constant. 1 == constant. |; +-------------------+----------------+-----------------------------------------+; | nonstop_tsc | ``1`` | Whether the tsc continues to count |; | | | despite whether the CPU is in a low |; | | | power state. 0 == stop. 1 == non-stop. |; +-------------------+----------------+-----------------------------------------+; | reserved | ``30`` | Not meaningful. |; +-------------------+----------------+-----------------------------------------+. Data Section; ============. Following the header in a trace is a data section with size matching the; buffer_size field in the header. The data section is a stream of elements of different types. There are a few categories of data in the sequence. - ``Function Records``: Function Records contain the timing of entry into and; exit from function execution. Function Records have 8 bytes each. - ``Metadata Records``: Metadata records serve many purposes. Mostly, they; capture information that may be too costly to record for each function, but; that is required to contextualize the fine-grained timings. They also are used; as markers for user-defined Event ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:8272,Integrability,depend,dependent,8272,"cal function entry. |; +---------------+--------------+-----------------------------------------------+; | Exit | ``1`` | Typical function exit. |; +---------------+--------------+-----------------------------------------------+; | Tail_Exit | ``2`` | An exit from a function due to tail call |; | | | optimization. |; +---------------+--------------+-----------------------------------------------+; | Entry_Args | ``3`` | A function entry that records arguments. |; +---------------+--------------+-----------------------------------------------+. Entry_Args records do not contain the arguments themselves. Instead, metadata; records for each of the logged args follow the function record in the stream. Metadata Records; ----------------. Interspersed throughout the buffer are 16 byte Metadata records. For typically; instrumented binaries, they will be sparser than Function records, and they; provide a fuller picture of the binary execution state. Metadata record layout is partially record dependent, but they share a common; structure. The same bit field rules described for function records apply to the first byte; of MetadataRecords. Within this byte, little endian machines use lsb to msb; ordering and big endian machines use msb to lsb ordering. +---------------+--------------+-----------------------------------------------+; | Field | Size | Description |; +===============+==============+===============================================+; | discriminant | ``1 bit`` | Indicates whether a reader should read a |; | | | Function or Metadata record. Set to ``1`` for |; | | | Metadata records. |; +---------------+--------------+-----------------------------------------------+; | record_kind | ``7 bits`` | The type of Metadata record. |; +---------------+--------------+-----------------------------------------------+; | data | ``15 bytes`` | A data field used differently for each record |; | | | type. |; +---------------+--------------+------------------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:11044,Integrability,depend,depends,11044,"s. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | thread_Id | ``2`` | Thread ID for buffer. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``13`` | Unused. |; +---------------+--------------+-----------------------------------------------+. WallClockTime Records; ---------------------. Following the NewBuffer record, each buffer records an absolute time as a frame; of reference for the durations recorded by timestamp counter deltas. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | seconds | ``8`` | Seconds on absolute timescale. The starting |; | | | point is unspecified and depends on the |; | | | implementation and platform configured by the |; | | | tracer. |; +---------------+--------------+-----------------------------------------------+; | microseconds | ``4`` | The microsecond component of the time. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. NewCpuId Records; ----------------. Each function entry invokes a routine to determine what CPU is executing.; Typically, this is done with readtscp, which reads the timestamp counter at the; same time. If the tracing detects that the execution has switched CPUs or if this is the; first instrumented entry point, the tracer will output a NewCpuId record. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+==========================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:11545,Integrability,rout,routine,11545,"-------. Following the NewBuffer record, each buffer records an absolute time as a frame; of reference for the durations recorded by timestamp counter deltas. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | seconds | ``8`` | Seconds on absolute timescale. The starting |; | | | point is unspecified and depends on the |; | | | implementation and platform configured by the |; | | | tracer. |; +---------------+--------------+-----------------------------------------------+; | microseconds | ``4`` | The microsecond component of the time. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. NewCpuId Records; ----------------. Each function entry invokes a routine to determine what CPU is executing.; Typically, this is done with readtscp, which reads the timestamp counter at the; same time. If the tracing detects that the execution has switched CPUs or if this is the; first instrumented entry point, the tracer will output a NewCpuId record. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | cpu_id | ``2`` | CPU Id. |; +---------------+--------------+-----------------------------------------------+; | absolute_tsc | ``8`` | The absolute value of the timestamp counter. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``5`` | Unused. |; +---------------+--------------+-----------------------------------------------+. TSCWrap Records; ---------------. Since each function record uses a 32 bit value to represent the n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:11096,Modifiability,config,configured,11096,"s. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | thread_Id | ``2`` | Thread ID for buffer. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``13`` | Unused. |; +---------------+--------------+-----------------------------------------------+. WallClockTime Records; ---------------------. Following the NewBuffer record, each buffer records an absolute time as a frame; of reference for the durations recorded by timestamp counter deltas. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | seconds | ``8`` | Seconds on absolute timescale. The starting |; | | | point is unspecified and depends on the |; | | | implementation and platform configured by the |; | | | tracer. |; +---------------+--------------+-----------------------------------------------+; | microseconds | ``4`` | The microsecond component of the time. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. NewCpuId Records; ----------------. Each function entry invokes a routine to determine what CPU is executing.; Typically, this is done with readtscp, which reads the timestamp counter at the; same time. If the tracing detects that the execution has switched CPUs or if this is the; first instrumented entry point, the tracer will output a NewCpuId record. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+==========================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:5618,Performance,optimiz,optimizations,5618,"gging; contiguous function argument sequences starting with argument zero, which will; be the ""this"" pointer for member function invocations. For example, we don't; support logging the first and third argument. A reader of the memory format must maintain a state machine. The format makes no; attempt to pad for alignment, and it is not seekable. Function Records; ----------------. Function Records have an 8 byte layout. This layout encodes information to; reconstruct a call stack of instrumented function and their durations. +---------------+--------------+-----------------------------------------------+; | Field | Size (bits) | Description |; +===============+==============+===============================================+; | discriminant | ``1`` | Indicates whether a reader should read a |; | | | Function or Metadata record. Set to ``0`` for |; | | | Function records. |; +---------------+--------------+-----------------------------------------------+; | action | ``3`` | Specifies whether the function is being |; | | | entered, exited, or is a non-standard entry |; | | | or exit produced by optimizations. |; +---------------+--------------+-----------------------------------------------+; | function_id | ``28`` | A numeric ID for the function. Resolved to a |; | | | name via the xray instrumentation map. The |; | | | instrumentation map is built by xray at |; | | | compile time into an object file and pairs |; | | | the function ids to addresses. It is used for |; | | | patching and as a lookup into the binary's |; | | | symbols to obtain names. |; +---------------+--------------+-----------------------------------------------+; | tsc_delta | ``32`` | The number of ticks of the timestamp counter |; | | | since a previous record recorded a delta or |; | | | other TSC resetting event. |; +---------------+--------------+-----------------------------------------------+. On little-endian machines, the bitfields are ordered from least significant bit; bit to most significan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:7575,Performance,optimiz,optimization,7575,"significant bit. A reader can read an 8 bit value and apply the mask; ``0x01`` for the discriminant. Similarly, they can read 32 bits and unsigned; shift right by ``0x04`` to obtain the function_id field. On big-endian machine, the bitfields are written in order from most significant; bit to least significant bit. A reader would read an 8 bit value and unsigned; shift right by 7 bits for the discriminant. The function_id field could be; obtained by reading a 32 bit value and applying the mask ``0x0FFFFFFF``. Function action types are as follows. +---------------+--------------+-----------------------------------------------+; | Type | Number | Description |; +===============+==============+===============================================+; | Entry | ``0`` | Typical function entry. |; +---------------+--------------+-----------------------------------------------+; | Exit | ``1`` | Typical function exit. |; +---------------+--------------+-----------------------------------------------+; | Tail_Exit | ``2`` | An exit from a function due to tail call |; | | | optimization. |; +---------------+--------------+-----------------------------------------------+; | Entry_Args | ``3`` | A function entry that records arguments. |; +---------------+--------------+-----------------------------------------------+. Entry_Args records do not contain the arguments themselves. Instead, metadata; records for each of the logged args follow the function record in the stream. Metadata Records; ----------------. Interspersed throughout the buffer are 16 byte Metadata records. For typically; instrumented binaries, they will be sparser than Function records, and they; provide a fuller picture of the binary execution state. Metadata record layout is partially record dependent, but they share a common; structure. The same bit field rules described for function records apply to the first byte; of MetadataRecords. Within this byte, little endian machines use lsb to msb; ordering and big endian ma",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:16653,Performance,optimiz,optimization,16653,"+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. EndOfBuffer Records; -------------------. An EndOfBuffer record type indicates that there is no more trace data in this; buffer. The reader is expected to seek past the remaining buffer_size expressed; before the start of buffer and look for either another header or EOF. Format Grammar and Invariants; =============================. Not all sequences of Metadata records and Function records are valid data. A; sequence should be parsed as a state machine. The expectations for a valid; format can be expressed as a context free grammar. This is an attempt to explain the format with statements in EBNF format. - Format := Header ThreadBuffer* EOF. - ThreadBuffer := NewBuffer WallClockTime NewCPUId BodySequence* End. - BodySequence := NewCPUId | TSCWrap | Function | CustomEvent. - Function := (Function_Entry_Args CallArgument*) | Function_Other_Type. - CustomEvent := CustomEventMarker CustomEventUnstructuredMemory. - End := EndOfBuffer RemainingBufferSizeToSkip. Function Record Order; ---------------------. There are a few clarifications that may help understand what is expected of; Function records. - Functions with an Exit are expected to have a corresponding Entry or; Entry_Args function record precede them in the trace. - Tail_Exit Function records record the Function ID of the function whose return; address the program counter will take. In other words, the final function that; would be popped off of the call stack if tail call optimization was not used. - Not all functions marked for instrumentation are necessarily in the trace. The; tracer uses heuristics to preserve the trace for non-trivial functions. - Not every entry must have a traced Exit or Tail Exit. The buffer may run out; of space or the program may request for the tracer to finalize toreturn the; buffer before an instrumented function exits.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:11697,Safety,detect,detects,11697,"-+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | seconds | ``8`` | Seconds on absolute timescale. The starting |; | | | point is unspecified and depends on the |; | | | implementation and platform configured by the |; | | | tracer. |; +---------------+--------------+-----------------------------------------------+; | microseconds | ``4`` | The microsecond component of the time. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. NewCpuId Records; ----------------. Each function entry invokes a routine to determine what CPU is executing.; Typically, this is done with readtscp, which reads the timestamp counter at the; same time. If the tracing detects that the execution has switched CPUs or if this is the; first instrumented entry point, the tracer will output a NewCpuId record. Its data segment is as follows. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | cpu_id | ``2`` | CPU Id. |; +---------------+--------------+-----------------------------------------------+; | absolute_tsc | ``8`` | The absolute value of the timestamp counter. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``5`` | Unused. |; +---------------+--------------+-----------------------------------------------+. TSCWrap Records; ---------------. Since each function record uses a 32 bit value to represent the number of ticks; of the timestamp counter since the last reference, it is possible for this value; to overflow, particularly for sparsely instrumented binaries. When this delta would not fit into a 32 bit rep",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:4287,Testability,log,logged,4287,"atching the; buffer_size field in the header. The data section is a stream of elements of different types. There are a few categories of data in the sequence. - ``Function Records``: Function Records contain the timing of entry into and; exit from function execution. Function Records have 8 bytes each. - ``Metadata Records``: Metadata records serve many purposes. Mostly, they; capture information that may be too costly to record for each function, but; that is required to contextualize the fine-grained timings. They also are used; as markers for user-defined Event Data payloads. Metadata records have 16; bytes each. - ``Event Data``: Free form data may be associated with events that are traced; by the binary and encode data defined by a handler function. Event data is; always preceded with a marker record which indicates how large it is. - ``Function Arguments``: The arguments to some functions are included in the; trace. These are either pointer addresses or primitives that are read and; logged independently of their types in a high level language. To the tracer,; they are all numbers. Function Records that have attached arguments will; indicate their presence on the function entry record. We only support logging; contiguous function argument sequences starting with argument zero, which will; be the ""this"" pointer for member function invocations. For example, we don't; support logging the first and third argument. A reader of the memory format must maintain a state machine. The format makes no; attempt to pad for alignment, and it is not seekable. Function Records; ----------------. Function Records have an 8 byte layout. This layout encodes information to; reconstruct a call stack of instrumented function and their durations. +---------------+--------------+-----------------------------------------------+; | Field | Size (bits) | Description |; +===============+==============+===============================================+; | discriminant | ``1`` | Indicates whet",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:4509,Testability,log,logging,4509," 8 bytes each. - ``Metadata Records``: Metadata records serve many purposes. Mostly, they; capture information that may be too costly to record for each function, but; that is required to contextualize the fine-grained timings. They also are used; as markers for user-defined Event Data payloads. Metadata records have 16; bytes each. - ``Event Data``: Free form data may be associated with events that are traced; by the binary and encode data defined by a handler function. Event data is; always preceded with a marker record which indicates how large it is. - ``Function Arguments``: The arguments to some functions are included in the; trace. These are either pointer addresses or primitives that are read and; logged independently of their types in a high level language. To the tracer,; they are all numbers. Function Records that have attached arguments will; indicate their presence on the function entry record. We only support logging; contiguous function argument sequences starting with argument zero, which will; be the ""this"" pointer for member function invocations. For example, we don't; support logging the first and third argument. A reader of the memory format must maintain a state machine. The format makes no; attempt to pad for alignment, and it is not seekable. Function Records; ----------------. Function Records have an 8 byte layout. This layout encodes information to; reconstruct a call stack of instrumented function and their durations. +---------------+--------------+-----------------------------------------------+; | Field | Size (bits) | Description |; +===============+==============+===============================================+; | discriminant | ``1`` | Indicates whether a reader should read a |; | | | Function or Metadata record. Set to ``0`` for |; | | | Function records. |; +---------------+--------------+-----------------------------------------------+; | action | ``3`` | Specifies whether the function is being |; | | | entered, exited, or is a no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:4684,Testability,log,logging,4684,"t may be too costly to record for each function, but; that is required to contextualize the fine-grained timings. They also are used; as markers for user-defined Event Data payloads. Metadata records have 16; bytes each. - ``Event Data``: Free form data may be associated with events that are traced; by the binary and encode data defined by a handler function. Event data is; always preceded with a marker record which indicates how large it is. - ``Function Arguments``: The arguments to some functions are included in the; trace. These are either pointer addresses or primitives that are read and; logged independently of their types in a high level language. To the tracer,; they are all numbers. Function Records that have attached arguments will; indicate their presence on the function entry record. We only support logging; contiguous function argument sequences starting with argument zero, which will; be the ""this"" pointer for member function invocations. For example, we don't; support logging the first and third argument. A reader of the memory format must maintain a state machine. The format makes no; attempt to pad for alignment, and it is not seekable. Function Records; ----------------. Function Records have an 8 byte layout. This layout encodes information to; reconstruct a call stack of instrumented function and their durations. +---------------+--------------+-----------------------------------------------+; | Field | Size (bits) | Description |; +===============+==============+===============================================+; | discriminant | ``1`` | Indicates whether a reader should read a |; | | | Function or Metadata record. Set to ``0`` for |; | | | Function records. |; +---------------+--------------+-----------------------------------------------+; | action | ``3`` | Specifies whether the function is being |; | | | entered, exited, or is a non-standard entry |; | | | or exit produced by optimizations. |; +---------------+--------------+-------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:7926,Testability,log,logged,7926,"ld could be; obtained by reading a 32 bit value and applying the mask ``0x0FFFFFFF``. Function action types are as follows. +---------------+--------------+-----------------------------------------------+; | Type | Number | Description |; +===============+==============+===============================================+; | Entry | ``0`` | Typical function entry. |; +---------------+--------------+-----------------------------------------------+; | Exit | ``1`` | Typical function exit. |; +---------------+--------------+-----------------------------------------------+; | Tail_Exit | ``2`` | An exit from a function due to tail call |; | | | optimization. |; +---------------+--------------+-----------------------------------------------+; | Entry_Args | ``3`` | A function entry that records arguments. |; +---------------+--------------+-----------------------------------------------+. Entry_Args records do not contain the arguments themselves. Instead, metadata; records for each of the logged args follow the function record in the stream. Metadata Records; ----------------. Interspersed throughout the buffer are 16 byte Metadata records. For typically; instrumented binaries, they will be sparser than Function records, and they; provide a fuller picture of the binary execution state. Metadata record layout is partially record dependent, but they share a common; structure. The same bit field rules described for function records apply to the first byte; of MetadataRecords. Within this byte, little endian machines use lsb to msb; ordering and big endian machines use msb to lsb ordering. +---------------+--------------+-----------------------------------------------+; | Field | Size | Description |; +===============+==============+===============================================+; | discriminant | ``1 bit`` | Indicates whether a reader should read a |; | | | Function or Metadata record. Set to ``1`` for |; | | | Metadata records. |; +---------------+--------------+-------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst:14240,Testability,log,logging,14240,"eserved | ``7`` | Unused. |; +---------------+--------------+-----------------------------------------------+. CallArgument Records; --------------------. Immediately following an Entry_Args type function record, there may be one or; more CallArgument records that contain the traced function's parameter values. The order of the CallArgument Record sequency corresponds one to one with the; order of the function parameters. CallArgument data segment:. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | argument | ``8`` | Numeric argument (may be pointer address). |; +---------------+--------------+-----------------------------------------------+; | reserved | ``7`` | Unused. |; +---------------+--------------+-----------------------------------------------+. CustomEventMarker Records; -------------------------. XRay provides the feature of logging custom events. This may be leveraged to; record tracing info for RPCs or similarly trace data that is application; specific. Custom Events themselves are an unstructured (application defined) segment of; memory with arbitrary size within the buffer. They are preceded by; CustomEventMarkers to indicate their presence and size. CustomEventMarker data segment:. +---------------+--------------+-----------------------------------------------+; | Field | Size (bytes) | Description |; +===============+==============+===============================================+; | event_size | ``4`` | Size of preceded event. |; +---------------+--------------+-----------------------------------------------+; | absolute_tsc | ``8`` | A timestamp counter of the event. |; +---------------+--------------+-----------------------------------------------+; | reserved | ``3`` | Unused. |; +---------------+--------------+-----------------------------------------------+. EndOfBuffer Records; ------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/XRayFDRFormat.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/yaml2obj.rst:3050,Usability,simpl,simplified,3050,"ynamicValueRelocTableSection: {type: int}; GuardRFVerifyStackPointerFunctionPointer: {type: int}; HotPatchTableOffset: {type: int}; EnclaveConfigurationPointer: {type: int}; VolatileMetadataPointer: {type: int}; GuardEHContinuationTable: {type: int}; GuardEHContinuationCount: {type: int}; GuardXFGCheckFunctionPointer: {type: int}; GuardXFGDispatchFunctionPointer: {type: int}; GuardXFGTableDispatchFunctionPointer: {type: int}; CastGuardOsDeterminedFailureMode: {type: int}. symbols:; - Name: .text; Value: 0; SectionNumber: 1; SimpleType: IMAGE_SYM_TYPE_NULL # (0); ComplexType: IMAGE_SYM_DTYPE_NULL # (0); StorageClass: IMAGE_SYM_CLASS_STATIC # (3); NumberOfAuxSymbols: 1; AuxiliaryData:; ""\x24\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00"" # |$.................|. - Name: _main; Value: 0; SectionNumber: 1; SimpleType: IMAGE_SYM_TYPE_NULL # (0); ComplexType: IMAGE_SYM_DTYPE_NULL # (0); StorageClass: IMAGE_SYM_CLASS_EXTERNAL # (2). Here's a simplified Kwalify_ schema with an extension to allow alternate types. .. _Kwalify: http://www.kuwata-lab.com/kwalify/ruby/users-guide.html. .. code-block:: yaml. type: map; mapping:; header:; type: map; mapping:; Machine: [ {type: str, enum:; [ IMAGE_FILE_MACHINE_UNKNOWN; , IMAGE_FILE_MACHINE_AM33; , IMAGE_FILE_MACHINE_AMD64; , IMAGE_FILE_MACHINE_ARM; , IMAGE_FILE_MACHINE_ARMNT; , IMAGE_FILE_MACHINE_ARM64; , IMAGE_FILE_MACHINE_EBC; , IMAGE_FILE_MACHINE_I386; , IMAGE_FILE_MACHINE_IA64; , IMAGE_FILE_MACHINE_M32R; , IMAGE_FILE_MACHINE_MIPS16; , IMAGE_FILE_MACHINE_MIPSFPU; , IMAGE_FILE_MACHINE_MIPSFPU16; , IMAGE_FILE_MACHINE_POWERPC; , IMAGE_FILE_MACHINE_POWERPCFP; , IMAGE_FILE_MACHINE_R4000; , IMAGE_FILE_MACHINE_SH3; , IMAGE_FILE_MACHINE_SH3DSP; , IMAGE_FILE_MACHINE_SH4; , IMAGE_FILE_MACHINE_SH5; , IMAGE_FILE_MACHINE_THUMB; , IMAGE_FILE_MACHINE_WCEMIPSV2; ]}; , {type: int}; ]; Characteristics:; - type: seq; sequence:; - type: str; enum: [ IMAGE_FILE_RELOCS_STRIPPED; , IMAGE_FILE_EXECUTABLE_IMAGE; , IMAGE_FILE_LINE_NU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/yaml2obj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/yaml2obj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/yaml2obj.rst:3179,Usability,guid,guide,3179,": int}; HotPatchTableOffset: {type: int}; EnclaveConfigurationPointer: {type: int}; VolatileMetadataPointer: {type: int}; GuardEHContinuationTable: {type: int}; GuardEHContinuationCount: {type: int}; GuardXFGCheckFunctionPointer: {type: int}; GuardXFGDispatchFunctionPointer: {type: int}; GuardXFGTableDispatchFunctionPointer: {type: int}; CastGuardOsDeterminedFailureMode: {type: int}. symbols:; - Name: .text; Value: 0; SectionNumber: 1; SimpleType: IMAGE_SYM_TYPE_NULL # (0); ComplexType: IMAGE_SYM_DTYPE_NULL # (0); StorageClass: IMAGE_SYM_CLASS_STATIC # (3); NumberOfAuxSymbols: 1; AuxiliaryData:; ""\x24\x00\x00\x00\x03\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00"" # |$.................|. - Name: _main; Value: 0; SectionNumber: 1; SimpleType: IMAGE_SYM_TYPE_NULL # (0); ComplexType: IMAGE_SYM_DTYPE_NULL # (0); StorageClass: IMAGE_SYM_CLASS_EXTERNAL # (2). Here's a simplified Kwalify_ schema with an extension to allow alternate types. .. _Kwalify: http://www.kuwata-lab.com/kwalify/ruby/users-guide.html. .. code-block:: yaml. type: map; mapping:; header:; type: map; mapping:; Machine: [ {type: str, enum:; [ IMAGE_FILE_MACHINE_UNKNOWN; , IMAGE_FILE_MACHINE_AM33; , IMAGE_FILE_MACHINE_AMD64; , IMAGE_FILE_MACHINE_ARM; , IMAGE_FILE_MACHINE_ARMNT; , IMAGE_FILE_MACHINE_ARM64; , IMAGE_FILE_MACHINE_EBC; , IMAGE_FILE_MACHINE_I386; , IMAGE_FILE_MACHINE_IA64; , IMAGE_FILE_MACHINE_M32R; , IMAGE_FILE_MACHINE_MIPS16; , IMAGE_FILE_MACHINE_MIPSFPU; , IMAGE_FILE_MACHINE_MIPSFPU16; , IMAGE_FILE_MACHINE_POWERPC; , IMAGE_FILE_MACHINE_POWERPCFP; , IMAGE_FILE_MACHINE_R4000; , IMAGE_FILE_MACHINE_SH3; , IMAGE_FILE_MACHINE_SH3DSP; , IMAGE_FILE_MACHINE_SH4; , IMAGE_FILE_MACHINE_SH5; , IMAGE_FILE_MACHINE_THUMB; , IMAGE_FILE_MACHINE_WCEMIPSV2; ]}; , {type: int}; ]; Characteristics:; - type: seq; sequence:; - type: str; enum: [ IMAGE_FILE_RELOCS_STRIPPED; , IMAGE_FILE_EXECUTABLE_IMAGE; , IMAGE_FILE_LINE_NUMS_STRIPPED; , IMAGE_FILE_LOCAL_SYMS_STRIPPED; , IMAGE_FILE_AGGRESSIVE_WS_TRIM; , IMAGE_FIL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/yaml2obj.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/yaml2obj.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5043,Availability,error,error,5043,"hatSize);; }; };. A YAML sequence is automatically inferred if you data type has begin()/end(); iterators and a push_back() method. Therefore any of the STL containers; (such as std::vector<>) will automatically translate to YAML sequences. Once you have defined specializations for your data types, you can; programmatically use YAML I/O to write a YAML document:. .. code-block:: c++. using llvm::yaml::Output;. Person tom;; tom.name = ""Tom"";; tom.hatSize = 8;; Person dan;; dan.name = ""Dan"";; dan.hatSize = 7;; std::vector<Person> persons;; persons.push_back(tom);; persons.push_back(dan);. Output yout(llvm::outs());; yout << persons;. This would write the following:. .. code-block:: yaml. - name: Tom; hat-size: 8; - name: Dan; hat-size: 7. And you can also read such YAML documents with the following code:. .. code-block:: c++. using llvm::yaml::Input;. typedef std::vector<Person> PersonList;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a seque",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5530,Availability,error,error,5530,".hatSize = 7;; std::vector<Person> persons;; persons.push_back(tom);; persons.push_back(dan);. Output yout(llvm::outs());; yout << persons;. This would write the following:. .. code-block:: yaml. - name: Tom; hat-size: 8; - name: Dan; hat-size: 7. And you can also read such YAML documents with the following code:. .. code-block:: c++. using llvm::yaml::Input;. typedef std::vector<Person> PersonList;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5568,Availability,error,error,5568,".hatSize = 7;; std::vector<Person> persons;; persons.push_back(tom);; persons.push_back(dan);. Output yout(llvm::outs());; yout << persons;. This would write the following:. .. code-block:: yaml. - name: Tom; hat-size: 8; - name: Dan; hat-size: 7. And you can also read such YAML documents with the following code:. .. code-block:: c++. using llvm::yaml::Input;. typedef std::vector<Person> PersonList;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5816,Availability,error,error,5816,". And you can also read such YAML documents with the following code:. .. code-block:: c++. using llvm::yaml::Input;. typedef std::vector<Person> PersonList;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string found; is convertible to that type and error out if not. Unique types; ------------; Given that YAML I/O is trait based, the selection of how to convert your data; to YAML is based on the type of your data. But in C++ type matching, typedefs; do no",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5856,Availability,error,error,5856,"k:: c++. using llvm::yaml::Input;. typedef std::vector<Person> PersonList;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string found; is convertible to that type and error out if not. Unique types; ------------; Given that YAML I/O is trait based, the selection of how to convert your data; to YAML is based on the type of your data. But in C++ type matching, typedefs; do not generate unique type names. That means if you have two typedefs of; unsigned in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5922,Availability,error,errors,5922,"st;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string found; is convertible to that type and error out if not. Unique types; ------------; Given that YAML I/O is trait based, the selection of how to convert your data; to YAML is based on the type of your data. But in C++ type matching, typedefs; do not generate unique type names. That means if you have two typedefs of; unsigned int, to YAML I/O both types look exactly like unsigned int. To; facilitat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:6589,Availability,error,error,6589,"r Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string found; is convertible to that type and error out if not. Unique types; ------------; Given that YAML I/O is trait based, the selection of how to convert your data; to YAML is based on the type of your data. But in C++ type matching, typedefs; do not generate unique type names. That means if you have two typedefs of; unsigned int, to YAML I/O both types look exactly like unsigned int. To; facilitate make unique type names, YAML I/O provides a macro which is used; like a typedef on built-in types, but expands to create a class with conversion; operators to and from the base type. For example:. .. code-block:: c++. LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyFooFlags); LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyBarFlags). This generates two classes MyFooFlags and MyBarFlags which you can use in your; native data structures instead of uint32_t. They are implicitly; converted to and from uint32_t. The point of creating these unique types; is that you can now specify traits on them to get different YAML c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:9272,Availability,error,error,9272,"n enumeration() method.; For instance, suppose you had an enumeration of CPUs and a struct with it as; a field:. .. code-block:: c++. enum CPUs {; cpu_x86_64 = 5,; cpu_x86 = 7,; cpu_PowerPC = 8; };. struct Info {; CPUs cpu;; uint32_t flags;; };. To support reading and writing of this enumeration, you can define a; ScalarEnumerationTraits specialization on CPUs, which can then be used; as a field type:. .. code-block:: c++. using llvm::yaml::ScalarEnumerationTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarEnumerationTraits<CPUs> {; static void enumeration(IO &io, CPUs &value) {; io.enumCase(value, ""x86_64"", cpu_x86_64);; io.enumCase(value, ""x86"", cpu_x86);; io.enumCase(value, ""PowerPC"", cpu_PowerPC);; }; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info &info) {; io.mapRequired(""cpu"", info.cpu);; io.mapOptional(""flags"", info.flags, 0);; }; };. When reading YAML, if the string found does not match any of the strings; specified by enumCase() methods, an error is automatically generated.; When writing YAML, if the value being written does not match any of the values; specified by the enumCase() methods, a runtime assertion is triggered. BitValue; --------; Another common data structure in C++ is a field where each bit has a unique; meaning. This is often used in a ""flags"" field. YAML I/O has support for; converting such fields to a flow sequence. For instance suppose you; had the following bit flags defined:. .. code-block:: c++. enum {; flagsPointy = 1; flagsHollow = 2; flagsFlat = 4; flagsRound = 8; };. LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyFlags). To support reading and writing of MyFlags, you specialize ScalarBitSetTraits<>; on MyFlags and provide the bit values and their names. .. code-block:: c++. using llvm::yaml::ScalarBitSetTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:10678,Availability,mask,mask,10678,"ined:. .. code-block:: c++. enum {; flagsPointy = 1; flagsHollow = 2; flagsFlat = 4; flagsRound = 8; };. LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyFlags). To support reading and writing of MyFlags, you specialize ScalarBitSetTraits<>; on MyFlags and provide the bit values and their names. .. code-block:: c++. using llvm::yaml::ScalarBitSetTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""hollow"", flagHollow);; io.bitSetCase(value, ""flat"", flagFlat);; io.bitSetCase(value, ""round"", flagRound);; io.bitSetCase(value, ""pointy"", flagPointy);; }; };. struct Info {; StringRef name;; MyFlags flags;; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info& info) {; io.mapRequired(""name"", info.name);; io.mapRequired(""flags"", info.flags);; }; };. With the above, YAML I/O (when writing) will test mask each value in the; bitset trait against the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCP",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:10916,Availability,error,error,10916,". To support reading and writing of MyFlags, you specialize ScalarBitSetTraits<>; on MyFlags and provide the bit values and their names. .. code-block:: c++. using llvm::yaml::ScalarBitSetTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""hollow"", flagHollow);; io.bitSetCase(value, ""flat"", flagFlat);; io.bitSetCase(value, ""round"", flagRound);; io.bitSetCase(value, ""pointy"", flagPointy);; }; };. struct Info {; StringRef name;; MyFlags flags;; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info& info) {; io.mapRequired(""name"", info.name);; io.mapRequired(""flags"", info.flags);; }; };. With the above, YAML I/O (when writing) will test mask each value in the; bitset trait against the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:11116,Availability,mask,mask,11116,"g llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""hollow"", flagHollow);; io.bitSetCase(value, ""flat"", flagFlat);; io.bitSetCase(value, ""round"", flagRound);; io.bitSetCase(value, ""pointy"", flagPointy);; }; };. struct Info {; StringRef name;; MyFlags flags;; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info& info) {; io.mapRequired(""name"", info.name);; io.mapRequired(""flags"", info.flags);; }; };. With the above, YAML I/O (when writing) will test mask each value in the; bitset trait against the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to the flags field,; and compare the result and values from the bitset. As in case of a regular; bitset, each that matches will cause the corresponding string to be added; to the flow sequence. Custom Sca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:11331,Availability,mask,maskedBitSet,11331,", flagRound);; io.bitSetCase(value, ""pointy"", flagPointy);; }; };. struct Info {; StringRef name;; MyFlags flags;; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info& info) {; io.mapRequired(""name"", info.name);; io.mapRequired(""flags"", info.flags);; }; };. With the above, YAML I/O (when writing) will test mask each value in the; bitset trait against the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to the flags field,; and compare the result and values from the bitset. As in case of a regular; bitset, each that matches will cause the corresponding string to be added; to the flow sequence. Custom Scalar; -------------; Sometimes for readability a scalar needs to be formatted in a custom way. For; instance your internal data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:11414,Availability,mask,mask,11414,", flagRound);; io.bitSetCase(value, ""pointy"", flagPointy);; }; };. struct Info {; StringRef name;; MyFlags flags;; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info& info) {; io.mapRequired(""name"", info.name);; io.mapRequired(""flags"", info.flags);; }; };. With the above, YAML I/O (when writing) will test mask each value in the; bitset trait against the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to the flags field,; and compare the result and values from the bitset. As in case of a regular; bitset, each that matches will cause the corresponding string to be added; to the flow sequence. Custom Scalar; -------------; Sometimes for readability a scalar needs to be formatted in a custom way. For; instance your internal data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some ti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:11691,Availability,mask,maskedBitSetCase,11691," the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to the flags field,; and compare the result and values from the bitset. As in case of a regular; bitset, each that matches will cause the corresponding string to be added; to the flow sequence. Custom Scalar; -------------; Sometimes for readability a scalar needs to be formatted in a custom way. For; instance your internal data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some time format (e.g. 4-May-2012 10:30pm). YAML I/O has a way to support; custom formatting and parsing of scalar types by specializing ScalarTraits<> on; your data type. When writing, YAML I/O will provide the native type and; your specialization must create a temporary llvm::StringRef. When reading,; YAML I/O will provide an llvm::StringRef of scalar and your specialization; must ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:11753,Availability,mask,maskedBitSetCase,11753,"onding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to the flags field,; and compare the result and values from the bitset. As in case of a regular; bitset, each that matches will cause the corresponding string to be added; to the flow sequence. Custom Scalar; -------------; Sometimes for readability a scalar needs to be formatted in a custom way. For; instance your internal data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some time format (e.g. 4-May-2012 10:30pm). YAML I/O has a way to support; custom formatting and parsing of scalar types by specializing ScalarTraits<> on; your data type. When writing, YAML I/O will provide the native type and; your specialization must create a temporary llvm::StringRef. When reading,; YAML I/O will provide an llvm::StringRef of scalar and your specialization; must convert that to your native data type. An outline of a custom sc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:11870,Availability,mask,mask,11870,"n string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCPU1, flagsCPUMask);; io.maskedBitSetCase(value, ""CPU2"", flagsCPU2, flagsCPUMask);; }; };. YAML I/O (when writing) will apply the enumeration mask to the flags field,; and compare the result and values from the bitset. As in case of a regular; bitset, each that matches will cause the corresponding string to be added; to the flow sequence. Custom Scalar; -------------; Sometimes for readability a scalar needs to be formatted in a custom way. For; instance your internal data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some time format (e.g. 4-May-2012 10:30pm). YAML I/O has a way to support; custom formatting and parsing of scalar types by specializing ScalarTraits<> on; your data type. When writing, YAML I/O will provide the native type and; your specialization must create a temporary llvm::StringRef. When reading,; YAML I/O will provide an llvm::StringRef of scalar and your specialization; must convert that to your native data type. An outline of a custom scalar type; looks like:. .. code-block:: c++. using llvm::yaml::ScalarTraits;; using llvm::yaml::",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:13210,Availability,error,error,13210,"l data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some time format (e.g. 4-May-2012 10:30pm). YAML I/O has a way to support; custom formatting and parsing of scalar types by specializing ScalarTraits<> on; your data type. When writing, YAML I/O will provide the native type and; your specialization must create a temporary llvm::StringRef. When reading,; YAML I/O will provide an llvm::StringRef of scalar and your specialization; must convert that to your native data type. An outline of a custom scalar type; looks like:. .. code-block:: c++. using llvm::yaml::ScalarTraits;; using llvm::yaml::IO;. template <>; struct ScalarTraits<MyCustomType> {; static void output(const MyCustomType &value, void*,; llvm::raw_ostream &out) {; out << value; // do custom formatting here; }; static StringRef input(StringRef scalar, void*, MyCustomType &value) {; // do custom parsing here. Return the empty string on success,; // or an error message on failure.; return StringRef();; }; // Determine if this scalar needs quotes.; static QuotingType mustQuote(StringRef) { return QuotingType::Single; }; };. Block Scalars; -------------. YAML block scalars are string literals that are represented in YAML using the; literal block notation, just like the example shown below:. .. code-block:: yaml. text: |; First line; Second line. The YAML I/O library provides support for translating between YAML block scalars; and specific C++ types by allowing you to specialize BlockScalarTraits<> on; your data type. The library doesn't provide any built-in support for block; scalar I/O for types like std::string and llvm::StringRef as they are already; supported by YAML I/O and use the ordinary scalar notation by default. BlockScalarTraits specializations are very similar to the; ScalarTraits specialization - YAML I/O will provide the native type and your; specialization must create a temporary llvm::StringRef when writing, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:13227,Availability,failure,failure,13227,"l data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some time format (e.g. 4-May-2012 10:30pm). YAML I/O has a way to support; custom formatting and parsing of scalar types by specializing ScalarTraits<> on; your data type. When writing, YAML I/O will provide the native type and; your specialization must create a temporary llvm::StringRef. When reading,; YAML I/O will provide an llvm::StringRef of scalar and your specialization; must convert that to your native data type. An outline of a custom scalar type; looks like:. .. code-block:: c++. using llvm::yaml::ScalarTraits;; using llvm::yaml::IO;. template <>; struct ScalarTraits<MyCustomType> {; static void output(const MyCustomType &value, void*,; llvm::raw_ostream &out) {; out << value; // do custom formatting here; }; static StringRef input(StringRef scalar, void*, MyCustomType &value) {; // do custom parsing here. Return the empty string on success,; // or an error message on failure.; return StringRef();; }; // Determine if this scalar needs quotes.; static QuotingType mustQuote(StringRef) { return QuotingType::Single; }; };. Block Scalars; -------------. YAML block scalars are string literals that are represented in YAML using the; literal block notation, just like the example shown below:. .. code-block:: yaml. text: |; First line; Second line. The YAML I/O library provides support for translating between YAML block scalars; and specific C++ types by allowing you to specialize BlockScalarTraits<> on; your data type. The library doesn't provide any built-in support for block; scalar I/O for types like std::string and llvm::StringRef as they are already; supported by YAML I/O and use the ordinary scalar notation by default. BlockScalarTraits specializations are very similar to the; ScalarTraits specialization - YAML I/O will provide the native type and your; specialization must create a temporary llvm::StringRef when writing, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:20069,Availability,error,error,20069,"Required; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps to how those optional fields are filled in. First, the; second parameter to the mapping() method is a reference to a native class. That; native class must have a default constructor. Whatever value the default; constructor initially sets for an optional field will be that field's value.; Second, the mapOptional() method has an optional third parameter. If provided; it is the value that mapOptional() should set that field to if the YAML document; does not have that key. There is one important difference between those two ways (default constructor; and third parameter to mapOptional). When YAML I/O generates a YAML document,; if the mapOptional() third parameter is used, if the actual value being written; is the same as (using ==) t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23170,Availability,error,errors,23170,".mapRequired(""cpu"", info.cpu);; // flags must come after cpu for this to work when reading yaml; if ( info.cpu == cpu_x86_64 ); io.mapRequired(""flags"", *(My86_64Flags*)info.flags);; else; io.mapRequired(""flags"", *(My86Flags*)info.flags);; }; };. Tags; ----. The YAML syntax supports tags as a way to specify the type of a node before; it is parsed. This allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23205,Availability,error,errors,23205,".mapRequired(""cpu"", info.cpu);; // flags must come after cpu for this to work when reading yaml; if ( info.cpu == cpu_x86_64 ); io.mapRequired(""flags"", *(My86_64Flags*)info.flags);; else; io.mapRequired(""flags"", *(My86Flags*)info.flags);; }; };. Tags; ----. The YAML syntax supports tags as a way to specify the type of a node before; it is parsed. This allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Ot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23457,Availability,error,error,23457,"his allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"".",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23560,Availability,error,error,23560,"his allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"".",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23687,Availability,error,error,23687,"ag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23765,Availability,error,error,23765,"ag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:24159,Availability,error,error,24159,"air is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:31410,Availability,error,errors,31410,"Doc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; pointer:. .. code-block:: c++. class Input : public IO {; public:; Input(StringRef inputContent, void *context=NULL);. Once you have an Input object, you can use the C++ stream operator to read; the document(s). If you expect there might be multiple YAML documents in; one file, you'll need to specialize DocumentListTraits on a list of your; document type and stream in that document list type. Otherwise you can; just stream in the document type. Also, you can check if there was; any syntax errors in the YAML be calling the error() method on the Input; object. For example:. .. code-block:: c++. // Reading a single document; using llvm::yaml::Input;. Input yin(mb.getBuffer());. // Parse the YAML file; MyDocType theDoc;; yin >> theDoc;. // Check for error; if ( yin.error() ); return;. .. code-block:: c++. // Reading multiple documents in one file; using llvm::yaml::Input;. LLVM_YAML_IS_DOCUMENT_LIST_VECTOR(MyDocType). Input yin(mb.getBuffer());. // Parse the YAML file; std::vector<MyDocType> theDocList;; yin >> theDocList;. // Check for error; if ( yin.error() ); return;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:31444,Availability,error,error,31444,"Doc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; pointer:. .. code-block:: c++. class Input : public IO {; public:; Input(StringRef inputContent, void *context=NULL);. Once you have an Input object, you can use the C++ stream operator to read; the document(s). If you expect there might be multiple YAML documents in; one file, you'll need to specialize DocumentListTraits on a list of your; document type and stream in that document list type. Otherwise you can; just stream in the document type. Also, you can check if there was; any syntax errors in the YAML be calling the error() method on the Input; object. For example:. .. code-block:: c++. // Reading a single document; using llvm::yaml::Input;. Input yin(mb.getBuffer());. // Parse the YAML file; MyDocType theDoc;; yin >> theDoc;. // Check for error; if ( yin.error() ); return;. .. code-block:: c++. // Reading multiple documents in one file; using llvm::yaml::Input;. LLVM_YAML_IS_DOCUMENT_LIST_VECTOR(MyDocType). Input yin(mb.getBuffer());. // Parse the YAML file; std::vector<MyDocType> theDocList;; yin >> theDocList;. // Check for error; if ( yin.error() ); return;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:31672,Availability,error,error,31672,"Doc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; pointer:. .. code-block:: c++. class Input : public IO {; public:; Input(StringRef inputContent, void *context=NULL);. Once you have an Input object, you can use the C++ stream operator to read; the document(s). If you expect there might be multiple YAML documents in; one file, you'll need to specialize DocumentListTraits on a list of your; document type and stream in that document list type. Otherwise you can; just stream in the document type. Also, you can check if there was; any syntax errors in the YAML be calling the error() method on the Input; object. For example:. .. code-block:: c++. // Reading a single document; using llvm::yaml::Input;. Input yin(mb.getBuffer());. // Parse the YAML file; MyDocType theDoc;; yin >> theDoc;. // Check for error; if ( yin.error() ); return;. .. code-block:: c++. // Reading multiple documents in one file; using llvm::yaml::Input;. LLVM_YAML_IS_DOCUMENT_LIST_VECTOR(MyDocType). Input yin(mb.getBuffer());. // Parse the YAML file; std::vector<MyDocType> theDocList;; yin >> theDocList;. // Check for error; if ( yin.error() ); return;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:31688,Availability,error,error,31688,"Doc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; pointer:. .. code-block:: c++. class Input : public IO {; public:; Input(StringRef inputContent, void *context=NULL);. Once you have an Input object, you can use the C++ stream operator to read; the document(s). If you expect there might be multiple YAML documents in; one file, you'll need to specialize DocumentListTraits on a list of your; document type and stream in that document list type. Otherwise you can; just stream in the document type. Also, you can check if there was; any syntax errors in the YAML be calling the error() method on the Input; object. For example:. .. code-block:: c++. // Reading a single document; using llvm::yaml::Input;. Input yin(mb.getBuffer());. // Parse the YAML file; MyDocType theDoc;; yin >> theDoc;. // Check for error; if ( yin.error() ); return;. .. code-block:: c++. // Reading multiple documents in one file; using llvm::yaml::Input;. LLVM_YAML_IS_DOCUMENT_LIST_VECTOR(MyDocType). Input yin(mb.getBuffer());. // Parse the YAML file; std::vector<MyDocType> theDocList;; yin >> theDocList;. // Check for error; if ( yin.error() ); return;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:31965,Availability,error,error,31965,"Doc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; pointer:. .. code-block:: c++. class Input : public IO {; public:; Input(StringRef inputContent, void *context=NULL);. Once you have an Input object, you can use the C++ stream operator to read; the document(s). If you expect there might be multiple YAML documents in; one file, you'll need to specialize DocumentListTraits on a list of your; document type and stream in that document list type. Otherwise you can; just stream in the document type. Also, you can check if there was; any syntax errors in the YAML be calling the error() method on the Input; object. For example:. .. code-block:: c++. // Reading a single document; using llvm::yaml::Input;. Input yin(mb.getBuffer());. // Parse the YAML file; MyDocType theDoc;; yin >> theDoc;. // Check for error; if ( yin.error() ); return;. .. code-block:: c++. // Reading multiple documents in one file; using llvm::yaml::Input;. LLVM_YAML_IS_DOCUMENT_LIST_VECTOR(MyDocType). Input yin(mb.getBuffer());. // Parse the YAML file; std::vector<MyDocType> theDocList;; yin >> theDocList;. // Check for error; if ( yin.error() ); return;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:31981,Availability,error,error,31981,"Doc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; pointer:. .. code-block:: c++. class Input : public IO {; public:; Input(StringRef inputContent, void *context=NULL);. Once you have an Input object, you can use the C++ stream operator to read; the document(s). If you expect there might be multiple YAML documents in; one file, you'll need to specialize DocumentListTraits on a list of your; document type and stream in that document list type. Otherwise you can; just stream in the document type. Also, you can check if there was; any syntax errors in the YAML be calling the error() method on the Input; object. For example:. .. code-block:: c++. // Reading a single document; using llvm::yaml::Input;. Input yin(mb.getBuffer());. // Parse the YAML file; MyDocType theDoc;; yin >> theDoc;. // Check for error; if ( yin.error() ); return;. .. code-block:: c++. // Reading multiple documents in one file; using llvm::yaml::Input;. LLVM_YAML_IS_DOCUMENT_LIST_VECTOR(MyDocType). Input yin(mb.getBuffer());. // Parse the YAML file; std::vector<MyDocType> theDocList;; yin >> theDocList;. // Check for error; if ( yin.error() ); return;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:15763,Deployability,configurat,configuration,15763,"ut(StringRef Scalar, void *Ctxt,; MyStringType &Value) {; Value.Str = Scalar.str();; return StringRef();; }; };. Mappings; ========. To be translated to or from a YAML mapping for your type T you must specialize; llvm::yaml::MappingTraits on T and implement the ""void mapping(IO &io, T&)""; method. If your native data structures use pointers to a class everywhere,; you can specialize on the class pointer. Examples:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. // Example of struct Foo which is used by value; template <>; struct MappingTraits<Foo> {; static void mapping(IO &io, Foo &foo) {; io.mapOptional(""size"", foo.size);; ...; }; };. // Example of struct Bar which is natively always a pointer; template <>; struct MappingTraits<Bar*> {; static void mapping(IO &io, Bar *&bar) {; io.mapOptional(""size"", bar->size);; ...; }; };. There are circumstances where we want to allow the entire mapping to be; read as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:15901,Deployability,configurat,configuration,15901,"pings; ========. To be translated to or from a YAML mapping for your type T you must specialize; llvm::yaml::MappingTraits on T and implement the ""void mapping(IO &io, T&)""; method. If your native data structures use pointers to a class everywhere,; you can specialize on the class pointer. Examples:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. // Example of struct Foo which is used by value; template <>; struct MappingTraits<Foo> {; static void mapping(IO &io, Foo &foo) {; io.mapOptional(""size"", foo.size);; ...; }; };. // Example of struct Bar which is natively always a pointer; template <>; struct MappingTraits<Bar*> {; static void mapping(IO &io, Bar *&bar) {; io.mapOptional(""size"", bar->size);; ...; }; };. There are circumstances where we want to allow the entire mapping to be; read as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind the struct's fields to YAML key names. For example:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:24844,Deployability,configurat,configuration,24844,"ck:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO &io, T&, size_t indx)``. For example:. .. code-block:: c++. template <>; struct SequenceTraits<MySeq> {; static size_t size(IO &io, MySeq &list) { ... }; static MySeqEl &element(IO &io, MySeq &list, size_t index) { ... }; };. The size() method returns how many elements are currently in your sequence.; The element() method returns a reference to the i'th element in the sequence.; When parsing YAML, the element() method may be called with an index one bigger; than the current size. Your element() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:26608,Deployability,configurat,configuration,26608,"nt() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that when written to YAML it uses the; inline notation (e.g [ foo, bar ] ). To specify that a sequence type should; be written in YAML as a flow sequence, your SequenceTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. template <>; struct SequenceTraits<MyList> {; static size_t size(IO &io, MyList &list) { ... }; static MyListEl &element(IO &io, MyList &list, size_t index) { ... }. // The existence of this member causes YAML I/O to use a flow sequence; static const bool flow = true;; };. With the above, if you used MyList as the data type in your native data; structures, then when converted to YAML, a flow sequence of integers; will be used (e.g. [ 10, -3, 4 ]). Flow sequences are subject to line wrapping according to the Output object; configuration. Utility Macros; --------------; Since a common source of sequences is std::vector<>, YAML I/O provides macros:; LLVM_YAML_IS_SEQUENCE_VECTOR() and LLVM_YAML_IS_FLOW_SEQUENCE_VECTOR() which; can be used to easily specify SequenceTraits<> on a std::vector type. YAML; I/O does not partial specialize SequenceTraits on std::vector<> because that; would force all vectors to be sequences. An example use of the macros:. .. code-block:: c++. std::vector<MyType1>;; std::vector<MyType2>;; LLVM_YAML_IS_SEQUENCE_VECTOR(MyType1); LLVM_YAML_IS_FLOW_SEQUENCE_VECTOR(MyType2). Document List; =============. YAML allows you to define multiple ""documents"" in a single YAML file. Each; new document starts with a left aligned ""---"" token. The end of all documents; is denoted with a left aligned ""..."" token. Many users of YAML will never; have need for multiple documents. The top level node in their YAML schema; will be a mapping or sequence. For those cases, the f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:18665,Energy Efficiency,allocate,allocated,18665,"YAML for should be in x,y coordinates. That; is, you want the yaml to look like:. .. code-block:: yaml. x: 10.3; y: -4.7. You can support this by defining a MappingTraits that normalizes the polar; coordinates to x,y coordinates when writing YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:18928,Energy Efficiency,allocate,allocated,18928," YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() metho",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:19583,Energy Efficiency,allocate,allocated,19583,"alizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps to how those optional fields are filled in. First, the; second parameter to the mapping() method is a reference to a native class. That; native class must have a default constructor. Whatever value the default; constructor i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:19737,Energy Efficiency,allocate,allocates,19737,"d polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps to how those optional fields are filled in. First, the; second parameter to the mapping() method is a reference to a native class. That; native class must have a default constructor. Whatever value the default; constructor initially sets for an optional field will be that field's value.; Second, the mapOptional() method has an optional third parameter. If provided; it is the value that mapOptional() should set that field to if the YAML document; does not ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:25595,Energy Efficiency,allocate,allocate,25595,"ruct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO &io, T&, size_t indx)``. For example:. .. code-block:: c++. template <>; struct SequenceTraits<MySeq> {; static size_t size(IO &io, MySeq &list) { ... }; static MySeqEl &element(IO &io, MySeq &list, size_t index) { ... }; };. The size() method returns how many elements are currently in your sequence.; The element() method returns a reference to the i'th element in the sequence.; When parsing YAML, the element() method may be called with an index one bigger; than the current size. Your element() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that when written to YAML it uses the; inline notation (e.g [ foo, bar ] ). To specify that a sequence type should; be written in YAML as a flow sequence, your SequenceTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. template <>; struct SequenceTraits<MyList> {; static size_t size(IO &io, MyList &list) { ... }; static MyListEl &element(IO &io, MyList &list, size_t index) { ... }. // The existence of this member causes YAML I/O to use a flow sequence; static const bool flow = true;; };. With the above, if you used MyList as the data type in your native data; structures, then when converted to YAML, a flow sequence of integers; will be used (e.g. [ 10, -3, 4 ]). Flow sequences are subject to line wrapping according to the Output object; configuration. Utility Macros; --------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:25724,Energy Efficiency,allocate,allocated,25724,"ruct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO &io, T&, size_t indx)``. For example:. .. code-block:: c++. template <>; struct SequenceTraits<MySeq> {; static size_t size(IO &io, MySeq &list) { ... }; static MySeqEl &element(IO &io, MySeq &list, size_t index) { ... }; };. The size() method returns how many elements are currently in your sequence.; The element() method returns a reference to the i'th element in the sequence.; When parsing YAML, the element() method may be called with an index one bigger; than the current size. Your element() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that when written to YAML it uses the; inline notation (e.g [ foo, bar ] ). To specify that a sequence type should; be written in YAML as a flow sequence, your SequenceTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. template <>; struct SequenceTraits<MyList> {; static size_t size(IO &io, MyList &list) { ... }; static MyListEl &element(IO &io, MyList &list, size_t index) { ... }. // The existence of this member causes YAML I/O to use a flow sequence; static const bool flow = true;; };. With the above, if you used MyList as the data type in your native data; structures, then when converted to YAML, a flow sequence of integers; will be used (e.g. [ 10, -3, 4 ]). Flow sequences are subject to line wrapping according to the Output object; configuration. Utility Macros; --------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:5536,Integrability,message,message,5536,".hatSize = 7;; std::vector<Person> persons;; persons.push_back(tom);; persons.push_back(dan);. Output yout(llvm::outs());; yout << persons;. This would write the following:. .. code-block:: yaml. - name: Tom; hat-size: 8; - name: Dan; hat-size: 7. And you can also read such YAML documents with the following code:. .. code-block:: c++. using llvm::yaml::Input;. typedef std::vector<Person> PersonList;; std::vector<PersonList> docs;. Input yin(document.getBuffer());; yin >> docs;. if ( yin.error() ); return;. // Process read document; for ( PersonList &pl : docs ) {; for ( Person &person : pl ) {; cout << ""name="" << person.name;; }; }. One other feature of YAML is the ability to define multiple documents in a; single file. That is why reading YAML produces a vector of your document type. Error Handling; ==============. When parsing a YAML document, if the input does not match your schema (as; expressed in your XxxTraits<> specializations). YAML I/O; will print out an error message and your Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:13216,Integrability,message,message,13216,"l data structure may use an integer for time (seconds since; some epoch), but in YAML it would be much nicer to express that integer in; some time format (e.g. 4-May-2012 10:30pm). YAML I/O has a way to support; custom formatting and parsing of scalar types by specializing ScalarTraits<> on; your data type. When writing, YAML I/O will provide the native type and; your specialization must create a temporary llvm::StringRef. When reading,; YAML I/O will provide an llvm::StringRef of scalar and your specialization; must convert that to your native data type. An outline of a custom scalar type; looks like:. .. code-block:: c++. using llvm::yaml::ScalarTraits;; using llvm::yaml::IO;. template <>; struct ScalarTraits<MyCustomType> {; static void output(const MyCustomType &value, void*,; llvm::raw_ostream &out) {; out << value; // do custom formatting here; }; static StringRef input(StringRef scalar, void*, MyCustomType &value) {; // do custom parsing here. Return the empty string on success,; // or an error message on failure.; return StringRef();; }; // Determine if this scalar needs quotes.; static QuotingType mustQuote(StringRef) { return QuotingType::Single; }; };. Block Scalars; -------------. YAML block scalars are string literals that are represented in YAML using the; literal block notation, just like the example shown below:. .. code-block:: yaml. text: |; First line; Second line. The YAML I/O library provides support for translating between YAML block scalars; and specific C++ types by allowing you to specialize BlockScalarTraits<> on; your data type. The library doesn't provide any built-in support for block; scalar I/O for types like std::string and llvm::StringRef as they are already; supported by YAML I/O and use the ordinary scalar notation by default. BlockScalarTraits specializations are very similar to the; ScalarTraits specialization - YAML I/O will provide the native type and your; specialization must create a temporary llvm::StringRef when writing, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23463,Integrability,message,message,23463,"his allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"".",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:24803,Integrability,wrap,wrapping,24803,"ck:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO &io, T&, size_t indx)``. For example:. .. code-block:: c++. template <>; struct SequenceTraits<MySeq> {; static size_t size(IO &io, MySeq &list) { ... }; static MySeqEl &element(IO &io, MySeq &list, size_t index) { ... }; };. The size() method returns how many elements are currently in your sequence.; The element() method returns a reference to the i'th element in the sequence.; When parsing YAML, the element() method may be called with an index one bigger; than the current size. Your element() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:26567,Integrability,wrap,wrapping,26567,"nt() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that when written to YAML it uses the; inline notation (e.g [ foo, bar ] ). To specify that a sequence type should; be written in YAML as a flow sequence, your SequenceTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. template <>; struct SequenceTraits<MyList> {; static size_t size(IO &io, MyList &list) { ... }; static MyListEl &element(IO &io, MyList &list, size_t index) { ... }. // The existence of this member causes YAML I/O to use a flow sequence; static const bool flow = true;; };. With the above, if you used MyList as the data type in your native data; structures, then when converted to YAML, a flow sequence of integers; will be used (e.g. [ 10, -3, 4 ]). Flow sequences are subject to line wrapping according to the Output object; configuration. Utility Macros; --------------; Since a common source of sequences is std::vector<>, YAML I/O provides macros:; LLVM_YAML_IS_SEQUENCE_VECTOR() and LLVM_YAML_IS_FLOW_SEQUENCE_VECTOR() which; can be used to easily specify SequenceTraits<> on a std::vector type. YAML; I/O does not partial specialize SequenceTraits on std::vector<> because that; would force all vectors to be sequences. An example use of the macros:. .. code-block:: c++. std::vector<MyType1>;; std::vector<MyType2>;; LLVM_YAML_IS_SEQUENCE_VECTOR(MyType1); LLVM_YAML_IS_FLOW_SEQUENCE_VECTOR(MyType2). Document List; =============. YAML allows you to define multiple ""documents"" in a single YAML file. Each; new document starts with a left aligned ""---"" token. The end of all documents; is denoted with a left aligned ""..."" token. Many users of YAML will never; have need for multiple documents. The top level node in their YAML schema; will be a mapping or sequence. For those cases, the f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:29223,Integrability,wrap,wrapping,29223,"s a pointer to; whatever state information you might need. For instance, in a previous example we showed how the conversion type for a; flags field could be determined at runtime based on the value of another field; in the mapping. But what if an inner mapping needs to know some field value; of an outer mapping? That is where the ""context"" parameter comes in. You; can set values in the context in the outer map's mapping() method and; retrieve those values in the inner map's mapping() method. The context value is just a void*. All your traits which use the context; and operate on your native data types, need to agree what the context value; actually is. It could be a pointer to an object or struct which your various; traits use to shared context sensitive information. Output; ======. The llvm::yaml::Output class is used to generate a YAML document from your; in-memory data structures, using traits defined on your data types.; To instantiate an Output object you need an llvm::raw_ostream, an optional; context pointer and an optional wrapping column:. .. code-block:: c++. class Output : public IO {; public:; Output(llvm::raw_ostream &, void *context = NULL, int WrapColumn = 70);. Once you have an Output object, you can use the C++ stream operator on it; to write your native data as YAML. One thing to recall is that a YAML file; can contain multiple ""documents"". If the top level data structure you are; streaming as YAML is a mapping, scalar, or sequence, then Output assumes you; are generating one document and wraps the mapping output; with ""``---``"" and trailing ""``...``"". The WrapColumn parameter will cause the flow mappings and sequences to; line-wrap when they go over the supplied column. Pass 0 to completely; suppress the wrapping. .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:29708,Integrability,wrap,wraps,29708,"g() method. The context value is just a void*. All your traits which use the context; and operate on your native data types, need to agree what the context value; actually is. It could be a pointer to an object or struct which your various; traits use to shared context sensitive information. Output; ======. The llvm::yaml::Output class is used to generate a YAML document from your; in-memory data structures, using traits defined on your data types.; To instantiate an Output object you need an llvm::raw_ostream, an optional; context pointer and an optional wrapping column:. .. code-block:: c++. class Output : public IO {; public:; Output(llvm::raw_ostream &, void *context = NULL, int WrapColumn = 70);. Once you have an Output object, you can use the C++ stream operator on it; to write your native data as YAML. One thing to recall is that a YAML file; can contain multiple ""documents"". If the top level data structure you are; streaming as YAML is a mapping, scalar, or sequence, then Output assumes you; are generating one document and wraps the mapping output; with ""``---``"" and trailing ""``...``"". The WrapColumn parameter will cause the flow mappings and sequences to; line-wrap when they go over the supplied column. Pass 0 to completely; suppress the wrapping. .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:29850,Integrability,wrap,wrap,29850," is. It could be a pointer to an object or struct which your various; traits use to shared context sensitive information. Output; ======. The llvm::yaml::Output class is used to generate a YAML document from your; in-memory data structures, using traits defined on your data types.; To instantiate an Output object you need an llvm::raw_ostream, an optional; context pointer and an optional wrapping column:. .. code-block:: c++. class Output : public IO {; public:; Output(llvm::raw_ostream &, void *context = NULL, int WrapColumn = 70);. Once you have an Output object, you can use the C++ stream operator on it; to write your native data as YAML. One thing to recall is that a YAML file; can contain multiple ""documents"". If the top level data structure you are; streaming as YAML is a mapping, scalar, or sequence, then Output assumes you; are generating one document and wraps the mapping output; with ""``---``"" and trailing ""``...``"". The WrapColumn parameter will cause the flow mappings and sequences to; line-wrap when they go over the supplied column. Pass 0 to completely; suppress the wrapping. .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Inp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:29929,Integrability,wrap,wrapping,29929," shared context sensitive information. Output; ======. The llvm::yaml::Output class is used to generate a YAML document from your; in-memory data structures, using traits defined on your data types.; To instantiate an Output object you need an llvm::raw_ostream, an optional; context pointer and an optional wrapping column:. .. code-block:: c++. class Output : public IO {; public:; Output(llvm::raw_ostream &, void *context = NULL, int WrapColumn = 70);. Once you have an Output object, you can use the C++ stream operator on it; to write your native data as YAML. One thing to recall is that a YAML file; can contain multiple ""documents"". If the top level data structure you are; streaming as YAML is a mapping, scalar, or sequence, then Output assumes you; are generating one document and wraps the mapping output; with ""``---``"" and trailing ""``...``"". The WrapColumn parameter will cause the flow mappings and sequences to; line-wrap when they go over the supplied column. Pass 0 to completely; suppress the wrapping. .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyMapType &info) {; Output yout(llvm::outs());; yout << info;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ... On the other hand, if the top level data structure you are streaming as YAML; has a DocumentListTraits specialization, then Output walks through each element; of your DocumentList and generates a ""---"" before the start of each element; and ends with a ""..."". .. code-block:: c++. using llvm::yaml::Output;. void dumpMyMapDoc(const MyDocListType &docList) {; Output yout(llvm::outs());; yout << docList;; }. The above could produce output like:. .. code-block:: yaml. ---; name: Tom; hat-size: 7; ---; name: Tom; shoe-size: 11; ... Input; =====. The llvm::yaml::Input class is used to parse YAML document(s) into your native; data structures. To instantiate an Input; object you need a StringRef to the entire YAML file, and optionally a context; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:15763,Modifiability,config,configuration,15763,"ut(StringRef Scalar, void *Ctxt,; MyStringType &Value) {; Value.Str = Scalar.str();; return StringRef();; }; };. Mappings; ========. To be translated to or from a YAML mapping for your type T you must specialize; llvm::yaml::MappingTraits on T and implement the ""void mapping(IO &io, T&)""; method. If your native data structures use pointers to a class everywhere,; you can specialize on the class pointer. Examples:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. // Example of struct Foo which is used by value; template <>; struct MappingTraits<Foo> {; static void mapping(IO &io, Foo &foo) {; io.mapOptional(""size"", foo.size);; ...; }; };. // Example of struct Bar which is natively always a pointer; template <>; struct MappingTraits<Bar*> {; static void mapping(IO &io, Bar *&bar) {; io.mapOptional(""size"", bar->size);; ...; }; };. There are circumstances where we want to allow the entire mapping to be; read as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:15901,Modifiability,config,configuration,15901,"pings; ========. To be translated to or from a YAML mapping for your type T you must specialize; llvm::yaml::MappingTraits on T and implement the ""void mapping(IO &io, T&)""; method. If your native data structures use pointers to a class everywhere,; you can specialize on the class pointer. Examples:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. // Example of struct Foo which is used by value; template <>; struct MappingTraits<Foo> {; static void mapping(IO &io, Foo &foo) {; io.mapOptional(""size"", foo.size);; ...; }; };. // Example of struct Bar which is natively always a pointer; template <>; struct MappingTraits<Bar*> {; static void mapping(IO &io, Bar *&bar) {; io.mapOptional(""size"", bar->size);; ...; }; };. There are circumstances where we want to allow the entire mapping to be; read as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind the struct's fields to YAML key names. For example:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:17409,Modifiability,variab,variable,17409,"Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind the struct's fields to YAML key names. For example:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Person> {; static void mapping(IO &io, Person &info) {; io.mapRequired(""name"", info.name);; io.mapOptional(""hat-size"", info.hatSize);; }; };. Normalization; ----------------. When [de]normalization is required, the mapping() method needs a way to access; normalized values as fields. To help with this, there is; a template MappingNormalization<> which you can then use to automatically; do the normalization and denormalization. The template is used to create; a local variable in your mapping() method which contains the normalized keys. Suppose you have native data type; Polar which specifies a position in polar coordinates (distance, angle):. .. code-block:: c++. struct Polar {; float distance;; float angle;; };. but you've decided the normalized YAML for should be in x,y coordinates. That; is, you want the yaml to look like:. .. code-block:: yaml. x: 10.3; y: -4.7. You can support this by defining a MappingTraits that normalizes the polar; coordinates to x,y coordinates when writing YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:18633,Modifiability,variab,variable,18633,"YAML for should be in x,y coordinates. That; is, you want the yaml to look like:. .. code-block:: yaml. x: 10.3; y: -4.7. You can support this by defining a MappingTraits that normalizes the polar; coordinates to x,y coordinates when writing YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:18896,Modifiability,variab,variable,18896," YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; NormalizedPolar(IO &io); : x(0.0), y(0.0) {; }; NormalizedPolar(IO &, Polar &polar); : x(polar.distance * cos(polar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() metho",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:19203,Modifiability,variab,variable,19203,"lar.angle)),; y(polar.distance * sin(polar.angle)) {; }; Polar denormalize(IO &) {; return Polar(sqrt(x*x+y*y), arctan(x,y));; }. float x;; float y;; };. static void mapping(IO &io, Polar &polar) {; MappingNormalization<NormalizedPolar, Polar> keys(io, polar);. io.mapRequired(""x"", keys->x);; io.mapRequired(""y"", keys->y);; }; };. When writing YAML, the local variable ""keys"" will be a stack allocated; instance of NormalizedPolar, constructed from the supplied polar object which; initializes it x and y fields. The mapRequired() methods then write out the x; and y values as key/value pairs. When reading YAML, the local variable ""keys"" will be a stack allocated instance; of NormalizedPolar, constructed by the empty constructor. The mapRequired; methods will find the matching key in the YAML document and fill in the x and y; fields of the NormalizedPolar object keys. At the end of the mapping() method; when the local keys variable goes out of scope, the denormalize() method will; automatically be called to convert the read values back to polar coordinates,; and then assigned back to the second parameter to mapping(). In some cases, the normalized class may be a subclass of the native type and; could be returned by the denormalize() method, except that the temporary; normalized instance is stack allocated. In these cases, the utility template; MappingNormalizationHeap<> can be used instead. It just like; MappingNormalization<> except that it heap allocates the normalized object; when reading YAML. It never destroys the normalized object. The denormalize(); method can this return ""this"". Default values; --------------; Within a mapping() method, calls to io.mapRequired() mean that that key is; required to exist when parsing YAML documents, otherwise YAML I/O will issue an; error. On the other hand, keys registered with io.mapOptional() are allowed to not; exist in the YAML document being read. So what value is put in the field; for those optional keys?; There are two steps t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:24844,Modifiability,config,configuration,24844,"ck:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO &io, T&, size_t indx)``. For example:. .. code-block:: c++. template <>; struct SequenceTraits<MySeq> {; static size_t size(IO &io, MySeq &list) { ... }; static MySeqEl &element(IO &io, MySeq &list, size_t index) { ... }; };. The size() method returns how many elements are currently in your sequence.; The element() method returns a reference to the i'th element in the sequence.; When parsing YAML, the element() method may be called with an index one bigger; than the current size. Your element() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:26608,Modifiability,config,configuration,26608,"nt() method should allocate space for one; more element (using default constructor if element is a C++ object) and returns; a reference to that new allocated space. Flow Sequence; -------------; A YAML ""flow sequence"" is a sequence that when written to YAML it uses the; inline notation (e.g [ foo, bar ] ). To specify that a sequence type should; be written in YAML as a flow sequence, your SequenceTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. template <>; struct SequenceTraits<MyList> {; static size_t size(IO &io, MyList &list) { ... }; static MyListEl &element(IO &io, MyList &list, size_t index) { ... }. // The existence of this member causes YAML I/O to use a flow sequence; static const bool flow = true;; };. With the above, if you used MyList as the data type in your native data; structures, then when converted to YAML, a flow sequence of integers; will be used (e.g. [ 10, -3, 4 ]). Flow sequences are subject to line wrapping according to the Output object; configuration. Utility Macros; --------------; Since a common source of sequences is std::vector<>, YAML I/O provides macros:; LLVM_YAML_IS_SEQUENCE_VECTOR() and LLVM_YAML_IS_FLOW_SEQUENCE_VECTOR() which; can be used to easily specify SequenceTraits<> on a std::vector type. YAML; I/O does not partial specialize SequenceTraits on std::vector<> because that; would force all vectors to be sequences. An example use of the macros:. .. code-block:: c++. std::vector<MyType1>;; std::vector<MyType2>;; LLVM_YAML_IS_SEQUENCE_VECTOR(MyType1); LLVM_YAML_IS_FLOW_SEQUENCE_VECTOR(MyType2). Document List; =============. YAML allows you to define multiple ""documents"" in a single YAML file. Each; new document starts with a left aligned ""---"" token. The end of all documents; is denoted with a left aligned ""..."" token. Many users of YAML will never; have need for multiple documents. The top level node in their YAML schema; will be a mapping or sequence. For those cases, the f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:410,Security,hash,hash,410,"=====================; YAML I/O; =====================. .. contents::; :local:. Introduction to YAML; ====================. YAML is a human readable data serialization language. The full YAML language; spec can be read at `yaml.org; <http://www.yaml.org/spec/1.2/spec.html#Introduction>`_. The simplest form of; yaml is just ""scalars"", ""mappings"", and ""sequences"". A scalar is any number; or string. The pound/hash symbol (#) begins a comment line. A mapping is; a set of key-value pairs where the key ends with a colon. For example:. .. code-block:: yaml. # a mapping; name: Tom; hat-size: 7. A sequence is a list of items where each item starts with a leading dash ('-').; For example:. .. code-block:: yaml. # a sequence; - x86; - x86_64; - PowerPC. You can combine mappings and sequences by indenting. For example a sequence; of mappings in which one of the mapping values is itself a sequence:. .. code-block:: yaml. # a sequence of mappings with one key's value being a sequence; - name: Tom; cpus:; - x86; - x86_64; - name: Bob; cpus:; - x86; - name: Dan; cpus:; - PowerPC; - x86. Sometime sequences are known to be short and the one entry per line is too; verbose, so YAML offers an alternate syntax for sequences called a ""Flow; Sequence"" in which you put comma separated sequence elements into square; brackets. The above example could then be simplified to :. .. code-block:: yaml. # a sequence of mappings with one key's value being a flow sequence; - name: Tom; cpus: [ x86, x86_64 ]; - name: Bob; cpus: [ x86 ]; - name: Dan; cpus: [ PowerPC, x86 ]. Introduction to YAML I/O; ========================. The use of indenting makes the YAML easy for a human to read and understand,; but having a program read and write YAML involves a lot of tedious details.; The YAML I/O library structures and simplifies reading and writing YAML; documents. YAML I/O assumes you have some ""native"" data structures which you want to be; able to dump as YAML and recreate from YAML. The first step is to try",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:6525,Security,validat,validate,6525,"r Input object's error() method will; return true. For instance the following document:. .. code-block:: yaml. - name: Tom; shoe-size: 12; - name: Dan; hat-size: 7. Has a key (shoe-size) that is not defined in the schema. YAML I/O will; automatically generate this error:. .. code-block:: yaml. YAML:2:2: error: unknown key 'shoe-size'; shoe-size: 12; ^~~~~~~~~. Similar errors are produced for other input not conforming to the schema. Scalars; =======. YAML scalars are just strings (i.e. not a sequence or mapping). The YAML I/O; library provides support for translating between YAML scalars and specific; C++ types. Built-in types; --------------; The following types have built-in support in YAML I/O:. * bool; * float; * double; * StringRef; * std::string; * int64_t; * int32_t; * int16_t; * int8_t; * uint64_t; * uint32_t; * uint16_t; * uint8_t. That is, you can use those types in fields of MappingTraits or as element type; in sequence. When reading, YAML I/O will validate that the string found; is convertible to that type and error out if not. Unique types; ------------; Given that YAML I/O is trait based, the selection of how to convert your data; to YAML is based on the type of your data. But in C++ type matching, typedefs; do not generate unique type names. That means if you have two typedefs of; unsigned int, to YAML I/O both types look exactly like unsigned int. To; facilitate make unique type names, YAML I/O provides a macro which is used; like a typedef on built-in types, but expands to create a class with conversion; operators to and from the base type. For example:. .. code-block:: c++. LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyFooFlags); LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyBarFlags). This generates two classes MyFooFlags and MyBarFlags which you can use in your; native data structures instead of uint32_t. They are implicitly; converted to and from uint32_t. The point of creating these unique types; is that you can now specify traits on them to get different YAML c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:17186,Security,access,access,17186,"R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind the struct's fields to YAML key names. For example:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Person> {; static void mapping(IO &io, Person &info) {; io.mapRequired(""name"", info.name);; io.mapOptional(""hat-size"", info.hatSize);; }; };. Normalization; ----------------. When [de]normalization is required, the mapping() method needs a way to access; normalized values as fields. To help with this, there is; a template MappingNormalization<> which you can then use to automatically; do the normalization and denormalization. The template is used to create; a local variable in your mapping() method which contains the normalized keys. Suppose you have native data type; Polar which specifies a position in polar coordinates (distance, angle):. .. code-block:: c++. struct Polar {; float distance;; float angle;; };. but you've decided the normalized YAML for should be in x,y coordinates. That; is, you want the yaml to look like:. .. code-block:: yaml. x: 10.3; y: -4.7. You can support this by defining a MappingTraits that normalizes the polar; coordinates to x,y coordinates when writing YAML and denormalizes x,y; coordinates into polar when reading YAML. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Polar> {. class NormalizedPolar {; public:; Normali",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23280,Security,validat,validate,23280," == cpu_x86_64 ); io.mapRequired(""flags"", *(My86_64Flags*)info.flags);; else; io.mapRequired(""flags"", *(My86Flags*)info.flags);; }; };. Tags; ----. The YAML syntax supports tags as a way to specify the type of a node before; it is parsed. This allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mappin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23369,Security,validat,validate,23369,"flags);; }; };. Tags; ----. The YAML syntax supports tags as a way to specify the type of a node before; it is parsed. This allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23489,Security,validat,validate,23489,"his allows dynamic types of nodes. But the YAML I/O model uses; static typing, so there are limits to how you can use tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"".",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23610,Security,validat,validate,23610,"se tags with the YAML I/O; model. Recently, we added support to YAML I/O for checking/setting the optional; tag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:24021,Security,validat,validate,24021,"air is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static const bool flow = true;; }. Flow mappings are subject to line wrapping according to the Output object; configuration. Sequence; ========. To be translated to or from a YAML sequence for your type T you must specialize; llvm::yaml::SequenceTraits on T and implement two methods:; ``size_t size(IO &io, T&)`` and; ``T::value_type& element(IO ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:9434,Testability,assert,assertion,9434,"pu_x86_64 = 5,; cpu_x86 = 7,; cpu_PowerPC = 8; };. struct Info {; CPUs cpu;; uint32_t flags;; };. To support reading and writing of this enumeration, you can define a; ScalarEnumerationTraits specialization on CPUs, which can then be used; as a field type:. .. code-block:: c++. using llvm::yaml::ScalarEnumerationTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarEnumerationTraits<CPUs> {; static void enumeration(IO &io, CPUs &value) {; io.enumCase(value, ""x86_64"", cpu_x86_64);; io.enumCase(value, ""x86"", cpu_x86);; io.enumCase(value, ""PowerPC"", cpu_PowerPC);; }; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info &info) {; io.mapRequired(""cpu"", info.cpu);; io.mapOptional(""flags"", info.flags, 0);; }; };. When reading YAML, if the string found does not match any of the strings; specified by enumCase() methods, an error is automatically generated.; When writing YAML, if the value being written does not match any of the values; specified by the enumCase() methods, a runtime assertion is triggered. BitValue; --------; Another common data structure in C++ is a field where each bit has a unique; meaning. This is often used in a ""flags"" field. YAML I/O has support for; converting such fields to a flow sequence. For instance suppose you; had the following bit flags defined:. .. code-block:: c++. enum {; flagsPointy = 1; flagsHollow = 2; flagsFlat = 4; flagsRound = 8; };. LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyFlags). To support reading and writing of MyFlags, you specialize ScalarBitSetTraits<>; on MyFlags and provide the bit values and their names. .. code-block:: c++. using llvm::yaml::ScalarBitSetTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""hollow"", flagHollow);; io.bitSetCase(value, ""flat"", flagFlat);; io.bitSetCase(value, ""round"", flagRound);; io.bitSetCase(value, ""po",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:10673,Testability,test,test,10673,"ined:. .. code-block:: c++. enum {; flagsPointy = 1; flagsHollow = 2; flagsFlat = 4; flagsRound = 8; };. LLVM_YAML_STRONG_TYPEDEF(uint32_t, MyFlags). To support reading and writing of MyFlags, you specialize ScalarBitSetTraits<>; on MyFlags and provide the bit values and their names. .. code-block:: c++. using llvm::yaml::ScalarBitSetTraits;; using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""hollow"", flagHollow);; io.bitSetCase(value, ""flat"", flagFlat);; io.bitSetCase(value, ""round"", flagRound);; io.bitSetCase(value, ""pointy"", flagPointy);; }; };. struct Info {; StringRef name;; MyFlags flags;; };. template <>; struct MappingTraits<Info> {; static void mapping(IO &io, Info& info) {; io.mapRequired(""name"", info.name);; io.mapRequired(""flags"", info.flags);; }; };. With the above, YAML I/O (when writing) will test mask each value in the; bitset trait against the flags field, and each that matches will; cause the corresponding string to be added to the flow sequence. The opposite; is done when reading and any unknown string values will result in an error. With; the above schema, a same valid YAML document is:. .. code-block:: yaml. name: Tom; flags: [ pointy, flat ]. Sometimes a ""flags"" field might contains an enumeration part; defined by a bit-mask. .. code-block:: c++. enum {; flagsFeatureA = 1,; flagsFeatureB = 2,; flagsFeatureC = 4,. flagsCPUMask = 24,. flagsCPU1 = 8,; flagsCPU2 = 16; };. To support reading and writing such fields, you need to use the maskedBitSet(); method and provide the bit values, their names and the enumeration mask. .. code-block:: c++. template <>; struct ScalarBitSetTraits<MyFlags> {; static void bitset(IO &io, MyFlags &value) {; io.bitSetCase(value, ""featureA"", flagsFeatureA);; io.bitSetCase(value, ""featureB"", flagsFeatureB);; io.bitSetCase(value, ""featureC"", flagsFeatureC);; io.maskedBitSetCase(value, ""CPU1"", flagsCP",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:23725,Testability,assert,assert,23725,"ag on a map. Using this functionality it is even possible to support different; mappings, as long as they are convertible. To check a tag, inside your mapping() method you can use io.mapTag() to specify; what the tag should be. This will also add that tag when writing yaml. Validation; ----------. Sometimes in a YAML map, each key/value pair is valid, but the combination is; not. This is similar to something having no syntax errors, but still having; semantic errors. To support semantic level checking, YAML I/O allows; an optional ``validate()`` method in a MappingTraits template specialization. When parsing YAML, the ``validate()`` method is call *after* all key/values in; the map have been processed. Any error message returned by the ``validate()``; method during input will be printed just a like a syntax error would be printed.; When writing YAML, the ``validate()`` method is called *before* the YAML; key/values are written. Any error during output will trigger an ``assert()``; because it is a programming error to have invalid struct values. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }; static std::string validate(IO &io, Stuff &stuff) {; // Look at all fields in 'stuff' and if there; // are any bad values return a string describing; // the error. Otherwise return an empty string.; return std::string{};; }; };. Flow Mapping; ------------; A YAML ""flow mapping"" is a mapping that uses the inline notation; (e.g { x: 1, y: 0 } ) when written to YAML. To specify that a type should be; written in YAML using flow mapping, your MappingTraits specialization should; add ""static const bool flow = true;"". For instance:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. struct Stuff {; ...; };. template <>; struct MappingTraits<Stuff> {; static void mapping(IO &io, Stuff &stuff) {; ...; }. static c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:294,Usability,simpl,simplest,294,"=====================; YAML I/O; =====================. .. contents::; :local:. Introduction to YAML; ====================. YAML is a human readable data serialization language. The full YAML language; spec can be read at `yaml.org; <http://www.yaml.org/spec/1.2/spec.html#Introduction>`_. The simplest form of; yaml is just ""scalars"", ""mappings"", and ""sequences"". A scalar is any number; or string. The pound/hash symbol (#) begins a comment line. A mapping is; a set of key-value pairs where the key ends with a colon. For example:. .. code-block:: yaml. # a mapping; name: Tom; hat-size: 7. A sequence is a list of items where each item starts with a leading dash ('-').; For example:. .. code-block:: yaml. # a sequence; - x86; - x86_64; - PowerPC. You can combine mappings and sequences by indenting. For example a sequence; of mappings in which one of the mapping values is itself a sequence:. .. code-block:: yaml. # a sequence of mappings with one key's value being a sequence; - name: Tom; cpus:; - x86; - x86_64; - name: Bob; cpus:; - x86; - name: Dan; cpus:; - PowerPC; - x86. Sometime sequences are known to be short and the one entry per line is too; verbose, so YAML offers an alternate syntax for sequences called a ""Flow; Sequence"" in which you put comma separated sequence elements into square; brackets. The above example could then be simplified to :. .. code-block:: yaml. # a sequence of mappings with one key's value being a flow sequence; - name: Tom; cpus: [ x86, x86_64 ]; - name: Bob; cpus: [ x86 ]; - name: Dan; cpus: [ PowerPC, x86 ]. Introduction to YAML I/O; ========================. The use of indenting makes the YAML easy for a human to read and understand,; but having a program read and write YAML involves a lot of tedious details.; The YAML I/O library structures and simplifies reading and writing YAML; documents. YAML I/O assumes you have some ""native"" data structures which you want to be; able to dump as YAML and recreate from YAML. The first step is to try",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:1354,Usability,simpl,simplified,1354,""", and ""sequences"". A scalar is any number; or string. The pound/hash symbol (#) begins a comment line. A mapping is; a set of key-value pairs where the key ends with a colon. For example:. .. code-block:: yaml. # a mapping; name: Tom; hat-size: 7. A sequence is a list of items where each item starts with a leading dash ('-').; For example:. .. code-block:: yaml. # a sequence; - x86; - x86_64; - PowerPC. You can combine mappings and sequences by indenting. For example a sequence; of mappings in which one of the mapping values is itself a sequence:. .. code-block:: yaml. # a sequence of mappings with one key's value being a sequence; - name: Tom; cpus:; - x86; - x86_64; - name: Bob; cpus:; - x86; - name: Dan; cpus:; - PowerPC; - x86. Sometime sequences are known to be short and the one entry per line is too; verbose, so YAML offers an alternate syntax for sequences called a ""Flow; Sequence"" in which you put comma separated sequence elements into square; brackets. The above example could then be simplified to :. .. code-block:: yaml. # a sequence of mappings with one key's value being a flow sequence; - name: Tom; cpus: [ x86, x86_64 ]; - name: Bob; cpus: [ x86 ]; - name: Dan; cpus: [ PowerPC, x86 ]. Introduction to YAML I/O; ========================. The use of indenting makes the YAML easy for a human to read and understand,; but having a program read and write YAML involves a lot of tedious details.; The YAML I/O library structures and simplifies reading and writing YAML; documents. YAML I/O assumes you have some ""native"" data structures which you want to be; able to dump as YAML and recreate from YAML. The first step is to try; writing example YAML for your data structures. You may find after looking at; possible YAML representations that a direct mapping of your data structures; to YAML is not very readable. Often the fields are not in the order that; a human would find readable. Or the same information is replicated in multiple; locations, making it hard for a hu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:1806,Usability,simpl,simplifies,1806,"example a sequence; of mappings in which one of the mapping values is itself a sequence:. .. code-block:: yaml. # a sequence of mappings with one key's value being a sequence; - name: Tom; cpus:; - x86; - x86_64; - name: Bob; cpus:; - x86; - name: Dan; cpus:; - PowerPC; - x86. Sometime sequences are known to be short and the one entry per line is too; verbose, so YAML offers an alternate syntax for sequences called a ""Flow; Sequence"" in which you put comma separated sequence elements into square; brackets. The above example could then be simplified to :. .. code-block:: yaml. # a sequence of mappings with one key's value being a flow sequence; - name: Tom; cpus: [ x86, x86_64 ]; - name: Bob; cpus: [ x86 ]; - name: Dan; cpus: [ PowerPC, x86 ]. Introduction to YAML I/O; ========================. The use of indenting makes the YAML easy for a human to read and understand,; but having a program read and write YAML involves a lot of tedious details.; The YAML I/O library structures and simplifies reading and writing YAML; documents. YAML I/O assumes you have some ""native"" data structures which you want to be; able to dump as YAML and recreate from YAML. The first step is to try; writing example YAML for your data structures. You may find after looking at; possible YAML representations that a direct mapping of your data structures; to YAML is not very readable. Often the fields are not in the order that; a human would find readable. Or the same information is replicated in multiple; locations, making it hard for a human to write such YAML correctly. In relational database theory there is a design step called normalization in; which you reorganize fields and tables. The same considerations need to; go into the design of your YAML encoding. But, you may not want to change; your existing native data structures. Therefore, when writing out YAML; there may be a normalization step, and when reading YAML there would be a; corresponding denormalization step. YAML I/O uses a non-in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:3794,Usability,simpl,simple,3794,"ould be a; corresponding denormalization step. YAML I/O uses a non-invasive, traits based design. YAML I/O defines some; abstract base templates. You specialize those templates on your data types.; For instance, if you have an enumerated type FooBar you could specialize; ScalarEnumerationTraits on that type and define the enumeration() method:. .. code-block:: c++. using llvm::yaml::ScalarEnumerationTraits;; using llvm::yaml::IO;. template <>; struct ScalarEnumerationTraits<FooBar> {; static void enumeration(IO &io, FooBar &value) {; ...; }; };. As with all YAML I/O template specializations, the ScalarEnumerationTraits is used for; both reading and writing YAML. That is, the mapping between in-memory enum; values and the YAML string representation is only in one place.; This assures that the code for writing and parsing of YAML stays in sync. To specify a YAML mappings, you define a specialization on; llvm::yaml::MappingTraits.; If your native data structure happens to be a struct that is already normalized,; then the specialization is simple. For example:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Person> {; static void mapping(IO &io, Person &info) {; io.mapRequired(""name"", info.name);; io.mapOptional(""hat-size"", info.hatSize);; }; };. A YAML sequence is automatically inferred if you data type has begin()/end(); iterators and a push_back() method. Therefore any of the STL containers; (such as std::vector<>) will automatically translate to YAML sequences. Once you have defined specializations for your data types, you can; programmatically use YAML I/O to write a YAML document:. .. code-block:: c++. using llvm::yaml::Output;. Person tom;; tom.name = ""Tom"";; tom.hatSize = 8;; Person dan;; dan.name = ""Dan"";; dan.hatSize = 7;; std::vector<Person> persons;; persons.push_back(tom);; persons.push_back(dan);. Output yout(llvm::outs());; yout << persons;. This would write the following:. .. code-block:: y",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst:16633,Usability,simpl,simple,16633,"ad as an enumeration. For example, say some configuration option; started as an enumeration. Then it got more complex so it is now a; mapping. But it is necessary to support the old configuration files.; In that case, add a function ``enumInput`` like for; ``ScalarEnumerationTraits::enumeration``. Examples:. .. code-block:: c++. struct FooBarEnum {; int Foo;; int Bar;; bool operator==(const FooBarEnum &R) const {; return Foo == R.Foo && Bar == R.Bar;; }; };. template <> struct MappingTraits<FooBarEnum> {; static void enumInput(IO &io, FooBarEnum &Val) {; io.enumCase(Val, ""OnlyFoo"", FooBarEnum({1, 0}));; io.enumCase(Val, ""OnlyBar"", FooBarEnum({0, 1}));; }; static void mapping(IO &io, FooBarEnum &Val) {; io.mapOptional(""Foo"", Val.Foo);; io.mapOptional(""Bar"", Val.Bar);; }; };. No Normalization; ----------------. The ``mapping()`` method is responsible, if needed, for normalizing and; denormalizing. In a simple case where the native data structure requires no; normalization, the mapping method just uses mapOptional() or mapRequired() to; bind the struct's fields to YAML key names. For example:. .. code-block:: c++. using llvm::yaml::MappingTraits;; using llvm::yaml::IO;. template <>; struct MappingTraits<Person> {; static void mapping(IO &io, Person &info) {; io.mapRequired(""name"", info.name);; io.mapOptional(""hat-size"", info.hatSize);; }; };. Normalization; ----------------. When [de]normalization is required, the mapping() method needs a way to access; normalized values as fields. To help with this, there is; a template MappingNormalization<> which you can then use to automatically; do the normalization and denormalization. The template is used to create; a local variable in your mapping() method which contains the normalized keys. Suppose you have native data type; Polar which specifies a position in polar coordinates (distance, angle):. .. code-block:: c++. struct Polar {; float distance;; float angle;; };. but you've decided the normalized YAML for should be in x,y ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/YamlIO.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/YamlIO.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vaddr_a5639c.rst:518,Integrability,depend,depends,518,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1013_vaddr_a5639c:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 1-12 dwords. Actual size depends on opcode, :ref:`dim<amdgpu_synid_dim>` and :ref:`a16<amdgpu_synid_a16>`. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vaddr_a5639c.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vaddr_a5639c.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vaddr_c5ab43.rst:518,Integrability,depend,depends,518,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1013_vaddr_c5ab43:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 8-12 dwords. Actual size depends on opcode and :ref:`a16<amdgpu_synid_a16>`. Examples:. .. parsed-literal::. image_bvh_intersect_ray v[4:7], v[9:16], s[4:7]; image_bvh64_intersect_ray v[5:8], v[1:12], s[8:11]; image_bvh_intersect_ray v[39:42], [v5, v4, v2, v1, v7, v3, v0, v6], s[12:15] a16; image_bvh64_intersect_ray v[39:42], [v50, v46, v23, v17, v16, v15, v21, v20, v19, v37, v40, v42], s[12:15]. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vaddr_c5ab43.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vaddr_c5ab43.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_9041ac.rst:234,Performance,load,loaded,234,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1013_vdst_9041ac:. vdst; ====. Image data to be loaded by an image instruction. *Size:* 4 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_9041ac.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_9041ac.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst:274,Integrability,depend,depends,274,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1013_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst:511,Integrability,depend,depending,511,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1013_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst:234,Performance,load,loaded,234,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1013_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1013_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_fx_operand.rst:261,Integrability,depend,depending,261,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_fx_operand:. FX Operand; ==========. This is a *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of the 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst:2148,Deployability,pipeline,pipeline,2148," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_POPS_PACKER pops_packer register.; HW_REG_SHADER_CYCLES Current graphics clock counter value.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst:2141,Performance,queue,queue,2141," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_POPS_PACKER pops_packer register.; HW_REG_SHADER_CYCLES Current graphics clock counter value.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst:247,Security,access,accessed,247,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; H",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:216,Integrability,message,message,216,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1134,Integrability,message,message,1134,"**********************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1196,Integrability,message,message,1196," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1285,Integrability,message,message,1285,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1477,Integrability,message,message,1477," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1495,Integrability,message,message,1495," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:1793,Integrability,message,message,1793," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:2730,Integrability,depend,depending,2730," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:2780,Integrability,message,message,2780," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:2894,Integrability,message,message,2894," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:3061,Integrability,message,message,3061," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:2720,Security,validat,validated,2720," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:3155,Security,validat,validation,3155," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst:3426,Security,validat,validation,3426," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_saddr_beaa25.rst:394,Availability,avail,available,394,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_saddr_beaa25:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx1030_vaddr_9aeece>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_saddr_beaa25.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_saddr_beaa25.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_9aeece.rst:268,Integrability,depend,depending,268,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vaddr_9aeece:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx1030_vaddr_9aeece>` + :ref:`offset12s<amdgpu_synid_flat_offset12s>`. :ref:`vaddr<amdgpu_synid_gfx1030_vaddr_9aeece>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx1030_saddr_beaa25>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx1030_saddr_beaa25>` + :ref:`vaddr<amdgpu_synid_gfx1030_vaddr_9aeece>` + :ref:`offset12s<amdgpu_synid_flat_offset12s>`. :ref:`vaddr<amdgpu_synid_gfx1030_vaddr_9aeece>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx1030_saddr_beaa25>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_9aeece.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_9aeece.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_a5639c.rst:518,Integrability,depend,depends,518,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vaddr_a5639c:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 1-12 dwords. Actual size depends on opcode, :ref:`dim<amdgpu_synid_dim>` and :ref:`a16<amdgpu_synid_a16>`. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_a5639c.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_a5639c.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_c5ab43.rst:518,Integrability,depend,depends,518,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vaddr_c5ab43:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 8-12 dwords. Actual size depends on opcode and :ref:`a16<amdgpu_synid_a16>`. Examples:. .. parsed-literal::. image_bvh_intersect_ray v[4:7], v[9:16], s[4:7]; image_bvh64_intersect_ray v[5:8], v[1:12], s[8:11]; image_bvh_intersect_ray v[39:42], [v5, v4, v2, v1, v7, v3, v0, v6], s[12:15] a16; image_bvh64_intersect_ray v[39:42], [v50, v46, v23, v17, v16, v15, v21, v20, v19, v37, v40, v42], s[12:15]. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_c5ab43.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vaddr_c5ab43.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vcc.rst:243,Integrability,depend,depends,243,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vcc:. vcc; ===. Vector condition code. This operand depends on wavefront size:. * Should be :ref:`vcc_lo<amdgpu_synid_vcc_lo>` if wavefront size is 32.; * Should be :ref:`vcc<amdgpu_synid_vcc>` if wavefront size is 64.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vcc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vcc.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_21b58d.rst:281,Integrability,depend,depends,281,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_21b58d.rst:488,Integrability,depend,depending,488,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_84fab6.rst:418,Integrability,depend,depends,418,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdata_84fab6:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_84fab6.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_84fab6.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_aa5a53.rst:418,Integrability,depend,depends,418,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdata_aa5a53:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_aa5a53.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_aa5a53.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_c08393.rst:281,Integrability,depend,depends,281,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdata_c08393:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_c08393.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdata_c08393.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_4d2300.rst:222,Performance,load,loaded,222,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_4d2300:. vdst; ====. Data loaded from memory. This is an optional operand. It must be used if and only if :ref:`lds<amdgpu_synid_lds>` is omitted. *Size:* 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_4d2300.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_4d2300.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_5ec176.rst:366,Integrability,depend,depending,366,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_5ec176:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` affects operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_5ec176.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_5ec176.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_5ec176.rst:234,Performance,load,loaded,234,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_5ec176:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` affects operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_5ec176.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_5ec176.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_9041ac.rst:234,Performance,load,loaded,234,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_9041ac:. vdst; ====. Image data to be loaded by an image instruction. *Size:* 4 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_9041ac.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_9041ac.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_dfa6da.rst:274,Integrability,depend,depends,274,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_dfa6da.rst:234,Performance,load,loaded,234,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst:274,Integrability,depend,depends,274,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst:511,Integrability,depend,depending,511,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst:234,Performance,load,loaded,234,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx1030_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx1030_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_fx_operand.rst:259,Integrability,depend,depending,259,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_fx_operand:. FX Operand; ==========. This is a *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of the 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst:2146,Deployability,pipeline,pipeline,2146," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_XNACK_MASK xnack_mask register.; HW_REG_POPS_PACKER pops_packer register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst:2139,Performance,queue,queue,2139," indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_TBA_LO tba_lo register.; HW_REG_TBA_HI tba_hi register.; HW_REG_TMA_LO tma_lo register.; HW_REG_TMA_HI tma_hi register.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; HW_REG_XNACK_MASK xnack_mask register.; HW_REG_POPS_PACKER pops_packer register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst:245,Security,access,accessed,245,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:214,Integrability,message,message,214,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; =======",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:1132,Integrability,message,message,1132,"************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:1194,Integrability,message,message,1194," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:1283,Integrability,message,message,1283,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:1475,Integrability,message,message,1475," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:1493,Integrability,message,message,1493," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:1791,Integrability,message,message,1791," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:2728,Integrability,depend,depending,2728," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:2778,Integrability,message,message,2778," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:2892,Integrability,message,message,2892," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:3059,Integrability,message,message,3059," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:2718,Security,validat,validated,2718," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:3153,Security,validat,validation,3153," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst:3424,Security,validat,validation,3424," operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_GET_DDID 11 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_probe.rst:217,Availability,mask,mask,217,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_probe:. probe; =====. A bit mask which indicates request permissions. This operand must be specified as an :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`.; The value is truncated to 7 bits, but only 3 low bits are significant. ============ ==============================; Bit Number Description; ============ ==============================; 0 Request *read* permission.; 1 Request *write* permission.; 2 Request *execute* permission.; ============ ==============================; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_probe.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_probe.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_saddr_beaa25.rst:390,Availability,avail,available,390,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_saddr_beaa25:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx10_vaddr_9aeece>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_saddr_beaa25.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_saddr_beaa25.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vaddr_9aeece.rst:266,Integrability,depend,depending,266,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vaddr_9aeece:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx10_vaddr_9aeece>` + :ref:`offset12s<amdgpu_synid_flat_offset12s>`. :ref:`vaddr<amdgpu_synid_gfx10_vaddr_9aeece>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx10_saddr_beaa25>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx10_saddr_beaa25>` + :ref:`vaddr<amdgpu_synid_gfx10_vaddr_9aeece>` + :ref:`offset12s<amdgpu_synid_flat_offset12s>`. :ref:`vaddr<amdgpu_synid_gfx10_vaddr_9aeece>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx10_saddr_beaa25>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vaddr_9aeece.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vaddr_9aeece.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vaddr_a5639c.rst:516,Integrability,depend,depends,516,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vaddr_a5639c:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 1-12 dwords. Actual size depends on opcode, :ref:`dim<amdgpu_synid_dim>` and :ref:`a16<amdgpu_synid_a16>`. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vaddr_a5639c.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vaddr_a5639c.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vcc.rst:241,Integrability,depend,depends,241,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vcc:. vcc; ===. Vector condition code. This operand depends on wavefront size:. * Should be :ref:`vcc_lo<amdgpu_synid_vcc_lo>` if wavefront size is 32.; * Should be :ref:`vcc<amdgpu_synid_vcc>` if wavefront size is 64.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vcc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vcc.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_21b58d.rst:279,Integrability,depend,depends,279,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_21b58d.rst:486,Integrability,depend,depending,486,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_84fab6.rst:416,Integrability,depend,depends,416,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdata_84fab6:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_84fab6.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_84fab6.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_aa5a53.rst:416,Integrability,depend,depends,416,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdata_aa5a53:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_aa5a53.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_aa5a53.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_c08393.rst:279,Integrability,depend,depends,279,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdata_c08393:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_c08393.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdata_c08393.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_4d2300.rst:220,Performance,load,loaded,220,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_4d2300:. vdst; ====. Data loaded from memory. This is an optional operand. It must be used if and only if :ref:`lds<amdgpu_synid_lds>` is omitted. *Size:* 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_4d2300.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_4d2300.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_5ec176.rst:364,Integrability,depend,depending,364,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_5ec176:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` affects operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_5ec176.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_5ec176.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_5ec176.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_5ec176:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` affects operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_5ec176.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_5ec176.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_dfa6da.rst:272,Integrability,depend,depends,272,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_dfa6da.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst:272,Integrability,depend,depends,272,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst:509,Integrability,depend,depending,509,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx10_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx10_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:227,Integrability,depend,dependent,227,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_delay:. delay; =====. A delay between dependent SALU/VALU instructions.; This operand may specify a delay for 2 instructions:; the one after the current *s_delay_alu* instruction; and for the second instruction indicated by *SKIP*. The bits of this operand have the following meaning:. ===== ========================================================== ============; Bits Description Value Range; ===== ========================================================== ============; 3:0 ID0: indicates a delay for the first instruction. 0..11; 6:4 SKIP: indicates the position of the second instruction. 0..5; 10:7 ID1: indicates a delay for the second instruction. 0..11; ===== ========================================================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A combination of *instid0*, *instskip*, *instid1* values which are described below. ======================== =========================== ===============; Syntax Description Default Value; ======================== =========================== ===============; instid0(<*ID name*>) A symbolic *ID0* value. instid0(NO_DEP); instskip(<*SKIP name*>) A symbolic *SKIP* value. instskip(SAME); instid1(<*ID name*>) A symbolic *ID1* value. instid1(NO_DEP); ======================== =========================== ===============. These values may be specified in any order.; When more than one value is specified, the values must be separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ==================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:2062,Integrability,depend,dependency,2062,"following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A combination of *instid0*, *instskip*, *instid1* values which are described below. ======================== =========================== ===============; Syntax Description Default Value; ======================== =========================== ===============; instid0(<*ID name*>) A symbolic *ID0* value. instid0(NO_DEP); instskip(<*SKIP name*>) A symbolic *SKIP* value. instskip(SAME); instid1(<*ID name*>) A symbolic *ID1* value. instid1(NO_DEP); ======================== =========================== ===============. These values may be specified in any order.; When more than one value is specified, the values must be separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:3238,Integrability,depend,dependency,3238,"separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal *SKIP names* are described in the following table. ======== ============================================================================; Name Description; ======== ============================================================================; SAME Apply second dependency to the same instruction. This is the default value.; NEXT Apply second dependency to the next instruction.; SKIP_1 Skip 1 instruction then apply dependency.; SKIP_2 Skip 2 instructions then apply dependency.; SKIP_3 Skip 3 instructions then apply dependency.; SKIP_4 Skip 4 instructions then apply dependency.; ======== ============================================================================. Examples:. .. parsed-literal::. s_delay_alu instid0(VALU_DEP_1); s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:3320,Integrability,depend,dependency,3320,"separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal *SKIP names* are described in the following table. ======== ============================================================================; Name Description; ======== ============================================================================; SAME Apply second dependency to the same instruction. This is the default value.; NEXT Apply second dependency to the next instruction.; SKIP_1 Skip 1 instruction then apply dependency.; SKIP_2 Skip 2 instructions then apply dependency.; SKIP_3 Skip 3 instructions then apply dependency.; SKIP_4 Skip 4 instructions then apply dependency.; ======== ============================================================================. Examples:. .. parsed-literal::. s_delay_alu instid0(VALU_DEP_1); s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:3394,Integrability,depend,dependency,3394,"separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal *SKIP names* are described in the following table. ======== ============================================================================; Name Description; ======== ============================================================================; SAME Apply second dependency to the same instruction. This is the default value.; NEXT Apply second dependency to the next instruction.; SKIP_1 Skip 1 instruction then apply dependency.; SKIP_2 Skip 2 instructions then apply dependency.; SKIP_3 Skip 3 instructions then apply dependency.; SKIP_4 Skip 4 instructions then apply dependency.; ======== ============================================================================. Examples:. .. parsed-literal::. s_delay_alu instid0(VALU_DEP_1); s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:3445,Integrability,depend,dependency,3445,"separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal *SKIP names* are described in the following table. ======== ============================================================================; Name Description; ======== ============================================================================; SAME Apply second dependency to the same instruction. This is the default value.; NEXT Apply second dependency to the next instruction.; SKIP_1 Skip 1 instruction then apply dependency.; SKIP_2 Skip 2 instructions then apply dependency.; SKIP_3 Skip 3 instructions then apply dependency.; SKIP_4 Skip 4 instructions then apply dependency.; ======== ============================================================================. Examples:. .. parsed-literal::. s_delay_alu instid0(VALU_DEP_1); s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:3496,Integrability,depend,dependency,3496,"separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal *SKIP names* are described in the following table. ======== ============================================================================; Name Description; ======== ============================================================================; SAME Apply second dependency to the same instruction. This is the default value.; NEXT Apply second dependency to the next instruction.; SKIP_1 Skip 1 instruction then apply dependency.; SKIP_2 Skip 2 instructions then apply dependency.; SKIP_3 Skip 3 instructions then apply dependency.; SKIP_4 Skip 4 instructions then apply dependency.; ======== ============================================================================. Examples:. .. parsed-literal::. s_delay_alu instid0(VALU_DEP_1); s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst:3547,Integrability,depend,dependency,3547,"separated from each other by a '|'. Valid *ID names* are defined below. =================== ===================================================================; Name Description; =================== ===================================================================; NO_DEP No dependency on any prior instruction. This is the default value.; VALU_DEP_1 Dependency on a previous VALU instruction, 1 opcode back.; VALU_DEP_2 Dependency on a previous VALU instruction, 2 opcodes back.; VALU_DEP_3 Dependency on a previous VALU instruction, 3 opcodes back.; VALU_DEP_4 Dependency on a previous VALU instruction, 4 opcodes back.; TRANS32_DEP_1 Dependency on a previous TRANS32 instruction, 1 opcode back.; TRANS32_DEP_2 Dependency on a previous TRANS32 instruction, 2 opcodes back.; TRANS32_DEP_3 Dependency on a previous TRANS32 instruction, 3 opcodes back.; FMA_ACCUM_CYCLE_1 Single cycle penalty for FMA accumulation.; SALU_CYCLE_1 1 cycle penalty for a prior SALU instruction.; SALU_CYCLE_2 2 cycle penalty for a prior SALU instruction.; SALU_CYCLE_3 3 cycle penalty for a prior SALU instruction.; =================== ===================================================================. Legal *SKIP names* are described in the following table. ======== ============================================================================; Name Description; ======== ============================================================================; SAME Apply second dependency to the same instruction. This is the default value.; NEXT Apply second dependency to the next instruction.; SKIP_1 Skip 1 instruction then apply dependency.; SKIP_2 Skip 2 instructions then apply dependency.; SKIP_3 Skip 3 instructions then apply dependency.; SKIP_4 Skip 4 instructions then apply dependency.; ======== ============================================================================. Examples:. .. parsed-literal::. s_delay_alu instid0(VALU_DEP_1); s_delay_alu instid0(VALU_DEP_1) | instskip(NEXT) | instid1(VALU_DEP_1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_delay.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_fx_operand.rst:259,Integrability,depend,depending,259,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_fx_operand:. FX Operand; ==========. This is a *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of the 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst:2146,Deployability,pipeline,pipeline,2146,"=============; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, 0, 1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst:2139,Performance,queue,queue,2139,"=============; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_REG_STATUS Shader read-only status.; HW_REG_TRAPSTS Trap status.; HW_REG_HW_ID1 Id of wave, simd, compute unit, etc.; HW_REG_HW_ID2 Id of queue, pipeline, etc.; HW_REG_GPR_ALLOC Per-wave SGPR and VGPR allocation.; HW_REG_LDS_ALLOC Per-wave LDS allocation.; HW_REG_IB_STS Counters of outstanding instructions.; HW_REG_SH_MEM_BASES Memory aperture.; HW_REG_FLAT_SCR_LO flat_scratch_lo register.; HW_REG_FLAT_SCR_HI flat_scratch_hi register.; ============================== ==========================================. Examples:. .. parsed-literal::. reg = 1; offset = 2; size = 4; hwreg_enc = reg | (offset << 6) | ((size - 1) << 11). s_getreg_b32 s2, 0x1881; s_getreg_b32 s2, hwreg_enc // the same as above; s_getreg_b32 s2, hwreg(1, 2, 4) // the same as above; s_getreg_b32 s2, hwreg(reg, offset, size) // the same as above. s_getreg_b32 s2, hwreg(15); s_getreg_b32 s2, hwreg(51, 1, 31); s_getreg_b32 s2, hwreg(HW_REG_LDS_ALLOC, 0, 1); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst:245,Security,access,accessed,245,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_b8ff6d.rst:221,Integrability,message,message,221,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_msg_b8ff6d:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 6:0 Message *type*. 0..127; 7:7 Must be 1. 1; 15:8 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(MSG_RTN_GET_DOORBELL) Get doorbell ID.; sendmsg(MSG_RTN_GET_DDID) Get Draw/Dispatch ID.; sendmsg(MSG_RTN_GET_TMA) Get TMA value.; sendmsg(MSG_RTN_GET_TBA) Get TBA value.; sendmsg(MSG_RTN_GET_REALTIME) Get REALTIME value.; sendmsg(MSG_RTN_SAVE_WAVE) Report that this wave is ready to be context-saved.; ==================================== ====================================================. Examples:. .. parsed-literal::. s_sendmsg_rtn_b32 s0, 132; s_sendmsg_rtn_b32 s0, sendmsg(MSG_GET_REALTIME); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_b8ff6d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_b8ff6d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:221,Integrability,message,message,221,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_msg_e37f7b:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1141,Integrability,message,message,1141,"***************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_msg_e37f7b:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1203,Integrability,message,message,1203," 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1292,Integrability,message,message,1292,"=========================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1484,Integrability,message,message,1484,"operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1502,Integrability,message,message,1502,"operation*. 0..7; 7:7 Must be 0. 0; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are val",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:1800,Integrability,message,message,1800," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:2491,Integrability,depend,depending,2491,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:2541,Integrability,message,message,2541,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:2655,Integrability,message,message,2655,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:2822,Integrability,message,message,2822,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:2481,Security,validat,validated,2481,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:2916,Security,validat,validation,2916,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst:3030,Security,validat,validation,3030,"============; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_HS_TESSFACTOR 2 \- \- \-; MSG_DEALLOC_VGPRS 3 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; s_sendmsg sendmsg(msg, op); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_msg_e37f7b.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_saddr_beaa25.rst:390,Availability,avail,available,390,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_saddr_beaa25:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx11_vaddr_0212e3>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_saddr_beaa25.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_saddr_beaa25.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_type_deviation_8d2078.rst:433,Integrability,depend,depends,433,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_type_deviation_8d2078:. Type Deviation; ==============. The *type* of this operand differs from the *type* :ref:`implied by the opcode<amdgpu_syn_instruction_mnemo>`. This tag specifies the actual operand *type*.; The number of data components depends on wavesize: 8 in wave32 mode and 4 in wave64 mode.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_type_deviation_8d2078.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_type_deviation_8d2078.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_0212e3.rst:266,Integrability,depend,depending,266,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vaddr_0212e3:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx11_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx11_vaddr_0212e3>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx11_saddr_beaa25>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx11_saddr_beaa25>` + :ref:`vaddr<amdgpu_synid_gfx11_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx11_vaddr_0212e3>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx11_saddr_beaa25>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_0212e3.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_0212e3.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_0bfea4.rst:516,Integrability,depend,depends,516,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vaddr_0bfea4:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 8-12 dwords. Actual size depends on opcode and :ref:`a16<amdgpu_synid_a16>`. This instruction expects NSA address to be partitioned into 5 groups; registers within each group must be contiguous. Examples:. .. parsed-literal::. image_bvh_intersect_ray v[4:7], v[9:16], s[4:7]; image_bvh64_intersect_ray v[5:8], v[1:12], s[8:11]; image_bvh_intersect_ray v[39:42], [v50, v46, v[20:22], v[40:42], v[47:49]], s[12:15]; image_bvh64_intersect_ray v[39:42], [v[50:51], v46, v[20:22], v[40:42], v[47:49]], s[12:15]. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_0bfea4.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_0bfea4.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_a5639c.rst:516,Integrability,depend,depends,516,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vaddr_a5639c:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. This operand may be specified using either :ref:`standard VGPR syntax<amdgpu_synid_v>` or special :ref:`NSA VGPR syntax<amdgpu_synid_nsa>`. *Size:* 1-12 dwords. Actual size depends on opcode, :ref:`dim<amdgpu_synid_dim>` and :ref:`a16<amdgpu_synid_a16>`. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_a5639c.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vaddr_a5639c.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vcc.rst:241,Integrability,depend,depends,241,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vcc:. vcc; ===. Vector condition code. This operand depends on wavefront size:. * Should be :ref:`vcc_lo<amdgpu_synid_vcc_lo>` if wavefront size is 32.; * Should be :ref:`vcc<amdgpu_synid_vcc>` if wavefront size is 64.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vcc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vcc.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_21b58d.rst:279,Integrability,depend,depends,279,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_21b58d.rst:486,Integrability,depend,depending,486,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_84fab6.rst:416,Integrability,depend,depends,416,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdata_84fab6:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_84fab6.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_84fab6.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_aa5a53.rst:416,Integrability,depend,depends,416,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdata_aa5a53:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_aa5a53.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_aa5a53.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_c08393.rst:279,Integrability,depend,depends,279,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdata_c08393:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_c08393.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdata_c08393.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_5ec176.rst:364,Integrability,depend,depending,364,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_5ec176:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` affects operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_5ec176.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_5ec176.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_5ec176.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_5ec176:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` affects operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_5ec176.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_5ec176.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_9041ac.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_9041ac:. vdst; ====. Image data to be loaded by an image instruction. *Size:* 4 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_9041ac.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_9041ac.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_dfa6da.rst:272,Integrability,depend,depends,272,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_dfa6da.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_e2d005.rst:354,Integrability,depend,depending,354,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_e2d005:. vdst; ====. Image data to be loaded by an image instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` and :ref:`tfe<amdgpu_synid_tfe>` affect operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_e2d005.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_e2d005.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_e2d005.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_e2d005:. vdst; ====. Image data to be loaded by an image instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` and :ref:`tfe<amdgpu_synid_tfe>` affect operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_e2d005.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_e2d005.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst:272,Integrability,depend,depends,272,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst:509,Integrability,depend,depending,509,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst:232,Performance,load,loaded,232,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx11_vdst_eae4c8:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx11_vdst_eae4c8.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_hwreg.rst:244,Security,access,accessed,244,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:213,Integrability,message,message,213,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1131,Integrability,message,message,1131,"*************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1193,Integrability,message,message,1193," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1282,Integrability,message,message,1282,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1474,Integrability,message,message,1474," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1492,Integrability,message,message,1492," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:1790,Integrability,message,message,1790," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the correspondi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:2559,Integrability,depend,depending,2559,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:2609,Integrability,message,message,2609,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:2723,Integrability,message,message,2723,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:2890,Integrability,message,message,2890,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:2549,Security,validat,validated,2549,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:2984,Security,validat,validation,2984,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst:3218,Security,validat,validation,3218,"d*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vaddr_887f26.rst:375,Integrability,depend,depends,375,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vaddr_887f26:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. *Size:* 1-12 dwords. Actual size depends on opcode and specific image being handled. Note. Image format and dimensions are encoded in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vaddr_887f26.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vaddr_887f26.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_84fab6.rst:415,Integrability,depend,depends,415,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vdata_84fab6:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_84fab6.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_84fab6.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_aa5a53.rst:415,Integrability,depend,depends,415,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vdata_aa5a53:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_aa5a53.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_aa5a53.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_c08393.rst:278,Integrability,depend,depends,278,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vdata_c08393:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_c08393.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdata_c08393.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_1f3009.rst:231,Performance,load,loaded,231,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vdst_1f3009:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies 1 dword. :ref:`tfe<amdgpu_synid_tfe>` adds one more dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_1f3009.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_1f3009.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_dfa6da.rst:271,Integrability,depend,depends,271,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_dfa6da.rst:231,Performance,load,loaded,231,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx7_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx7_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_hwreg.rst:244,Security,access,accessed,244,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_imask.rst:228,Availability,mask,mask,228,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_imask:. imask; =====. This operand is a mask which controls indexing mode for operands of subsequent instructions.; Bits 0, 1 and 2 control indexing of *src0*, *src1* and *src2*, while bit 3 controls indexing of *dst*.; Value 1 enables indexing, and value 0 disables it. ===== ========================================; Bit Meaning; ===== ========================================; 0 Enables or disables *src0* indexing.; 1 Enables or disables *src1* indexing.; 2 Enables or disables *src2* indexing.; 3 Enables or disables *dst* indexing.; ===== ========================================. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 15.; * A *gpr_idx* value which is described below. ==================================== =============================================; Gpr_idx Value Syntax Description; ==================================== =============================================; gpr_idx(*<operand list>*) Enable indexing for the specified *operands*; and disable it for the rest.; *Operand list* is a comma-separated list of; values which may include:. * SRC0 - enable *src0* indexing. * SRC1 - enable *src1* indexing. * SRC2 - enable *src2* indexing. * DST - enable *dst* indexing. Each of these values may be specified only; once. *Operand list* may be empty; this syntax; disables indexing for all operands.; ==================================== =============================================. Examples:. .. parsed-literal::. s_set_gpr_idx_mode 0; s_set_gpr_idx_mode gpr_idx() // the same as above. s_set_gpr_idx_mode 15; s_set_gpr_idx_mode gpr_idx(DST,SRC0,SRC1,SRC2) // the same as above; s_set_gpr_idx_mode gpr_idx(SRC0,SRC1,S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_imask.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_imask.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:213,Integrability,message,message,213,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1131,Integrability,message,message,1131,"*************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1193,Integrability,message,message,1193," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1282,Integrability,message,message,1282,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1474,Integrability,message,message,1474," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ==============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1492,Integrability,message,message,1492," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ==============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:1790,Integrability,message,message,1790," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:2584,Integrability,depend,depending,2584,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:2634,Integrability,message,message,2634,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:2748,Integrability,message,message,2748,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:2915,Integrability,message,message,2915,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:2574,Security,validat,validated,2574,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:3009,Security,validat,validation,3009,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst:3243,Security,validat,validation,3243,"================ ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_HOST_TRAP_ACK 3 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_probe.rst:216,Availability,mask,mask,216,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_probe:. probe; =====. A bit mask which indicates request permissions. This operand must be specified as an :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`.; The value is truncated to 7 bits, but only 3 low bits are significant. ============ ==============================; Bit Number Description; ============ ==============================; 0 Request *read* permission.; 1 Request *write* permission.; 2 Request *execute* permission.; ============ ==============================; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_probe.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_probe.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vaddr_887f26.rst:375,Integrability,depend,depends,375,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vaddr_887f26:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. *Size:* 1-12 dwords. Actual size depends on opcode and specific image being handled. Note. Image format and dimensions are encoded in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vaddr_887f26.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vaddr_887f26.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_4f639e.rst:271,Integrability,depend,depends,271,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_4f639e:. vdata; =====. 16-bit data to store by a buffer instruction. *Size:* depends on GFX8 GPU revision:. * 3 dwords for GFX8.0. This H/W supports no packing.; * 2 dwords for GFX8.1+. This H/W supports data packing. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_4f639e.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_4f639e.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_629a92.rst:278,Integrability,depend,depends,278,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_629a92:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_629a92.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_629a92.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_629a92.rst:485,Integrability,depend,depending,485,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_629a92:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_629a92.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_629a92.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_84fab6.rst:415,Integrability,depend,depends,415,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_84fab6:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_84fab6.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_84fab6.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_886702.rst:271,Integrability,depend,depends,271,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_886702:. vdata; =====. 16-bit data to store by a buffer instruction. *Size:* depends on GFX8 GPU revision:. * 4 dwords for GFX8.0. This H/W supports no packing.; * 2 dwords for GFX8.1+. This H/W supports data packing. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_886702.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_886702.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_aa5a53.rst:415,Integrability,depend,depends,415,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_aa5a53:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_aa5a53.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_aa5a53.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_c08393.rst:278,Integrability,depend,depends,278,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_c08393:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_c08393.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_c08393.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_f2bf57.rst:271,Integrability,depend,depends,271,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdata_f2bf57:. vdata; =====. 16-bit data to store by a buffer instruction. *Size:* depends on GFX8 GPU revision:. * 2 dwords for GFX8.0. This H/W supports no packing.; * 1 dword for GFX8.1+. This H/W supports data packing. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_f2bf57.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdata_f2bf57.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_2d89ba.rst:305,Integrability,depend,depends,305,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_2d89ba:. vdst; ====. Instruction output: data read from a memory buffer and converted to 16-bit format. *Size:* depends on GFX8 GPU revision and :ref:`tfe<amdgpu_synid_tfe>`:. * 4 dwords for GFX8.0. This H/W supports no packing.; * 2 dwords for GFX8.1+. This H/W supports data packing.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_2d89ba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_2d89ba.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst:271,Integrability,depend,depends,271,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_4730df:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst:508,Integrability,depend,depending,508,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_4730df:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst:231,Performance,load,loaded,231,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_4730df:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`, :ref:`tfe<amdgpu_synid_tfe>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_4730df.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_6f591e.rst:305,Integrability,depend,depends,305,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_6f591e:. vdst; ====. Instruction output: data read from a memory buffer and converted to 16-bit format. *Size:* depends on GFX8 GPU revision:. * 4 dwords for GFX8.0. This H/W supports no packing.; * 2 dwords for GFX8.1+. This H/W supports data packing. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_6f591e.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_6f591e.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_829fc5.rst:363,Integrability,depend,depending,363,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_829fc5:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` and :ref:`tfe<amdgpu_synid_tfe>` affect operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_829fc5.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_829fc5.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_829fc5.rst:231,Performance,load,loaded,231,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_829fc5:. vdst; ====. Image data to be loaded by an *image_gather4* instruction. *Size:* 4 data elements by default. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`. :ref:`d16<amdgpu_synid_d16>` and :ref:`tfe<amdgpu_synid_tfe>` affect operand size as follows:. * :ref:`d16<amdgpu_synid_d16>` has different meanings for GFX8.0 and GFX8.1:. * For GFX8.0, this modifier does not affect the size of data elements in registers. Values in registers are stored in low 16 bits, high 16 bits are unused. There is no packing.; * Starting from GFX8.1, this modifier specifies that values in registers are packed; each value occupies 16 bits. * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_829fc5.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_829fc5.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_b61114.rst:305,Integrability,depend,depends,305,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_b61114:. vdst; ====. Instruction output: data read from a memory buffer and converted to 16-bit format. *Size:* depends on GFX8 GPU revision and :ref:`tfe<amdgpu_synid_tfe>`:. * 2 dwords for GFX8.0. This H/W supports no packing.; * 1 dword for GFX8.1+. This H/W supports data packing.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_b61114.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_b61114.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_c360a5.rst:305,Integrability,depend,depends,305,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_c360a5:. vdst; ====. Instruction output: data read from a memory buffer and converted to 16-bit format. *Size:* depends on GFX8 GPU revision:. * 3 dwords for GFX8.0. This H/W supports no packing.; * 2 dwords for GFX8.1+. This H/W supports data packing. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_c360a5.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_c360a5.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_d809e2.rst:305,Integrability,depend,depends,305,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_d809e2:. vdst; ====. Instruction output: data read from a memory buffer and converted to 16-bit format. *Size:* depends on GFX8 GPU revision:. * 2 dwords for GFX8.0. This H/W supports no packing.; * 1 dword for GFX8.1+. This H/W supports data packing. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_d809e2.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_d809e2.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_de9309.rst:305,Integrability,depend,depends,305,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_de9309:. vdst; ====. Instruction output: data read from a memory buffer and converted to 16-bit format. *Size:* depends on GFX8 GPU revision and :ref:`tfe<amdgpu_synid_tfe>`:. * 3 dwords for GFX8.0. This H/W supports no packing.; * 2 dwords for GFX8.1+. This H/W supports data packing.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_de9309.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_de9309.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_dfa6da.rst:271,Integrability,depend,depends,271,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_dfa6da.rst:231,Performance,load,loaded,231,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx8_vdst_dfa6da:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`tfe<amdgpu_synid_tfe>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword.; * :ref:`tfe<amdgpu_synid_tfe>` adds 1 dword if specified. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_dfa6da.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx8_vdst_dfa6da.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx900_fx_operand.rst:261,Integrability,depend,depending,261,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx900_fx_operand:. FX Operand; ==========. This is an *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx900_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx900_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx904_fx_operand.rst:261,Integrability,depend,depending,261,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx904_fx_operand:. FX Operand; ==========. This is an *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx904_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx904_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx906_fx_operand.rst:261,Integrability,depend,depending,261,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx906_fx_operand:. FX Operand; ==========. This is an *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx906_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx906_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_fx_operand.rst:260,Integrability,depend,depending,260,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx908_fx_operand:. FX Operand; ==========. This is a *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of the 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_saddr.rst:385,Availability,avail,available,385,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx908_saddr:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx908_vaddr_0212e3>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`flat_scratch<amdgpu_synid_flat_scratch>`, :ref:`xnack_mask<amdgpu_synid_xnack_mask>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_saddr.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_saddr.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_vaddr_0212e3.rst:267,Integrability,depend,depending,267,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx908_vaddr_0212e3:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx908_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx908_vaddr_0212e3>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx908_saddr>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx908_saddr>` + :ref:`vaddr<amdgpu_synid_gfx908_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx908_vaddr_0212e3>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx908_saddr>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_vaddr_0212e3.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx908_vaddr_0212e3.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_fx_operand.rst:260,Integrability,depend,depending,260,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_fx_operand:. FX Operand; ==========. This is a *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of the 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_hwreg.rst:246,Security,access,accessed,246,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_imask.rst:230,Availability,mask,mask,230,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_imask:. imask; =====. This operand is a mask which controls indexing mode for operands of subsequent instructions.; Bits 0, 1 and 2 control indexing of *src0*, *src1* and *src2*, while bit 3 controls indexing of *dst*.; Value 1 enables indexing, and value 0 disables it. ===== ========================================; Bit Meaning; ===== ========================================; 0 Enables or disables *src0* indexing.; 1 Enables or disables *src1* indexing.; 2 Enables or disables *src2* indexing.; 3 Enables or disables *dst* indexing.; ===== ========================================. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 15.; * A *gpr_idx* value which is described below. ==================================== =============================================; Gpr_idx Value Syntax Description; ==================================== =============================================; gpr_idx(*<operand list>*) Enable indexing for the specified *operands*; and disable it for the rest.; *Operand list* is a comma-separated list of; values which may include:. * SRC0 - enable *src0* indexing. * SRC1 - enable *src1* indexing. * SRC2 - enable *src2* indexing. * DST - enable *dst* indexing. Each of these values may be specified only; once. *Operand list* may be empty; this syntax; disables indexing for all operands.; ==================================== =============================================. Examples:. .. parsed-literal::. s_set_gpr_idx_mode 0; s_set_gpr_idx_mode gpr_idx() // the same as above. s_set_gpr_idx_mode 15; s_set_gpr_idx_mode gpr_idx(DST,SRC0,SRC1,SRC2) // the same as above; s_set_gpr_idx_mode gpr_idx(SRC0,SRC1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_imask.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_imask.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:215,Integrability,message,message,215,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ======",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1133,Integrability,message,message,1133,"***********************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1195,Integrability,message,message,1195," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1284,Integrability,message,message,1284,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1476,Integrability,message,message,1476," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1494,Integrability,message,message,1494," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:1792,Integrability,message,message,1792," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is speci",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:2738,Integrability,depend,depending,2738,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:2788,Integrability,message,message,2788,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:2902,Integrability,message,message,2902,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:3069,Integrability,message,message,3069,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:2728,Security,validat,validated,2728,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:3163,Security,validat,validation,3163,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst:3434,Security,validat,validation,3434,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_probe.rst:218,Availability,mask,mask,218,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_probe:. probe; =====. A bit mask which indicates request permissions. This operand must be specified as an :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`.; The value is truncated to 7 bits, but only 3 low bits are significant. ============ ==============================; Bit Number Description; ============ ==============================; 0 Request *read* permission.; 1 Request *write* permission.; 2 Request *execute* permission.; ============ ==============================; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_probe.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_probe.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_saddr_a37373.rst:392,Availability,avail,available,392,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_saddr_a37373:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx90a_vaddr_0212e3>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`flat_scratch<amdgpu_synid_flat_scratch>`, :ref:`xnack_mask<amdgpu_synid_xnack_mask>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_saddr_a37373.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_saddr_a37373.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vaddr_0212e3.rst:267,Integrability,depend,depending,267,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vaddr_0212e3:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx90a_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx90a_vaddr_0212e3>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx90a_saddr_a37373>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx90a_saddr_a37373>` + :ref:`vaddr<amdgpu_synid_gfx90a_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx90a_vaddr_0212e3>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx90a_saddr_a37373>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vaddr_0212e3.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vaddr_0212e3.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vaddr_cc213c.rst:377,Integrability,depend,depends,377,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vaddr_cc213c:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. *Size:* 1-12 dwords. Actual size depends on opcode, specific image being handled and :ref:`a16<amdgpu_synid_a16>`. Note. Image format and dimensions are encoded in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vaddr_cc213c.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vaddr_cc213c.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_898c08.rst:417,Integrability,depend,depends,417,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdata_898c08:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_898c08.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_898c08.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_929b59.rst:280,Integrability,depend,depends,280,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdata_929b59:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_929b59.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_929b59.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_999247.rst:417,Integrability,depend,depends,417,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdata_999247:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_999247.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_999247.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_cbb01e.rst:280,Integrability,depend,depends,280,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdata_cbb01e:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_cbb01e.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_cbb01e.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_cbb01e.rst:487,Integrability,depend,depending,487,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdata_cbb01e:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_cbb01e.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdata_cbb01e.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_92bb33.rst:221,Performance,load,loaded,221,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdst_92bb33:. vdst; ====. Data loaded from memory. This is an optional operand. It must be used if and only if :ref:`lds<amdgpu_synid_lds>` is omitted. *Size:* 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_92bb33.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_92bb33.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst:273,Integrability,depend,depends,273,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdst_a9ee3f:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst:480,Integrability,depend,depending,480,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdst_a9ee3f:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst:233,Performance,load,loaded,233,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdst_a9ee3f:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data elements in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_a9ee3f.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_f5eb9d.rst:273,Integrability,depend,depends,273,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdst_f5eb9d:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_f5eb9d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_f5eb9d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_f5eb9d.rst:233,Performance,load,loaded,233,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx90a_vdst_f5eb9d:. vdst; ====. Image data to be loaded by an image instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`, :ref:`a<amdgpu_synid_a>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_f5eb9d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx90a_vdst_f5eb9d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_fx_operand.rst:260,Integrability,depend,depending,260,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_fx_operand:. FX Operand; ==========. This is a *f32* or *f16* operand depending on instruction modifiers:. * Operand size is controlled by :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>`.; * Location of the 16-bit operand is controlled by :ref:`m_op_sel<amdgpu_synid_mad_mix_op_sel>`.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_fx_operand.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_fx_operand.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_hwreg.rst:246,Security,access,accessed,246,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_imask.rst:230,Availability,mask,mask,230,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_imask:. imask; =====. This operand is a mask which controls indexing mode for operands of subsequent instructions.; Bits 0, 1 and 2 control indexing of *src0*, *src1* and *src2*, while bit 3 controls indexing of *dst*.; Value 1 enables indexing, and value 0 disables it. ===== ========================================; Bit Meaning; ===== ========================================; 0 Enables or disables *src0* indexing.; 1 Enables or disables *src1* indexing.; 2 Enables or disables *src2* indexing.; 3 Enables or disables *dst* indexing.; ===== ========================================. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 15.; * A *gpr_idx* value which is described below. ==================================== =============================================; Gpr_idx Value Syntax Description; ==================================== =============================================; gpr_idx(*<operand list>*) Enable indexing for the specified *operands*; and disable it for the rest.; *Operand list* is a comma-separated list of; values which may include:. * SRC0 - enable *src0* indexing. * SRC1 - enable *src1* indexing. * SRC2 - enable *src2* indexing. * DST - enable *dst* indexing. Each of these values may be specified only; once. *Operand list* may be empty; this syntax; disables indexing for all operands.; ==================================== =============================================. Examples:. .. parsed-literal::. s_set_gpr_idx_mode 0; s_set_gpr_idx_mode gpr_idx() // the same as above. s_set_gpr_idx_mode 15; s_set_gpr_idx_mode gpr_idx(DST,SRC0,SRC1,SRC2) // the same as above; s_set_gpr_idx_mode gpr_idx(SRC0,SRC1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_imask.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_imask.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:215,Integrability,message,message,215,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ======",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:1133,Integrability,message,message,1133,"***********************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:1195,Integrability,message,message,1195," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:1284,Integrability,message,message,1284,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:1476,Integrability,message,message,1476," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:1494,Integrability,message,message,1494," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:1792,Integrability,message,message,1792," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is speci",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:2738,Integrability,depend,depending,2738,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:2788,Integrability,message,message,2788,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:2902,Integrability,message,message,2902,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:3069,Integrability,message,message,3069,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:2728,Security,validat,validated,2728,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:3163,Security,validat,validation,3163,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst:3434,Security,validat,validation,3434,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_probe.rst:218,Availability,mask,mask,218,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_probe:. probe; =====. A bit mask which indicates request permissions. This operand must be specified as an :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`.; The value is truncated to 7 bits, but only 3 low bits are significant. ============ ==============================; Bit Number Description; ============ ==============================; 0 Request *read* permission.; 1 Request *write* permission.; 2 Request *execute* permission.; ============ ==============================; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_probe.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_probe.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_saddr_a37373.rst:392,Availability,avail,available,392,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_saddr_a37373:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx940_vaddr_0212e3>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`flat_scratch<amdgpu_synid_flat_scratch>`, :ref:`xnack_mask<amdgpu_synid_xnack_mask>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_saddr_a37373.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_saddr_a37373.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_vaddr_0212e3.rst:267,Integrability,depend,depending,267,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx940_vaddr_0212e3:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx940_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx940_vaddr_0212e3>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx940_saddr_a37373>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx940_saddr_a37373>` + :ref:`vaddr<amdgpu_synid_gfx940_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx940_vaddr_0212e3>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx940_saddr_a37373>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_vaddr_0212e3.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx940_vaddr_0212e3.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_hwreg.rst:244,Security,access,accessed,244,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_hwreg:. hwreg; =====. Bits of a hardware register being accessed. The bits of this operand have the following meaning:. ======= ===================== ============; Bits Description Value Range; ======= ===================== ============; 5:0 Register *id*. 0..63; 10:6 First bit *offset*. 0..31; 15:11 *Size* in bits. 1..32; ======= ===================== ============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * An *hwreg* value which is described below. ==================================== ===============================================================================; Hwreg Value Syntax Description; ==================================== ===============================================================================; hwreg({0..63}) All bits of a register indicated by the register *id*.; hwreg(<*name*>) All bits of a register indicated by the register *name*.; hwreg({0..63}, {0..31}, {1..32}) Register bits indicated by the register *id*, first bit *offset* and *size*.; hwreg(<*name*>, {0..31}, {1..32}) Register bits indicated by the register *name*, first bit *offset* and *size*.; ==================================== ===============================================================================. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Predefined register *names* include:. ============================== ==========================================; Name Description; ============================== ==========================================; HW_REG_MODE Shader writable mode bits.; HW_R",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_hwreg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_hwreg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_imask.rst:228,Availability,mask,mask,228,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_imask:. imask; =====. This operand is a mask which controls indexing mode for operands of subsequent instructions.; Bits 0, 1 and 2 control indexing of *src0*, *src1* and *src2*, while bit 3 controls indexing of *dst*.; Value 1 enables indexing, and value 0 disables it. ===== ========================================; Bit Meaning; ===== ========================================; 0 Enables or disables *src0* indexing.; 1 Enables or disables *src1* indexing.; 2 Enables or disables *src2* indexing.; 3 Enables or disables *dst* indexing.; ===== ========================================. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 15.; * A *gpr_idx* value which is described below. ==================================== =============================================; Gpr_idx Value Syntax Description; ==================================== =============================================; gpr_idx(*<operand list>*) Enable indexing for the specified *operands*; and disable it for the rest.; *Operand list* is a comma-separated list of; values which may include:. * SRC0 - enable *src0* indexing. * SRC1 - enable *src1* indexing. * SRC2 - enable *src2* indexing. * DST - enable *dst* indexing. Each of these values may be specified only; once. *Operand list* may be empty; this syntax; disables indexing for all operands.; ==================================== =============================================. Examples:. .. parsed-literal::. s_set_gpr_idx_mode 0; s_set_gpr_idx_mode gpr_idx() // the same as above. s_set_gpr_idx_mode 15; s_set_gpr_idx_mode gpr_idx(DST,SRC0,SRC1,SRC2) // the same as above; s_set_gpr_idx_mode gpr_idx(SRC0,SRC1,S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_imask.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_imask.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:213,Integrability,message,message,213,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:1131,Integrability,message,message,1131,"*************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_msg:. msg; ===. A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:1193,Integrability,message,message,1193," A 16-bit message code. The bits of this operand have the following meaning:. ============ =============================== ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DO",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:1282,Integrability,message,message,1282,"============================= ===============; Bits Description Value Range; ============ =============================== ===============; 3:0 Message *type*. 0..15; 6:4 Optional *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:1474,Integrability,message,message,1474," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:1492,Integrability,message,message,1492," *operation*. 0..7; 7:7 Unused. \-; 9:8 Optional *stream*. 0..3; 15:10 Unused. \-; ============ =============================== ===============. This operand may be specified as one of the following:. * An :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`. The value must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:1790,Integrability,message,message,1790," must be in the range from 0 to 0xFFFF.; * A *sendmsg* value which is described below. ==================================== ====================================================; Sendmsg Value Syntax Description; ==================================== ====================================================; sendmsg(<*type*>) A message identified by its *type*.; sendmsg(<*type*>,<*op*>) A message identified by its *type* and *operation*.; sendmsg(<*type*>,<*op*>,<*stream*>) A message identified by its *type* and *operation*; with a stream *id*.; ==================================== ====================================================. *Type* may be specified using message *name* or message *id*. *Op* may be specified using operation *name* or operation *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is speci",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:2736,Integrability,depend,depending,2736,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:2786,Integrability,message,message,2786,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:2900,Integrability,message,message,2900,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:3067,Integrability,message,message,3067,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:2726,Security,validat,validated,2726,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:3161,Security,validat,validation,3161,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst:3432,Security,validat,validation,3432,"n *id*. Stream *id* is an integer in the range from 0 to 3. Numeric values may be specified as positive :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Each message type supports specific operations:. ====================== ========== ============================== ============ ==========; Message name Message Id Supported Operations Operation Id Stream Id; ====================== ========== ============================== ============ ==========; MSG_INTERRUPT 1 \- \- \-; MSG_GS 2 GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_GS_DONE 3 GS_OP_NOP 0 \-; \ GS_OP_CUT 1 Optional; \ GS_OP_EMIT 2 Optional; \ GS_OP_EMIT_CUT 3 Optional; MSG_SAVEWAVE 4 \- \- \-; MSG_STALL_WAVE_GEN 5 \- \- \-; MSG_HALT_WAVES 6 \- \- \-; MSG_ORDERED_PS_DONE 7 \- \- \-; MSG_EARLY_PRIM_DEALLOC 8 \- \- \-; MSG_GS_ALLOC_REQ 9 \- \- \-; MSG_GET_DOORBELL 10 \- \- \-; MSG_SYSMSG 15 SYSMSG_OP_ECC_ERR_INTERRUPT 1 \-; \ SYSMSG_OP_REG_RD 2 \-; \ SYSMSG_OP_TTRACE_PC 4 \-; ====================== ========== ============================== ============ ==========. *Sendmsg* arguments are validated depending on how *type* value is specified:. * If message *type* is specified by name, arguments values must satisfy limitations detailed in the table above.; * If message *type* is specified as a number, each argument must not exceed the corresponding value range (see the first table). Examples:. .. parsed-literal::. // numeric message code; msg = 0x10; s_sendmsg 0x12; s_sendmsg msg + 2. // sendmsg with strict arguments validation; s_sendmsg sendmsg(MSG_INTERRUPT); s_sendmsg sendmsg(MSG_GS, GS_OP_EMIT); s_sendmsg sendmsg(MSG_GS, 2); s_sendmsg sendmsg(MSG_GS_DONE, GS_OP_EMIT_CUT, 1); s_sendmsg sendmsg(MSG_SYSMSG, SYSMSG_OP_TTRACE_PC); s_sendmsg sendmsg(MSG_GET_DOORBELL). // sendmsg with validation of value range only; msg = 2; op = 3; stream = 1; s_sendmsg sendmsg(msg, op, stream); s_sendmsg sendmsg(2, GS_OP_CUT); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_msg.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_probe.rst:216,Availability,mask,mask,216,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_probe:. probe; =====. A bit mask which indicates request permissions. This operand must be specified as an :ref:`integer_number<amdgpu_synid_integer_number>` or an :ref:`absolute_expression<amdgpu_synid_absolute_expression>`.; The value is truncated to 7 bits, but only 3 low bits are significant. ============ ==============================; Bit Number Description; ============ ==============================; 0 Request *read* permission.; 1 Request *write* permission.; 2 Request *execute* permission.; ============ ==============================; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_probe.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_probe.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_saddr_a37373.rst:388,Availability,avail,available,388,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_saddr_a37373:. saddr; =====. An optional 64-bit flat global address. Must be specified as :ref:`off<amdgpu_synid_off>` if not used. See :ref:`vaddr<amdgpu_synid_gfx9_vaddr_0212e3>` for description of available addressing modes. *Size:* 2 dwords. *Operands:* :ref:`s<amdgpu_synid_s>`, :ref:`flat_scratch<amdgpu_synid_flat_scratch>`, :ref:`xnack_mask<amdgpu_synid_xnack_mask>`, :ref:`vcc<amdgpu_synid_vcc>`, :ref:`ttmp<amdgpu_synid_ttmp>`, :ref:`off<amdgpu_synid_off>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_saddr_a37373.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_saddr_a37373.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vaddr_0212e3.rst:265,Integrability,depend,depending,265,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vaddr_0212e3:. vaddr; =====. A 64-bit flat global address or a 32-bit offset depending on addressing mode:. * Address = :ref:`vaddr<amdgpu_synid_gfx9_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx9_vaddr_0212e3>` is a 64-bit address. This mode is indicated by :ref:`saddr<amdgpu_synid_gfx9_saddr_a37373>` set to :ref:`off<amdgpu_synid_off>`.; * Address = :ref:`saddr<amdgpu_synid_gfx9_saddr_a37373>` + :ref:`vaddr<amdgpu_synid_gfx9_vaddr_0212e3>` + :ref:`offset13s<amdgpu_synid_flat_offset13s>`. :ref:`vaddr<amdgpu_synid_gfx9_vaddr_0212e3>` is a 32-bit offset. This mode is used when :ref:`saddr<amdgpu_synid_gfx9_saddr_a37373>` is not :ref:`off<amdgpu_synid_off>`. *Size:* 1 or 2 dwords. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vaddr_0212e3.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vaddr_0212e3.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vaddr_cc213c.rst:375,Integrability,depend,depends,375,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vaddr_cc213c:. vaddr; =====. Image address which includes from one to four dimensional coordinates and other data used to locate a position in the image. *Size:* 1-12 dwords. Actual size depends on opcode, specific image being handled and :ref:`a16<amdgpu_synid_a16>`. Note. Image format and dimensions are encoded in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vaddr_cc213c.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vaddr_cc213c.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_21b58d.rst:278,Integrability,depend,depends,278,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_21b58d.rst:485,Integrability,depend,depending,485,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vdata_21b58d:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` and :ref:`d16<amdgpu_synid_d16>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify from 1 to 4 data elements. Each data element occupies either 32 bits or 16 bits, depending on :ref:`d16<amdgpu_synid_d16>`.; * :ref:`d16<amdgpu_synid_d16>` specifies that data in registers are packed; each value occupies 16 bits. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_21b58d.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_21b58d.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_84fab6.rst:415,Integrability,depend,depends,415,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vdata_84fab6:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 2 data elements for 32-bit-per-pixel surfaces or 4 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_84fab6.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_84fab6.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_aa5a53.rst:415,Integrability,depend,depends,415,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vdata_aa5a53:. vdata; =====. Input data for an atomic instruction. Optionally, this operand may be used to store output data:. * If :ref:`glc<amdgpu_synid_glc>` is specified, gets the memory value before the operation. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>`:. * :ref:`dmask<amdgpu_synid_dmask>` may specify 1 data element for 32-bit-per-pixel surfaces or 2 data elements for 64-bit-per-pixel surfaces. Each data element occupies 1 dword. Note: the surface data format is indicated in the image resource constant, but not in the instruction. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_aa5a53.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_aa5a53.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_c08393.rst:278,Integrability,depend,depends,278,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vdata_c08393:. vdata; =====. Image data to store by an *image_store* instruction. *Size:* depends on :ref:`dmask<amdgpu_synid_dmask>` which may specify from 1 to 4 data elements. Each data element occupies 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_c08393.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdata_c08393.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdst_4d2300.rst:219,Performance,load,loaded,219,"..; **************************************************; * *; * Automatically generated file, do not edit! *; * *; **************************************************. .. _amdgpu_synid_gfx9_vdst_4d2300:. vdst; ====. Data loaded from memory. This is an optional operand. It must be used if and only if :ref:`lds<amdgpu_synid_lds>` is omitted. *Size:* 1 dword. *Operands:* :ref:`v<amdgpu_synid_v>`; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdst_4d2300.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPU/gfx9_vdst_4d2300.rst
