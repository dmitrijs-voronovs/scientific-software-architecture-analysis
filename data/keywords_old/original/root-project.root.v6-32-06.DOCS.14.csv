id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:32949,Performance,concurren,concurrently,32949,"ormation`. 2.17 Allow MD5 Checksums to be Optionally Present; -------------------------------------------------. In DWARF Version 5 the file timestamp and file size can be optional, but if the; MD5 checksum is present it must be valid for all files. This is a problem if; using link time optimization to combine compilation units where some have MD5; checksums and some do not. Therefore, sSupport to allow MD5 checksums to be; optionally present in the line table is added. See :ref:`amdgpu-dwarf-line-number-information`. 2.18 Add the HIP Programing Language; ------------------------------------. The HIP programming language [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select bet",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:33496,Performance,concurren,concurrent,33496,"anguage [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_itera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:33618,Performance,concurren,concurrency,33618,"imizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:33631,Performance,optimiz,optimizations,33631,"imizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:33730,Performance,concurren,concurrency,33730,"imizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:33960,Performance,concurren,concurrent,33960,"For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34096,Performance,concurren,concurrent,34096,"o hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34233,Performance,concurren,concurrency,34233," to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34260,Performance,concurren,concurrency,34260," to execute multiple iterations using; vector registers. Note that although this is similar to SIMT execution, the way a client debugger; uses the information is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34394,Performance,concurren,concurrent,34394,"on is fundamentally different. In SIMT execution the debugger; needs to present the concurrent execution as distinct source language threads; that the user can list and switch focus between. With iteration concurrency; optimizations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each vectorized loop iteration. On the first iteration of the generated vectorized loop, iterations 0 to 7 of; the source language loop will be executed using SI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:34690,Performance,concurren,concurrently,34690,"zations, such as software pipelining and vectorized SIMD, the debugger; must not present the concurrency as distinct source language threads. Instead,; it must inform the user that multiple loop iterations are executing in parallel; and allow the user to select between them. In general, SIMT execution fixes the number of concurrent executions per target; architecture thread. However, both software pipelining and SIMD vectorization; may vary the number of concurrent iterations for different loops executed by a; single source language thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each vectorized loop iteration. On the first iteration of the generated vectorized loop, iterations 0 to 7 of; the source language loop will be executed using SIMD instructions. Then on the; next iteration of the generated vectorized loop, iteration 8 to 15 will be; executed, and so on. If the source language loop accesses an array element based on the loop; iteration index, the compi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:35233,Performance,concurren,concurrently,35233,"e thread. It is possible for the compiler to use both SIMT concurrency and iteration; concurrency techniques in the code of a single source language thread. Therefore, a DWARF operation is required to denote the current concurrent; iteration instance, much like ``DW_OP_push_object_address`` denotes the current; object. See ``DW_OP_LLVM_push_iteration`` in; :ref:`amdgpu-dwarf-literal-operations`. In addition, a way is needed for the compiler to communicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each vectorized loop iteration. On the first iteration of the generated vectorized loop, iterations 0 to 7 of; the source language loop will be executed using SIMD instructions. Then on the; next iteration of the generated vectorized loop, iteration 8 to 15 will be; executed, and so on. If the source language loop accesses an array element based on the loop; iteration index, the compiler may read the element into a register for the; duration of that iteration. Next iteration it will read the next element into; the register, and so on. With SIMD, this generalizes to the compiler reading; array elements 0 to 7 into a vector register on the first vectorized loop; iteration, then array elements 8 to 15 on the next iteration, and so on. The DWARF location description for the array needs to express that all elements; are in memory, except the slice that has been promoted to the vector register.; The starting positio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:37173,Performance,load,loads,37173,"lue based on the iteration; index modulo the vectorization size. This cannot be expressed by ``DW_OP_piece``; and ``DW_OP_bit_piece`` which only allow constant offsets to be expressed. Therefore, a new operator is defined that takes two location descriptions, an; offset and a size, and creates a composite that effectively uses the second; location description as an overlay of the first, positioned according to the; offset and size. See ``DW_OP_LLVM_overlay`` and ``DW_OP_LLVM_bit_overlay`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. Consider an array that has been partially registerized such that the currently; processed elements are held in registers, whereas the remainder of the array; remains in memory. Consider the loop in this C function, for example:. .. code::; :number-lines:. extern void foo(uint32_t dst[], uint32_t src[], int len) {; for (int i = 0; i < len; ++i); dst[i] += src[i];; }. Inside the loop body, the machine code loads ``src[i]`` and ``dst[i]`` into; registers, adds them, and stores the result back into ``dst[i]``. Considering the location of ``dst`` and ``src`` in the loop body, the elements; ``dst[i]`` and ``src[i]`` would be located in registers, all other elements are; located in memory. Let register ``R0`` contain the base address of ``dst``,; register ``R1`` contain ``i``, and register ``R2`` contain the registerized; ``dst[i]`` element. We can describe the location of ``dst`` as a memory location; with a register location overlaid at a runtime offset involving ``i``:. .. code::; :number-lines:. // 1. Memory location description of dst elements located in memory:; DW_OP_breg0 0. // 2. Register location description of element dst[i] is located in R2:; DW_OP_reg2. // 3. Offset of the register within the memory of dst:; DW_OP_breg1 0; DW_OP_lit4; DW_OP_mul. // 4. The size of the register element:; DW_OP_lit4. // 5. Make a composite location description for dst that is the memory #1 with; // the register #2 positioned as an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:43721,Performance,perform,performed,43721,"ections, replaces DWARF Version 5 section 2.5; and section 2.6. The new DWARF expression operation extensions are defined as; well as clarifying the extensions to already existing DWARF Version 5; operations. It is based on the text of the existing DWARF Version 5 standard. DWARF expressions describe how to compute a value or specify a location. *The evaluation of a DWARF expression can provide the location of an object, the; value of an array bound, the length of a dynamic string, the desired value; itself, and so on.*. If the evaluation of a DWARF expression does not encounter an error, then it can; either result in a value (see :ref:`amdgpu-dwarf-expression-value`) or a; location description (see :ref:`amdgpu-dwarf-location-description`). When a; DWARF expression is evaluated, it may be specified whether a value or location; description is required as the result kind. If a result kind is specified, and the result of the evaluation does not match; the specified result kind, then the implicit conversions described in; :ref:`amdgpu-dwarf-memory-location-description-operations` are performed if; valid. Otherwise, the DWARF expression is ill-formed. If the evaluation of a DWARF expression encounters an evaluation error, then the; result is an evaluation error. .. note::. Decided to define the concept of an evaluation error. An alternative is to; introduce an undefined value base type in a similar way to location; descriptions having an undefined location description. Then operations that; encounter an evaluation error can return the undefined location description or; value with an undefined base type. All operations that act on values would return an undefined entity if given an; undefined value. The expression would then always evaluate to completion, and; can be tested to determine if it is an undefined entity. However, this would add considerable additional complexity and does not match; that GDB throws an exception when these evaluation errors occur. If a DWARF exp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:47427,Performance,optimiz,optimizations,47427,"expression. This applies to source languages that are implemented for a target; architecture using a SIMT execution model. These implementations map source; language threads of execution to lanes of the target architecture threads. It is required for operations that are related to SIMT lanes. *For example, the* ``DW_OP_LLVM_push_lane`` *operation and*; ``DW_OP_LLVM_form_aspace_address`` *operation when given an address space that; is SIMT lane specific.*. If specified, it must be consistent with the value of the ``DW_AT_LLVM_lanes``; attribute of the subprogram corresponding to context's frame and program; location. It is consistent if the value is greater than or equal to 0 and less; than the, possibly default, value of the ``DW_AT_LLVM_lanes`` attribute.; Otherwise the result is undefined. *A current iteration*. The 0 based source language iteration instance to be used in evaluating a user; presented expression. This applies to target architectures that support; optimizations that result in executing multiple source language loop iterations; concurrently. *For example, software pipelining and SIMD vectorization.*. It is required for operations that are related to source language loop; iterations. *For example, the* ``DW_OP_LLVM_push_iteration`` *operation.*. If specified, it must be consistent with the value of the; ``DW_AT_LLVM_iterations`` attribute of the subprogram corresponding to; context's frame and program location. It is consistent if the value is greater; than or equal to 0 and less than the, possibly default, value of the; ``DW_AT_LLVM_iterations`` attribute. Otherwise the result is undefined. *A current call frame*. The target architecture call frame identifier. It identifies a call frame that; corresponds to an active invocation of a subprogram in the current thread. It; is identified by its address on the call stack. The address is referred to as; the Canonical Frame Address (CFA). The call frame information is used to; determine the CFA for the call",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:47508,Performance,concurren,concurrently,47508,"expression. This applies to source languages that are implemented for a target; architecture using a SIMT execution model. These implementations map source; language threads of execution to lanes of the target architecture threads. It is required for operations that are related to SIMT lanes. *For example, the* ``DW_OP_LLVM_push_lane`` *operation and*; ``DW_OP_LLVM_form_aspace_address`` *operation when given an address space that; is SIMT lane specific.*. If specified, it must be consistent with the value of the ``DW_AT_LLVM_lanes``; attribute of the subprogram corresponding to context's frame and program; location. It is consistent if the value is greater than or equal to 0 and less; than the, possibly default, value of the ``DW_AT_LLVM_lanes`` attribute.; Otherwise the result is undefined. *A current iteration*. The 0 based source language iteration instance to be used in evaluating a user; presented expression. This applies to target architectures that support; optimizations that result in executing multiple source language loop iterations; concurrently. *For example, software pipelining and SIMD vectorization.*. It is required for operations that are related to source language loop; iterations. *For example, the* ``DW_OP_LLVM_push_iteration`` *operation.*. If specified, it must be consistent with the value of the; ``DW_AT_LLVM_iterations`` attribute of the subprogram corresponding to; context's frame and program location. It is consistent if the value is greater; than or equal to 0 and less than the, possibly default, value of the; ``DW_AT_LLVM_iterations`` attribute. Otherwise the result is undefined. *A current call frame*. The target architecture call frame identifier. It identifies a call frame that; corresponds to an active invocation of a subprogram in the current thread. It; is identified by its address on the call stack. The address is referred to as; the Canonical Frame Address (CFA). The call frame information is used to; determine the CFA for the call",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:51033,Performance,load,loaded,51033,"he; program location associated with the call site in the current caller frame; F that invoked the callee frame. * If the current lane is specified and the architecture program location LPC; computed by the ``DW_AT_LLVM_lane_pc`` attribute for the current lane is not; the undefined location description (indicating the lane was not active on; entry to the call frame), it must be LPC. * Otherwise the result is undefined. *A current compilation unit*. The compilation unit debug information entry that contains the DWARF expression; being evaluated. It is required for operations that reference debug information associated with; the same compilation unit, including indicating if such references use the; 32-bit or 64-bit DWARF format. It can also provide the default address space; address size if no current target architecture is specified. *For example, the* ``DW_OP_constx`` *and* ``DW_OP_addrx`` *operations.*. *Note that this compilation unit may not be the same as the compilation unit; determined from the loaded code object corresponding to the current program; location. For example, the evaluation of the expression E associated with a*; ``DW_AT_location`` *attribute of the debug information entry operand of the*; ``DW_OP_call*`` *operations is evaluated with the compilation unit that; contains E and not the one that contains the* ``DW_OP_call*`` *operation; expression.*. *A current target architecture*. The target architecture. It is required for operations that specify target architecture specific; entities. *For example, target architecture specific entities include DWARF register; identifiers, DWARF lane identifiers, DWARF address space identifiers, the; default address space, and the address space address sizes.*. If specified:. * If the current frame is specified, then the current target architecture must; be the same as the target architecture of the current frame. * If the current frame is specified and is the top frame, and if the current; thread is specified, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:54511,Performance,optimiz,optimized,54511,"description is invalid (see; :ref:`amdgpu-dwarf-location-description`). *An initial stack*. This is a list of values or location descriptions that will be pushed on the; operation expression evaluation stack in the order provided before evaluation; of an operation expression starts. Some debugger information entries have attributes that evaluate their DWARF; expression value with initial stack entries. In all other cases the initial; stack is empty. The result is undefined if any location descriptions are invalid (see; :ref:`amdgpu-dwarf-location-description`). If the evaluation requires a context element that is not specified, then the; result of the evaluation is an error. *A DWARF expression for a location description may be able to be evaluated; without a thread, lane, call frame, program location, or architecture context.; For example, the location of a global variable may be able to be evaluated; without such context. If the expression evaluates with an error then it may; indicate the variable has been optimized and so requires more context.*. *The DWARF expression for call frame information (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) operations are restricted to; those that do not require the compilation unit context to be specified.*. The DWARF is ill-formed if all the ``address_size`` fields in the headers of all; the entries in the ``.debug_info``, ``.debug_addr``, ``.debug_line``,; ``.debug_rnglists``, ``.debug_rnglists.dwo``, ``.debug_loclists``, and; ``.debug_loclists.dwo`` sections corresponding to any given program location do; not match. .. _amdgpu-dwarf-expression-value:. A.2.5.2 DWARF Expression Value; ++++++++++++++++++++++++++++++. A value has a type and a literal value. It can represent a literal value of any; supported base type of the target architecture. The base type specifies the; size, encoding, and endianity of the literal value. .. note::. It may be desirable to add an implicit pointer base type encoding. It would be; used for ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:57126,Performance,optimiz,optimization,57126,"ed type used for stack operations; defined in DWARF Version 4 and before.*. An integral type is a base type that has an encoding of ``DW_ATE_signed``,; ``DW_ATE_signed_char``, ``DW_ATE_unsigned``, ``DW_ATE_unsigned_char``,; ``DW_ATE_boolean``, or any target architecture defined integral encoding in the; inclusive range ``DW_ATE_lo_user`` to ``DW_ATE_hi_user``. .. note::. It is unclear if ``DW_ATE_address`` is an integral type. GDB does not seem to; consider it as integral. .. _amdgpu-dwarf-location-description:. A.2.5.3 DWARF Location Description; ++++++++++++++++++++++++++++++++++. *Debugging information must provide consumers a way to find the location of; program variables, determine the bounds of dynamic arrays and strings, and; possibly to find the base address of a subprogram’s call frame or the return; address of a subprogram. Furthermore, to meet the needs of recent computer; architectures and optimization techniques, debugging information must be able to; describe the location of an object whose location changes over the object’s; lifetime, and may reside at multiple locations simultaneously during parts of an; object's lifetime.*. Information about the location of program objects is provided by location; descriptions. Location descriptions can consist of one or more single location descriptions. A single location description specifies the location storage that holds a; program object and a position within the location storage where the program; object starts. The position within the location storage is expressed as a bit; offset relative to the start of the location storage. A location storage is a linear stream of bits that can hold values. Each; location storage has a size in bits and can be accessed using a zero-based bit; offset. The ordering of bits within a location storage uses the bit numbering; and direction conventions that are appropriate to the current language on the; target architecture. There are five kinds of location storage:. *memory locat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:60774,Performance,optimiz,optimization,60774,"ultiple locations over part or all of its lifetime.*. If a location description has more than one single location description, the; DWARF expression is ill-formed if the object value held in each single location; description's position within the associated location storage is not the same; value, except for the parts of the value that are uninitialized. *A location description that has more than one single location description can; only be created by a location list expression that has overlapping program; location ranges, or certain expression operations that act on a location; description that has more than one single location description. There are no; operation expression operations that can directly create a location description; with more than one single location description.*. *A location description with more than one single location description can be; used to describe objects that reside in more than one piece of storage at the; same time. An object may have more than one location as a result of; optimization. For example, a value that is only read may be promoted from memory; to a register for some region of code, but later code may revert to reading the; value from memory as the register may be used for other purposes. For the code; region where the value is in a register, any change to the object value must be; made in both the register and the memory so both regions of code will read the; updated value.*. *A consumer of a location description with more than one single location; description can read the object's value from any of the single location; descriptions (since they all refer to location storage that has the same value),; but must write any changed value to all the single location descriptions.*. The evaluation of an expression may require context elements to create a; location description. If such a location description is accessed, the storage it; denotes is that associated with the context element values specified when the; location descrip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:66147,Performance,perform,performed,66147,"l one past the last operation of the stream is reached. The result of the evaluation is:. * If an operation has an evaluation error, or an operation evaluates an; expression that has an evaluation error, then the result is an evaluation; error. * If the current result kind specifies a location description, then:. * If the stack is empty, the result is a location description with one; undefined location description. *This rule is for backwards compatibility with DWARF Version 5 which has no; explicit operation to create an undefined location description, and uses an; empty operation expression for this purpose.*. * If the top stack entry is a location description, or can be converted; to one (see :ref:`amdgpu-dwarf-memory-location-description-operations`),; then the result is that, possibly converted, location description. Any other; entries on the stack are discarded. * Otherwise the DWARF expression is ill-formed. .. note::. Could define this case as returning an implicit location description as; if the ``DW_OP_implicit`` operation is performed. * If the current result kind specifies a value, then:. * If the top stack entry is a value, or can be converted to one (see; :ref:`amdgpu-dwarf-memory-location-description-operations`), then the result; is that, possibly converted, value. Any other entries on the stack are; discarded. * Otherwise the DWARF expression is ill-formed. * If the current result kind is not specified, then:. * If the stack is empty, the result is a location description with one; undefined location description. *This rule is for backwards compatibility with DWARF Version 5 which has no; explicit operation to create an undefined location description, and uses an; empty operation expression for this purpose.*. .. note::. This rule is consistent with the rule above for when a location; description is requested. However, GDB appears to report this as an error; and no GDB tests appear to cause an empty stack for this case. * Otherwise, the top stack entr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:72319,Performance,perform,perform,72319,"uation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This operation pops the top of stack. If the value popped; is not the constant 0, the 2-byte constant operand is the number of bytes of; the DWARF operation expression to skip forward or backward from the current; operation, beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 5. ``DW_OP_call2, DW_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_call4``, and ``DW_OP_call_ref`` perform DWARF; procedure calls during evaluation of a DWARF operation expression. ``DW_OP_call2`` and ``DW_OP_call4``, have one operand that is, respectively,; a 2-byte or 4-byte unsigned offset DR that represents the byte offset of a; debugging information entry D relative to the beginning of the current; compilation unit. ``DW_OP_call_ref`` has one operand that is a 4-byte unsigned value in the; 32-bit DWARF format, or an 8-byte unsigned value in the 64-bit DWARF format,; that represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit. D may not be in the current compilation unit. .. note::. DWARF Version 5 states that DR can be an offset in a ``.debug_info``; section other than the one that contains the current compilation unit. It; states that relocation of references from one executable or shared object; file to another must be performed by the consumer. But given that DR is; defined as",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:73272,Performance,perform,performed,73272,"_OP_call4, DW_OP_call_ref``. ``DW_OP_call2``, ``DW_OP_call4``, and ``DW_OP_call_ref`` perform DWARF; procedure calls during evaluation of a DWARF operation expression. ``DW_OP_call2`` and ``DW_OP_call4``, have one operand that is, respectively,; a 2-byte or 4-byte unsigned offset DR that represents the byte offset of a; debugging information entry D relative to the beginning of the current; compilation unit. ``DW_OP_call_ref`` has one operand that is a 4-byte unsigned value in the; 32-bit DWARF format, or an 8-byte unsigned value in the 64-bit DWARF format,; that represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit. D may not be in the current compilation unit. .. note::. DWARF Version 5 states that DR can be an offset in a ``.debug_info``; section other than the one that contains the current compilation unit. It; states that relocation of references from one executable or shared object; file to another must be performed by the consumer. But given that DR is; defined as an offset in a ``.debug_info`` section this seems impossible.; If DR was defined as an implementation defined value, then the consumer; could choose to interpret the value in an implementation defined manner to; reference a debug information in another executable or shared object. In ELF the ``.debug_info`` section is in a non-\ ``PT_LOAD`` segment so; standard dynamic relocations cannot be used. But even if they were loaded; segments and dynamic relocations were used, DR would need to be the; address of D, not an offset in a ``.debug_info`` section. That would also; need DR to be the size of a global address. So it would not be possible to; use the 32-bit DWARF format in a 64-bit global address space. In addition,; the consumer would need to determine what executable or shared object the; relocated address was in so it could determine the containing compilation; unit. GDB only interprets",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:73754,Performance,load,loaded,73754,"hat represents the byte offset DR of a debugging information entry D; relative to the beginning of the ``.debug_info`` section that contains the; current compilation unit. D may not be in the current compilation unit. .. note::. DWARF Version 5 states that DR can be an offset in a ``.debug_info``; section other than the one that contains the current compilation unit. It; states that relocation of references from one executable or shared object; file to another must be performed by the consumer. But given that DR is; defined as an offset in a ``.debug_info`` section this seems impossible.; If DR was defined as an implementation defined value, then the consumer; could choose to interpret the value in an implementation defined manner to; reference a debug information in another executable or shared object. In ELF the ``.debug_info`` section is in a non-\ ``PT_LOAD`` segment so; standard dynamic relocations cannot be used. But even if they were loaded; segments and dynamic relocations were used, DR would need to be the; address of D, not an offset in a ``.debug_info`` section. That would also; need DR to be the size of a global address. So it would not be possible to; use the 32-bit DWARF format in a 64-bit global address space. In addition,; the consumer would need to determine what executable or shared object the; relocated address was in so it could determine the containing compilation; unit. GDB only interprets DR as an offset in the ``.debug_info`` section that; contains the current compilation unit. This comment also applies to ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer``. *Operand interpretation of* ``DW_OP_call2``\ *,* ``DW_OP_call4``\ *, and*; ``DW_OP_call_ref`` *is exactly like that for* ``DW_FORM_ref2``\ *,; ``DW_FORM_ref4``\ *, and* ``DW_FORM_ref_addr``\ *, respectively.*. The call operation is evaluated by:. * If D has a ``DW_AT_location`` attribute that is encoded as a ``exprloc``; that specifies an operation expression E, then ex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:80542,Performance,optimiz,optimized,80542,"ion 5,; and the new semantics for DWARF Version 6 which has been done for some; other features. Another option is to limit the execution to be on the same stack only to; the evaluation of an expression E that is the value of a; ``DW_AT_location`` attribute of a ``DW_TAG_dwarf_procedure`` debugging; information entry. The DWARF would be ill-formed if E is a location list; expression that does not match exactly one location list entry. In all; other cases the evaluation of an expression E that is the value of a; ``DW_AT_location`` attribute would evaluate E with the current context,; except the result kind is a location description, the compilation unit; is the one that contains D, and the initial stack is empty. The location; description result is pushed on the stack. * If D has a ``DW_AT_const_value`` attribute with a value V, then it is as; if a ``DW_OP_implicit_value V`` operation was executed. *This allows a call operation to be used to compute the location; description for any variable or formal parameter regardless of whether the; producer has optimized it to a constant. This is consistent with the*; ``DW_OP_implicit_pointer`` *operation.*. .. note::. Alternatively, could deprecate using ``DW_AT_const_value`` for; ``DW_TAG_variable`` and ``DW_TAG_formal_parameter`` debugger information; entries that are constants and instead use ``DW_AT_location`` with an; operation expression that results in a location description with one; implicit location description. Then this rule would not be required. * Otherwise, there is no effect and no changes are made to the stack. .. note::. In DWARF Version 5, if D does not have a ``DW_AT_location`` then; ``DW_OP_call*`` is defined to have no effect. It is unclear that this is; the right definition as a producer should be able to rely on using; ``DW_OP_call*`` to get a location description for any non-\; ``DW_TAG_dwarf_procedure`` debugging information entries. Also, the; producer should not be creating DWARF with ``DW_OP_call*`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:85891,Performance,optimiz,optimizations,85891,"ize of the byte block B can be inferred from the type D; definition, it is encoded explicitly into the operation so that the; operation can be parsed easily without reference to the* ``.debug_info``; *section.*. 8. ``DW_OP_LLVM_push_lane`` *New*. ``DW_OP_LLVM_push_lane`` pushes the current lane as a value with the generic; type. *For source languages that are implemented using a SIMT execution model,; this is the zero-based lane number that corresponds to the source language; thread of execution upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_lanes`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. 9. ``DW_OP_LLVM_push_iteration`` *New*. ``DW_OP_LLVM_push_iteration`` pushes the current iteration as a value with; the generic type. *For source language implementations with optimizations that cause multiple; loop iterations to execute concurrently, this is the zero-based iteration; number that corresponds to the source language concurrent loop iteration; upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_iterations`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. .. _amdgpu-dwarf-arithmetic-logical-operations:. A.2.5.4.3.2 Arithmetic and Logical Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.4. .. _amdgpu-dwarf-type-conversions-operations:. A.2.5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value ope",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:85953,Performance,concurren,concurrently,85953,"ize of the byte block B can be inferred from the type D; definition, it is encoded explicitly into the operation so that the; operation can be parsed easily without reference to the* ``.debug_info``; *section.*. 8. ``DW_OP_LLVM_push_lane`` *New*. ``DW_OP_LLVM_push_lane`` pushes the current lane as a value with the generic; type. *For source languages that are implemented using a SIMT execution model,; this is the zero-based lane number that corresponds to the source language; thread of execution upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_lanes`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. 9. ``DW_OP_LLVM_push_iteration`` *New*. ``DW_OP_LLVM_push_iteration`` pushes the current iteration as a value with; the generic type. *For source language implementations with optimizations that cause multiple; loop iterations to execute concurrently, this is the zero-based iteration; number that corresponds to the source language concurrent loop iteration; upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_iterations`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. .. _amdgpu-dwarf-arithmetic-logical-operations:. A.2.5.4.3.2 Arithmetic and Logical Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.4. .. _amdgpu-dwarf-type-conversions-operations:. A.2.5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value ope",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:86048,Performance,concurren,concurrent,86048,"ize of the byte block B can be inferred from the type D; definition, it is encoded explicitly into the operation so that the; operation can be parsed easily without reference to the* ``.debug_info``; *section.*. 8. ``DW_OP_LLVM_push_lane`` *New*. ``DW_OP_LLVM_push_lane`` pushes the current lane as a value with the generic; type. *For source languages that are implemented using a SIMT execution model,; this is the zero-based lane number that corresponds to the source language; thread of execution upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_lanes`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. 9. ``DW_OP_LLVM_push_iteration`` *New*. ``DW_OP_LLVM_push_iteration`` pushes the current iteration as a value with; the generic type. *For source language implementations with optimizations that cause multiple; loop iterations to execute concurrently, this is the zero-based iteration; number that corresponds to the source language concurrent loop iteration; upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_iterations`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. .. _amdgpu-dwarf-arithmetic-logical-operations:. A.2.5.4.3.2 Arithmetic and Logical Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.4. .. _amdgpu-dwarf-type-conversions-operations:. A.2.5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value ope",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:87401,Performance,perform,performing,87401,"s; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.4. .. _amdgpu-dwarf-type-conversions-operations:. A.2.5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value operations currently defined:. 1. ``DW_OP_regval_type``. ``DW_OP_regval_type`` has two operands. The first is an unsigned LEB128; integer that represents a register number R. The second is an unsigned; LEB128 integer DR that represents the byte offset of a debugging information; entry D relative to the beginning of the current compilation unit, that; provides the type T of the register value. The operation is equivalent to performing ``DW_OP_regx R; DW_OP_deref_type; DR``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:88952,Performance,perform,performing,88952," use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions allow a composite location description to be used to combine; multiple registers. 2. ``DW_OP_deref``. S is the bit size of the generic type divided by 8 (the byte size) and; rounded up to a whole number. DR is the offset of a hypothetical debug; information entry D in the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. 3. ``DW_OP_deref_size``. ``DW_OP_deref_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. TS is the smaller of the generic type bit size and S scaled by 8 (the byte; size). If TS is smaller than the generic type bit size then T is an unsigned; integral type of bit size TS, otherwise T is the generic type. DR is the; offset of a hypothetical debug information entry D in the current; compilation unit for a base type T. .. note::. Truncating the value when S is larger than the generic type matches what; GDB does. This allows the generic type size to not be an integral byte; size. It does allow S to be arbitrarily large. Should S be restricted to; the size of the generic type rounded up to a multiple of 8?. The operation is equivalent to performing ``DW_OP_deref_type S, DR``, except; if T is not the generic type, the value V pushed is zero-extended to the; generic type bit size and its type changed to the generic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:89777,Performance,perform,performing,89777," the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. 3. ``DW_OP_deref_size``. ``DW_OP_deref_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. TS is the smaller of the generic type bit size and S scaled by 8 (the byte; size). If TS is smaller than the generic type bit size then T is an unsigned; integral type of bit size TS, otherwise T is the generic type. DR is the; offset of a hypothetical debug information entry D in the current; compilation unit for a base type T. .. note::. Truncating the value when S is larger than the generic type matches what; GDB does. This allows the generic type size to not be an integral byte; size. It does allow S to be arbitrarily large. Should S be restricted to; the size of the generic type rounded up to a multiple of 8?. The operation is equivalent to performing ``DW_OP_deref_type S, DR``, except; if T is not the generic type, the value V pushed is zero-extended to the; generic type bit size and its type changed to the generic type. 4. ``DW_OP_deref_type``. ``DW_OP_deref_type`` has two operands. The first is a 1-byte unsigned; integral constant S. The second is an unsigned LEB128 integer DR that; represents the byte offset of a debugging information entry D relative to; the beginning of the current compilation unit, that provides the type T of; the result value. TS is the bit size of the type T. *While the size of the pushed value V can be inferred from the type T, it is; encoded explicitly as the operand S so that the operation can be parsed; easily without reference to the* ``.debug_info`` *section.*. .. note::. It is unclear why the operand S is needed. Unlike ``DW_OP_const_type``,; the size is not needed for parsing. Any evaluation needs to get the base; type T to push with the value to know its encoding and bit size. It pops one stack entry that must be a location description L. A value V of TS bits is",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:91838,Performance,perform,performing,91838,"S bits is retrieved from the location storage LS specified by; one of the single location descriptions SL of L. *If L, or the location description of any composite location description; part that is a subcomponent of L, has more than one single location; description, then any one of them can be selected as they are required to; all have the same value. For any single location description SL, bits are; retrieved from the associated storage location starting at the bit offset; specified by SL. For a composite location description, the retrieved bits; are the concatenation of the N bits from each composite location part PL,; where N is limited to the size of PL.*. V is pushed on the stack with the type T. .. note::. This definition makes it an evaluation error if L is a register location; description that has less than TS bits remaining in the register storage.; Particularly since these extensions extend location descriptions to have; a bit offset, it would be odd to define this as performing sign extension; based on the type, or be target architecture dependent, as the number of; remaining bits could be any number. This matches the GDB implementation; for ``DW_OP_deref_type``. These extensions define ``DW_OP_*breg*`` in terms of; ``DW_OP_regval_type``. ``DW_OP_regval_type`` is defined in terms of; ``DW_OP_regx``, which uses a 0 bit offset, and ``DW_OP_deref_type``.; Therefore, it requires the register size to be greater or equal to the; address size of the address space. This matches the GDB implementation for; ``DW_OP_*breg*``. The DWARF is ill-formed if D is not in the current compilation unit, D is; not a ``DW_TAG_base_type`` debugging information entry, or if TS divided by; 8 (the byte size) and rounded up to a whole number is not equal to S. .. note::. This definition allows the base type to be a bit size since there seems no; reason to restrict it. It is an evaluation error if any bit of the value is retrieved from the; undefined location storage or the offset o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:93476,Performance,perform,performing,93476,"`` debugging information entry, or if TS divided by; 8 (the byte size) and rounded up to a whole number is not equal to S. .. note::. This definition allows the base type to be a bit size since there seems no; reason to restrict it. It is an evaluation error if any bit of the value is retrieved from the; undefined location storage or the offset of any bit exceeds the size of the; location storage LS specified by any single location description SL of L. See :ref:`amdgpu-dwarf-implicit-location-description-operations` for special; rules concerning implicit location descriptions created by the; ``DW_OP_implicit_pointer`` and ``DW_OP_LLVM_aspace_implicit_pointer``; operations. 5. ``DW_OP_xderef`` *Deprecated*. ``DW_OP_xderef`` pops two stack entries. The first must be an integral type; value that represents an address A. The second must be an integral type; value that represents a target architecture specific address space; identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref``. The value V retrieved is left; on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 6. ``DW_OP_xderef_size`` *Deprecated*. ``DW_OP_xderef_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_size S``. The zero-extended; value V retrieved is left on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 7. ``DW_OP_xderef_type`` *Deprecated*. ``DW_OP_xder",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:94148,Performance,perform,performing,94148,"tions. 5. ``DW_OP_xderef`` *Deprecated*. ``DW_OP_xderef`` pops two stack entries. The first must be an integral type; value that represents an address A. The second must be an integral type; value that represents a target architecture specific address space; identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref``. The value V retrieved is left; on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 6. ``DW_OP_xderef_size`` *Deprecated*. ``DW_OP_xderef_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_size S``. The zero-extended; value V retrieved is left on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 7. ``DW_OP_xderef_type`` *Deprecated*. ``DW_OP_xderef_type`` has two operands. The first is a 1-byte unsigned; integral constant S. The second operand is an unsigned LEB128 integer DR; that represents the byte offset of a debugging information entry D relative; to the beginning of the current compilation unit, that provides the type T; of the result value. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_type S DR``. The value V; retrieved is left on th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:95053,Performance,perform,performing,95053," specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_size S``. The zero-extended; value V retrieved is left on the stack with the generic type. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 7. ``DW_OP_xderef_type`` *Deprecated*. ``DW_OP_xderef_type`` has two operands. The first is a 1-byte unsigned; integral constant S. The second operand is an unsigned LEB128 integer DR; that represents the byte offset of a debugging information entry D relative; to the beginning of the current compilation unit, that provides the type T; of the result value. It pops two stack entries. The first must be an integral type value that; represents an address A. The second must be an integral type value that; represents a target architecture specific address space identifier AS. The operation is equivalent to performing ``DW_OP_swap;; DW_OP_LLVM_form_aspace_address; DW_OP_deref_type S DR``. The value V; retrieved is left on the stack with the type T. *This operation is deprecated as the* ``DW_OP_LLVM_form_aspace_address``; *operation can be used and provides greater expressiveness.*. 8. ``DW_OP_entry_value`` *Deprecated*. ``DW_OP_entry_value`` pushes the value of an expression that is evaluated in; the context of the calling frame. *It may be used to determine the value of arguments on entry to the current; call frame provided they are not clobbered.*. It has two operands. The first is an unsigned LEB128 integer S. The second; is a block of bytes, with a length equal S, interpreted as a DWARF; operation expression E. E is evaluated with the current context, except the result kind is; unspecified, the call frame is the one that called the current frame, the; program location is the call site in the calling frame, the object is; unspecified, and the initial stack is empty. The calling frame information; is obtained b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:96544,Performance,perform,performed,96544," is evaluated in; the context of the calling frame. *It may be used to determine the value of arguments on entry to the current; call frame provided they are not clobbered.*. It has two operands. The first is an unsigned LEB128 integer S. The second; is a block of bytes, with a length equal S, interpreted as a DWARF; operation expression E. E is evaluated with the current context, except the result kind is; unspecified, the call frame is the one that called the current frame, the; program location is the call site in the calling frame, the object is; unspecified, and the initial stack is empty. The calling frame information; is obtained by virtually unwinding the current call frame using the call; frame information (see :ref:`amdgpu-dwarf-call-frame-information`). If the result of E is a location description L (see; :ref:`amdgpu-dwarf-register-location-description-operations`), and the last; operation executed by E is a ``DW_OP_reg*`` for register R with a target; architecture specific base type of T, then the contents of the register are; retrieved as if a ``DW_OP_deref_type DR`` operation was performed where DR; is the offset of a hypothetical debug information entry in the current; compilation unit for T. The resulting value V s pushed on the stack. *Using* ``DW_OP_reg*`` *provides a more compact form for the case where the; value was in a register on entry to the subprogram.*. .. note::. It is unclear how this provides a more compact expression, as; ``DW_OP_regval_type`` could be used which is marginally larger. If the result of E is a value V, then V is pushed on the stack. Otherwise, the DWARF expression is ill-formed. *The* ``DW_OP_entry_value`` *operation is deprecated as its main usage is; provided by other means. DWARF Version 5 added the*; ``DW_TAG_call_site_parameter`` *debugger information entry for call sites; that has* ``DW_AT_call_value``\ *,* ``DW_AT_call_data_location``\ *, and*; ``DW_AT_call_data_value`` *attributes that provide DWARF expressions t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:98991,Performance,perform,performing,98991,"es the operations that push location descriptions on the; stack. .. _amdgpu-dwarf-general-location-description-operations:. A.2.5.4.4.1 General Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces part of DWARF Version 5 section 2.5.1.3. 1. ``DW_OP_LLVM_offset`` *New*. ``DW_OP_LLVM_offset`` pops two stack entries. The first must be an integral; type value that represents a byte displacement B. The second must be a; location description L. It adds the value of B scaled by 8 (the byte size) to the bit offset of each; single location description SL of L, and pushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 2. ``DW_OP_LLVM_offset_uconst`` *New*. ``DW_OP_LLVM_offset_uconst`` has a single unsigned LEB128 integer operand; that represents a byte displacement B. The operation is equivalent to performing ``DW_OP_constu B;; DW_OP_LLVM_offset``. *This operation is supplied specifically to be able to encode more field; displacements in two bytes than can be done with* ``DW_OP_lit*;; DW_OP_LLVM_offset``\ *.*. .. note::. Should this be named ``DW_OP_LLVM_offset_uconst`` to match; ``DW_OP_plus_uconst``, or ``DW_OP_LLVM_offset_constu`` to match; ``DW_OP_constu``?. 3. ``DW_OP_LLVM_bit_offset`` *New*. ``DW_OP_LLVM_bit_offset`` pops two stack entries. The first must be an; integral type value that represents a bit displacement B. The second must be; a location description L. It adds the value of B to the bit offset of each single location description; SL of L, and pushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 4. ``DW_OP_push_object_address``. ``DW_OP_push_object_address`` pushes the location description L of the; current object. *This object may correspond to an ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:103202,Performance,optimiz,optimization,103202," 5. ``DW_OP_LLVM_call_frame_entry_reg`` *New*. ``DW_OP_LLVM_call_frame_entry_reg`` has a single unsigned LEB128 integer; operand that represents a target architecture register number R. It pushes a location description L that holds the value of register R on; entry to the current subprogram as defined by the call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`). *If there is no call frame information defined, then the default rules for; the target architecture are used. If the register rule is* undefined\ *, then; the undefined location description is pushed. If the register rule is* same; value\ *, then a register location description for R is pushed.*. .. _amdgpu-dwarf-undefined-location-description-operations:. A.2.5.4.4.2 Undefined Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.1. *The undefined location storage represents a piece or all of an object that is; present in the source but not in the object code (perhaps due to optimization).; Neither reading nor writing to the undefined location storage is meaningful.*. An undefined location description specifies the undefined location storage.; There is no concept of the size of the undefined location storage, nor of a bit; offset for an undefined location description. The ``DW_OP_LLVM_*offset``; operations leave an undefined location description unchanged. The; ``DW_OP_*piece`` operations can explicitly or implicitly specify an undefined; location description, allowing any size and offset to be specified, and results; in a part with all undefined bits. 1. ``DW_OP_LLVM_undefined`` *New*. ``DW_OP_LLVM_undefined`` pushes a location description L that comprises one; undefined location description SL. .. _amdgpu-dwarf-memory-location-description-operations:. A.2.5.4.4.3 Memory Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces par",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:109368,Performance,load,loaded,109368,"wards compatibility? If not, it; can be eliminated, and the producer can use; ``DW_OP_LLVM_form_aspace_address``. If a stack entry is required to be a value, but it is a location description L; with one memory location description SL in the target architecture default; address space with a bit offset B that is a multiple of 8, then it is implicitly; converted to a value equal to B divided by 8 (the byte size) with the generic; type. 1. ``DW_OP_addr``. ``DW_OP_addr`` has a single byte constant value operand, which has the size; of the generic type, that represents an address A. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 2. ``DW_OP_addrx``. ``DW_OP_addrx`` has a single unsigned LEB128 integer operand that represents; a zero-based index into the ``.debug_addr`` section relative to the value of; the ``DW_AT_addr_base`` attribute of the associated compilation unit. The; address value A in the ``.debug_addr`` section has the size of the generic; type. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 3. ``DW_OP_LLVM_form_aspace_address`` *New*. ``DW_OP_LLVM_form_as",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:110210,Performance,load,loaded,110210,"the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 2. ``DW_OP_addrx``. ``DW_OP_addrx`` has a single unsigned LEB128 integer operand that represents; a zero-based index into the ``.debug_addr`` section relative to the value of; the ``DW_AT_addr_base`` attribute of the associated compilation unit. The; address value A in the ``.debug_addr`` section has the size of the generic; type. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage corresponding to the; target architecture default address space with a bit offset equal to A; scaled by 8 (the byte size). *If the DWARF is part of a code object, then A may need to be relocated. For; example, in the ELF code object format, A must be adjusted by the difference; between the ELF segment virtual address and the virtual address at which the; segment is loaded.*. 3. ``DW_OP_LLVM_form_aspace_address`` *New*. ``DW_OP_LLVM_form_aspace_address`` pops top two stack entries. The first; must be an integral type value that represents a target architecture; specific address space identifier AS. The second must be an integral type; value that represents an address A. The address size S is defined as the address bit size of the target; architecture specific address space that corresponds to AS. A is adjusted to S bits by zero extending if necessary, and then treating; the least significant S bits as an unsigned value A'. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage LS that corresponds; to AS with a bit offset equal to A' scaled by 8 (the byte size). If AS is an address space that is specific to context elements, then LS; corresponds to the location storage associated with the cur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:113838,Performance,perform,perform,113838,"port a; thread-local storage class. Variables with this storage class have distinct; values and addresses in distinct threads, much as automatic variables have; distinct values and addresses in each subprogram invocation. Typically,; there is a single block of storage containing all thread-local variables; declared in the main executable, and a separate block for the variables; declared in each shared library. Each thread-local variable can then be; accessed in its block using an identifier. This identifier is typically a; byte offset into the block and pushed onto the DWARF stack by one of the*; ``DW_OP_const*`` *operations prior to the* ``DW_OP_form_tls_address``; *operation. Computing the address of the appropriate block can be complex; (in some cases, the compiler emits a function call to do it), and difficult; to describe using ordinary DWARF location descriptions. Instead of forcing; complex thread-local storage calculations into the DWARF expressions, the*; ``DW_OP_form_tls_address`` *allows the consumer to perform the computation; based on the target architecture specific run-time environment.*. 5. ``DW_OP_call_frame_cfa``. ``DW_OP_call_frame_cfa`` pushes the location description L of the Canonical; Frame Address (CFA) of the current subprogram, obtained from the call frame; information on the stack. See :ref:`amdgpu-dwarf-call-frame-information`. *Although the value of the* ``DW_AT_frame_base`` *attribute of the debugger; information entry corresponding to the current subprogram can be computed; using a location list expression, in some cases this would require an; extensive location list because the values of the registers used in; computing the CFA change during a subprogram execution. If the call frame; information is present, then it already encodes such changes, and it is; space efficient to reference that using the* ``DW_OP_call_frame_cfa``; *operation.*. 6. ``DW_OP_fbreg``. ``DW_OP_fbreg`` has a single signed LEB128 integer operand that represents a;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:115927,Performance,perform,performed,115927,"ibute of the debugger information; entry corresponding to the current subprogram as described in; :ref:`amdgpu-dwarf-low-level-information`. The location description L is updated as if the ``DW_OP_LLVM_offset_uconst; B`` operation was applied. The updated L is pushed on the stack. 7. ``DW_OP_breg0``, ``DW_OP_breg1``, ..., ``DW_OP_breg31``. The ``DW_OP_breg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The register number R corresponds to; the N in the operation name. They have a single signed LEB128 integer operand that represents a byte; displacement B. The address space identifier AS is defined as the one corresponding to the; target architecture specific default address space. The address size S is defined as the address bit size of the target; architecture specific address space corresponding to AS. The contents of the register specified by R are retrieved as if a; ``DW_OP_regval_type R, DR`` operation was performed where DR is the offset; of a hypothetical debug information entry in the current compilation unit; for an unsigned integral base type of size S bits. B is added and the least; significant S bits are treated as an unsigned value to be used as an address; A. They push a location description L comprising one memory location; description LS on the stack. LS specifies the memory location storage that; corresponds to AS with a bit offset equal to A scaled by 8 (the byte size). 8. ``DW_OP_bregx``. ``DW_OP_bregx`` has two operands. The first is an unsigned LEB128 integer; that represents a register number R. The second is a signed LEB128; integer that represents a byte displacement B. The action is the same as for ``DW_OP_breg<N>``, except that R is used as; the register number and B is used as the byte displacement. 9. ``DW_OP_LLVM_aspace_bregx`` *New*. ``DW_OP_LLVM_aspace_bregx`` has two operands. The first is an unsigned; LEB128 integer that represents a register number R. The second is a signed; LEB128 i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:118648,Performance,perform,performing,118648,"er-location-description-operations:. A.2.5.4.4.4 Register Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.3. There is a register location storage that corresponds to each of the target; architecture registers. The size of each register location storage corresponds; to the size of the corresponding target architecture register. A register location description specifies a register location storage. The bit; offset corresponds to a bit position within the register. Bits accessed using a; register location description access the corresponding target architecture; register starting at the specified bit offset. 1. ``DW_OP_reg0``, ``DW_OP_reg1``, ..., ``DW_OP_reg31``. ``DW_OP_reg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The target architecture register; number R corresponds to the N in the operation name. The operation is equivalent to performing ``DW_OP_regx R``. 2. ``DW_OP_regx``. ``DW_OP_regx`` has a single unsigned LEB128 integer operand that represents; a target architecture register number R. If the current call frame is the top call frame, it pushes a location; description L that specifies one register location description SL on the; stack. SL specifies the register location storage that corresponds to R with; a bit offset of 0 for the current thread. If the current call frame is not the top call frame, call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`) is used to determine the; location description that holds the register for the current call frame and; current program location of the current thread. The resulting location; description L is pushed. *Note that if call frame information is used, the resulting location; description may be register, memory, or undefined.*. *An implementation may evaluate the call frame information immediately, or; may defer evaluation until L is accessed b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:122481,Performance,optimiz,optimizing,122481,"size, encoding, and endianity specified by V's base type. It pushes a location description L with one implicit location description SL; on the stack. SL specifies LS with a bit offset of 0. *The* ``DW_OP_stack_value`` *operation specifies that the object does not; exist in memory, but its value is nonetheless known. In this form, the; location description specifies the actual value of the object, rather than; specifying the memory or register storage that holds the value.*. See ``DW_OP_implicit_pointer`` (following) for special rules concerning; implicit pointer values produced by dereferencing implicit location; descriptions created by the ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer`` operations. Note: Since location descriptions are allowed on the stack, the; ``DW_OP_stack_value`` operation no longer terminates the DWARF operation; expression execution as in DWARF Version 5. 3. ``DW_OP_implicit_pointer``. *An optimizing compiler may eliminate a pointer, while still retaining the; value that the pointer addressed.* ``DW_OP_implicit_pointer`` *allows a; producer to describe this value.*. ``DW_OP_implicit_pointer`` *specifies an object is a pointer to the target; architecture default address space that cannot be represented as a real; pointer, even though the value it would point to can be described. In this; form, the location description specifies a debugging information entry that; represents the actual location description of the object to which the; pointer would point. Thus, a consumer of the debug information would be able; to access the dereferenced pointer, even when it cannot access the pointer; itself.*. ``DW_OP_implicit_pointer`` has two operands. The first operand is a 4-byte; unsigned value in the 32-bit DWARF format, or an 8-byte unsigned value in; the 64-bit DWARF format, that represents the byte offset DR of a debugging; information entry D relative to the beginning of the ``.debug_info`` section; that contains the current co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:141639,Performance,perform,performing,141639," type value that represents the overlay bit size value BS. The; second must be an integral type value that represents the overlay bit offset; value BO. The third must be a location description that represents the; overlay location description OL. The fourth must be a location description; that represents the base location description BL. The DWARF expression is ill-formed if BS or BO are negative values. *rbss(L)* is the minimum remaining bit storage size of L which is defined as; follows. LS is the location storage and LO is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object who",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:141979,Performance,perform,performing,141979,"ption BL. The DWARF expression is ill-formed if BS or BO are negative values. *rbss(L)* is the minimum remaining bit storage size of L which is defined as; follows. LS is the location storage and LO is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of loca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:142056,Performance,perform,performing,142056," is the minimum remaining bit storage size of L which is defined as; follows. LS is the location storage and LO is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of location list entries. Each; location list entry is one of the following kinds:. *Bounded ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:142174,Performance,perform,performing,142174,"O is the location bit offset; specified by a single location description SL of L. The remaining bit; storage size RBSS of SL is the bit size of LS minus LO. *rbss(L)* is the; minimum RBSS of each single location description SL of L. The DWARF expression is ill-formed if *rbss(BL)* is less than BO plus BS. If BS is 0, then the operation pushes BL. If BO is 0 and BS equals *rbss(BL)*, then the operation pushes OL. Otherwise, the operation is equivalent to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of location list entries. Each; location list entry is one of the following kinds:. *Bounded location description*. This kind of location list entry provides an operation expression that; evaluates to the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:142552,Performance,optimiz,optimization,142552,"to performing the following steps to; push a composite location description. *The composite location description is conceptually the base location; description BL with the overlay location description OL positioned as an; overlay starting at the overlay offset BO and covering overlay bit size BS.*. 1. If BO is not 0 then push BL followed by performing the ``DW_OP_bit_piece; BO, 0`` operation.; 2. Push OL followed by performing the ``DW_OP_bit_piece BS, 0`` operation.; 3. If *rbss(BL)* is greater than BO plus BS, push BL followed by performing; the ``DW_OP_bit_piece (rbss(BL) - BO - BS), (BO + BS)`` operation.; 4. Perform the ``DW_OP_LLVM_piece_end`` operation. .. _amdgpu-dwarf-location-list-expressions:. A.2.5.5 DWARF Location List Expressions; +++++++++++++++++++++++++++++++++++++++. .. note::. This section replaces DWARF Version 5 section 2.6.2. *To meet the needs of recent computer architectures and optimization techniques,; debugging information must be able to describe the location of an object whose; location changes over the object’s lifetime, and may reside at multiple; locations during parts of an object's lifetime. Location list expressions are; used in place of operation expressions whenever the object whose location is; being described has these requirements.*. A location list expression consists of a series of location list entries. Each; location list entry is one of the following kinds:. *Bounded location description*. This kind of location list entry provides an operation expression that; evaluates to the location description of an object that is valid over a; lifetime bounded by a starting and ending address. The starting address is the; lowest address of the address range over which the location is valid. The; ending address is the address of the first location past the highest address; of the address range. The location list entry matches when the current program location is within; the given range. There are several kinds of bounded location descr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:165802,Performance,concurren,concurrently,165802,"rwise it is; inactive. The result of the attribute is the value V. *Some targets may update the target architecture execution mask for regions; of code that must execute with different sets of lanes than the current; active lanes. For example, some code must execute with all lanes made; temporarily active.* ``DW_AT_LLVM_active_lane`` *allows the compiler to; provide the means to determine the source language active lanes at any; program location. Typically, this attribute will use a loclist to express; different locations of the active lane mask at different program locations.*. If not present and ``DW_AT_LLVM_lanes`` is greater than 1, then the target; architecture execution mask is used. 7. A ``DW_TAG_subprogram``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_entry_point`` debugger information entry may have a; ``DW_AT_LLVM_iterations`` attribute whose value is an integer constant or a; DWARF expression E. Its value is the number of source language loop; iterations executing concurrently by the target architecture for a single; source language thread of execution. *A compiler may generate code that executes more than one iteration of a; source language loop concurrently using optimization techniques such as; software pipelining or SIMD vectorization. The number of concurrent; iterations may vary for different loop nests in the same subprogram.; Typically, this attribute will use a loclist to express different values at; different program locations.*. If the attribute is an integer constant, then the value is the constant. The; DWARF is ill-formed if the constant is less than or equal to 0. Otherwise, E is evaluated with a context that has a result kind of a; location description, an unspecified object, the compilation unit that; contains E, an empty initial stack, and other context elements corresponding; to the source language thread of execution upon which the user is focused,; if any. The DWARF is ill-formed if the result is not a location description; comprised ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:165988,Performance,concurren,concurrently,165988,"ifferent sets of lanes than the current; active lanes. For example, some code must execute with all lanes made; temporarily active.* ``DW_AT_LLVM_active_lane`` *allows the compiler to; provide the means to determine the source language active lanes at any; program location. Typically, this attribute will use a loclist to express; different locations of the active lane mask at different program locations.*. If not present and ``DW_AT_LLVM_lanes`` is greater than 1, then the target; architecture execution mask is used. 7. A ``DW_TAG_subprogram``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_entry_point`` debugger information entry may have a; ``DW_AT_LLVM_iterations`` attribute whose value is an integer constant or a; DWARF expression E. Its value is the number of source language loop; iterations executing concurrently by the target architecture for a single; source language thread of execution. *A compiler may generate code that executes more than one iteration of a; source language loop concurrently using optimization techniques such as; software pipelining or SIMD vectorization. The number of concurrent; iterations may vary for different loop nests in the same subprogram.; Typically, this attribute will use a loclist to express different values at; different program locations.*. If the attribute is an integer constant, then the value is the constant. The; DWARF is ill-formed if the constant is less than or equal to 0. Otherwise, E is evaluated with a context that has a result kind of a; location description, an unspecified object, the compilation unit that; contains E, an empty initial stack, and other context elements corresponding; to the source language thread of execution upon which the user is focused,; if any. The DWARF is ill-formed if the result is not a location description; comprised of one implicit location description, that when read as the; generic type, results in a value V that is less than or equal to 0. The; result of the attribute is the value V. I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:166007,Performance,optimiz,optimization,166007,"ifferent sets of lanes than the current; active lanes. For example, some code must execute with all lanes made; temporarily active.* ``DW_AT_LLVM_active_lane`` *allows the compiler to; provide the means to determine the source language active lanes at any; program location. Typically, this attribute will use a loclist to express; different locations of the active lane mask at different program locations.*. If not present and ``DW_AT_LLVM_lanes`` is greater than 1, then the target; architecture execution mask is used. 7. A ``DW_TAG_subprogram``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_entry_point`` debugger information entry may have a; ``DW_AT_LLVM_iterations`` attribute whose value is an integer constant or a; DWARF expression E. Its value is the number of source language loop; iterations executing concurrently by the target architecture for a single; source language thread of execution. *A compiler may generate code that executes more than one iteration of a; source language loop concurrently using optimization techniques such as; software pipelining or SIMD vectorization. The number of concurrent; iterations may vary for different loop nests in the same subprogram.; Typically, this attribute will use a loclist to express different values at; different program locations.*. If the attribute is an integer constant, then the value is the constant. The; DWARF is ill-formed if the constant is less than or equal to 0. Otherwise, E is evaluated with a context that has a result kind of a; location description, an unspecified object, the compilation unit that; contains E, an empty initial stack, and other context elements corresponding; to the source language thread of execution upon which the user is focused,; if any. The DWARF is ill-formed if the result is not a location description; comprised of one implicit location description, that when read as the; generic type, results in a value V that is less than or equal to 0. The; result of the attribute is the value V. I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:166097,Performance,concurren,concurrent,166097,"LVM_active_lane`` *allows the compiler to; provide the means to determine the source language active lanes at any; program location. Typically, this attribute will use a loclist to express; different locations of the active lane mask at different program locations.*. If not present and ``DW_AT_LLVM_lanes`` is greater than 1, then the target; architecture execution mask is used. 7. A ``DW_TAG_subprogram``, ``DW_TAG_inlined_subroutine``, or; ``DW_TAG_entry_point`` debugger information entry may have a; ``DW_AT_LLVM_iterations`` attribute whose value is an integer constant or a; DWARF expression E. Its value is the number of source language loop; iterations executing concurrently by the target architecture for a single; source language thread of execution. *A compiler may generate code that executes more than one iteration of a; source language loop concurrently using optimization techniques such as; software pipelining or SIMD vectorization. The number of concurrent; iterations may vary for different loop nests in the same subprogram.; Typically, this attribute will use a loclist to express different values at; different program locations.*. If the attribute is an integer constant, then the value is the constant. The; DWARF is ill-formed if the constant is less than or equal to 0. Otherwise, E is evaluated with a context that has a result kind of a; location description, an unspecified object, the compilation unit that; contains E, an empty initial stack, and other context elements corresponding; to the source language thread of execution upon which the user is focused,; if any. The DWARF is ill-formed if the result is not a location description; comprised of one implicit location description, that when read as the; generic type, results in a value V that is less than or equal to 0. The; result of the attribute is the value V. If not present, the default value of 1 is used. A.3.4 Call Site Entries and Parameters; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. A.3.4.2 Call Sit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:174464,Performance,optimiz,optimized,174464," rules; used by the ``DW_OP_call*`` operations. .. note::. Delete the description of how the ``DW_OP_call*`` operations evaluate a; ``DW_AT_location`` attribute as that is now described in the operations. .. note::. See the discussion about the ``DW_AT_location`` attribute in the; ``DW_OP_call*`` operation. Having each attribute only have a single; purpose and single execution semantics seems desirable. It makes it easier; for the consumer that no longer have to track the context. It makes it; easier for the producer as it can rely on a single semantics for each; attribute. For that reason, limiting the ``DW_AT_location`` attribute to only; supporting evaluating the location description of an object, and using a; different attribute and encoding class for the evaluation of DWARF; expression *procedures* on the same operation expression stack seems; desirable. 2. ``DW_AT_const_value``. .. note::. Could deprecate using the ``DW_AT_const_value`` attribute for; ``DW_TAG_variable`` or ``DW_TAG_formal_parameter`` debugger information; entries that have been optimized to a constant. Instead,; ``DW_AT_location`` could be used with a DWARF expression that produces an; implicit location description now that any location description can be; used within a DWARF expression. This allows the ``DW_OP_call*`` operations; to be used to push the location description of any variable regardless of; how it is optimized. 3. ``DW_AT_LLVM_memory_space``. A ``DW_AT_memory_space`` attribute with a constant value representing a source; language specific DWARF memory space (see 2.14 ""Memory Spaces""). If omitted,; defaults to ``DW_MSPACE_none``. A.4.2 Common Block Entries; ~~~~~~~~~~~~~~~~~~~~~~~~~~. A common block entry also has a ``DW_AT_location`` attribute whose value is a; DWARF expression E that describes the location of the common block at run-time.; The result of the attribute is obtained by evaluating E with a context that has; a result kind of a location description, an unspecified obj",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:174807,Performance,optimiz,optimized,174807,"purpose and single execution semantics seems desirable. It makes it easier; for the consumer that no longer have to track the context. It makes it; easier for the producer as it can rely on a single semantics for each; attribute. For that reason, limiting the ``DW_AT_location`` attribute to only; supporting evaluating the location description of an object, and using a; different attribute and encoding class for the evaluation of DWARF; expression *procedures* on the same operation expression stack seems; desirable. 2. ``DW_AT_const_value``. .. note::. Could deprecate using the ``DW_AT_const_value`` attribute for; ``DW_TAG_variable`` or ``DW_TAG_formal_parameter`` debugger information; entries that have been optimized to a constant. Instead,; ``DW_AT_location`` could be used with a DWARF expression that produces an; implicit location description now that any location description can be; used within a DWARF expression. This allows the ``DW_OP_call*`` operations; to be used to push the location description of any variable regardless of; how it is optimized. 3. ``DW_AT_LLVM_memory_space``. A ``DW_AT_memory_space`` attribute with a constant value representing a source; language specific DWARF memory space (see 2.14 ""Memory Spaces""). If omitted,; defaults to ``DW_MSPACE_none``. A.4.2 Common Block Entries; ~~~~~~~~~~~~~~~~~~~~~~~~~~. A common block entry also has a ``DW_AT_location`` attribute whose value is a; DWARF expression E that describes the location of the common block at run-time.; The result of the attribute is obtained by evaluating E with a context that has; a result kind of a location description, an unspecified object, the compilation; unit that contains E, an empty initial stack, and other context elements; corresponding to the source language thread of execution upon which the user is; focused, if any. The result of the evaluation is the location description of the; base of the common block. See :ref:`amdgpu-dwarf-control-flow-operations` for; special evalu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:184732,Performance,load,loads,184732,"t.*. 1. The ``DW_AT_data_location`` attribute may be used with any type that; provides one or more levels of hidden indirection and/or run-time parameters; in its representation. Its value is a DWARF operation expression E which; computes the location description of the data for an object. When this; attribute is omitted, the location description of the data is the same as; the location description of the object. The result of the attribute is obtained by evaluating E with a context that; has a result kind of a location description, an object that is the location; description of the data descriptor, the compilation unit that contains E, an; empty initial stack, and other context elements corresponding to the source; language thread of execution upon which the user is focused, if any. The; result of the evaluation is the location description of the base of the; member entry. *E will typically involve an operation expression that begins with a*; ``DW_OP_push_object_address`` *operation which loads the location; description of the object which can then serve as a descriptor in subsequent; calculation.*. .. note::. Since ``DW_AT_data_member_location``, ``DW_AT_use_location``, and; ``DW_AT_vtable_elem_location`` allow both operation expressions and; location list expressions, why does ``DW_AT_data_location`` not allow; both? In all cases they apply to data objects so less likely that; optimization would cause different operation expressions for different; program location ranges. But if supporting for some then should be for; all. It seems odd this attribute is not the same as; ``DW_AT_data_member_location`` in having an initial stack with the; location description of the object since the expression has to need it. A.6 Other Debugging Information; -------------------------------. .. note::. This section provides changes to existing debugger information entry; attributes. These would be incorporated into the corresponding DWARF Version 5; chapter 6 sections. A.6.1 Accelera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:185130,Performance,optimiz,optimization,185130,"s omitted, the location description of the data is the same as; the location description of the object. The result of the attribute is obtained by evaluating E with a context that; has a result kind of a location description, an object that is the location; description of the data descriptor, the compilation unit that contains E, an; empty initial stack, and other context elements corresponding to the source; language thread of execution upon which the user is focused, if any. The; result of the evaluation is the location description of the base of the; member entry. *E will typically involve an operation expression that begins with a*; ``DW_OP_push_object_address`` *operation which loads the location; description of the object which can then serve as a descriptor in subsequent; calculation.*. .. note::. Since ``DW_AT_data_member_location``, ``DW_AT_use_location``, and; ``DW_AT_vtable_elem_location`` allow both operation expressions and; location list expressions, why does ``DW_AT_data_location`` not allow; both? In all cases they apply to data objects so less likely that; optimization would cause different operation expressions for different; program location ranges. But if supporting for some then should be for; all. It seems odd this attribute is not the same as; ``DW_AT_data_member_location`` in having an initial stack with the; location description of the object since the expression has to need it. A.6 Other Debugging Information; -------------------------------. .. note::. This section provides changes to existing debugger information entry; attributes. These would be incorporated into the corresponding DWARF Version 5; chapter 6 sections. A.6.1 Accelerated Access; ~~~~~~~~~~~~~~~~~~~~~~~~. .. _amdgpu-dwarf-lookup-by-name:. A.6.1.1 Lookup By Name; ++++++++++++++++++++++. A.6.1.1.1 Contents of the Name Index; ####################################. .. note::. The following provides changes to DWARF Version 5 section 6.1.1.1. The rule for debugger information entri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:218465,Performance,load,loader,218465,"ect file.; This type of reference (DW_FORM_ref_addr) is an offset from the; beginning of the .debug_info section of the target executable or shared; object file, or, for references within a supplementary object file, an; offset from the beginning of the local .debug_info section; it is; relocatable in a relocatable object file and frequently relocated in an; executable or shared object file. In the 32-bit DWARF format, this; offset is a 4-byte unsigned value; in the 64-bit DWARF format, it is an; 8-byte unsigned value (see; :ref:`amdgpu-dwarf-32-bit-and-64-bit-dwarf-formats`). *A debugging information entry that may be referenced by another; compilation unit using DW_FORM_ref_addr must have a global symbolic; name.*. *For a reference from one executable or shared object file to another,; the reference is resolved by the debugger to identify the executable or; shared object file and the offset into that file's* ``.debug_info``; *section in the same fashion as the run time loader, either when the; debug information is first read, or when the reference is used.*. A.7.7 DWARF Expressions; ~~~~~~~~~~~~~~~~~~~~~~~. .. note::. Rename DWARF Version 5 section 7.7 to reflect the unification of location; descriptions into DWARF expressions. A.7.7.1 Operation Expressions; +++++++++++++++++++++++++++++. .. note::. Rename DWARF Version 5 section 7.7.1 and delete section 7.7.2 to reflect the; unification of location descriptions into DWARF expressions. This augments DWARF Version 5 section 7.7.1 and Table 7.9, and adds a new; table describing vendor extension operations for ``DW_OP_LLVM_user``. A DWARF operation expression is stored in a block of contiguous bytes. The bytes; form a sequence of operations. Each operation is a 1-byte code that identifies; that operation, followed by zero or more bytes of additional data. The encoding; for the operation ``DW_OP_LLVM_user`` is described in; :ref:`amdgpu-dwarf-operation-encodings-table`, and the encoding of all; ``DW_OP_LLVM_user`` vend",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:13241,Safety,avoid,avoid,13241,"; operations which define that it causes wrap-around. Having the offset operations allows ``DW_OP_push_object_address`` to push a; location description that may be in a register, or be an implicit value. The; DWARF expression of ``DW_TAG_ptr_to_member_type`` can use the offset operations; without regard to what kind of location description was pushed. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack` has; generalized location storage to be bit indexable, ``DW_OP_LLVM_bit_offset``; generalizes DWARF to work with bit fields. This is generally not possible in; DWARF Version 5. The ``DW_OP_*piece`` operations only allow literal indices. A way to use a; computed offset of an arbitrary location description (such as a vector register); is required. The offset operations provide this ability since they can be used; to compute a location description on the stack. It could be possible to define ``DW_OP_plus``, ``DW_OP_plus_uconst``, and; ``DW_OP_minus`` to operate on location descriptions to avoid needing; ``DW_OP_LLVM_offset`` and ``DW_OP_LLVM_offset_uconst``. However, this is not; proposed since currently the arithmetic operations are defined to require values; of the same base type and produces a result with the same base type. Allowing; these operations to act on location descriptions would permit the first operand; to be a location description and the second operand to be an integral value; type, or vice versa, and return a location description. This complicates the; rules for implicit conversions between default address space memory location; descriptions and generic base type values. Currently the rules would convert; such a location description to the memory address value and then perform two's; compliment wrap around arithmetic. If the result was used as a location; description, it would be implicitly converted back to a default address space; memory location description. This is different to the overflow rules on location; descriptio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:14427,Safety,avoid,avoids,14427,"equire values; of the same base type and produces a result with the same base type. Allowing; these operations to act on location descriptions would permit the first operand; to be a location description and the second operand to be an integral value; type, or vice versa, and return a location description. This complicates the; rules for implicit conversions between default address space memory location; descriptions and generic base type values. Currently the rules would convert; such a location description to the memory address value and then perform two's; compliment wrap around arithmetic. If the result was used as a location; description, it would be implicitly converted back to a default address space; memory location description. This is different to the overflow rules on location; descriptions. To allow control, an operation that converts a memory location; description to an address integral type value would be required. Keeping a; separation of location description operations and arithmetic operations avoids; this semantic complexity. See ``DW_OP_LLVM_offset``, ``DW_OP_LLVM_offset_uconst``, and; ``DW_OP_LLVM_bit_offset`` in; :ref:`amdgpu-dwarf-general-location-description-operations`. 2.5 Generalize Creation of Undefined Location Descriptions; ----------------------------------------------------------. Current DWARF uses an empty expression to indicate an undefined location; description. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack`; allows location descriptions to be created on the stack, it is necessary to have; an explicit way to specify an undefined location description. For example, the ``DW_OP_LLVM_select_bit_piece`` (see; :ref:`amdgpu-dwarf-support-for-divergent-control-flow-of-simt-hardware`); operation takes more than one location description on the stack. Without this; ability, it is not possible to specify that a particular one of the input; location descriptions is undefined. See the ``DW_OP_LLVM_undefined`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:26163,Safety,avoid,avoid,26163,"er assigns to the variable. Another usage is to create an expression that evaluates to provide a vector of; logical PCs for active and inactive lanes in a SIMT execution model. Again the; EXEC register is used to select between active and inactive PC values. In order; to represent a vector of PC values, a way to create a composite location; description that is a vector of a single location is used. It may be possible to use existing DWARF to incrementally build the composite; location description, possibly using the DWARF operations for control flow to; create a loop. However, for the AMDGPU that would require loop iteration of 64.; A concern is that the resulting DWARF would have a significant size and would be; reasonably common as it is needed for every vector register that is spilled in a; function. AMDGPU can have up to 512 vector registers. Another concern is the; time taken to evaluate such non-trivial expressions repeatedly. To avoid these issues, a composite location description that can be created as a; masked select is proposed. In addition, an operation that creates a composite; location description that is a vector on another location description is needed.; These operations generate the composite location description using a single; DWARF operation that combines all lanes of the vector in one step. The DWARF; expression is more compact, and can be evaluated by a consumer far more; efficiently. An example that uses these operations is referenced in the; :ref:`amdgpu-dwarf-further-examples` appendix. See ``DW_OP_LLVM_select_bit_piece`` and ``DW_OP_LLVM_extend`` in; :ref:`amdgpu-dwarf-composite-location-description-operations`. 2.11 DWARF Operation to Access Call Frame Entry Registers; ---------------------------------------------------------. As described in; :ref:`amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions`,; a DWARF expression involving the set of SIMT lanes active on entry to a; subprogram is required. The SIMT active lane ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:63860,Safety,avoid,avoid,63860,"program location is used to select the call; frame information entry, and further execution of the thread occurs.*. *A DWARF expression can be used to compute a location description for an object.; A subsequent DWARF expression evaluation can be given the object location; description as the object context or initial stack context to compute a; component of the object. The final result is undefined if the object location; description becomes invalid between the two expression evaluations.*. A change of a thread's program location may not make a location description; invalid, yet may still render it as no longer meaningful. Accessing such a; location description, or using it as the object context or initial stack context; of an expression evaluation, may produce an undefined result. *For example, a location description may specify a register that no longer holds; the intended program object after a program location change. One way to avoid; such problems is to recompute location descriptions associated with threads when; their program locations change.*. .. _amdgpu-dwarf-operation-expressions:. A.2.5.4 DWARF Operation Expressions; +++++++++++++++++++++++++++++++++++. An operation expression is comprised of a stream of operations, each consisting; of an opcode followed by zero or more operands. The number of operands is; implied by the opcode. Operations represent a postfix operation on a simple stack machine. Each stack; entry can hold either a value or a location description. Operations can act on; entries on the stack, including adding entries and removing entries. If the kind; of a stack entry does not match the kind required by the operation and is not; implicitly convertible to the required kind (see; :ref:`amdgpu-dwarf-memory-location-description-operations`), then the DWARF; operation expression is ill-formed. Evaluation of an operation expression starts with an empty stack on which the; entries from the initial stack provided by the context are pushed in the o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:76181,Safety,avoid,avoids,76181,"operation; has been evaluated, the stack is therefore as it is left by the evaluation; of the operations of E. Since E is evaluated on the same stack as the call; operation, E can use, and/or remove entries already on the stack, and can; add new entries to the stack. *Values on the stack at the time of the call may be used as parameters by; the called expression and values left on the stack by the called expression; may be used as return values by prior agreement between the calling and; called expressions.*. * If D has a ``DW_AT_location`` attribute that is encoded as a ``loclist`` or; ``loclistsptr``, then the specified location list expression E is; evaluated. The evaluation of E uses the current context, except the result; kind is a location description, the compilation unit is the one that; contains D, and the initial stack is empty. The location description; result is pushed on the stack. .. note::. This rule avoids having to define how to execute a matched location list; entry operation expression on the same stack as the call when there are; multiple matches. But it allows the call to obtain the location; description for a variable or formal parameter which may use a location; list expression. An alternative is to treat the case when D has a ``DW_AT_location``; attribute that is encoded as a ``loclist`` or ``loclistsptr``, and the; specified location list expression E' matches a single location list; entry with operation expression E, the same as the ``exprloc`` case and; evaluate on the same stack. But this is not attractive as if the attribute is for a variable that; happens to end with a non-singleton stack, it will not simply put a; location description on the stack. Presumably the intent of using; ``DW_OP_call*`` on a variable or formal parameter debugger information; entry is to push just one location description on the stack. That; location description may have more than one single location description. The previous rule for ``exprloc`` also has the sa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:87577,Safety,avoid,avoids,87577,"5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value operations currently defined:. 1. ``DW_OP_regval_type``. ``DW_OP_regval_type`` has two operands. The first is an unsigned LEB128; integer that represents a register number R. The second is an unsigned; LEB128 integer DR that represents the byte offset of a debugging information; entry D relative to the beginning of the current compilation unit, that; provides the type T of the register value. The operation is equivalent to performing ``DW_OP_regx R; DW_OP_deref_type; DR``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:136214,Safety,avoid,avoid,136214,"erwise, the DWARF expression is ill-formed. *Many compilers store a single variable in sets of registers or store a; variable partially in memory and partially in registers.* ``DW_OP_piece``; *provides a way of describing where a part of a variable is located.*. *If a non-0 byte displacement is required, the* ``DW_OP_LLVM_offset``; *operation can be used to update the location description before using it as; the part location description of a* ``DW_OP_piece`` *operation.*. *The evaluation rules for the* ``DW_OP_piece`` *operation allow it to be; compatible with the DWARF Version 5 definition.*. .. note::. Since these extensions allow location descriptions to be entries on the; stack, a simpler operation to create composite location descriptions could; be defined. For example, just one operation that specifies how many parts,; and pops pairs of stack entries for the part size and location; description. Not only would this be a simpler operation and avoid the; complexities of incomplete composite location descriptions, but it may; also have a smaller encoding in practice. However, the desire for; compatibility with DWARF Version 5 is likely a stronger consideration. 2. ``DW_OP_bit_piece``. ``DW_OP_bit_piece`` has two operands. The first is an unsigned LEB128; integer that represents the part bit size S. The second is an unsigned; LEB128 integer that represents a bit displacement B. The action is the same as for ``DW_OP_piece``, except that any part created; has the bit size S, and the location description PL of any created part is; updated as if the ``DW_OP_constu B; DW_OP_LLVM_bit_offset`` operations were; applied. ``DW_OP_bit_piece`` *is used instead of* ``DW_OP_piece`` *when the piece to; be assembled is not byte-sized or is not at the start of the part location; description.*. *If a computed bit displacement is required, the* ``DW_OP_LLVM_bit_offset``; *operation can be used to update the location description before using it as; the part location description of a*",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:170781,Safety,avoid,avoid,170781,"tack, and other context elements corresponding to the source language; thread of execution upon which the user is focused, if any. The resulting; value V\ :sub:`3` is the value in L\ :sub:`2` at the time of the call made; by the call site. The result of these attributes is undefined if the current call frame is not; for the subprogram containing the ``DW_TAG_call_site_parameter`` debugger; information entry or the current program location is not for the call site; containing the ``DW_TAG_call_site_parameter`` debugger information entry in; the current call frame. *The consumer may have to virtually unwind to the call site (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) in order to evaluate these; attributes. This will ensure the source language thread of execution upon; which the user is focused corresponds to the call site needed to evaluate; the expression.*. If it is not possible to avoid the expressions of these attributes from; accessing registers or memory locations that might be clobbered by the; subprogram being called by the call site, then the associated attribute; should not be provided. *The reason for the restriction is that the parameter may need to be; accessed during the execution of the callee. The consumer may virtually; unwind from the called subprogram back to the caller and then evaluate the; attribute expressions. The call frame information (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) will not be able to restore; registers that have been clobbered, and clobbered memory will no longer have; the value at the time of the call.*. 3. Each call site parameter entry may also have a ``DW_AT_call_parameter``; attribute which contains a reference to a ``DW_TAG_formal_parameter`` entry,; ``DW_AT_type attribute`` referencing the type of the parameter or; ``DW_AT_name`` attribute describing the parameter's name. *Examples using call site entries and related attributes are found in Appendix; D.15.*. .. _amdgpu-dwarf-lexical-block-entries:. A.3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:190610,Safety,recover,recoverable,190610,"resent, then the MD5 checksum is valid. ``DW_LNCT_LLVM_is_MD5`` is always paired with the ``DW_FORM_udata`` form. *This allows a compilation unit to have a mixture of files with and without; MD5 checksums. This can happen when multiple relocatable files are linked; together.*. .. _amdgpu-dwarf-call-frame-information:. A.6.4 Call Frame Information; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. note::. This section provides changes to existing call frame information and defines; instructions added by these extensions. Additional support is added for; address spaces. Register unwind DWARF expressions are generalized to allow any; location description, including those with composite and implicit location; descriptions. These changes would be incorporated into the DWARF Version 5 section 6.4. .. _amdgpu-dwarf-structure_of-call-frame-information:. A.6.4.1 Structure of Call Frame Information; +++++++++++++++++++++++++++++++++++++++++++. The register rules are:. *undefined*; A register that has this rule has no recoverable value in the previous frame.; The previous value of this register is the undefined location description (see; :ref:`amdgpu-dwarf-undefined-location-description-operations`). *By convention, the register is not preserved by a callee.*. *same value*; This register has not been modified from the previous caller frame. If the current frame is the top frame, then the previous value of this; register is the location description L that specifies one register location; description SL. SL specifies the register location storage that corresponds to; the register with a bit offset of 0 for the current thread. If the current frame is not the top frame, then the previous value of this; register is the location description obtained using the call frame information; for the callee frame and callee program location invoked by the current caller; frame for the same register. *By convention, the register is preserved by the callee, but the callee has; not modified it.*. *offset(N)*; N i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:193298,Safety,avoid,avoids,193298," context,; except the result kind is a location description, the compilation unit is; unspecified, the object is unspecified, and an initial stack comprising the; location description of the current CFA (see; :ref:`amdgpu-dwarf-operation-expressions`). The DWARF is ill-formed if the CFA location description is not a memory byte; address location description, or if the register size does not match the size; of an address in the address space of the current CFA location description. *Since the CFA location description is required to be a memory byte address; location description, the value of val_offset(N) will also be a memory byte; address location description since it is offsetting the CFA location; description by N bytes. Furthermore, the value of val_offset(N) will be a; memory byte address in the same address space as the CFA location; description.*. .. note::. Should DWARF allow the address size to be a different size to the size of; the register? Requiring them to be the same bit size avoids any issue of; conversion as the bit contents of the register is simply interpreted as a; value of the address. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers,; and to actually reading bytes from the next register (or reads out of bounds; for the last register) for smaller registers. There are no GDB tests that; read a register out of bounds (except an illegal hand written assembly; test). *register(R)*; This register has been stored in another register numbered R. The previous value of this register is the location description obtained using; the call frame information for the current frame and current program location; for register R. The DWARF is ill-formed if the size of this register does not match the size; of register R or if there is a cyclic dependency in the call frame; information. .. note::. Should this also allow R to be larger than this register? If so is the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:10180,Security,access,access,10180,"ut a; location description on the stack. Furthermore, debugger information entry; attributes such as ``DW_AT_data_member_location``, ``DW_AT_use_location``, and; ``DW_AT_vtable_elem_location`` are defined as pushing a location description on; the expression stack before evaluating the expression. DWARF Version 5 only allows the stack to contain values and so only a single; memory address can be on the stack. This makes these operations and attributes; incapable of handling location descriptions with multiple places, or places; other than memory. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack`; allows the stack to contain location descriptions, the operations are; generalized to support location descriptions that can have multiple places. This; is backwards compatible with DWARF Version 5 and allows objects with multiple; places to be supported. For example, the expression that describes how to access; the field of an object can be evaluated with a location description that has; multiple places and will result in a location description with multiple places. With this change, the separate DWARF Version 5 sections that described DWARF; expressions and location lists are unified into a single section that describes; DWARF expressions in general. This unification is a natural consequence of, and; a necessity of, allowing location descriptions to be part of the evaluation; stack. See :ref:`amdgpu-dwarf-location-description`. 2.4 Generalize Offsetting of Location Descriptions; --------------------------------------------------. The ``DW_OP_plus`` and ``DW_OP_minus`` operations can be defined to operate on a; memory location description in the default target architecture specific address; space and a generic type value to produce an updated memory location; description. This allows them to continue to be used to offset an address. To generalize offsetting to any location description, including location; descriptions that describe when byt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:22124,Security,access,access,22124,"DW_OP_LLVM_aspace_implicit_pointer``; (:ref:`amdgpu-dwarf-implicit-location-description-operations`) operation is; added to allow the address space to be specified. Almost all uses of addresses in DWARF are limited to defining location; descriptions, or to be dereferenced to read memory. The exception is; ``DW_CFA_val_offset`` which uses the address to set the value of a register. In; order to support address spaces, the CFA DWARF expression is defined to be a; memory location description. This allows it to specify an address space which is; used to convert the offset address back to an address in that address space. See; :ref:`amdgpu-dwarf-call-frame-information`. This approach of extending memory location descriptions to support address; spaces, allows all existing DWARF Version 5 expressions to have the identical; semantics. It allows the compiler to explicitly specify the address space it is; using. For example, a compiler could choose to access private memory in a; swizzled manner when mapping a source language thread to the lane of a wavefront; in a SIMT manner. Or a compiler could choose to access it in an unswizzled; manner if mapping the same language with the wavefront being the thread. It also allows the compiler to mix the address space it uses to access private; memory. For example, for SIMT it can still spill entire vector registers in an; unswizzled manner, while using a swizzled private memory for SIMT variable; access. This approach also allows memory location descriptions for different address; spaces to be combined using the regular ``DW_OP_*piece`` operations. Location descriptions are an abstraction of storage. They give freedom to the; consumer on how to implement them. They allow the address space to encode lane; information so they can be used to read memory with only the memory location; description and no extra information. The same set of operations can operate on; locations independent of their kind of storage. The ``DW_OP_deref*`` theref",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:22282,Security,access,access,22282,"o be specified. Almost all uses of addresses in DWARF are limited to defining location; descriptions, or to be dereferenced to read memory. The exception is; ``DW_CFA_val_offset`` which uses the address to set the value of a register. In; order to support address spaces, the CFA DWARF expression is defined to be a; memory location description. This allows it to specify an address space which is; used to convert the offset address back to an address in that address space. See; :ref:`amdgpu-dwarf-call-frame-information`. This approach of extending memory location descriptions to support address; spaces, allows all existing DWARF Version 5 expressions to have the identical; semantics. It allows the compiler to explicitly specify the address space it is; using. For example, a compiler could choose to access private memory in a; swizzled manner when mapping a source language thread to the lane of a wavefront; in a SIMT manner. Or a compiler could choose to access it in an unswizzled; manner if mapping the same language with the wavefront being the thread. It also allows the compiler to mix the address space it uses to access private; memory. For example, for SIMT it can still spill entire vector registers in an; unswizzled manner, while using a swizzled private memory for SIMT variable; access. This approach also allows memory location descriptions for different address; spaces to be combined using the regular ``DW_OP_*piece`` operations. Location descriptions are an abstraction of storage. They give freedom to the; consumer on how to implement them. They allow the address space to encode lane; information so they can be used to read memory with only the memory location; description and no extra information. The same set of operations can operate on; locations independent of their kind of storage. The ``DW_OP_deref*`` therefore; can be used on any storage kind, including memory location descriptions of; different address spaces. Therefore, the ``DW_OP_xderef*`` operations",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:22447,Security,access,access,22447," dereferenced to read memory. The exception is; ``DW_CFA_val_offset`` which uses the address to set the value of a register. In; order to support address spaces, the CFA DWARF expression is defined to be a; memory location description. This allows it to specify an address space which is; used to convert the offset address back to an address in that address space. See; :ref:`amdgpu-dwarf-call-frame-information`. This approach of extending memory location descriptions to support address; spaces, allows all existing DWARF Version 5 expressions to have the identical; semantics. It allows the compiler to explicitly specify the address space it is; using. For example, a compiler could choose to access private memory in a; swizzled manner when mapping a source language thread to the lane of a wavefront; in a SIMT manner. Or a compiler could choose to access it in an unswizzled; manner if mapping the same language with the wavefront being the thread. It also allows the compiler to mix the address space it uses to access private; memory. For example, for SIMT it can still spill entire vector registers in an; unswizzled manner, while using a swizzled private memory for SIMT variable; access. This approach also allows memory location descriptions for different address; spaces to be combined using the regular ``DW_OP_*piece`` operations. Location descriptions are an abstraction of storage. They give freedom to the; consumer on how to implement them. They allow the address space to encode lane; information so they can be used to read memory with only the memory location; description and no extra information. The same set of operations can operate on; locations independent of their kind of storage. The ``DW_OP_deref*`` therefore; can be used on any storage kind, including memory location descriptions of; different address spaces. Therefore, the ``DW_OP_xderef*`` operations are; unnecessary, except to become a more compact way to encode a non-default address; space address followe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:22619,Security,access,access,22619,"r. In; order to support address spaces, the CFA DWARF expression is defined to be a; memory location description. This allows it to specify an address space which is; used to convert the offset address back to an address in that address space. See; :ref:`amdgpu-dwarf-call-frame-information`. This approach of extending memory location descriptions to support address; spaces, allows all existing DWARF Version 5 expressions to have the identical; semantics. It allows the compiler to explicitly specify the address space it is; using. For example, a compiler could choose to access private memory in a; swizzled manner when mapping a source language thread to the lane of a wavefront; in a SIMT manner. Or a compiler could choose to access it in an unswizzled; manner if mapping the same language with the wavefront being the thread. It also allows the compiler to mix the address space it uses to access private; memory. For example, for SIMT it can still spill entire vector registers in an; unswizzled manner, while using a swizzled private memory for SIMT variable; access. This approach also allows memory location descriptions for different address; spaces to be combined using the regular ``DW_OP_*piece`` operations. Location descriptions are an abstraction of storage. They give freedom to the; consumer on how to implement them. They allow the address space to encode lane; information so they can be used to read memory with only the memory location; description and no extra information. The same set of operations can operate on; locations independent of their kind of storage. The ``DW_OP_deref*`` therefore; can be used on any storage kind, including memory location descriptions of; different address spaces. Therefore, the ``DW_OP_xderef*`` operations are; unnecessary, except to become a more compact way to encode a non-default address; space address followed by dereferencing it. See; :ref:`amdgpu-dwarf-general-operations`. 2.9 Support for Vector Base Types; -------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:32099,Security,checksum,checksum,32099,"hen it contains information from; multiple vendors. Augmentation strings occur in the ``DW_AT_LLVM_augmentation``; attribute, in the lookup by name table, and in the CFI Common Information Entry; (CIE). See :ref:`amdgpu-dwarf-full-and-partial-compilation-unit-entries`,; :ref:`amdgpu-dwarf-name-index-section-header`, and; :ref:`amdgpu-dwarf-structure_of-call-frame-information`. 2.16 Support Embedding Source Text for Online Compilation; ---------------------------------------------------------. AMDGPU supports programming languages that include online compilation where the; source text may be created at runtime. For example, the OpenCL and HIP language; runtimes support online compilation. To support is, a way to embed the source; text in the debug information is provided. See :ref:`amdgpu-dwarf-line-number-information`. 2.17 Allow MD5 Checksums to be Optionally Present; -------------------------------------------------. In DWARF Version 5 the file timestamp and file size can be optional, but if the; MD5 checksum is present it must be valid for all files. This is a problem if; using link time optimization to combine compilation units where some have MD5; checksums and some do not. Therefore, sSupport to allow MD5 checksums to be; optionally present in the line table is added. See :ref:`amdgpu-dwarf-line-number-information`. 2.18 Add the HIP Programing Language; ------------------------------------. The HIP programming language [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:32252,Security,checksum,checksums,32252,"lookup by name table, and in the CFI Common Information Entry; (CIE). See :ref:`amdgpu-dwarf-full-and-partial-compilation-unit-entries`,; :ref:`amdgpu-dwarf-name-index-section-header`, and; :ref:`amdgpu-dwarf-structure_of-call-frame-information`. 2.16 Support Embedding Source Text for Online Compilation; ---------------------------------------------------------. AMDGPU supports programming languages that include online compilation where the; source text may be created at runtime. For example, the OpenCL and HIP language; runtimes support online compilation. To support is, a way to embed the source; text in the debug information is provided. See :ref:`amdgpu-dwarf-line-number-information`. 2.17 Allow MD5 Checksums to be Optionally Present; -------------------------------------------------. In DWARF Version 5 the file timestamp and file size can be optional, but if the; MD5 checksum is present it must be valid for all files. This is a problem if; using link time optimization to combine compilation units where some have MD5; checksums and some do not. Therefore, sSupport to allow MD5 checksums to be; optionally present in the line table is added. See :ref:`amdgpu-dwarf-line-number-information`. 2.18 Add the HIP Programing Language; ------------------------------------. The HIP programming language [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:32312,Security,checksum,checksums,32312,"mpilation-unit-entries`,; :ref:`amdgpu-dwarf-name-index-section-header`, and; :ref:`amdgpu-dwarf-structure_of-call-frame-information`. 2.16 Support Embedding Source Text for Online Compilation; ---------------------------------------------------------. AMDGPU supports programming languages that include online compilation where the; source text may be created at runtime. For example, the OpenCL and HIP language; runtimes support online compilation. To support is, a way to embed the source; text in the debug information is provided. See :ref:`amdgpu-dwarf-line-number-information`. 2.17 Allow MD5 Checksums to be Optionally Present; -------------------------------------------------. In DWARF Version 5 the file timestamp and file size can be optional, but if the; MD5 checksum is present it must be valid for all files. This is a problem if; using link time optimization to combine compilation units where some have MD5; checksums and some do not. Therefore, sSupport to allow MD5 checksums to be; optionally present in the line table is added. See :ref:`amdgpu-dwarf-line-number-information`. 2.18 Add the HIP Programing Language; ------------------------------------. The HIP programming language [:ref:`HIP <amdgpu-dwarf-HIP>`], which is supported; by the AMDGPU, is added. See :ref:`amdgpu-dwarf-language-names-table`. 2.19 Support for Source Language Optimizations that Result in Concurrent Iteration Execution; --------------------------------------------------------------------------------------------. A compiler can perform loop optimizations that result in the generated code; executing multiple iterations concurrently. For example, software pipelining; schedules multiple iterations in an interleaved fashion to allow the; instructions of one iteration to hide the latencies of the instructions of; another iteration. Another example is vectorization that can exploit SIMD; hardware to allow a single instruction to execute multiple iterations using; vector registers. Note that alth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:35567,Security,access,accesses,35567,"unicate how many source; language loop iterations are executing concurrently. See; ``DW_AT_LLVM_iterations`` in :ref:`amdgpu-dwarf-low-level-information`. 2.20 DWARF Operation to Create Runtime Overlay Composite Location Description; -----------------------------------------------------------------------------. It is common in SIMD vectorization for the compiler to generate code that; promotes portions of an array into vector registers. For example, if the; hardware has vector registers with 8 elements, and 8 wide SIMD instructions, the; compiler may vectorize a loop so that is executes 8 iterations concurrently for; each vectorized loop iteration. On the first iteration of the generated vectorized loop, iterations 0 to 7 of; the source language loop will be executed using SIMD instructions. Then on the; next iteration of the generated vectorized loop, iteration 8 to 15 will be; executed, and so on. If the source language loop accesses an array element based on the loop; iteration index, the compiler may read the element into a register for the; duration of that iteration. Next iteration it will read the next element into; the register, and so on. With SIMD, this generalizes to the compiler reading; array elements 0 to 7 into a vector register on the first vectorized loop; iteration, then array elements 8 to 15 on the next iteration, and so on. The DWARF location description for the array needs to express that all elements; are in memory, except the slice that has been promoted to the vector register.; The starting position of the slice is a runtime value based on the iteration; index modulo the vectorization size. This cannot be expressed by ``DW_OP_piece``; and ``DW_OP_bit_piece`` which only allow constant offsets to be expressed. Therefore, a new operator is defined that takes two location descriptions, an; offset and a size, and creates a composite that effectively uses the second; location description as an overlay of the first, positioned according to the; offs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:57944,Security,access,accessed,57944,"nd strings, and; possibly to find the base address of a subprogram’s call frame or the return; address of a subprogram. Furthermore, to meet the needs of recent computer; architectures and optimization techniques, debugging information must be able to; describe the location of an object whose location changes over the object’s; lifetime, and may reside at multiple locations simultaneously during parts of an; object's lifetime.*. Information about the location of program objects is provided by location; descriptions. Location descriptions can consist of one or more single location descriptions. A single location description specifies the location storage that holds a; program object and a position within the location storage where the program; object starts. The position within the location storage is expressed as a bit; offset relative to the start of the location storage. A location storage is a linear stream of bits that can hold values. Each; location storage has a size in bits and can be accessed using a zero-based bit; offset. The ordering of bits within a location storage uses the bit numbering; and direction conventions that are appropriate to the current language on the; target architecture. There are five kinds of location storage:. *memory location storage*; Corresponds to the target architecture memory address spaces. *register location storage*; Corresponds to the target architecture registers. *implicit location storage*; Corresponds to fixed values that can only be read. *undefined location storage*; Indicates no value is available and therefore cannot be read or written. *composite location storage*; Allows a mixture of these where some bits come from one location storage and; some from another location storage, or from disjoint parts of the same; location storage. .. note::. It may be better to add an implicit pointer location storage kind used by the; ``DW_OP_implicit_pointer`` and ``DW_OP_LLVM_aspace_implicit_pointer``; operations. It would specify",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:61630,Security,access,accessed,61630,"e. An object may have more than one location as a result of; optimization. For example, a value that is only read may be promoted from memory; to a register for some region of code, but later code may revert to reading the; value from memory as the register may be used for other purposes. For the code; region where the value is in a register, any change to the object value must be; made in both the register and the memory so both regions of code will read the; updated value.*. *A consumer of a location description with more than one single location; description can read the object's value from any of the single location; descriptions (since they all refer to location storage that has the same value),; but must write any changed value to all the single location descriptions.*. The evaluation of an expression may require context elements to create a; location description. If such a location description is accessed, the storage it; denotes is that associated with the context element values specified when the; location description was created, which may differ from the context at the time; it is accessed. *For example, creating a register location description requires the thread; context: the location storage is for the specified register of that thread.; Creating a memory location description for an address space may required a; thread and a lane context: the location storage is the memory associated with; that thread and lane.*. If any of the context elements required to create a location description change,; the location description becomes invalid and accessing it is undefined. *Examples of context that can invalidate a location description are:*. * *The thread context is required and execution causes the thread to terminate.*; * *The call frame context is required and further execution causes the call; frame to return to the calling frame.*; * *The program location is required and further execution of the thread occurs.; That could change the location list entry or",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:61822,Security,access,accessed,61822,"e. An object may have more than one location as a result of; optimization. For example, a value that is only read may be promoted from memory; to a register for some region of code, but later code may revert to reading the; value from memory as the register may be used for other purposes. For the code; region where the value is in a register, any change to the object value must be; made in both the register and the memory so both regions of code will read the; updated value.*. *A consumer of a location description with more than one single location; description can read the object's value from any of the single location; descriptions (since they all refer to location storage that has the same value),; but must write any changed value to all the single location descriptions.*. The evaluation of an expression may require context elements to create a; location description. If such a location description is accessed, the storage it; denotes is that associated with the context element values specified when the; location description was created, which may differ from the context at the time; it is accessed. *For example, creating a register location description requires the thread; context: the location storage is for the specified register of that thread.; Creating a memory location description for an address space may required a; thread and a lane context: the location storage is the memory associated with; that thread and lane.*. If any of the context elements required to create a location description change,; the location description becomes invalid and accessing it is undefined. *Examples of context that can invalidate a location description are:*. * *The thread context is required and execution causes the thread to terminate.*; * *The call frame context is required and further execution causes the call; frame to return to the calling frame.*; * *The program location is required and further execution of the thread occurs.; That could change the location list entry or",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:62291,Security,access,accessing,62291,"re than one single location; description can read the object's value from any of the single location; descriptions (since they all refer to location storage that has the same value),; but must write any changed value to all the single location descriptions.*. The evaluation of an expression may require context elements to create a; location description. If such a location description is accessed, the storage it; denotes is that associated with the context element values specified when the; location description was created, which may differ from the context at the time; it is accessed. *For example, creating a register location description requires the thread; context: the location storage is for the specified register of that thread.; Creating a memory location description for an address space may required a; thread and a lane context: the location storage is the memory associated with; that thread and lane.*. If any of the context elements required to create a location description change,; the location description becomes invalid and accessing it is undefined. *Examples of context that can invalidate a location description are:*. * *The thread context is required and execution causes the thread to terminate.*; * *The call frame context is required and further execution causes the call; frame to return to the calling frame.*; * *The program location is required and further execution of the thread occurs.; That could change the location list entry or call frame information entry that; applies.*; * *An operation uses call frame information:*. * *Any of the frames used in the virtual call frame unwinding return.*; * *The top call frame is used, the program location is used to select the call; frame information entry, and further execution of the thread occurs.*. *A DWARF expression can be used to compute a location description for an object.; A subsequent DWARF expression evaluation can be given the object location; description as the object context or initial stack co",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:68725,Security,access,accessed,68725,"###. 1. ``DW_OP_LLVM_user``. ``DW_OP_LLVM_user`` encodes a vendor extension operation. It has at least one; operand: a ULEB128 constant identifying a vendor extension operation. The; remaining operands are defined by the vendor extension. The vendor extension; opcode 0 is reserved and cannot be used by any vendor extension. *The DW_OP_user encoding space can be understood to supplement the space; defined by DW_OP_lo_user and DW_OP_hi_user that is allocated by the standard; for the same purpose.*. .. _amdgpu-dwarf-stack-operations:. A.2.5.4.1 Stack Operations; ##########################. .. note::. This section replaces DWARF Version 5 section 2.5.1.3. The following operations manipulate the DWARF stack. Operations that index the; stack assume that the top of the stack (most recently added entry) has index 0.; They allow the stack entries to be either a value or location description. If any stack entry accessed by a stack operation is an incomplete composite; location description (see; :ref:`amdgpu-dwarf-composite-location-description-operations`), then the DWARF; expression is ill-formed. .. note::. These operations now support stack entries that are values and location; descriptions. .. note::. If it is desired to also make them work with incomplete composite location; descriptions, then would need to define that the composite location storage; specified by the incomplete composite location description is also replicated; when a copy is pushed. This ensures that each copy of the incomplete composite; location description can update the composite location storage they specify; independently. 1. ``DW_OP_dup``. ``DW_OP_dup`` duplicates the stack entry at the top of the stack. 2. ``DW_OP_drop``. ``DW_OP_drop`` pops the stack entry at the top of the stack and discards it. 3. ``DW_OP_pick``. ``DW_OP_pick`` has a single unsigned 1-byte operand that represents an index; I. A copy of the stack entry with index I is pushed onto the stack. 4. ``DW_OP_over``. ``DW_OP_over`` pu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:97659,Security,access,access,97659,". The resulting value V s pushed on the stack. *Using* ``DW_OP_reg*`` *provides a more compact form for the case where the; value was in a register on entry to the subprogram.*. .. note::. It is unclear how this provides a more compact expression, as; ``DW_OP_regval_type`` could be used which is marginally larger. If the result of E is a value V, then V is pushed on the stack. Otherwise, the DWARF expression is ill-formed. *The* ``DW_OP_entry_value`` *operation is deprecated as its main usage is; provided by other means. DWARF Version 5 added the*; ``DW_TAG_call_site_parameter`` *debugger information entry for call sites; that has* ``DW_AT_call_value``\ *,* ``DW_AT_call_data_location``\ *, and*; ``DW_AT_call_data_value`` *attributes that provide DWARF expressions to; compute actual parameter values at the time of the call, and requires the; producer to ensure the expressions are valid to evaluate even when virtually; unwound. The* ``DW_OP_LLVM_call_frame_entry_reg`` *operation provides access; to registers in the virtually unwound calling frame.*. .. note::. GDB only implements ``DW_OP_entry_value`` when E is exactly; ``DW_OP_reg*`` or ``DW_OP_breg*; DW_OP_deref*``. .. _amdgpu-dwarf-location-description-operations:. A.2.5.4.4 Location Description Operations; #########################################. This section describes the operations that push location descriptions on the; stack. .. _amdgpu-dwarf-general-location-description-operations:. A.2.5.4.4.1 General Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces part of DWARF Version 5 section 2.5.1.3. 1. ``DW_OP_LLVM_offset`` *New*. ``DW_OP_LLVM_offset`` pops two stack entries. The first must be an integral; type value that represents a byte displacement B. The second must be a; location description L. It adds the value of B scaled by 8 (the byte size) to the bit offset of each; single location description SL of L, and pushes the updated L. It is an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:100602,Security,access,access,100602,"presents a bit displacement B. The second must be; a location description L. It adds the value of B to the bit offset of each single location description; SL of L, and pushes the updated L. It is an evaluation error if the updated bit offset of any SL is less than 0; or greater than or equal to the size of the location storage specified by; SL. 4. ``DW_OP_push_object_address``. ``DW_OP_push_object_address`` pushes the location description L of the; current object. *This object may correspond to an independent variable that is part of a; user presented expression that is being evaluated. The object location; description may be determined from the variable's own debugging information; entry or it may be a component of an array, structure, or class whose; address has been dynamically determined by an earlier step during user; expression evaluation.*. *This operation provides explicit functionality (especially for arrays; involving descriptors) that is analogous to the implicit push of the base; location description of a structure prior to evaluation of a*; ``DW_AT_data_member_location`` *to access a data member of a structure.*. .. note::. This operation could be removed and the object location description; specified as the initial stack as for ``DW_AT_data_member_location``. Or this operation could be used instead of needing to specify an initial; stack. The latter approach is more composable as access to the object may; be needed at any point of the expression, and passing it as the initial; stack requires the entire expression to be aware where on the stack it is.; If this were done, ``DW_AT_use_location`` would require a; ``DW_OP_push_object2_address`` operation for the second object. Or a more general way to pass an arbitrary number of arguments in and an; operation to get the Nth one such as ``DW_OP_arg N``. A vector of; arguments would then be passed in the expression context rather than an; initial stack. This could also resolve the issues with ``DW_OP_call*`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:100914,Security,access,access,100914,"may correspond to an independent variable that is part of a; user presented expression that is being evaluated. The object location; description may be determined from the variable's own debugging information; entry or it may be a component of an array, structure, or class whose; address has been dynamically determined by an earlier step during user; expression evaluation.*. *This operation provides explicit functionality (especially for arrays; involving descriptors) that is analogous to the implicit push of the base; location description of a structure prior to evaluation of a*; ``DW_AT_data_member_location`` *to access a data member of a structure.*. .. note::. This operation could be removed and the object location description; specified as the initial stack as for ``DW_AT_data_member_location``. Or this operation could be used instead of needing to specify an initial; stack. The latter approach is more composable as access to the object may; be needed at any point of the expression, and passing it as the initial; stack requires the entire expression to be aware where on the stack it is.; If this were done, ``DW_AT_use_location`` would require a; ``DW_OP_push_object2_address`` operation for the second object. Or a more general way to pass an arbitrary number of arguments in and an; operation to get the Nth one such as ``DW_OP_arg N``. A vector of; arguments would then be passed in the expression context rather than an; initial stack. This could also resolve the issues with ``DW_OP_call*`` by; allowing a specific number of arguments passed in and returned to be; specified. The ``DW_OP_call*`` operation could then always execute on a; separate stack: the number of arguments would be specified in a new call; operation and taken from the callers stack, and similarly the number of; return results specified and copied from the called stack back to the; callee stack when the called expression was complete. The only attribute that specifies a current object is; ``DW_AT_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:105015,Security,access,accessed,105015," .. note::. This section replaces parts of DWARF Version 5 section 2.5.1.1, 2.5.1.2,; 2.5.1.3, and 2.6.1.1.2. Each of the target architecture specific address spaces has a corresponding; memory location storage that denotes the linear addressable memory of that; address space. The size of each memory location storage corresponds to the range; of the addresses in the corresponding address space. *It is target architecture defined how address space location storage maps to; target architecture physical memory. For example, they may be independent; memory, or more than one location storage may alias the same physical memory; possibly at different offsets and with different interleaving. The mapping may; also be dictated by the source language address classes.*. A memory location description specifies a memory location storage. The bit; offset corresponds to a bit position within a byte of the memory. Bits accessed; using a memory location description, access the corresponding target; architecture memory starting at the bit position within the byte specified by; the bit offset. A memory location description that has a bit offset that is a multiple of 8 (the; byte size) is defined to be a byte address memory location description. It has a; memory byte address A that is equal to the bit offset divided by 8. A memory location description that does not have a bit offset that is a multiple; of 8 (the byte size) is defined to be a bit field memory location description.; It has a bit position B equal to the bit offset modulo 8, and a memory byte; address A equal to the bit offset minus B that is then divided by 8. The address space AS of a memory location description is defined to be the; address space that corresponds to the memory location storage associated with; the memory location description. A location description that is comprised of one byte address memory location; description SL is defined to be a memory byte address location description. It; has a byte address equa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:105062,Security,access,access,105062," .. note::. This section replaces parts of DWARF Version 5 section 2.5.1.1, 2.5.1.2,; 2.5.1.3, and 2.6.1.1.2. Each of the target architecture specific address spaces has a corresponding; memory location storage that denotes the linear addressable memory of that; address space. The size of each memory location storage corresponds to the range; of the addresses in the corresponding address space. *It is target architecture defined how address space location storage maps to; target architecture physical memory. For example, they may be independent; memory, or more than one location storage may alias the same physical memory; possibly at different offsets and with different interleaving. The mapping may; also be dictated by the source language address classes.*. A memory location description specifies a memory location storage. The bit; offset corresponds to a bit position within a byte of the memory. Bits accessed; using a memory location description, access the corresponding target; architecture memory starting at the bit position within the byte specified by; the bit offset. A memory location description that has a bit offset that is a multiple of 8 (the; byte size) is defined to be a byte address memory location description. It has a; memory byte address A that is equal to the bit offset divided by 8. A memory location description that does not have a bit offset that is a multiple; of 8 (the byte size) is defined to be a bit field memory location description.; It has a bit position B equal to the bit offset modulo 8, and a memory byte; address A equal to the bit offset minus B that is then divided by 8. The address space AS of a memory location description is defined to be the; address space that corresponds to the memory location storage associated with; the memory location description. A location description that is comprised of one byte address memory location; description SL is defined to be a memory byte address location description. It; has a byte address equa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:111442,Security,access,accessed,111442,"size S is defined as the address bit size of the target; architecture specific address space that corresponds to AS. A is adjusted to S bits by zero extending if necessary, and then treating; the least significant S bits as an unsigned value A'. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage LS that corresponds; to AS with a bit offset equal to A' scaled by 8 (the byte size). If AS is an address space that is specific to context elements, then LS; corresponds to the location storage associated with the current context. *For example, if AS is for per thread storage then LS is the location; storage for the current thread. For languages that are implemented using a; SIMT execution model, then if AS is for per lane storage then LS is the; location storage for the current lane of the current thread. Therefore, if L; is accessed by an operation, the location storage selected when the location; description was created is accessed, and not the location storage associated; with the current context of the access operation.*. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. See :ref:`amdgpu-dwarf-implicit-location-description-operations` for special; rules concerning implicit pointer values produced by dereferencing implicit; location descriptions created by the ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer`` operations. 4. ``DW_OP_form_tls_address``. ``DW_OP_form_tls_address`` pops one stack entry that must be an integral; type value and treats it as a thread-local storage address TA. It pushes a location description L with one memory location description SL; on the stack. SL is the target architecture specific memory location; description that corresponds to the thread-local storage address TA. The meaning of the thread-local storage address TA is defined by the; run-time environme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:111544,Security,access,accessed,111544,"size S is defined as the address bit size of the target; architecture specific address space that corresponds to AS. A is adjusted to S bits by zero extending if necessary, and then treating; the least significant S bits as an unsigned value A'. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage LS that corresponds; to AS with a bit offset equal to A' scaled by 8 (the byte size). If AS is an address space that is specific to context elements, then LS; corresponds to the location storage associated with the current context. *For example, if AS is for per thread storage then LS is the location; storage for the current thread. For languages that are implemented using a; SIMT execution model, then if AS is for per lane storage then LS is the; location storage for the current lane of the current thread. Therefore, if L; is accessed by an operation, the location storage selected when the location; description was created is accessed, and not the location storage associated; with the current context of the access operation.*. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. See :ref:`amdgpu-dwarf-implicit-location-description-operations` for special; rules concerning implicit pointer values produced by dereferencing implicit; location descriptions created by the ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer`` operations. 4. ``DW_OP_form_tls_address``. ``DW_OP_form_tls_address`` pops one stack entry that must be an integral; type value and treats it as a thread-local storage address TA. It pushes a location description L with one memory location description SL; on the stack. SL is the target architecture specific memory location; description that corresponds to the thread-local storage address TA. The meaning of the thread-local storage address TA is defined by the; run-time environme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:111627,Security,access,access,111627,"size S is defined as the address bit size of the target; architecture specific address space that corresponds to AS. A is adjusted to S bits by zero extending if necessary, and then treating; the least significant S bits as an unsigned value A'. It pushes a location description L with one memory location description SL; on the stack. SL specifies the memory location storage LS that corresponds; to AS with a bit offset equal to A' scaled by 8 (the byte size). If AS is an address space that is specific to context elements, then LS; corresponds to the location storage associated with the current context. *For example, if AS is for per thread storage then LS is the location; storage for the current thread. For languages that are implemented using a; SIMT execution model, then if AS is for per lane storage then LS is the; location storage for the current lane of the current thread. Therefore, if L; is accessed by an operation, the location storage selected when the location; description was created is accessed, and not the location storage associated; with the current context of the access operation.*. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. See :ref:`amdgpu-dwarf-implicit-location-description-operations` for special; rules concerning implicit pointer values produced by dereferencing implicit; location descriptions created by the ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer`` operations. 4. ``DW_OP_form_tls_address``. ``DW_OP_form_tls_address`` pops one stack entry that must be an integral; type value and treats it as a thread-local storage address TA. It pushes a location description L with one memory location description SL; on the stack. SL is the target architecture specific memory location; description that corresponds to the thread-local storage address TA. The meaning of the thread-local storage address TA is defined by the; run-time environme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:113262,Security,access,accessed,113262," L with one memory location description SL; on the stack. SL is the target architecture specific memory location; description that corresponds to the thread-local storage address TA. The meaning of the thread-local storage address TA is defined by the; run-time environment. If the run-time environment supports multiple; thread-local storage blocks for a single thread, then the block; corresponding to the executable or shared library containing this DWARF; expression is used. *Some implementations of C, C++, Fortran, and other languages, support a; thread-local storage class. Variables with this storage class have distinct; values and addresses in distinct threads, much as automatic variables have; distinct values and addresses in each subprogram invocation. Typically,; there is a single block of storage containing all thread-local variables; declared in the main executable, and a separate block for the variables; declared in each shared library. Each thread-local variable can then be; accessed in its block using an identifier. This identifier is typically a; byte offset into the block and pushed onto the DWARF stack by one of the*; ``DW_OP_const*`` *operations prior to the* ``DW_OP_form_tls_address``; *operation. Computing the address of the appropriate block can be complex; (in some cases, the compiler emits a function call to do it), and difficult; to describe using ordinary DWARF location descriptions. Instead of forcing; complex thread-local storage calculations into the DWARF expressions, the*; ``DW_OP_form_tls_address`` *allows the consumer to perform the computation; based on the target architecture specific run-time environment.*. 5. ``DW_OP_call_frame_cfa``. ``DW_OP_call_frame_cfa`` pushes the location description L of the Canonical; Frame Address (CFA) of the current subprogram, obtained from the call frame; information on the stack. See :ref:`amdgpu-dwarf-call-frame-information`. *Although the value of the* ``DW_AT_frame_base`` *attribute of the debugger; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:118222,Security,access,accessed,118222,"sed as; the address space identifier. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. .. note::. Could also consider adding ``DW_OP_LLVM_aspace_breg0,; DW_OP_LLVM_aspace_breg1, ..., DW_OP_LLVM_aspace_bref31`` which would save; encoding size. .. _amdgpu-dwarf-register-location-description-operations:. A.2.5.4.4.4 Register Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.3. There is a register location storage that corresponds to each of the target; architecture registers. The size of each register location storage corresponds; to the size of the corresponding target architecture register. A register location description specifies a register location storage. The bit; offset corresponds to a bit position within the register. Bits accessed using a; register location description access the corresponding target architecture; register starting at the specified bit offset. 1. ``DW_OP_reg0``, ``DW_OP_reg1``, ..., ``DW_OP_reg31``. ``DW_OP_reg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The target architecture register; number R corresponds to the N in the operation name. The operation is equivalent to performing ``DW_OP_regx R``. 2. ``DW_OP_regx``. ``DW_OP_regx`` has a single unsigned LEB128 integer operand that represents; a target architecture register number R. If the current call frame is the top call frame, it pushes a location; description L that specifies one register location description SL on the; stack. SL specifies the register location storage that corresponds to R with; a bit offset of 0 for the current thread. If the current call frame is not the top call frame, call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`) is used to determine the; location description that holds the register for the curre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:118270,Security,access,access,118270,"sed as; the address space identifier. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. .. note::. Could also consider adding ``DW_OP_LLVM_aspace_breg0,; DW_OP_LLVM_aspace_breg1, ..., DW_OP_LLVM_aspace_bref31`` which would save; encoding size. .. _amdgpu-dwarf-register-location-description-operations:. A.2.5.4.4.4 Register Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.3. There is a register location storage that corresponds to each of the target; architecture registers. The size of each register location storage corresponds; to the size of the corresponding target architecture register. A register location description specifies a register location storage. The bit; offset corresponds to a bit position within the register. Bits accessed using a; register location description access the corresponding target architecture; register starting at the specified bit offset. 1. ``DW_OP_reg0``, ``DW_OP_reg1``, ..., ``DW_OP_reg31``. ``DW_OP_reg<N>`` operations encode the numbers of up to 32 registers,; numbered from 0 through 31, inclusive. The target architecture register; number R corresponds to the N in the operation name. The operation is equivalent to performing ``DW_OP_regx R``. 2. ``DW_OP_regx``. ``DW_OP_regx`` has a single unsigned LEB128 integer operand that represents; a target architecture register number R. If the current call frame is the top call frame, it pushes a location; description L that specifies one register location description SL on the; stack. SL specifies the register location storage that corresponds to R with; a bit offset of 0 for the current thread. If the current call frame is not the top call frame, call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`) is used to determine the; location description that holds the register for the curre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:119636,Security,access,accessed,119636,"in the operation name. The operation is equivalent to performing ``DW_OP_regx R``. 2. ``DW_OP_regx``. ``DW_OP_regx`` has a single unsigned LEB128 integer operand that represents; a target architecture register number R. If the current call frame is the top call frame, it pushes a location; description L that specifies one register location description SL on the; stack. SL specifies the register location storage that corresponds to R with; a bit offset of 0 for the current thread. If the current call frame is not the top call frame, call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`) is used to determine the; location description that holds the register for the current call frame and; current program location of the current thread. The resulting location; description L is pushed. *Note that if call frame information is used, the resulting location; description may be register, memory, or undefined.*. *An implementation may evaluate the call frame information immediately, or; may defer evaluation until L is accessed by an operation. If evaluation is; deferred, R and the current context can be recorded in L. When accessed, the; recorded context is used to evaluate the call frame information, not the; current context of the access operation.*. *These operations obtain a register location. To fetch the contents of a; register, it is necessary to use* ``DW_OP_regval_type``\ *, use one of the*; ``DW_OP_breg*`` *register-based addressing operations, or use* ``DW_OP_deref*``; *on a register location description.*. .. _amdgpu-dwarf-implicit-location-description-operations:. A.2.5.4.4.5 Implicit Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.4. Implicit location storage represents a piece or all of an object which has no; actual location in the program but whose contents are nonetheless known, either; as a constant or can be computed from other location",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:119743,Security,access,accessed,119743,"number R. If the current call frame is the top call frame, it pushes a location; description L that specifies one register location description SL on the; stack. SL specifies the register location storage that corresponds to R with; a bit offset of 0 for the current thread. If the current call frame is not the top call frame, call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`) is used to determine the; location description that holds the register for the current call frame and; current program location of the current thread. The resulting location; description L is pushed. *Note that if call frame information is used, the resulting location; description may be register, memory, or undefined.*. *An implementation may evaluate the call frame information immediately, or; may defer evaluation until L is accessed by an operation. If evaluation is; deferred, R and the current context can be recorded in L. When accessed, the; recorded context is used to evaluate the call frame information, not the; current context of the access operation.*. *These operations obtain a register location. To fetch the contents of a; register, it is necessary to use* ``DW_OP_regval_type``\ *, use one of the*; ``DW_OP_breg*`` *register-based addressing operations, or use* ``DW_OP_deref*``; *on a register location description.*. .. _amdgpu-dwarf-implicit-location-description-operations:. A.2.5.4.4.5 Implicit Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.4. Implicit location storage represents a piece or all of an object which has no; actual location in the program but whose contents are nonetheless known, either; as a constant or can be computed from other locations and values in the program. An implicit location description specifies an implicit location storage. The bit; offset corresponds to a bit position within the implicit location storage. Bits; accessed using an i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:119855,Security,access,access,119855,"number R. If the current call frame is the top call frame, it pushes a location; description L that specifies one register location description SL on the; stack. SL specifies the register location storage that corresponds to R with; a bit offset of 0 for the current thread. If the current call frame is not the top call frame, call frame information; (see :ref:`amdgpu-dwarf-call-frame-information`) is used to determine the; location description that holds the register for the current call frame and; current program location of the current thread. The resulting location; description L is pushed. *Note that if call frame information is used, the resulting location; description may be register, memory, or undefined.*. *An implementation may evaluate the call frame information immediately, or; may defer evaluation until L is accessed by an operation. If evaluation is; deferred, R and the current context can be recorded in L. When accessed, the; recorded context is used to evaluate the call frame information, not the; current context of the access operation.*. *These operations obtain a register location. To fetch the contents of a; register, it is necessary to use* ``DW_OP_regval_type``\ *, use one of the*; ``DW_OP_breg*`` *register-based addressing operations, or use* ``DW_OP_deref*``; *on a register location description.*. .. _amdgpu-dwarf-implicit-location-description-operations:. A.2.5.4.4.5 Implicit Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.4. Implicit location storage represents a piece or all of an object which has no; actual location in the program but whose contents are nonetheless known, either; as a constant or can be computed from other locations and values in the program. An implicit location description specifies an implicit location storage. The bit; offset corresponds to a bit position within the implicit location storage. Bits; accessed using an i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:120786,Security,access,accessed,120786,"xt of the access operation.*. *These operations obtain a register location. To fetch the contents of a; register, it is necessary to use* ``DW_OP_regval_type``\ *, use one of the*; ``DW_OP_breg*`` *register-based addressing operations, or use* ``DW_OP_deref*``; *on a register location description.*. .. _amdgpu-dwarf-implicit-location-description-operations:. A.2.5.4.4.5 Implicit Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.4. Implicit location storage represents a piece or all of an object which has no; actual location in the program but whose contents are nonetheless known, either; as a constant or can be computed from other locations and values in the program. An implicit location description specifies an implicit location storage. The bit; offset corresponds to a bit position within the implicit location storage. Bits; accessed using an implicit location description, access the corresponding; implicit storage value starting at the bit offset. 1. ``DW_OP_implicit_value``. ``DW_OP_implicit_value`` has two operands. The first is an unsigned LEB128; integer that represents a byte size S. The second is a block of bytes with a; length equal to S treated as a literal value V. An implicit location storage LS is created with the literal value V and a; size of S. It pushes location description L with one implicit location description SL; on the stack. SL specifies LS with a bit offset of 0. 2. ``DW_OP_stack_value``. ``DW_OP_stack_value`` pops one stack entry that must be a value V. An implicit location storage LS is created with the literal value V using; the size, encoding, and endianity specified by V's base type. It pushes a location description L with one implicit location description SL; on the stack. SL specifies LS with a bit offset of 0. *The* ``DW_OP_stack_value`` *operation specifies that the object does not; exist in memory, but its value is nonetheless kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:120835,Security,access,access,120835,"xt of the access operation.*. *These operations obtain a register location. To fetch the contents of a; register, it is necessary to use* ``DW_OP_regval_type``\ *, use one of the*; ``DW_OP_breg*`` *register-based addressing operations, or use* ``DW_OP_deref*``; *on a register location description.*. .. _amdgpu-dwarf-implicit-location-description-operations:. A.2.5.4.4.5 Implicit Location Description Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces DWARF Version 5 section 2.6.1.1.4. Implicit location storage represents a piece or all of an object which has no; actual location in the program but whose contents are nonetheless known, either; as a constant or can be computed from other locations and values in the program. An implicit location description specifies an implicit location storage. The bit; offset corresponds to a bit position within the implicit location storage. Bits; accessed using an implicit location description, access the corresponding; implicit storage value starting at the bit offset. 1. ``DW_OP_implicit_value``. ``DW_OP_implicit_value`` has two operands. The first is an unsigned LEB128; integer that represents a byte size S. The second is a block of bytes with a; length equal to S treated as a literal value V. An implicit location storage LS is created with the literal value V and a; size of S. It pushes location description L with one implicit location description SL; on the stack. SL specifies LS with a bit offset of 0. 2. ``DW_OP_stack_value``. ``DW_OP_stack_value`` pops one stack entry that must be a value V. An implicit location storage LS is created with the literal value V using; the size, encoding, and endianity specified by V's base type. It pushes a location description L with one implicit location description SL; on the stack. SL specifies LS with a bit offset of 0. *The* ``DW_OP_stack_value`` *operation specifies that the object does not; exist in memory, but its value is nonetheless kno",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:123115,Security,access,access,123115,"erencing implicit location; descriptions created by the ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer`` operations. Note: Since location descriptions are allowed on the stack, the; ``DW_OP_stack_value`` operation no longer terminates the DWARF operation; expression execution as in DWARF Version 5. 3. ``DW_OP_implicit_pointer``. *An optimizing compiler may eliminate a pointer, while still retaining the; value that the pointer addressed.* ``DW_OP_implicit_pointer`` *allows a; producer to describe this value.*. ``DW_OP_implicit_pointer`` *specifies an object is a pointer to the target; architecture default address space that cannot be represented as a real; pointer, even though the value it would point to can be described. In this; form, the location description specifies a debugging information entry that; represents the actual location description of the object to which the; pointer would point. Thus, a consumer of the debug information would be able; to access the dereferenced pointer, even when it cannot access the pointer; itself.*. ``DW_OP_implicit_pointer`` has two operands. The first operand is a 4-byte; unsigned value in the 32-bit DWARF format, or an 8-byte unsigned value in; the 64-bit DWARF format, that represents the byte offset DR of a debugging; information entry D relative to the beginning of the ``.debug_info`` section; that contains the current compilation unit. The second operand is a signed; LEB128 integer that represents a byte displacement B. *Note that D might not be in the current compilation unit.*. *The first operand interpretation is exactly like that for*; ``DW_FORM_ref_addr``\ *.*. The address space identifier AS is defined as the one corresponding to the; target architecture specific default address space. The address size S is defined as the address bit size of the target; architecture specific address space corresponding to AS. An implicit location storage LS is created with the debugging information; entry D, addre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:123168,Security,access,access,123168,"erencing implicit location; descriptions created by the ``DW_OP_implicit_pointer`` and; ``DW_OP_LLVM_aspace_implicit_pointer`` operations. Note: Since location descriptions are allowed on the stack, the; ``DW_OP_stack_value`` operation no longer terminates the DWARF operation; expression execution as in DWARF Version 5. 3. ``DW_OP_implicit_pointer``. *An optimizing compiler may eliminate a pointer, while still retaining the; value that the pointer addressed.* ``DW_OP_implicit_pointer`` *allows a; producer to describe this value.*. ``DW_OP_implicit_pointer`` *specifies an object is a pointer to the target; architecture default address space that cannot be represented as a real; pointer, even though the value it would point to can be described. In this; form, the location description specifies a debugging information entry that; represents the actual location description of the object to which the; pointer would point. Thus, a consumer of the debug information would be able; to access the dereferenced pointer, even when it cannot access the pointer; itself.*. ``DW_OP_implicit_pointer`` has two operands. The first operand is a 4-byte; unsigned value in the 32-bit DWARF format, or an 8-byte unsigned value in; the 64-bit DWARF format, that represents the byte offset DR of a debugging; information entry D relative to the beginning of the ``.debug_info`` section; that contains the current compilation unit. The second operand is a signed; LEB128 integer that represents a byte displacement B. *Note that D might not be in the current compilation unit.*. *The first operand interpretation is exactly like that for*; ``DW_FORM_ref_addr``\ *.*. The address space identifier AS is defined as the one corresponding to the; target architecture specific default address space. The address size S is defined as the address bit size of the target; architecture specific address space corresponding to AS. An implicit location storage LS is created with the debugging information; entry D, addre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:126135,Security,access,accessing,126135,"ebugging information entry of; D, and a base type of T. If AS is the target architecture default address; space, then T is the generic type. Otherwise, T is a target architecture; specific integral type with a bit size equal to S. If IPV is either implicitly converted to a location description (only done; if AS is the target architecture default address space) or used by; ``DW_OP_LLVM_form_aspace_address`` (only done if the address space popped by; ``DW_OP_LLVM_form_aspace_address`` is AS), then the resulting location; description RL is:. * If D has a ``DW_AT_location`` attribute, the DWARF expression E from the; ``DW_AT_location`` attribute is evaluated with the current context, except; that the result kind is a location description, the compilation unit is; the one that contains D, the object is unspecified, and the initial stack; is empty. RL is the expression result. *Note that E is evaluated with the context of the expression accessing; IPV, and not the context of the expression that contained the*; ``DW_OP_implicit_pointer`` *or* ``DW_OP_LLVM_aspace_implicit_pointer``; *operation that created L.*. * If D has a ``DW_AT_const_value`` attribute, then an implicit location; storage RLS is created from the ``DW_AT_const_value`` attribute's value; with a size matching the size of the ``DW_AT_const_value`` attribute's; value. RL comprises one implicit location description SRL. SRL specifies; RLS with a bit offset of 0. .. note::. If using ``DW_AT_const_value`` for variables and formal parameters is; deprecated and instead ``DW_AT_location`` is used with an implicit; location description, then this rule would not be required. * Otherwise, it is an evaluation error. The bit offset of RL is updated as if the ``DW_OP_LLVM_offset_uconst B``; operation was applied. If a ``DW_OP_stack_value`` operation pops a value that is the same as IPV,; then it pushes a location description that is the same as L. It is an evaluation error if LS or IPV is accessed in any other manner. *The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:127157,Security,access,accessed,127157," and not the context of the expression that contained the*; ``DW_OP_implicit_pointer`` *or* ``DW_OP_LLVM_aspace_implicit_pointer``; *operation that created L.*. * If D has a ``DW_AT_const_value`` attribute, then an implicit location; storage RLS is created from the ``DW_AT_const_value`` attribute's value; with a size matching the size of the ``DW_AT_const_value`` attribute's; value. RL comprises one implicit location description SRL. SRL specifies; RLS with a bit offset of 0. .. note::. If using ``DW_AT_const_value`` for variables and formal parameters is; deprecated and instead ``DW_AT_location`` is used with an implicit; location description, then this rule would not be required. * Otherwise, it is an evaluation error. The bit offset of RL is updated as if the ``DW_OP_LLVM_offset_uconst B``; operation was applied. If a ``DW_OP_stack_value`` operation pops a value that is the same as IPV,; then it pushes a location description that is the same as L. It is an evaluation error if LS or IPV is accessed in any other manner. *The restrictions on how an implicit pointer location description created; by* ``DW_OP_implicit_pointer`` *and* ``DW_OP_LLVM_aspace_implicit_pointer``; *can be used are to simplify the DWARF consumer. Similarly, for an implicit; pointer value created by* ``DW_OP_deref*`` *and* ``DW_OP_stack_value``\ *.*. 4. ``DW_OP_LLVM_aspace_implicit_pointer`` *New*. ``DW_OP_LLVM_aspace_implicit_pointer`` has two operands that are the same as; for ``DW_OP_implicit_pointer``. It pops one stack entry that must be an integral type value that represents; a target architecture specific address space identifier AS. The location description L that is pushed on the stack is the same as for; ``DW_OP_implicit_pointer``, except that the address space identifier used is; AS. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. .. note::. This definition of ``DW_OP_LLVM_aspace_implicit_point",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:148377,Security,access,access,148377,"ated* ``DW_AT_loclists_base`` *attribute are new in DWARF; Version 5. Together they eliminate most, or all of the code object relocations; previously needed for location list expressions.*. .. note::. The rest of this section is the same as DWARF Version 5 section 2.6.2. .. _amdgpu-dwarf-address-spaces:. A.2.13 Address Spaces; ~~~~~~~~~~~~~~~~~~~~~. .. note::. This is a new section after DWARF Version 5 section 2.12 Segmented Addresses. DWARF address spaces correspond to target architecture specific linear; addressable memory areas. They are used in DWARF expression location; descriptions to describe in which target architecture specific memory area data; resides. *Target architecture specific DWARF address spaces may correspond to hardware; supported facilities such as memory utilizing base address registers, scratchpad; memory, and memory with special interleaving. The size of addresses in these; address spaces may vary. Their access and allocation may be hardware managed; with each thread or group of threads having access to independent storage. For; these reasons they may have properties that do not allow them to be viewed as; part of the unified global virtual address space accessible by all threads.*. *It is target architecture specific whether multiple DWARF address spaces are; supported and how source language memory spaces map to target architecture; specific DWARF address spaces. A target architecture may map multiple source; language memory spaces to the same target architecture specific DWARF address; class. Optimization may determine that variable lifetime and access pattern; allows them to be allocated in faster scratchpad memory represented by a; different DWARF address space than the default for the source language memory; space.*. Although DWARF address space identifiers are target architecture specific,; ``DW_ASPACE_LLVM_none`` is a common address space supported by all target; architectures, and defined as the target architecture default address s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:148468,Security,access,access,148468,"ated* ``DW_AT_loclists_base`` *attribute are new in DWARF; Version 5. Together they eliminate most, or all of the code object relocations; previously needed for location list expressions.*. .. note::. The rest of this section is the same as DWARF Version 5 section 2.6.2. .. _amdgpu-dwarf-address-spaces:. A.2.13 Address Spaces; ~~~~~~~~~~~~~~~~~~~~~. .. note::. This is a new section after DWARF Version 5 section 2.12 Segmented Addresses. DWARF address spaces correspond to target architecture specific linear; addressable memory areas. They are used in DWARF expression location; descriptions to describe in which target architecture specific memory area data; resides. *Target architecture specific DWARF address spaces may correspond to hardware; supported facilities such as memory utilizing base address registers, scratchpad; memory, and memory with special interleaving. The size of addresses in these; address spaces may vary. Their access and allocation may be hardware managed; with each thread or group of threads having access to independent storage. For; these reasons they may have properties that do not allow them to be viewed as; part of the unified global virtual address space accessible by all threads.*. *It is target architecture specific whether multiple DWARF address spaces are; supported and how source language memory spaces map to target architecture; specific DWARF address spaces. A target architecture may map multiple source; language memory spaces to the same target architecture specific DWARF address; class. Optimization may determine that variable lifetime and access pattern; allows them to be allocated in faster scratchpad memory represented by a; different DWARF address space than the default for the source language memory; space.*. Although DWARF address space identifiers are target architecture specific,; ``DW_ASPACE_LLVM_none`` is a common address space supported by all target; architectures, and defined as the target architecture default address s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:148632,Security,access,accessible,148632,"ously needed for location list expressions.*. .. note::. The rest of this section is the same as DWARF Version 5 section 2.6.2. .. _amdgpu-dwarf-address-spaces:. A.2.13 Address Spaces; ~~~~~~~~~~~~~~~~~~~~~. .. note::. This is a new section after DWARF Version 5 section 2.12 Segmented Addresses. DWARF address spaces correspond to target architecture specific linear; addressable memory areas. They are used in DWARF expression location; descriptions to describe in which target architecture specific memory area data; resides. *Target architecture specific DWARF address spaces may correspond to hardware; supported facilities such as memory utilizing base address registers, scratchpad; memory, and memory with special interleaving. The size of addresses in these; address spaces may vary. Their access and allocation may be hardware managed; with each thread or group of threads having access to independent storage. For; these reasons they may have properties that do not allow them to be viewed as; part of the unified global virtual address space accessible by all threads.*. *It is target architecture specific whether multiple DWARF address spaces are; supported and how source language memory spaces map to target architecture; specific DWARF address spaces. A target architecture may map multiple source; language memory spaces to the same target architecture specific DWARF address; class. Optimization may determine that variable lifetime and access pattern; allows them to be allocated in faster scratchpad memory represented by a; different DWARF address space than the default for the source language memory; space.*. Although DWARF address space identifiers are target architecture specific,; ``DW_ASPACE_LLVM_none`` is a common address space supported by all target; architectures, and defined as the target architecture default address space. DWARF address space identifiers are used by:. * The ``DW_AT_LLVM_address_space`` attribute. * The DWARF expression operations: ``DW_OP_asp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:149034,Security,access,access,149034,"ta; resides. *Target architecture specific DWARF address spaces may correspond to hardware; supported facilities such as memory utilizing base address registers, scratchpad; memory, and memory with special interleaving. The size of addresses in these; address spaces may vary. Their access and allocation may be hardware managed; with each thread or group of threads having access to independent storage. For; these reasons they may have properties that do not allow them to be viewed as; part of the unified global virtual address space accessible by all threads.*. *It is target architecture specific whether multiple DWARF address spaces are; supported and how source language memory spaces map to target architecture; specific DWARF address spaces. A target architecture may map multiple source; language memory spaces to the same target architecture specific DWARF address; class. Optimization may determine that variable lifetime and access pattern; allows them to be allocated in faster scratchpad memory represented by a; different DWARF address space than the default for the source language memory; space.*. Although DWARF address space identifiers are target architecture specific,; ``DW_ASPACE_LLVM_none`` is a common address space supported by all target; architectures, and defined as the target architecture default address space. DWARF address space identifiers are used by:. * The ``DW_AT_LLVM_address_space`` attribute. * The DWARF expression operations: ``DW_OP_aspace_bregx``,; ``DW_OP_form_aspace_address``, ``DW_OP_aspace_implicit_pointer``, and; ``DW_OP_xderef*``. * The CFI instructions: ``DW_CFA_def_aspace_cfa`` and; ``DW_CFA_def_aspace_cfa_sf``. .. note::. Currently, DWARF defines address class values as being target architecture; specific, and defines a DW_AT_address_class attribute. With the removal of; DW_AT_segment in DWARF 6, it is unclear how the address class is intended to; be used as the term is not used elsewhere. Should these be replaced by this; proposal'",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:152955,Security,expose,expose,152955,"group local shared; ``DW_MSPACE_LLVM_private`` thread private; ``DW_MSPACE_LLVM_lo_user``; ``DW_MSPACE_LLVM_hi_user``; =========================== ============ ============== ============== ==============. .. note::. The approach presented in; :ref:`amdgpu-dwarf-source-language-memory-spaces-table` is to define the; default ``DW_MSPACE_LLVM_none`` to be the generic address class and not the; global address class. This matches how CLANG and LLVM have added support for; CUDA-like languages on top of existing C++ language support. This allows all; addresses to be generic by default which matches CUDA-like languages. An alternative approach is to define ``DW_MSPACE_LLVM_none`` as being the; global memory space and then change ``DW_MSPACE_LLVM_global`` to; ``DW_MSPACE_LLVM_generic``. This would match the reality that languages that; do not support multiple memory spaces only have one default global memory; space. Generally, in these languages if they expose that the target; architecture supports multiple memory spaces, the default one is still the; global memory space. Then a language that does support multiple memory spaces; has to explicitly indicate which pointers have the added ability to reference; more than the global memory space. However, compilers generating DWARF for; CUDA-like languages would then have to define every CUDA-like language pointer; type or reference type with a ``DW_AT_LLVM_memory_space`` attribute of; ``DW_MSPACE_LLVM_generic`` to match the language semantics. A.3 Program Scope Entries; -------------------------. .. note::. This section provides changes to existing debugger information entry; attributes. These would be incorporated into the corresponding DWARF Version 5; chapter 3 sections. A.3.1 Unit Entries; ~~~~~~~~~~~~~~~~~~. .. _amdgpu-dwarf-full-and-partial-compilation-unit-entries:. A.3.1.1 Full and Partial Compilation Unit Entries; +++++++++++++++++++++++++++++++++++++++++++++++++. .. note::. This augments DWARF Version 5 section 3.1.1 an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:170829,Security,access,accessing,170829,"tack, and other context elements corresponding to the source language; thread of execution upon which the user is focused, if any. The resulting; value V\ :sub:`3` is the value in L\ :sub:`2` at the time of the call made; by the call site. The result of these attributes is undefined if the current call frame is not; for the subprogram containing the ``DW_TAG_call_site_parameter`` debugger; information entry or the current program location is not for the call site; containing the ``DW_TAG_call_site_parameter`` debugger information entry in; the current call frame. *The consumer may have to virtually unwind to the call site (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) in order to evaluate these; attributes. This will ensure the source language thread of execution upon; which the user is focused corresponds to the call site needed to evaluate; the expression.*. If it is not possible to avoid the expressions of these attributes from; accessing registers or memory locations that might be clobbered by the; subprogram being called by the call site, then the associated attribute; should not be provided. *The reason for the restriction is that the parameter may need to be; accessed during the execution of the callee. The consumer may virtually; unwind from the called subprogram back to the caller and then evaluate the; attribute expressions. The call frame information (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) will not be able to restore; registers that have been clobbered, and clobbered memory will no longer have; the value at the time of the call.*. 3. Each call site parameter entry may also have a ``DW_AT_call_parameter``; attribute which contains a reference to a ``DW_TAG_formal_parameter`` entry,; ``DW_AT_type attribute`` referencing the type of the parameter or; ``DW_AT_name`` attribute describing the parameter's name. *Examples using call site entries and related attributes are found in Appendix; D.15.*. .. _amdgpu-dwarf-lexical-block-entries:. A.3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:171068,Security,access,accessed,171068,"n L\ :sub:`2` at the time of the call made; by the call site. The result of these attributes is undefined if the current call frame is not; for the subprogram containing the ``DW_TAG_call_site_parameter`` debugger; information entry or the current program location is not for the call site; containing the ``DW_TAG_call_site_parameter`` debugger information entry in; the current call frame. *The consumer may have to virtually unwind to the call site (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) in order to evaluate these; attributes. This will ensure the source language thread of execution upon; which the user is focused corresponds to the call site needed to evaluate; the expression.*. If it is not possible to avoid the expressions of these attributes from; accessing registers or memory locations that might be clobbered by the; subprogram being called by the call site, then the associated attribute; should not be provided. *The reason for the restriction is that the parameter may need to be; accessed during the execution of the callee. The consumer may virtually; unwind from the called subprogram back to the caller and then evaluate the; attribute expressions. The call frame information (see*; :ref:`amdgpu-dwarf-call-frame-information`\ *) will not be able to restore; registers that have been clobbered, and clobbered memory will no longer have; the value at the time of the call.*. 3. Each call site parameter entry may also have a ``DW_AT_call_parameter``; attribute which contains a reference to a ``DW_TAG_formal_parameter`` entry,; ``DW_AT_type attribute`` referencing the type of the parameter or; ``DW_AT_name`` attribute describing the parameter's name. *Examples using call site entries and related attributes are found in Appendix; D.15.*. .. _amdgpu-dwarf-lexical-block-entries:. A.3.5 Lexical Block Entries; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. note::. This section is the same as DWARF Version 5 section 3.5. A.4 Data Object and Object List Entries; ---------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:188995,Security,access,access,188995,"information:. A.6.2 Line Number Information; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. A.6.2.4 The Line Number Program Header; ++++++++++++++++++++++++++++++++++++++. A.6.2.4.1 Standard Content Descriptions; #######################################. .. note::. This augments DWARF Version 5 section 6.2.4.1. .. _amdgpu-dwarf-line-number-information-dw-lnct-llvm-source:. 1. ``DW_LNCT_LLVM_source``. The component is a null-terminated UTF-8 source text string with ""\ ``\n``\; "" line endings. This content code is paired with the same forms as; ``DW_LNCT_path``. It can be used for file name entries. The value is an empty null-terminated string if no source is available. If; the source is available but is an empty file then the value is a; null-terminated single ""\ ``\n``\ "". *When the source field is present, consumers can use the embedded source; instead of attempting to discover the source on disk using the file path; provided by the* ``DW_LNCT_path`` *field. When the source field is absent,; consumers can access the file to get the source text.*. *This is particularly useful for programming languages that support runtime; compilation and runtime generation of source text. In these cases, the; source text does not reside in any permanent file. For example, the OpenCL; language [:ref:`OpenCL <amdgpu-dwarf-OpenCL>`] supports online compilation.*. 2. ``DW_LNCT_LLVM_is_MD5``. ``DW_LNCT_LLVM_is_MD5`` indicates if the ``DW_LNCT_MD5`` content kind, if; present, is valid: when 0 it is not valid and when 1 it is valid. If; ``DW_LNCT_LLVM_is_MD5`` content kind is not present, and ``DW_LNCT_MD5``; content kind is present, then the MD5 checksum is valid. ``DW_LNCT_LLVM_is_MD5`` is always paired with the ``DW_FORM_udata`` form. *This allows a compilation unit to have a mixture of files with and without; MD5 checksums. This can happen when multiple relocatable files are linked; together.*. .. _amdgpu-dwarf-call-frame-information:. A.6.4 Call Frame Information; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. not",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:189625,Security,checksum,checksum,189625,"s. The value is an empty null-terminated string if no source is available. If; the source is available but is an empty file then the value is a; null-terminated single ""\ ``\n``\ "". *When the source field is present, consumers can use the embedded source; instead of attempting to discover the source on disk using the file path; provided by the* ``DW_LNCT_path`` *field. When the source field is absent,; consumers can access the file to get the source text.*. *This is particularly useful for programming languages that support runtime; compilation and runtime generation of source text. In these cases, the; source text does not reside in any permanent file. For example, the OpenCL; language [:ref:`OpenCL <amdgpu-dwarf-OpenCL>`] supports online compilation.*. 2. ``DW_LNCT_LLVM_is_MD5``. ``DW_LNCT_LLVM_is_MD5`` indicates if the ``DW_LNCT_MD5`` content kind, if; present, is valid: when 0 it is not valid and when 1 it is valid. If; ``DW_LNCT_LLVM_is_MD5`` content kind is not present, and ``DW_LNCT_MD5``; content kind is present, then the MD5 checksum is valid. ``DW_LNCT_LLVM_is_MD5`` is always paired with the ``DW_FORM_udata`` form. *This allows a compilation unit to have a mixture of files with and without; MD5 checksums. This can happen when multiple relocatable files are linked; together.*. .. _amdgpu-dwarf-call-frame-information:. A.6.4 Call Frame Information; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. note::. This section provides changes to existing call frame information and defines; instructions added by these extensions. Additional support is added for; address spaces. Register unwind DWARF expressions are generalized to allow any; location description, including those with composite and implicit location; descriptions. These changes would be incorporated into the DWARF Version 5 section 6.4. .. _amdgpu-dwarf-structure_of-call-frame-information:. A.6.4.1 Structure of Call Frame Information; +++++++++++++++++++++++++++++++++++++++++++. The register rules are:. *undefined*; A r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:189799,Security,checksum,checksums,189799,"the source field is present, consumers can use the embedded source; instead of attempting to discover the source on disk using the file path; provided by the* ``DW_LNCT_path`` *field. When the source field is absent,; consumers can access the file to get the source text.*. *This is particularly useful for programming languages that support runtime; compilation and runtime generation of source text. In these cases, the; source text does not reside in any permanent file. For example, the OpenCL; language [:ref:`OpenCL <amdgpu-dwarf-OpenCL>`] supports online compilation.*. 2. ``DW_LNCT_LLVM_is_MD5``. ``DW_LNCT_LLVM_is_MD5`` indicates if the ``DW_LNCT_MD5`` content kind, if; present, is valid: when 0 it is not valid and when 1 it is valid. If; ``DW_LNCT_LLVM_is_MD5`` content kind is not present, and ``DW_LNCT_MD5``; content kind is present, then the MD5 checksum is valid. ``DW_LNCT_LLVM_is_MD5`` is always paired with the ``DW_FORM_udata`` form. *This allows a compilation unit to have a mixture of files with and without; MD5 checksums. This can happen when multiple relocatable files are linked; together.*. .. _amdgpu-dwarf-call-frame-information:. A.6.4 Call Frame Information; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. note::. This section provides changes to existing call frame information and defines; instructions added by these extensions. Additional support is added for; address spaces. Register unwind DWARF expressions are generalized to allow any; location description, including those with composite and implicit location; descriptions. These changes would be incorporated into the DWARF Version 5 section 6.4. .. _amdgpu-dwarf-structure_of-call-frame-information:. A.6.4.1 Structure of Call Frame Information; +++++++++++++++++++++++++++++++++++++++++++. The register rules are:. *undefined*; A register that has this rule has no recoverable value in the previous frame.; The previous value of this register is the undefined location description (see; :ref:`amdgpu-dwarf-undefined-lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:7575,Testability,test,tests,7575,",; bit addressing, the ability for composite location descriptions to be composed; of any kind of location description, and the ability to support objects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GPU; and non-GPU code. Examining the GDB debugger and LLVM compiler, it appears only; to require modest changes as they both already have to support general use of; location descriptions. It is anticipated that will also be the case for other; debuggers and compilers. GDB has been modified to evaluate DWARF Version 5 expressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5; rules. The code in GDB actually became simpler as all evaluation is done on a; single stack and there was no longer a need to maintain a separate structure for; the location description results. This gives confidence in backwards; compatibility. See :ref:`amdgpu-dwarf-expressions` and nested sections. This extension is separately described at *Allow Location Descriptions on the; DWARF Expression Stack* [:ref:`AMDGPU-DWARF-LOC; <amdgpu-dwarf-AMDGPU-DWARF-LOC>`]. 2.2 Generalize CFI to Allow Any Location Description Kind; ---------------------------------------------------------. CFI describes restoring callee saved registers that are spilled. Currently CFI; only allows a location description that is a register, memory address, or; implicit location description. AMDGPU optimized code may spill scalar registers; into portions of vector registers. This requires extending CFI to allow any; location description kind to be supported. See :ref:`am",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:7639,Testability,test,test,7639,",; bit addressing, the ability for composite location descriptions to be composed; of any kind of location description, and the ability to support objects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GPU; and non-GPU code. Examining the GDB debugger and LLVM compiler, it appears only; to require modest changes as they both already have to support general use of; location descriptions. It is anticipated that will also be the case for other; debuggers and compilers. GDB has been modified to evaluate DWARF Version 5 expressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5; rules. The code in GDB actually became simpler as all evaluation is done on a; single stack and there was no longer a need to maintain a separate structure for; the location description results. This gives confidence in backwards; compatibility. See :ref:`amdgpu-dwarf-expressions` and nested sections. This extension is separately described at *Allow Location Descriptions on the; DWARF Expression Stack* [:ref:`AMDGPU-DWARF-LOC; <amdgpu-dwarf-AMDGPU-DWARF-LOC>`]. 2.2 Generalize CFI to Allow Any Location Description Kind; ---------------------------------------------------------. CFI describes restoring callee saved registers that are spilled. Currently CFI; only allows a location description that is a register, memory address, or; implicit location description. AMDGPU optimized code may spill scalar registers; into portions of vector registers. This requires extending CFI to allow any; location description kind to be supported. See :ref:`am",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:25321,Testability,log,logical,25321,"specify that a base type is a vector is; required. See ``DW_AT_LLVM_vector_size`` in :ref:`amdgpu-dwarf-base-type-entries`. .. _amdgpu-dwarf-operation-to-create-vector-composite-location-descriptions:. 2.10 DWARF Operations to Create Vector Composite Location Descriptions; ----------------------------------------------------------------------. AMDGPU optimized code may spill vector registers to non-global address space; memory, and this spilling may be done only for SIMT lanes that are active on; entry to the subprogram. To support this the CFI rule for the partially spilled; register needs to use an expression that uses the EXEC register as a bit mask to; select between the register (for inactive lanes) and the stack spill location; (for active lanes that are spilled). This needs to evaluate to a location; description, and not a value, as a debugger needs to change the value if the; user assigns to the variable. Another usage is to create an expression that evaluates to provide a vector of; logical PCs for active and inactive lanes in a SIMT execution model. Again the; EXEC register is used to select between active and inactive PC values. In order; to represent a vector of PC values, a way to create a composite location; description that is a vector of a single location is used. It may be possible to use existing DWARF to incrementally build the composite; location description, possibly using the DWARF operations for control flow to; create a loop. However, for the AMDGPU that would require loop iteration of 64.; A concern is that the resulting DWARF would have a significant size and would be; reasonably common as it is needed for every vector register that is spilled in a; function. AMDGPU can have up to 512 vector registers. Another concern is the; time taken to evaluate such non-trivial expressions repeatedly. To avoid these issues, a composite location description that can be created as a; masked select is proposed. In addition, an operation that creates a compo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:44416,Testability,test,tested,44416,"aluated, it may be specified whether a value or location; description is required as the result kind. If a result kind is specified, and the result of the evaluation does not match; the specified result kind, then the implicit conversions described in; :ref:`amdgpu-dwarf-memory-location-description-operations` are performed if; valid. Otherwise, the DWARF expression is ill-formed. If the evaluation of a DWARF expression encounters an evaluation error, then the; result is an evaluation error. .. note::. Decided to define the concept of an evaluation error. An alternative is to; introduce an undefined value base type in a similar way to location; descriptions having an undefined location description. Then operations that; encounter an evaluation error can return the undefined location description or; value with an undefined base type. All operations that act on values would return an undefined entity if given an; undefined value. The expression would then always evaluate to completion, and; can be tested to determine if it is an undefined entity. However, this would add considerable additional complexity and does not match; that GDB throws an exception when these evaluation errors occur. If a DWARF expression is ill-formed, then the result is undefined. The following sections detail the rules for when a DWARF expression is; ill-formed or results in an evaluation error. A DWARF expression can either be encoded as an operation expression (see; :ref:`amdgpu-dwarf-operation-expressions`), or as a location list expression; (see :ref:`amdgpu-dwarf-location-list-expressions`). .. _amdgpu-dwarf-expression-evaluation-context:. A.2.5.1 DWARF Expression Evaluation Context; +++++++++++++++++++++++++++++++++++++++++++. A DWARF expression is evaluated in a context that can include a number of; context elements. If multiple context elements are specified then they must be; self consistent or the result of the evaluation is undefined. The context; elements that can be specified are:. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:67013,Testability,test,tests,67013," is ill-formed. .. note::. Could define this case as returning an implicit location description as; if the ``DW_OP_implicit`` operation is performed. * If the current result kind specifies a value, then:. * If the top stack entry is a value, or can be converted to one (see; :ref:`amdgpu-dwarf-memory-location-description-operations`), then the result; is that, possibly converted, value. Any other entries on the stack are; discarded. * Otherwise the DWARF expression is ill-formed. * If the current result kind is not specified, then:. * If the stack is empty, the result is a location description with one; undefined location description. *This rule is for backwards compatibility with DWARF Version 5 which has no; explicit operation to create an undefined location description, and uses an; empty operation expression for this purpose.*. .. note::. This rule is consistent with the rule above for when a location; description is requested. However, GDB appears to report this as an error; and no GDB tests appear to cause an empty stack for this case. * Otherwise, the top stack entry is returned. Any other entries on the stack; are discarded. An operation expression is encoded as a byte block with some form of prefix that; specifies the byte count. It can be used:. * as the value of a debugging information entry attribute that is encoded using; class ``exprloc`` (see :ref:`amdgpu-dwarf-classes-and-forms`),. * as the operand to certain operation expression operations,. * as the operand to certain call frame information operations (see; :ref:`amdgpu-dwarf-call-frame-information`),. * and in location list entries (see; :ref:`amdgpu-dwarf-location-list-expressions`). .. _amdgpu-dwarf-vendor-extensions-operations:. A.2.5.4.0 Vendor Extension Operations; #####################################. 1. ``DW_OP_LLVM_user``. ``DW_OP_LLVM_user`` encodes a vendor extension operation. It has at least one; operand: a ULEB128 constant identifying a vendor extension operation. The; remaining opera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:86345,Testability,log,logical-operations,86345,"lemented using a SIMT execution model,; this is the zero-based lane number that corresponds to the source language; thread of execution upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_lanes`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. 9. ``DW_OP_LLVM_push_iteration`` *New*. ``DW_OP_LLVM_push_iteration`` pushes the current iteration as a value with; the generic type. *For source language implementations with optimizations that cause multiple; loop iterations to execute concurrently, this is the zero-based iteration; number that corresponds to the source language concurrent loop iteration; upon which the user is focused.*. The value must be greater than or equal to 0 and less than the value of the; ``DW_AT_LLVM_iterations`` attribute, otherwise the DWARF expression is; ill-formed. See :ref:`amdgpu-dwarf-low-level-information`. .. _amdgpu-dwarf-arithmetic-logical-operations:. A.2.5.4.3.2 Arithmetic and Logical Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.4. .. _amdgpu-dwarf-type-conversions-operations:. A.2.5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value operations currently defined:. 1. ``DW_OP_regval_type``. ``DW_OP_regval_type`` has two operands. The first is an unsigned LEB128; integer that represents a register number R. The second is an unsigned; LEB128 integer DR that represents the byte offset of a debugging information; entry D relative to the beginning of the current compilation unit, that; provides the ty",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:87998,Testability,test,test,87998,"tly defined:. 1. ``DW_OP_regval_type``. ``DW_OP_regval_type`` has two operands. The first is an unsigned LEB128; integer that represents a register number R. The second is an unsigned; LEB128 integer DR that represents the byte offset of a debugging information; entry D relative to the beginning of the current compilation unit, that; provides the type T of the register value. The operation is equivalent to performing ``DW_OP_regx R; DW_OP_deref_type; DR``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions allow a composite location description to be used to combine; multiple registers. 2. ``DW_OP_deref``. S is the bit size of the generic type divided by 8 (the byte size) and; rounded up to a whole number. DR is the offset of a hypothetical debug; information entry D in the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:88431,Testability,test,test,88431,"R``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions allow a composite location description to be used to combine; multiple registers. 2. ``DW_OP_deref``. S is the bit size of the generic type divided by 8 (the byte size) and; rounded up to a whole number. DR is the offset of a hypothetical debug; information entry D in the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. 3. ``DW_OP_deref_size``. ``DW_OP_deref_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. TS is the smaller of the generic type bit size and S scaled by 8 (the byte; size). If TS is smaller than the generic type bit size then T is an unsigned; integral type of bit size TS, otherwise T is the generic type. DR is the; offset of a hypothetical debug information entry D in the current; compilation unit for a base ty",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:88511,Testability,test,test,88511,"R``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions allow a composite location description to be used to combine; multiple registers. 2. ``DW_OP_deref``. S is the bit size of the generic type divided by 8 (the byte size) and; rounded up to a whole number. DR is the offset of a hypothetical debug; information entry D in the current compilation unit for a base type of the; generic type. The operation is equivalent to performing ``DW_OP_deref_type S, DR``. 3. ``DW_OP_deref_size``. ``DW_OP_deref_size`` has a single 1-byte unsigned integral constant that; represents a byte result size S. TS is the smaller of the generic type bit size and S scaled by 8 (the byte; size). If TS is smaller than the generic type bit size then T is an unsigned; integral type of bit size TS, otherwise T is the generic type. DR is the; offset of a hypothetical debug information entry D in the current; compilation unit for a base ty",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:193708,Testability,test,tests,193708,"current CFA location description. *Since the CFA location description is required to be a memory byte address; location description, the value of val_offset(N) will also be a memory byte; address location description since it is offsetting the CFA location; description by N bytes. Furthermore, the value of val_offset(N) will be a; memory byte address in the same address space as the CFA location; description.*. .. note::. Should DWARF allow the address size to be a different size to the size of; the register? Requiring them to be the same bit size avoids any issue of; conversion as the bit contents of the register is simply interpreted as a; value of the address. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers,; and to actually reading bytes from the next register (or reads out of bounds; for the last register) for smaller registers. There are no GDB tests that; read a register out of bounds (except an illegal hand written assembly; test). *register(R)*; This register has been stored in another register numbered R. The previous value of this register is the location description obtained using; the call frame information for the current frame and current program location; for register R. The DWARF is ill-formed if the size of this register does not match the size; of register R or if there is a cyclic dependency in the call frame; information. .. note::. Should this also allow R to be larger than this register? If so is the value; stored in the low order bits and it is undefined what is stored in the; extra upper bits?. *expression(E)*; The previous value of this register is located at the location description; produced by evaluating the DWARF operation expression E (see; :ref:`amdgpu-dwarf-operation-expressions`). E is evaluated with the current context, except the result kind is a location; description, the compilation unit is unspecified, the object is unspecified,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:193792,Testability,test,test,193792,"current CFA location description. *Since the CFA location description is required to be a memory byte address; location description, the value of val_offset(N) will also be a memory byte; address location description since it is offsetting the CFA location; description by N bytes. Furthermore, the value of val_offset(N) will be a; memory byte address in the same address space as the CFA location; description.*. .. note::. Should DWARF allow the address size to be a different size to the size of; the register? Requiring them to be the same bit size avoids any issue of; conversion as the bit contents of the register is simply interpreted as a; value of the address. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers,; and to actually reading bytes from the next register (or reads out of bounds; for the last register) for smaller registers. There are no GDB tests that; read a register out of bounds (except an illegal hand written assembly; test). *register(R)*; This register has been stored in another register numbered R. The previous value of this register is the location description obtained using; the call frame information for the current frame and current program location; for register R. The DWARF is ill-formed if the size of this register does not match the size; of register R or if there is a cyclic dependency in the call frame; information. .. note::. Should this also allow R to be larger than this register? If so is the value; stored in the low order bits and it is undefined what is stored in the; extra upper bits?. *expression(E)*; The previous value of this register is located at the location description; produced by evaluating the DWARF operation expression E (see; :ref:`amdgpu-dwarf-operation-expressions`). E is evaluated with the current context, except the result kind is a location; description, the compilation unit is unspecified, the object is unspecified,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:3632,Usability,feedback,feedback,3632,"owed by appendix; :ref:`amdgpu-dwarf-changes-relative-to-dwarf-version-5` which contains the; textual changes for the extensions relative to the DWARF Version 5 standard.; There are a number of notes included that raise open questions, or provide; alternative approaches that may be worth considering. Then appendix; :ref:`amdgpu-dwarf-further-examples` links to the AMD GPU specific usage of the; extensions that includes an example. Finally, appendix; :ref:`amdgpu-dwarf-references` provides references to further information. .. _amdgpu-dwarf-extensions:. 2. Extensions; =============. The extensions continue to evolve through collaboration with many individuals and; active prototyping within the GDB debugger and LLVM compiler. Input has also; been very much appreciated from the developers working on the Perforce TotalView; HPC Debugger and GCC compiler. The inputs provided and insights gained so far have been incorporated into this; current version. The plan is to participate in upstreaming the work and; addressing any feedback. If there is general interest then some or all of these; extensions could be submitted as future DWARF standard proposals. The general principles in designing the extensions have been:. 1. Be backwards compatible with the DWARF Version 5 [:ref:`DWARF; <amdgpu-dwarf-DWARF>`] standard. 2. Be vendor and architecture neutral. They are intended to apply to other; heterogeneous hardware devices including GPUs, DSPs, FPGAs, and other; specialized hardware. These collectively include similar characteristics and; requirements as AMDGPU devices. 3. Provide improved optimization support for non-GPU code. For example, some; extensions apply to traditional CPU hardware that supports large vector; registers. Compilers can map source languages, and source language; extensions, that describe large scale parallel execution, onto the lanes of; the vector registers. This is common in programming languages used in ML and; HPC. 4. Fully define well-formed DWARF in a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:7046,Usability,simpl,simplest,7046,"xpressions to retain their same meaning,; while enabling the ability to explicitly create memory location descriptions in; non-default address spaces and generalizing the power of composite location; descriptions to any kind of location description. For those familiar with the definition of location descriptions in DWARF Version; 5, the definitions in these extensions are presented differently, but does in; fact define the same concept with the same fundamental semantics. However, it; does so in a way that allows the concept to extend to support address spaces,; bit addressing, the ability for composite location descriptions to be composed; of any kind of location description, and the ability to support objects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GPU; and non-GPU code. Examining the GDB debugger and LLVM compiler, it appears only; to require modest changes as they both already have to support general use of; location descriptions. It is anticipated that will also be the case for other; debuggers and compilers. GDB has been modified to evaluate DWARF Version 5 expressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5; rules. The code in GDB actually became simpler as all evaluation is done on a; single stack and there was no longer a need to maintain a separate structure for; the location description results. This gives confidence in backwards; compatibility. See :ref:`amdgpu-dwarf-expressions` and nested sections. This extension is separately described at *Allow Location Descriptions on the; DWA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:7708,Usability,simpl,simpler,7708,"jects located; at multiple places. Collectively these changes expand the set of architectures; that can be supported and improves support for optimized code. Several approaches were considered, and the one presented, together with the; extensions it enables, appears to be the simplest and cleanest one that offers; the greatest improvement of DWARF's ability to support debugging optimized GPU; and non-GPU code. Examining the GDB debugger and LLVM compiler, it appears only; to require modest changes as they both already have to support general use of; location descriptions. It is anticipated that will also be the case for other; debuggers and compilers. GDB has been modified to evaluate DWARF Version 5 expressions with location; descriptions as stack entries and with implicit conversions. All GDB tests have; passed, except one that turned out to be an invalid test case by DWARF Version 5; rules. The code in GDB actually became simpler as all evaluation is done on a; single stack and there was no longer a need to maintain a separate structure for; the location description results. This gives confidence in backwards; compatibility. See :ref:`amdgpu-dwarf-expressions` and nested sections. This extension is separately described at *Allow Location Descriptions on the; DWARF Expression Stack* [:ref:`AMDGPU-DWARF-LOC; <amdgpu-dwarf-AMDGPU-DWARF-LOC>`]. 2.2 Generalize CFI to Allow Any Location Description Kind; ---------------------------------------------------------. CFI describes restoring callee saved registers that are spilled. Currently CFI; only allows a location description that is a register, memory address, or; implicit location description. AMDGPU optimized code may spill scalar registers; into portions of vector registers. This requires extending CFI to allow any; location description kind to be supported. See :ref:`amdgpu-dwarf-call-frame-information`. 2.3 Generalize DWARF Operation Expressions to Support Multiple Places; -----------------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:11565,Usability,simpl,simpler,11565,"ize Offsetting of Location Descriptions; --------------------------------------------------. The ``DW_OP_plus`` and ``DW_OP_minus`` operations can be defined to operate on a; memory location description in the default target architecture specific address; space and a generic type value to produce an updated memory location; description. This allows them to continue to be used to offset an address. To generalize offsetting to any location description, including location; descriptions that describe when bytes are in registers, are implicit, or a; composite of these, the ``DW_OP_LLVM_offset``, ``DW_OP_LLVM_offset_uconst``, and; ``DW_OP_LLVM_bit_offset`` offset operations are added. The offset operations can operate on location storage of any size. For example,; implicit location storage could be any number of bits in size. It is simpler to; define offsets that exceed the size of the location storage as being an; evaluation error, than having to force an implementation to support potentially; infinite precision offsets to allow it to correctly track a series of positive; and negative offsets that may transiently overflow or underflow, but end up in; range. This is simple for the arithmetic operations as they are defined in terms; of two's complement arithmetic on a base type of a fixed size. Therefore, the; offset operation define that integer overflow is ill-formed. This is in contrast; to the ``DW_OP_plus``, ``DW_OP_plus_uconst``, and ``DW_OP_minus`` arithmetic; operations which define that it causes wrap-around. Having the offset operations allows ``DW_OP_push_object_address`` to push a; location description that may be in a register, or be an implicit value. The; DWARF expression of ``DW_TAG_ptr_to_member_type`` can use the offset operations; without regard to what kind of location description was pushed. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack` has; generalized location storage to be bit indexable, ``DW_OP_LLVM_bit_offset``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:11906,Usability,simpl,simple,11906,"pecific address; space and a generic type value to produce an updated memory location; description. This allows them to continue to be used to offset an address. To generalize offsetting to any location description, including location; descriptions that describe when bytes are in registers, are implicit, or a; composite of these, the ``DW_OP_LLVM_offset``, ``DW_OP_LLVM_offset_uconst``, and; ``DW_OP_LLVM_bit_offset`` offset operations are added. The offset operations can operate on location storage of any size. For example,; implicit location storage could be any number of bits in size. It is simpler to; define offsets that exceed the size of the location storage as being an; evaluation error, than having to force an implementation to support potentially; infinite precision offsets to allow it to correctly track a series of positive; and negative offsets that may transiently overflow or underflow, but end up in; range. This is simple for the arithmetic operations as they are defined in terms; of two's complement arithmetic on a base type of a fixed size. Therefore, the; offset operation define that integer overflow is ill-formed. This is in contrast; to the ``DW_OP_plus``, ``DW_OP_plus_uconst``, and ``DW_OP_minus`` arithmetic; operations which define that it causes wrap-around. Having the offset operations allows ``DW_OP_push_object_address`` to push a; location description that may be in a register, or be an implicit value. The; DWARF expression of ``DW_TAG_ptr_to_member_type`` can use the offset operations; without regard to what kind of location description was pushed. Since; :ref:`amdgpu-dwarf-allow-location-description-on-the-dwarf-evaluation-stack` has; generalized location storage to be bit indexable, ``DW_OP_LLVM_bit_offset``; generalizes DWARF to work with bit fields. This is generally not possible in; DWARF Version 5. The ``DW_OP_*piece`` operations only allow literal indices. A way to use a; computed offset of an arbitrary location description (such as a v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:64323,Usability,simpl,simple,64323,"ined if the object location; description becomes invalid between the two expression evaluations.*. A change of a thread's program location may not make a location description; invalid, yet may still render it as no longer meaningful. Accessing such a; location description, or using it as the object context or initial stack context; of an expression evaluation, may produce an undefined result. *For example, a location description may specify a register that no longer holds; the intended program object after a program location change. One way to avoid; such problems is to recompute location descriptions associated with threads when; their program locations change.*. .. _amdgpu-dwarf-operation-expressions:. A.2.5.4 DWARF Operation Expressions; +++++++++++++++++++++++++++++++++++. An operation expression is comprised of a stream of operations, each consisting; of an opcode followed by zero or more operands. The number of operands is; implied by the opcode. Operations represent a postfix operation on a simple stack machine. Each stack; entry can hold either a value or a location description. Operations can act on; entries on the stack, including adding entries and removing entries. If the kind; of a stack entry does not match the kind required by the operation and is not; implicitly convertible to the required kind (see; :ref:`amdgpu-dwarf-memory-location-description-operations`), then the DWARF; operation expression is ill-formed. Evaluation of an operation expression starts with an empty stack on which the; entries from the initial stack provided by the context are pushed in the order; provided. Then the operations are evaluated, starting with the first operation; of the stream. Evaluation continues until either an operation has an evaluation; error, or until one past the last operation of the stream is reached. The result of the evaluation is:. * If an operation has an evaluation error, or an operation evaluates an; expression that has an evaluation error, then the re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:70639,Usability,simpl,simple,70639,"gle unsigned 1-byte operand that represents an index; I. A copy of the stack entry with index I is pushed onto the stack. 4. ``DW_OP_over``. ``DW_OP_over`` pushes a copy of the entry with index 1. *This is equivalent to a* ``DW_OP_pick 1`` *operation.*. 5. ``DW_OP_swap``. ``DW_OP_swap`` swaps the top two stack entries. The entry at the top of the; stack becomes the second stack entry, and the second stack entry becomes the; top of the stack. 6. ``DW_OP_rot``. ``DW_OP_rot`` rotates the first three stack entries. The entry at the top of; the stack becomes the third stack entry, the second entry becomes the top of; the stack, and the third entry becomes the second entry. *Examples illustrating many of these stack operations are found in Appendix; D.1.2 on page 289.*. .. _amdgpu-dwarf-control-flow-operations:. A.2.5.4.2 Control Flow Operations; #################################. .. note::. This section replaces DWARF Version 5 section 2.5.1.5. The following operations provide simple control of the flow of a DWARF operation; expression. 1. ``DW_OP_nop``. ``DW_OP_nop`` is a place holder. It has no effect on the DWARF stack; entries. 2. ``DW_OP_le``, ``DW_OP_ge``, ``DW_OP_eq``, ``DW_OP_lt``, ``DW_OP_gt``,; ``DW_OP_ne``. .. note::. The same as in DWARF Version 5 section 2.5.1.5. 3. ``DW_OP_skip``. ``DW_OP_skip`` is an unconditional branch. Its single operand is a 2-byte; signed integer constant. The 2-byte constant is the number of bytes of the; DWARF expression to skip forward or backward from the current operation,; beginning after the 2-byte constant. If the updated position is at one past the end of the last operation, then; the operation expression evaluation is complete. Otherwise, the DWARF expression is ill-formed if the updated operation; position is not in the range of the first to last operation inclusive, or; not at the start of an operation. 4. ``DW_OP_bra``. ``DW_OP_bra`` is a conditional branch. Its single operand is a 2-byte signed; integer constant. This op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:76911,Usability,simpl,simply,76911," specified location list expression E is; evaluated. The evaluation of E uses the current context, except the result; kind is a location description, the compilation unit is the one that; contains D, and the initial stack is empty. The location description; result is pushed on the stack. .. note::. This rule avoids having to define how to execute a matched location list; entry operation expression on the same stack as the call when there are; multiple matches. But it allows the call to obtain the location; description for a variable or formal parameter which may use a location; list expression. An alternative is to treat the case when D has a ``DW_AT_location``; attribute that is encoded as a ``loclist`` or ``loclistsptr``, and the; specified location list expression E' matches a single location list; entry with operation expression E, the same as the ``exprloc`` case and; evaluate on the same stack. But this is not attractive as if the attribute is for a variable that; happens to end with a non-singleton stack, it will not simply put a; location description on the stack. Presumably the intent of using; ``DW_OP_call*`` on a variable or formal parameter debugger information; entry is to push just one location description on the stack. That; location description may have more than one single location description. The previous rule for ``exprloc`` also has the same problem, as normally; a variable or formal parameter location expression may leave multiple; entries on the stack and only return the top entry. GDB implements ``DW_OP_call*`` by always executing E on the same stack.; If the location list has multiple matching entries, it simply picks the; first one and ignores the rest. This seems fundamentally at odds with; the desire to support multiple places for variables. So, it feels like ``DW_OP_call*`` should both support pushing a location; description on the stack for a variable or formal parameter, and also; support being able to execute an operation expression on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:77529,Usability,simpl,simply,77529,"W_AT_location``; attribute that is encoded as a ``loclist`` or ``loclistsptr``, and the; specified location list expression E' matches a single location list; entry with operation expression E, the same as the ``exprloc`` case and; evaluate on the same stack. But this is not attractive as if the attribute is for a variable that; happens to end with a non-singleton stack, it will not simply put a; location description on the stack. Presumably the intent of using; ``DW_OP_call*`` on a variable or formal parameter debugger information; entry is to push just one location description on the stack. That; location description may have more than one single location description. The previous rule for ``exprloc`` also has the same problem, as normally; a variable or formal parameter location expression may leave multiple; entries on the stack and only return the top entry. GDB implements ``DW_OP_call*`` by always executing E on the same stack.; If the location list has multiple matching entries, it simply picks the; first one and ignores the rest. This seems fundamentally at odds with; the desire to support multiple places for variables. So, it feels like ``DW_OP_call*`` should both support pushing a location; description on the stack for a variable or formal parameter, and also; support being able to execute an operation expression on the same stack.; Being able to specify a different operation expression for different; program locations seems a desirable feature to retain. A solution to that is to have a distinct ``DW_AT_LLVM_proc`` attribute; for the ``DW_TAG_dwarf_procedure`` debugging information entry. Then the; ``DW_AT_location`` attribute expression is always executed separately; and pushes a location description (that may have multiple single; location descriptions), and the ``DW_AT_LLVM_proc`` attribute expression; is always executed on the same stack and can leave anything on the; stack. The ``DW_AT_LLVM_proc`` attribute could have the new classes; ``exprproc``, ``",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:79135,Usability,clear,clearly,79135,"procedure`` debugging information entry. Then the; ``DW_AT_location`` attribute expression is always executed separately; and pushes a location description (that may have multiple single; location descriptions), and the ``DW_AT_LLVM_proc`` attribute expression; is always executed on the same stack and can leave anything on the; stack. The ``DW_AT_LLVM_proc`` attribute could have the new classes; ``exprproc``, ``loclistproc``, and ``loclistsptrproc`` to indicate that; the expression is executed on the same stack. ``exprproc`` is the same; encoding as ``exprloc``. ``loclistproc`` and ``loclistsptrproc`` are the; same encoding as their non-\ ``proc`` counterparts, except the DWARF is; ill-formed if the location list does not match exactly one location list; entry and a default entry is required. These forms indicate explicitly; that the matched single operation expression must be executed on the; same stack. This is better than ad hoc special rules for ``loclistproc``; and ``loclistsptrproc`` which are currently clearly defined to always; return a location description. The producer then explicitly indicates; the intent through the attribute classes. Such a change would be a breaking change for how GDB implements; ``DW_OP_call*``. However, are the breaking cases actually occurring in; practice? GDB could implement the current approach for DWARF Version 5,; and the new semantics for DWARF Version 6 which has been done for some; other features. Another option is to limit the execution to be on the same stack only to; the evaluation of an expression E that is the value of a; ``DW_AT_location`` attribute of a ``DW_TAG_dwarf_procedure`` debugging; information entry. The DWARF would be ill-formed if E is a location list; expression that does not match exactly one location list entry. In all; other cases the evaluation of an expression E that is the value of a; ``DW_AT_location`` attribute would evaluate E with the current context,; except the result kind is a location descrip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:87669,Usability,simpl,simply,87669,"5.4.3.3 Type Conversion Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section is the same as DWARF Version 5 section 2.5.1.6. .. _amdgpu-dwarf-general-operations:. A.2.5.4.3.4 Special Value Operations; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. .. note::. This section replaces parts of DWARF Version 5 sections 2.5.1.2, 2.5.1.3, and; 2.5.1.7. There are these special value operations currently defined:. 1. ``DW_OP_regval_type``. ``DW_OP_regval_type`` has two operands. The first is an unsigned LEB128; integer that represents a register number R. The second is an unsigned; LEB128 integer DR that represents the byte offset of a debugging information; entry D relative to the beginning of the current compilation unit, that; provides the type T of the register value. The operation is equivalent to performing ``DW_OP_regx R; DW_OP_deref_type; DR``. .. note::. Should DWARF allow the type T to be a larger size than the size of the; register R? Restricting a larger bit size avoids any issue of conversion; as the, possibly truncated, bit contents of the register is simply; interpreted as a value of T. If a conversion is wanted it can be done; explicitly using a ``DW_OP_convert`` operation. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers.; Removing use of the target hook does not cause any test failures in common; architectures. If the compiler for a target architecture did want some; form of conversion, including a larger result type, it could always; explicitly use the ``DW_OP_convert`` operation. If T is a larger type than the register size, then the default GDB; register hook reads bytes from the next register (or reads out of bounds; for the last register!). Removing use of the target hook does not cause; any test failures in common architectures (except an illegal hand written; assembly test). If a target architecture requires this behavior, these; extensions",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:127359,Usability,simpl,simplify,127359,"ration that created L.*. * If D has a ``DW_AT_const_value`` attribute, then an implicit location; storage RLS is created from the ``DW_AT_const_value`` attribute's value; with a size matching the size of the ``DW_AT_const_value`` attribute's; value. RL comprises one implicit location description SRL. SRL specifies; RLS with a bit offset of 0. .. note::. If using ``DW_AT_const_value`` for variables and formal parameters is; deprecated and instead ``DW_AT_location`` is used with an implicit; location description, then this rule would not be required. * Otherwise, it is an evaluation error. The bit offset of RL is updated as if the ``DW_OP_LLVM_offset_uconst B``; operation was applied. If a ``DW_OP_stack_value`` operation pops a value that is the same as IPV,; then it pushes a location description that is the same as L. It is an evaluation error if LS or IPV is accessed in any other manner. *The restrictions on how an implicit pointer location description created; by* ``DW_OP_implicit_pointer`` *and* ``DW_OP_LLVM_aspace_implicit_pointer``; *can be used are to simplify the DWARF consumer. Similarly, for an implicit; pointer value created by* ``DW_OP_deref*`` *and* ``DW_OP_stack_value``\ *.*. 4. ``DW_OP_LLVM_aspace_implicit_pointer`` *New*. ``DW_OP_LLVM_aspace_implicit_pointer`` has two operands that are the same as; for ``DW_OP_implicit_pointer``. It pops one stack entry that must be an integral type value that represents; a target architecture specific address space identifier AS. The location description L that is pushed on the stack is the same as for; ``DW_OP_implicit_pointer``, except that the address space identifier used is; AS. The DWARF expression is ill-formed if AS is not one of the values defined by; the target architecture specific ``DW_ASPACE_LLVM_*`` values. .. note::. This definition of ``DW_OP_LLVM_aspace_implicit_pointer`` may change when; full support for address classes is added as required for languages such; as OpenCL/SyCL. *Typically a* ``DW_OP_imp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:135947,Usability,simpl,simpler,135947,"n L comprised of one incomplete; composite location description SL is pushed on the stack. An incomplete composite location storage LS is created with a single; part P. P specifies the location description PL and has a bit size of S; scaled by 8 (the byte size). SL specifies LS with a bit offset of 0. * Otherwise, the DWARF expression is ill-formed. *Many compilers store a single variable in sets of registers or store a; variable partially in memory and partially in registers.* ``DW_OP_piece``; *provides a way of describing where a part of a variable is located.*. *If a non-0 byte displacement is required, the* ``DW_OP_LLVM_offset``; *operation can be used to update the location description before using it as; the part location description of a* ``DW_OP_piece`` *operation.*. *The evaluation rules for the* ``DW_OP_piece`` *operation allow it to be; compatible with the DWARF Version 5 definition.*. .. note::. Since these extensions allow location descriptions to be entries on the; stack, a simpler operation to create composite location descriptions could; be defined. For example, just one operation that specifies how many parts,; and pops pairs of stack entries for the part size and location; description. Not only would this be a simpler operation and avoid the; complexities of incomplete composite location descriptions, but it may; also have a smaller encoding in practice. However, the desire for; compatibility with DWARF Version 5 is likely a stronger consideration. 2. ``DW_OP_bit_piece``. ``DW_OP_bit_piece`` has two operands. The first is an unsigned LEB128; integer that represents the part bit size S. The second is an unsigned; LEB128 integer that represents a bit displacement B. The action is the same as for ``DW_OP_piece``, except that any part created; has the bit size S, and the location description PL of any created part is; updated as if the ``DW_OP_constu B; DW_OP_LLVM_bit_offset`` operations were; applied. ``DW_OP_bit_piece`` *is used instead of* ``DW_OP_pi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:136192,Usability,simpl,simpler,136192,"erwise, the DWARF expression is ill-formed. *Many compilers store a single variable in sets of registers or store a; variable partially in memory and partially in registers.* ``DW_OP_piece``; *provides a way of describing where a part of a variable is located.*. *If a non-0 byte displacement is required, the* ``DW_OP_LLVM_offset``; *operation can be used to update the location description before using it as; the part location description of a* ``DW_OP_piece`` *operation.*. *The evaluation rules for the* ``DW_OP_piece`` *operation allow it to be; compatible with the DWARF Version 5 definition.*. .. note::. Since these extensions allow location descriptions to be entries on the; stack, a simpler operation to create composite location descriptions could; be defined. For example, just one operation that specifies how many parts,; and pops pairs of stack entries for the part size and location; description. Not only would this be a simpler operation and avoid the; complexities of incomplete composite location descriptions, but it may; also have a smaller encoding in practice. However, the desire for; compatibility with DWARF Version 5 is likely a stronger consideration. 2. ``DW_OP_bit_piece``. ``DW_OP_bit_piece`` has two operands. The first is an unsigned LEB128; integer that represents the part bit size S. The second is an unsigned; LEB128 integer that represents a bit displacement B. The action is the same as for ``DW_OP_piece``, except that any part created; has the bit size S, and the location description PL of any created part is; updated as if the ``DW_OP_constu B; DW_OP_LLVM_bit_offset`` operations were; applied. ``DW_OP_bit_piece`` *is used instead of* ``DW_OP_piece`` *when the piece to; be assembled is not byte-sized or is not at the start of the part location; description.*. *If a computed bit displacement is required, the* ``DW_OP_LLVM_bit_offset``; *operation can be used to update the location description before using it as; the part location description of a*",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:159034,Usability,simpl,simpler,159034,"g*`` *to be used instead of*; ``DW_OP_breg* 0``\ *.*. .. note::. This rule could be removed and require the producer to create the required; location description directly using ``DW_OP_call_frame_cfa``,; ``DW_OP_breg*``, or ``DW_OP_LLVM_aspace_bregx``. This would also then; allow a target to implement the call frames within a large register. Otherwise, the DWARF is ill-formed if SL is not a memory location; description in any of the target architecture specific address spaces. The resulting L is the *frame base* for the subprogram or entry point. *Typically, E will use the* ``DW_OP_call_frame_cfa`` *operation or be a; stack pointer register plus or minus some offset.*. *The frame base for a subprogram is typically an address relative to the; first unit of storage allocated for the subprogram's stack frame. The*; ``DW_AT_frame_base`` *attribute can be used in several ways:*. 1. *In subprograms that need location lists to locate local variables, the*; ``DW_AT_frame_base`` *can hold the needed location list, while all; variables' location descriptions can be simpler ones involving the frame; base.*. 2. *It can be used in resolving ""up-level"" addressing within; nested routines. (See also* ``DW_AT_static_link``\ *, below)*. *Some languages support nested subroutines. In such languages, it is; possible to reference the local variables of an outer subroutine from within; an inner subroutine. The* ``DW_AT_static_link`` *and* ``DW_AT_frame_base``; *attributes allow debuggers to support this same kind of referencing.*. 3. If a ``DW_TAG_subprogram`` or ``DW_TAG_entry_point`` debugger information; entry is lexically nested, it may have a ``DW_AT_static_link`` attribute,; whose value is a DWARF expression E. The result of the attribute is obtained by evaluating E with a context that; has a result kind of a location description, an unspecified object, the; compilation unit that contains E, an empty initial stack, and other context; elements corresponding to the source language th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:193369,Usability,simpl,simply,193369," context,; except the result kind is a location description, the compilation unit is; unspecified, the object is unspecified, and an initial stack comprising the; location description of the current CFA (see; :ref:`amdgpu-dwarf-operation-expressions`). The DWARF is ill-formed if the CFA location description is not a memory byte; address location description, or if the register size does not match the size; of an address in the address space of the current CFA location description. *Since the CFA location description is required to be a memory byte address; location description, the value of val_offset(N) will also be a memory byte; address location description since it is offsetting the CFA location; description by N bytes. Furthermore, the value of val_offset(N) will be a; memory byte address in the same address space as the CFA location; description.*. .. note::. Should DWARF allow the address size to be a different size to the size of; the register? Requiring them to be the same bit size avoids any issue of; conversion as the bit contents of the register is simply interpreted as a; value of the address. GDB has a per register hook that allows a target specific conversion on a; register by register basis. It defaults to truncation of bigger registers,; and to actually reading bytes from the next register (or reads out of bounds; for the last register) for smaller registers. There are no GDB tests that; read a register out of bounds (except an illegal hand written assembly; test). *register(R)*; This register has been stored in another register numbered R. The previous value of this register is the location description obtained using; the call frame information for the current frame and current program location; for register R. The DWARF is ill-formed if the size of this register does not match the size; of register R or if there is a cyclic dependency in the call frame; information. .. note::. Should this also allow R to be larger than this register? If so is the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:235254,Usability,guid,guide,235254,nstead of ``DW_OP_add`` when; acting on a location description. Need to provide examples of new features. .. _amdgpu-dwarf-references:. D. References; =============. .. _amdgpu-dwarf-AMD:. 1. [AMD] `Advanced Micro Devices <https://www.amd.com/>`__. .. _amdgpu-dwarf-AMD-ROCgdb:. 2. [AMD-ROCgdb] `AMD ROCm Debugger (ROCgdb) <https://github.com/ROCm-Developer-Tools/ROCgdb>`__. .. _amdgpu-dwarf-AMD-ROCm:. 3. [AMD-ROCm] `AMD ROCm Platform <https://rocm-documentation.readthedocs.io>`__. .. _amdgpu-dwarf-AMDGPU-DWARF-LOC:. 4. [AMDGPU-DWARF-LOC] `Allow Location Descriptions on the DWARF Expression Stack <https://llvm.org/docs/AMDGPUDwarfExtensionAllowLocationDescriptionOnTheDwarfExpressionStack/AMDGPUDwarfExtensionAllowLocationDescriptionOnTheDwarfExpressionStack.html>`__. .. _amdgpu-dwarf-AMDGPU-LLVM:. 5. [AMDGPU-LLVM] `User Guide for AMDGPU LLVM Backend <https://llvm.org/docs/AMDGPUUsage.html>`__. .. _amdgpu-dwarf-CUDA:. 6. [CUDA] `Nvidia CUDA Language <https://docs.nvidia.com/cuda/cuda-c-programming-guide/>`__. .. _amdgpu-dwarf-DWARF:. 7. [DWARF] `DWARF Debugging Information Format <http://dwarfstd.org/>`__. .. _amdgpu-dwarf-ELF:. 8. [ELF] `Executable and Linkable Format (ELF) <http://www.sco.com/developers/gabi/>`__. .. _amdgpu-dwarf-GCC:. 9. [GCC] `GCC: The GNU Compiler Collection <https://www.gnu.org/software/gcc/>`__. .. _amdgpu-dwarf-GDB:. 10. [GDB] `GDB: The GNU Project Debugger <https://www.gnu.org/software/gdb/>`__. .. _amdgpu-dwarf-HIP:. 11. [HIP] `HIP Programming Guide <https://rocm-documentation.readthedocs.io/en/latest/Programming_Guides/Programming-Guides.html#hip-programing-guide>`__. .. _amdgpu-dwarf-HSA:. 12. [HSA] `Heterogeneous System Architecture (HSA) Foundation <http://www.hsafoundation.com/>`__. .. _amdgpu-dwarf-LLVM:. 13. [LLVM] `The LLVM Compiler Infrastructure <https://llvm.org/>`__. .. _amdgpu-dwarf-OpenCL:. 14. [OpenCL] `The OpenCL Specification Version 2.0 <http://www.khronos.org/registry/cl/specs/opencl-2.0.pdf>`__. .. _amdgpu-dwarf-Perforce-To,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst:235854,Usability,guid,guide,235854,ro Devices <https://www.amd.com/>`__. .. _amdgpu-dwarf-AMD-ROCgdb:. 2. [AMD-ROCgdb] `AMD ROCm Debugger (ROCgdb) <https://github.com/ROCm-Developer-Tools/ROCgdb>`__. .. _amdgpu-dwarf-AMD-ROCm:. 3. [AMD-ROCm] `AMD ROCm Platform <https://rocm-documentation.readthedocs.io>`__. .. _amdgpu-dwarf-AMDGPU-DWARF-LOC:. 4. [AMDGPU-DWARF-LOC] `Allow Location Descriptions on the DWARF Expression Stack <https://llvm.org/docs/AMDGPUDwarfExtensionAllowLocationDescriptionOnTheDwarfExpressionStack/AMDGPUDwarfExtensionAllowLocationDescriptionOnTheDwarfExpressionStack.html>`__. .. _amdgpu-dwarf-AMDGPU-LLVM:. 5. [AMDGPU-LLVM] `User Guide for AMDGPU LLVM Backend <https://llvm.org/docs/AMDGPUUsage.html>`__. .. _amdgpu-dwarf-CUDA:. 6. [CUDA] `Nvidia CUDA Language <https://docs.nvidia.com/cuda/cuda-c-programming-guide/>`__. .. _amdgpu-dwarf-DWARF:. 7. [DWARF] `DWARF Debugging Information Format <http://dwarfstd.org/>`__. .. _amdgpu-dwarf-ELF:. 8. [ELF] `Executable and Linkable Format (ELF) <http://www.sco.com/developers/gabi/>`__. .. _amdgpu-dwarf-GCC:. 9. [GCC] `GCC: The GNU Compiler Collection <https://www.gnu.org/software/gcc/>`__. .. _amdgpu-dwarf-GDB:. 10. [GDB] `GDB: The GNU Project Debugger <https://www.gnu.org/software/gdb/>`__. .. _amdgpu-dwarf-HIP:. 11. [HIP] `HIP Programming Guide <https://rocm-documentation.readthedocs.io/en/latest/Programming_Guides/Programming-Guides.html#hip-programing-guide>`__. .. _amdgpu-dwarf-HSA:. 12. [HSA] `Heterogeneous System Architecture (HSA) Foundation <http://www.hsafoundation.com/>`__. .. _amdgpu-dwarf-LLVM:. 13. [LLVM] `The LLVM Compiler Infrastructure <https://llvm.org/>`__. .. _amdgpu-dwarf-OpenCL:. 14. [OpenCL] `The OpenCL Specification Version 2.0 <http://www.khronos.org/registry/cl/specs/opencl-2.0.pdf>`__. .. _amdgpu-dwarf-Perforce-TotalView:. 15. [Perforce-TotalView] `Perforce TotalView HPC Debugging Software <https://totalview.io/products/totalview>`__. .. _amdgpu-dwarf-SEMVER:. 16. [SEMVER] `Semantic Versioning <https://semver.org/>`__; ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUDwarfExtensionsForHeterogeneousDebugging.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUInstructionNotation.rst:3019,Integrability,depend,depending,3019," and values are labelled with 's' prefix.; * Operands which accept any registers and values have no prefix. Examples:. .. parsed-literal::. vdata // operand only accepts vector registers; sdst // operand only accepts scalar registers; src1 // operand accepts vector registers, scalar registers, and scalar values. .. _amdgpu_syn_instruction_operand_tags:. Operand Tags; ^^^^^^^^^^^^. Operand tags indicate special operand properties. ============== =================================================================================; Operand tag Meaning; ============== =================================================================================; :opt An optional operand.; :m An operand which may be used with operand modifiers; :ref:`abs<amdgpu_synid_abs>`, :ref:`neg<amdgpu_synid_neg>` or; :ref:`sext<amdgpu_synid_sext>`.; :dst An input operand which is also used as a destination; if :ref:`glc<amdgpu_synid_glc>` modifier is specified.; :fx This is a *f32* or *f16* operand, depending on; :ref:`m_op_sel_hi<amdgpu_synid_mad_mix_op_sel_hi>` modifier.; :<type> The operand *type* differs from the *type*; :ref:`implied by the opcode name<amdgpu_syn_instruction_type>`.; This tag specifies the actual operand *type*.; ============== =================================================================================. Examples:. .. parsed-literal::. src1:m // src1 operand may be used with operand modifiers; vdata:dst // vdata operand may be used as both source and destination; vdst:u32 // vdst operand has u32 type. .. _amdgpu_syn_instruction_modifiers_notation:. Modifiers; =========. An instruction may have zero or more optional *modifiers*. They are space-separated in the description:. | ``<``\ :ref:`description of modifier 0<amdgpu_syn_instruction_modifier_notation>`\ ``>; <``\ :ref:`description of modifier 1<amdgpu_syn_instruction_modifier_notation>`\ ``> ...``. The order of *modifiers* is fixed. .. _amdgpu_syn_instruction_modifier_notation:. Notation; ~~~~~~~~. A *modifier* is des",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUInstructionNotation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUInstructionNotation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:3563,Availability,mask,mask,3563,"sitive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; ==================== ====================================================================. Examples:. .. parsed-literal::. offset:65535; offset:0xffff; offset:-x-y. .. _amdgpu_synid_sw_offset16:. swizzle pattern; ~~~~~~~~~~~~~~~. This is a special modifier that may be used with *ds_swizzle_b32* instruction only.; It specifies a swizzle pattern in numeric or symbolic form. The default value is 0. ======================================================= ===========================================================; Syntax Description; ======================================================= ===========================================================; offset:{0..0xFFFF} Specifies a 16-bit swizzle pattern.; offset:swizzle(QUAD_PERM,{0..3},{0..3},{0..3},{0..3}) Specifies a quad permute mode pattern. Each number is a lane *id*.; offset:swizzle(BITMASK_PERM, ""<mask>"") Specifies a bitmask permute mode pattern. The pattern converts a 5-bit lane *id* to another; lane *id* with which the lane interacts. The *mask* is a 5-character sequence which; specifies how to transform the bits of the; lane *id*. The following characters are allowed:. * ""0"" - set bit to 0. * ""1"" - set bit to 1. * ""p"" - preserve bit. * ""i"" - inverse bit. offset:swizzle(BROADCAST,{2..32},{0..N}) Specifies a broadcast mode. Broadcasts the value of any particular lane to; all lanes in its group. The first numeric parameter is a group; size and must be equal to 2, 4, 8, 16 or 32. The second numeric parameter is an index of the; lane being broadcast. The index must not exceed group size.; offset:swizzle(SWAP,{1..16}) Specifies a swap mode. Swaps the neighboring groups of; 1, 2, 4, 8 or 16 lanes.; offset:swizzle(REVERSE,{2..32}) Specifies a reverse mode. Reverses the lanes for groups of 2, 4, 8, 16 or 32 lanes.; ======================================================= ======================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:3710,Availability,mask,mask,3710,"=====================================. Examples:. .. parsed-literal::. offset:65535; offset:0xffff; offset:-x-y. .. _amdgpu_synid_sw_offset16:. swizzle pattern; ~~~~~~~~~~~~~~~. This is a special modifier that may be used with *ds_swizzle_b32* instruction only.; It specifies a swizzle pattern in numeric or symbolic form. The default value is 0. ======================================================= ===========================================================; Syntax Description; ======================================================= ===========================================================; offset:{0..0xFFFF} Specifies a 16-bit swizzle pattern.; offset:swizzle(QUAD_PERM,{0..3},{0..3},{0..3},{0..3}) Specifies a quad permute mode pattern. Each number is a lane *id*.; offset:swizzle(BITMASK_PERM, ""<mask>"") Specifies a bitmask permute mode pattern. The pattern converts a 5-bit lane *id* to another; lane *id* with which the lane interacts. The *mask* is a 5-character sequence which; specifies how to transform the bits of the; lane *id*. The following characters are allowed:. * ""0"" - set bit to 0. * ""1"" - set bit to 1. * ""p"" - preserve bit. * ""i"" - inverse bit. offset:swizzle(BROADCAST,{2..32},{0..N}) Specifies a broadcast mode. Broadcasts the value of any particular lane to; all lanes in its group. The first numeric parameter is a group; size and must be equal to 2, 4, 8, 16 or 32. The second numeric parameter is an index of the; lane being broadcast. The index must not exceed group size.; offset:swizzle(SWAP,{1..16}) Specifies a swap mode. Swaps the neighboring groups of; 1, 2, 4, 8 or 16 lanes.; offset:swizzle(REVERSE,{2..32}) Specifies a reverse mode. Reverses the lanes for groups of 2, 4, 8, 16 or 32 lanes.; ======================================================= ===========================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:6471,Availability,mask,mask,6471,"ecifies if this is the last export from the shader to the target. By default,; an *export* instruction does not finish an export sequence. ======================================== ================================================; Syntax Description; ======================================== ================================================; done Indicates the last export operation.; ======================================== ================================================. .. _amdgpu_synid_compr:. compr; ~~~~~. Indicates if the data is compressed (data is not compressed by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; compr Data is compressed.; ======================================== ================================================. .. _amdgpu_synid_vm:. vm; ~~. Specifies if the :ref:`exec<amdgpu_synid_exec>` mask is valid for this *export* instruction; (the mask is not valid by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; vm Set the flag indicating a valid; :ref:`exec<amdgpu_synid_exec>` mask.; ======================================== ================================================. .. _amdgpu_synid_row_en:. row_en; ~~~~~~. Specifies whether to export one row or multiple rows of data. ======================================== ================================================; Syntax Description; ======================================== ================================================; row_en Export multiple rows using row index from M0.; ======================================== ================================================. FLAT Modifiers; --------------. .. _amdgpu_synid_flat_offset12:. offset12; ~~~~~~~~. Specifies an immediate unsigned ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:6521,Availability,mask,mask,6521,"ecifies if this is the last export from the shader to the target. By default,; an *export* instruction does not finish an export sequence. ======================================== ================================================; Syntax Description; ======================================== ================================================; done Indicates the last export operation.; ======================================== ================================================. .. _amdgpu_synid_compr:. compr; ~~~~~. Indicates if the data is compressed (data is not compressed by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; compr Data is compressed.; ======================================== ================================================. .. _amdgpu_synid_vm:. vm; ~~. Specifies if the :ref:`exec<amdgpu_synid_exec>` mask is valid for this *export* instruction; (the mask is not valid by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; vm Set the flag indicating a valid; :ref:`exec<amdgpu_synid_exec>` mask.; ======================================== ================================================. .. _amdgpu_synid_row_en:. row_en; ~~~~~~. Specifies whether to export one row or multiple rows of data. ======================================== ================================================; Syntax Description; ======================================== ================================================; row_en Export multiple rows using row index from M0.; ======================================== ================================================. FLAT Modifiers; --------------. .. _amdgpu_synid_flat_offset12:. offset12; ~~~~~~~~. Specifies an immediate unsigned ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:6821,Availability,mask,mask,6821,"==========================; Syntax Description; ======================================== ================================================; done Indicates the last export operation.; ======================================== ================================================. .. _amdgpu_synid_compr:. compr; ~~~~~. Indicates if the data is compressed (data is not compressed by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; compr Data is compressed.; ======================================== ================================================. .. _amdgpu_synid_vm:. vm; ~~. Specifies if the :ref:`exec<amdgpu_synid_exec>` mask is valid for this *export* instruction; (the mask is not valid by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; vm Set the flag indicating a valid; :ref:`exec<amdgpu_synid_exec>` mask.; ======================================== ================================================. .. _amdgpu_synid_row_en:. row_en; ~~~~~~. Specifies whether to export one row or multiple rows of data. ======================================== ================================================; Syntax Description; ======================================== ================================================; row_en Export multiple rows using row index from M0.; ======================================== ================================================. FLAT Modifiers; --------------. .. _amdgpu_synid_flat_offset12:. offset12; ~~~~~~~~. Specifies an immediate unsigned 12-bit offset, in bytes. The default value is 0. ================= ====================================================================; Syntax Description; ================= ===========================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:38267,Availability,mask,mask,38267,"re is no default value. The *dpp8_sel* modifier must specify exactly 8 values.; The first value selects which lane to read from to supply data into lane 0.; The second value controls lane 1 and so on. Each value may be specified as either; an :ref:`integer number<amdgpu_synid_integer_number>` or; an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. =============================================================== ===========================; Syntax Description; =============================================================== ===========================; dpp8:[{0..7},{0..7},{0..7},{0..7},{0..7},{0..7},{0..7},{0..7}] Select lanes to read from.; =============================================================== ===========================. Examples:. .. parsed-literal::. dpp8:[7,6,5,4,3,2,1,0]; dpp8:[0,1,0,1,0,1,0,1]. .. _amdgpu_synid_fi8:. fi; ~~. Controls interaction with inactive lanes for *dpp8* instructions. The default value is zero. Note: *inactive* lanes are those whose :ref:`exec<amdgpu_synid_exec>` mask bit is zero. ==================================== =====================================================; Syntax Description; ==================================== =====================================================; fi:0 Fetch zero when accessing data from inactive lanes.; fi:1 Fetch pre-existing values from inactive lanes.; ==================================== =====================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. DPP Modifiers; -------------. .. _amdgpu_synid_dpp_ctrl:. dpp_ctrl; ~~~~~~~~. Specifies how data is shared between threads. This is a mandatory modifier.; There is no default value. Note: the lanes of a wavefront are organized in four *rows* and four *banks*. ======================================== ========================================================; Syntax Description; =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:44405,Availability,mask,mask,44405,"==================== ==================================================; row_newbcast:{1..15} Broadcast a thread within a row to the whole row.; ======================================== ==================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Examples:. .. parsed-literal::. row_newbcast:3. .. _amdgpu_synid_row_mask:. row_mask; ~~~~~~~~. Controls which rows are enabled for data sharing. By default, all rows are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================= ====================================================================; Syntax Description; ================= ====================================================================; row_mask:{0..15} Specifies a *row mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one row; (0 - disabled, 1 - enabled). In *wave32* mode, the values shall be limited to {0..7}.; ================= ====================================================================. Examples:. .. parsed-literal::. row_mask:0xf; row_mask:0b1010; row_mask:x|y. .. _amdgpu_synid_bank_mask:. bank_mask; ~~~~~~~~~. Controls which banks are enabled for data sharing. By default, all banks are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================== ====================================================================; Syntax Description; ================== ====================================================================; bank_mask:{0..15} Specifies a *bank mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_abs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:44573,Availability,mask,mask,44573,"a row to the whole row.; ======================================== ==================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Examples:. .. parsed-literal::. row_newbcast:3. .. _amdgpu_synid_row_mask:. row_mask; ~~~~~~~~. Controls which rows are enabled for data sharing. By default, all rows are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================= ====================================================================; Syntax Description; ================= ====================================================================; row_mask:{0..15} Specifies a *row mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one row; (0 - disabled, 1 - enabled). In *wave32* mode, the values shall be limited to {0..7}.; ================= ====================================================================. Examples:. .. parsed-literal::. row_mask:0xf; row_mask:0b1010; row_mask:x|y. .. _amdgpu_synid_bank_mask:. bank_mask; ~~~~~~~~~. Controls which banks are enabled for data sharing. By default, all banks are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================== ====================================================================; Syntax Description; ================== ====================================================================; bank_mask:{0..15} Specifies a *bank mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one bank; (0 - disabled, 1 - enabled).; ================== =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:45343,Availability,mask,mask,45343,"ow mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one row; (0 - disabled, 1 - enabled). In *wave32* mode, the values shall be limited to {0..7}.; ================= ====================================================================. Examples:. .. parsed-literal::. row_mask:0xf; row_mask:0b1010; row_mask:x|y. .. _amdgpu_synid_bank_mask:. bank_mask; ~~~~~~~~~. Controls which banks are enabled for data sharing. By default, all banks are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================== ====================================================================; Syntax Description; ================== ====================================================================; bank_mask:{0..15} Specifies a *bank mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one bank; (0 - disabled, 1 - enabled).; ================== ====================================================================. Examples:. .. parsed-literal::. bank_mask:0x3; bank_mask:0b0011; bank_mask:x&y. .. _amdgpu_synid_bound_ctrl:. bound_ctrl; ~~~~~~~~~~. Controls data sharing when accessing an invalid lane. By default, data sharing with; invalid lanes is disabled. ======================================== ================================================; Syntax Description; ======================================== ================================================; bound_ctrl:1 Enables data sharing with invalid lanes. Accessing data from an invalid lane will; return zero. bound_ctrl:0 (GFX11+) Disables data sharing with invalid lanes.; ======================================== ================================================. .. WARNING:: For historical reasons,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:45511,Availability,mask,mask,45511,"_absolute_expression>`. Each of the 4 bits in the mask controls one row; (0 - disabled, 1 - enabled). In *wave32* mode, the values shall be limited to {0..7}.; ================= ====================================================================. Examples:. .. parsed-literal::. row_mask:0xf; row_mask:0b1010; row_mask:x|y. .. _amdgpu_synid_bank_mask:. bank_mask; ~~~~~~~~~. Controls which banks are enabled for data sharing. By default, all banks are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================== ====================================================================; Syntax Description; ================== ====================================================================; bank_mask:{0..15} Specifies a *bank mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one bank; (0 - disabled, 1 - enabled).; ================== ====================================================================. Examples:. .. parsed-literal::. bank_mask:0x3; bank_mask:0b0011; bank_mask:x&y. .. _amdgpu_synid_bound_ctrl:. bound_ctrl; ~~~~~~~~~~. Controls data sharing when accessing an invalid lane. By default, data sharing with; invalid lanes is disabled. ======================================== ================================================; Syntax Description; ======================================== ================================================; bound_ctrl:1 Enables data sharing with invalid lanes. Accessing data from an invalid lane will; return zero. bound_ctrl:0 (GFX11+) Disables data sharing with invalid lanes.; ======================================== ================================================. .. WARNING:: For historical reasons, *bound_ctrl:0* has the same meaning as *bound_ctrl:1* for older architectures. .. _amdgpu_synid_fi16:. fi; ~~. Controls ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:46681,Availability,mask,mask,46681,"Examples:. .. parsed-literal::. bank_mask:0x3; bank_mask:0b0011; bank_mask:x&y. .. _amdgpu_synid_bound_ctrl:. bound_ctrl; ~~~~~~~~~~. Controls data sharing when accessing an invalid lane. By default, data sharing with; invalid lanes is disabled. ======================================== ================================================; Syntax Description; ======================================== ================================================; bound_ctrl:1 Enables data sharing with invalid lanes. Accessing data from an invalid lane will; return zero. bound_ctrl:0 (GFX11+) Disables data sharing with invalid lanes.; ======================================== ================================================. .. WARNING:: For historical reasons, *bound_ctrl:0* has the same meaning as *bound_ctrl:1* for older architectures. .. _amdgpu_synid_fi16:. fi; ~~. Controls interaction with *inactive* lanes for *dpp16* instructions. The default value is zero. Note: *inactive* lanes are those whose :ref:`exec<amdgpu_synid_exec>` mask bit is zero. ======================================== ==================================================; Syntax Description; ======================================== ==================================================; fi:0 Interaction with inactive lanes is controlled by; :ref:`bound_ctrl<amdgpu_synid_bound_ctrl>`. fi:1 Fetch pre-existing values from inactive lanes.; ======================================== ==================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. SDWA Modifiers; --------------. clamp; ~~~~~. See a description :ref:`here<amdgpu_synid_clamp>`. omod; ~~~~. See a description :ref:`here<amdgpu_synid_omod>`. .. _amdgpu_synid_dst_sel:. dst_sel; ~~~~~~~. Selects which bits in the destination are affected. By default, all bits are affected. ======================================== ====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:11471,Integrability,depend,depending,11471,"e a description :ref:`here<amdgpu_synid_sc0>`. sc1; ~~~. See a description :ref:`here<amdgpu_synid_sc1>`. nt; ~~. See a description :ref:`here<amdgpu_synid_nt>`. MIMG Modifiers; --------------. .. _amdgpu_synid_dmask:. dmask; ~~~~~. Specifies which channels (image components) are used by the operation.; By default, no channels are used. =============== ====================================================================; Syntax Description; =============== ====================================================================; dmask:{0..15} Specifies image channels as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each bit corresponds to one of 4 image components (RGBA). If the specified bit value is 0, the image component is not used,; while value 1 means that the component is used.; =============== ====================================================================. This modifier has some limitations depending on the instruction kind:. =================================================== ========================; Instruction Kind Valid dmask Values; =================================================== ========================; 32-bit atomic *cmpswap* 0x3; 32-bit atomic instructions except for *cmpswap* 0x1; 64-bit atomic *cmpswap* 0xF; 64-bit atomic instructions except for *cmpswap* 0x3; *gather4* 0x1, 0x2, 0x4, 0x8; GFX11+ *msaa_load* 0x1, 0x2, 0x4, 0x8; Other instructions any value; =================================================== ========================. Examples:. .. parsed-literal::. dmask:0xf; dmask:0b1111; dmask:x|y|z. .. _amdgpu_synid_unorm:. unorm; ~~~~~. Specifies whether the address is normalized or not (the address is normalized by default). ======================== ========================================; Syntax Description; ======================== ========================================; unorm Force the address to be not normalized.; ======================== ====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17102,Integrability,synchroniz,synchronization,17102,"h is supported; for compatibility with SP3 assembler:. =============================== =========================================================; Syntax Description; =============================== =========================================================; dim:SQ_RSRC_IMG_1D One-dimensional image.; dim:SQ_RSRC_IMG_2D Two-dimensional image.; dim:SQ_RSRC_IMG_3D Three-dimensional image.; dim:SQ_RSRC_IMG_CUBE Cubemap array.; dim:SQ_RSRC_IMG_1D_ARRAY One-dimensional image array.; dim:SQ_RSRC_IMG_2D_ARRAY Two-dimensional image array.; dim:SQ_RSRC_IMG_2D_MSAA Two-dimensional multi-sample auto-aliasing image.; dim:SQ_RSRC_IMG_2D_MSAA_ARRAY Two-dimensional multi-sample auto-aliasing image array.; =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:53352,Integrability,depend,depends,53352,"0,1]. .. _amdgpu_synid_dpp_op_sel:. dpp_op_sel; ~~~~~~~~~~. This is a special version of *op_sel* used for *permlane* opcodes to specify; dpp-like mode bits - :ref:`fi<amdgpu_synid_fi16>` and; :ref:`bound_ctrl<amdgpu_synid_bound_ctrl>`. ======================================== =================================================================; Syntax Description; ======================================== =================================================================; op_sel:[{0..1},{0..1}] The first bit specifies :ref:`fi<amdgpu_synid_fi16>`, the second; bit specifies :ref:`bound_ctrl<amdgpu_synid_bound_ctrl>`.; ======================================== =================================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Examples:. .. parsed-literal::. op_sel:[0,0]. .. _amdgpu_synid_clamp:. clamp; ~~~~~. Clamp meaning depends on instruction. For *v_cmp* instructions, clamp modifier indicates that the compare signals; if a floating-point exception occurs. By default, signaling is disabled. For integer operations, clamp modifier indicates that the result must be clamped; to the largest and smallest representable value. By default, there is no clamping. For floating-point operations, clamp modifier indicates that the result must be clamped; to the range [0.0, 1.0]. By default, there is no clamping. Note: clamp modifier is applied after :ref:`output modifiers<amdgpu_synid_omod>` (if any). ======================================== ================================================; Syntax Description; ======================================== ================================================; clamp Enables clamping (or signaling).; ======================================== ================================================. .. _amdgpu_synid_omod:. omod; ~~~~. Specifies if an output modifier must be applied to the re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:48601,Modifiability,extend,extend,48601,"cted. ======================================== ================================================; Syntax Description; ======================================== ================================================; dst_sel:DWORD Use bits 31:0.; dst_sel:BYTE_0 Use bits 7:0.; dst_sel:BYTE_1 Use bits 15:8.; dst_sel:BYTE_2 Use bits 23:16.; dst_sel:BYTE_3 Use bits 31:24.; dst_sel:WORD_0 Use bits 15:0.; dst_sel:WORD_1 Use bits 31:16.; ======================================== ================================================. .. _amdgpu_synid_dst_unused:. dst_unused; ~~~~~~~~~~. Controls what to do with the bits in the destination which are not selected; by :ref:`dst_sel<amdgpu_synid_dst_sel>`.; By default, unused bits are preserved. ======================================== ================================================; Syntax Description; ======================================== ================================================; dst_unused:UNUSED_PAD Pad with zeros.; dst_unused:UNUSED_SEXT Sign-extend upper bits, zero lower bits.; dst_unused:UNUSED_PRESERVE Preserve bits.; ======================================== ================================================. .. _amdgpu_synid_src0_sel:. src0_sel; ~~~~~~~~. Controls which bits in the src0 are used. By default, all bits are used. ======================================== ================================================; Syntax Description; ======================================== ================================================; src0_sel:DWORD Use bits 31:0.; src0_sel:BYTE_0 Use bits 7:0.; src0_sel:BYTE_1 Use bits 15:8.; src0_sel:BYTE_2 Use bits 23:16.; src0_sel:BYTE_3 Use bits 31:24.; src0_sel:WORD_0 Use bits 15:0.; src0_sel:WORD_1 Use bits 31:16.; ======================================== ================================================. .. _amdgpu_synid_src1_sel:. src1_sel; ~~~~~~~~. Controls which bits in the src1 are used. By default, all bits are used. ======================================== ===============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:50379,Modifiability,extend,extends,50379,".. _amdgpu_synid_src1_sel:. src1_sel; ~~~~~~~~. Controls which bits in the src1 are used. By default, all bits are used. ======================================== ================================================; Syntax Description; ======================================== ================================================; src1_sel:DWORD Use bits 31:0.; src1_sel:BYTE_0 Use bits 7:0.; src1_sel:BYTE_1 Use bits 15:8.; src1_sel:BYTE_2 Use bits 23:16.; src1_sel:BYTE_3 Use bits 31:24.; src1_sel:WORD_0 Use bits 15:0.; src1_sel:WORD_1 Use bits 31:16.; ======================================== ================================================. .. _amdgpu_synid_sdwa_operand_modifiers:. SDWA Operand Modifiers; ----------------------. Operand modifiers are not used separately. They are applied to source operands. abs; ~~~. See a description :ref:`here<amdgpu_synid_abs>`. neg; ~~~. See a description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_sext:. sext; ~~~~. Sign-extends the value of a (sub-dword) integer operand to fill all 32 bits. Valid for integer operands only. ======================================== ================================================; Syntax Description; ======================================== ================================================; sext(<operand>) Sign-extend operand value.; ======================================== ================================================. Examples:. .. parsed-literal::. sext(v4); sext(v255). VOP3 Modifiers; --------------. .. _amdgpu_synid_vop3_op_sel:. op_sel; ~~~~~~. Selects the low [15:0] or high [31:16] operand bits for source and destination operands.; By default, low bits are used for all operands. The number of values specified with the op_sel modifier must match the number of instruction; operands (both source and destination). The first value controls src0, the second value controls src1; and so on, except that the last value controls destination.; The value 0 selects the low bits, while 1 selects the high bit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:50707,Modifiability,extend,extend,50707,"================; Syntax Description; ======================================== ================================================; src1_sel:DWORD Use bits 31:0.; src1_sel:BYTE_0 Use bits 7:0.; src1_sel:BYTE_1 Use bits 15:8.; src1_sel:BYTE_2 Use bits 23:16.; src1_sel:BYTE_3 Use bits 31:24.; src1_sel:WORD_0 Use bits 15:0.; src1_sel:WORD_1 Use bits 31:16.; ======================================== ================================================. .. _amdgpu_synid_sdwa_operand_modifiers:. SDWA Operand Modifiers; ----------------------. Operand modifiers are not used separately. They are applied to source operands. abs; ~~~. See a description :ref:`here<amdgpu_synid_abs>`. neg; ~~~. See a description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_sext:. sext; ~~~~. Sign-extends the value of a (sub-dword) integer operand to fill all 32 bits. Valid for integer operands only. ======================================== ================================================; Syntax Description; ======================================== ================================================; sext(<operand>) Sign-extend operand value.; ======================================== ================================================. Examples:. .. parsed-literal::. sext(v4); sext(v255). VOP3 Modifiers; --------------. .. _amdgpu_synid_vop3_op_sel:. op_sel; ~~~~~~. Selects the low [15:0] or high [31:16] operand bits for source and destination operands.; By default, low bits are used for all operands. The number of values specified with the op_sel modifier must match the number of instruction; operands (both source and destination). The first value controls src0, the second value controls src1; and so on, except that the last value controls destination.; The value 0 selects the low bits, while 1 selects the high bits. Note: op_sel modifier affects 16-bit operands only. For 32-bit operands, the value specified; by op_sel must be 0. ======================================== ===================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:14397,Performance,load,loads,14397,"============================ ================================================; lwe Enables LOD warning.; ======================================== ================================================. .. _amdgpu_synid_da:. da; ~~. Specifies if an array index must be sent to TA. By default, the array index is not sent. ======================================== ================================================; Syntax Description; ======================================== ================================================; da Send an array index to TA.; ======================================== ================================================. .. _amdgpu_synid_d16:. d16; ~~~. Specifies data size: 16 or 32 bits (32 bits by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; d16 Enables 16-bits data mode. On loads, convert data in memory to 16-bit; format before storing it in VGPRs. For stores, convert 16-bit data in VGPRs to; 32 bits before writing the values to memory. Note that GFX8.0 does not support data packing.; Each 16-bit data element occupies 1 VGPR. GFX8.1 and GFX9+ support data packing.; Each pair of 16-bit data elements; occupies 1 VGPR.; ======================================== ================================================. .. _amdgpu_synid_a16:. a16; ~~~. Specifies the size of image address components: 16 or 32 bits (32 bits by default). ======================================== ================================================; Syntax Description; ======================================== ================================================; a16 Enables 16-bits image address components.; ======================================== ================================================. .. _amdgpu_synid_dim:. dim; ~~~. Specifies surface dimension. This is a mandatory modifier. There is no default value. ===================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17057,Performance,cache,cache,17057,"g table defines an alternative syntax which is supported; for compatibility with SP3 assembler:. =============================== =========================================================; Syntax Description; =============================== =========================================================; dim:SQ_RSRC_IMG_1D One-dimensional image.; dim:SQ_RSRC_IMG_2D Two-dimensional image.; dim:SQ_RSRC_IMG_3D Three-dimensional image.; dim:SQ_RSRC_IMG_CUBE Cubemap array.; dim:SQ_RSRC_IMG_1D_ARRAY One-dimensional image array.; dim:SQ_RSRC_IMG_2D_ARRAY Two-dimensional image array.; dim:SQ_RSRC_IMG_2D_MSAA Two-dimensional multi-sample auto-aliasing image.; dim:SQ_RSRC_IMG_2D_MSAA_ARRAY Two-dimensional multi-sample auto-aliasing image array.; =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== =============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17176,Performance,cache,cache,17176,"=================== =========================================================; Syntax Description; =============================== =========================================================; dim:SQ_RSRC_IMG_1D One-dimensional image.; dim:SQ_RSRC_IMG_2D Two-dimensional image.; dim:SQ_RSRC_IMG_3D Three-dimensional image.; dim:SQ_RSRC_IMG_CUBE Cubemap array.; dim:SQ_RSRC_IMG_1D_ARRAY One-dimensional image array.; dim:SQ_RSRC_IMG_2D_ARRAY Two-dimensional image array.; dim:SQ_RSRC_IMG_2D_MSAA Two-dimensional multi-sample auto-aliasing image.; dim:SQ_RSRC_IMG_2D_MSAA_ARRAY Two-dimensional multi-sample auto-aliasing image array.; =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== =========================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17270,Performance,cache,cache,17270,"Syntax Description; =============================== =========================================================; dim:SQ_RSRC_IMG_1D One-dimensional image.; dim:SQ_RSRC_IMG_2D Two-dimensional image.; dim:SQ_RSRC_IMG_3D Three-dimensional image.; dim:SQ_RSRC_IMG_CUBE Cubemap array.; dim:SQ_RSRC_IMG_1D_ARRAY One-dimensional image array.; dim:SQ_RSRC_IMG_2D_ARRAY Two-dimensional image array.; dim:SQ_RSRC_IMG_2D_MSAA Two-dimensional multi-sample auto-aliasing image.; dim:SQ_RSRC_IMG_2D_MSAA_ARRAY Two-dimensional multi-sample auto-aliasing image array.; =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17503,Performance,cache,cache,17503,"onal image.; dim:SQ_RSRC_IMG_2D Two-dimensional image.; dim:SQ_RSRC_IMG_3D Three-dimensional image.; dim:SQ_RSRC_IMG_CUBE Cubemap array.; dim:SQ_RSRC_IMG_1D_ARRAY One-dimensional image array.; dim:SQ_RSRC_IMG_2D_ARRAY Two-dimensional image array.; dim:SQ_RSRC_IMG_2D_MSAA Two-dimensional multi-sample auto-aliasing image.; dim:SQ_RSRC_IMG_2D_MSAA_ARRAY Two-dimensional multi-sample auto-aliasing image array.; =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:17838,Performance,cache,cache,17838," =============================== =========================================================. dlc; ~~~. See a description :ref:`here<amdgpu_synid_dlc>`. Miscellaneous Modifiers; -----------------------. .. _amdgpu_synid_dlc:. dlc; ~~~. Controls device level cache policy for memory operations. Used for synchronization.; When specified, forces operation to bypass device level cache, making the operation device; level coherent. By default, instructions use device level cache. ======================================== ================================================; Syntax Description; ======================================== ================================================; dlc Bypass device level cache.; ======================================== ================================================. .. _amdgpu_synid_glc:. glc; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`slc<amdgpu_synid_slc>`; to specify cache policy. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; glc Set glc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ======================================== ===========================; lds Store the result in LDS.; ======================================== ===========================. .. _amdgpu_synid_nv:. nv; ~~. Specifies if the instruction is operating on non-volatile memory.; By default, memory is volatile. ======================================== ================================================; Syntax Description; =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:19109,Performance,cache,cache,19109," to 1.; ======================================== ================================================. .. _amdgpu_synid_lds:. lds; ~~~. Specifies where to store the result: VGPRs or LDS (VGPRs by default). ======================================== ===========================; Syntax Description; ======================================== ===========================; lds Store the result in LDS.; ======================================== ===========================. .. _amdgpu_synid_nv:. nv; ~~. Specifies if the instruction is operating on non-volatile memory.; By default, memory is volatile. ======================================== ================================================; Syntax Description; ======================================== ================================================; nv Indicates that the instruction operates on; non-volatile memory.; ======================================== ================================================. .. _amdgpu_synid_slc:. slc; ~~~. Controls behavior of L2 cache. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; slc Set slc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_tfe:. tfe; ~~~. Controls access to partially resident textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:20125,Performance,cache,cache,20125,"trols behavior of L2 cache. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; slc Set slc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_tfe:. tfe; ~~~. Controls access to partially resident textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu_synid_sc1>`; to specify cache policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc0 Set sc0 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc1:. sc1; ~~~. This modifier is used together with :ref:`sc0<amdgpu_synid_sc0>` to specify cache; policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc1 Set sc1 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_nt:. nt; ~~. Indicates an operation with non-temporal data. ======================================== ================================================; Syntax Description; ======",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:20564,Performance,cache,cache,20564," textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu_synid_sc1>`; to specify cache policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc0 Set sc0 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc1:. sc1; ~~~. This modifier is used together with :ref:`sc0<amdgpu_synid_sc0>` to specify cache; policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc1 Set sc1 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_nt:. nt; ~~. Indicates an operation with non-temporal data. ======================================== ================================================; Syntax Description; ======================================== ================================================; nt Set nt bit to 1.; ======================================== ================================================. MUBUF/MTBUF Modifiers; ---------------------. .. _amdgpu_synid_idxen:. idxen; ~~~~~. Specifies whether address components include an index. By default, the index is not used. May be used together with :ref:`offen<amdgpu_synid_offen>`. Cannot be us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:35975,Performance,perform,performed,35975,"`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; ============================= ====================================================================. Examples:. .. parsed-literal::. offset:-1; offset:0xfffff; offset:-x. VINTRP/VINTERP/LDSDIR Modifiers; -------------------------------. .. _amdgpu_synid_high:. high; ~~~~. Specifies which half of the LDS word to use. Low half of LDS word is used by default. ======================================== ================================; Syntax Description; ======================================== ================================; high Use the high half of LDS word.; ======================================== ================================. neg; ~~~. See a description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_wait_exp:. wait_exp; ~~~~~~~~. Specifies a wait on the EXP counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 7, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================ ======================================================; Syntax Description; ================ ======================================================; wait_exp:{0..7} An additional wait on the EXP counter before; issuing this instruction.; ================ ======================================================. .. _amdgpu_synid_wait_vdst:. wait_vdst; ~~~~~~~~~. Specifies a wait on the VA_VDST counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 15, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================== ======================================================; Syntax Description; ================== ======================================================; wait_vdst:{0..15} An additional wait on the VA_VDST counter before; issuing t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:36634,Performance,perform,performed,36634,"=================== ================================. neg; ~~~. See a description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_wait_exp:. wait_exp; ~~~~~~~~. Specifies a wait on the EXP counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 7, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================ ======================================================; Syntax Description; ================ ======================================================; wait_exp:{0..7} An additional wait on the EXP counter before; issuing this instruction.; ================ ======================================================. .. _amdgpu_synid_wait_vdst:. wait_vdst; ~~~~~~~~~. Specifies a wait on the VA_VDST counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 15, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================== ======================================================; Syntax Description; ================== ======================================================; wait_vdst:{0..15} An additional wait on the VA_VDST counter before; issuing this instruction.; ================== ======================================================. DPP8 Modifiers; --------------. .. _amdgpu_synid_dpp8_sel:. dpp8_sel; ~~~~~~~~. Selects which lanes to pull data from, within a group of 8 lanes. This is a mandatory modifier.; There is no default value. The *dpp8_sel* modifier must specify exactly 8 values.; The first value selects which lane to read from to supply data into lane 0.; The second value controls lane 1 and so on. Each value may be specified as either; an :ref:`integer number<amdgpu_synid_integer_number>` or; an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. =======================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:36023,Safety,safe,safe,36023,".; ============================= ====================================================================. Examples:. .. parsed-literal::. offset:-1; offset:0xfffff; offset:-x. VINTRP/VINTERP/LDSDIR Modifiers; -------------------------------. .. _amdgpu_synid_high:. high; ~~~~. Specifies which half of the LDS word to use. Low half of LDS word is used by default. ======================================== ================================; Syntax Description; ======================================== ================================; high Use the high half of LDS word.; ======================================== ================================. neg; ~~~. See a description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_wait_exp:. wait_exp; ~~~~~~~~. Specifies a wait on the EXP counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 7, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================ ======================================================; Syntax Description; ================ ======================================================; wait_exp:{0..7} An additional wait on the EXP counter before; issuing this instruction.; ================ ======================================================. .. _amdgpu_synid_wait_vdst:. wait_vdst; ~~~~~~~~~. Specifies a wait on the VA_VDST counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 15, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================== ======================================================; Syntax Description; ================== ======================================================; wait_vdst:{0..15} An additional wait on the VA_VDST counter before; issuing this instruction.; ================== ================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:36682,Safety,safe,safe,36682,"description :ref:`here<amdgpu_synid_neg>`. .. _amdgpu_synid_wait_exp:. wait_exp; ~~~~~~~~. Specifies a wait on the EXP counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 7, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================ ======================================================; Syntax Description; ================ ======================================================; wait_exp:{0..7} An additional wait on the EXP counter before; issuing this instruction.; ================ ======================================================. .. _amdgpu_synid_wait_vdst:. wait_vdst; ~~~~~~~~~. Specifies a wait on the VA_VDST counter before issuing the current instruction.; The counter must be less than or equal to this value before the instruction is issued.; If set to 15, no wait is performed. The default value is zero. This is a safe value, but it may be suboptimal. ================== ======================================================; Syntax Description; ================== ======================================================; wait_vdst:{0..15} An additional wait on the VA_VDST counter before; issuing this instruction.; ================== ======================================================. DPP8 Modifiers; --------------. .. _amdgpu_synid_dpp8_sel:. dpp8_sel; ~~~~~~~~. Selects which lanes to pull data from, within a group of 8 lanes. This is a mandatory modifier.; There is no default value. The *dpp8_sel* modifier must specify exactly 8 values.; The first value selects which lane to read from to supply data into lane 0.; The second value controls lane 1 and so on. Each value may be specified as either; an :ref:`integer number<amdgpu_synid_integer_number>` or; an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. =============================================================== ===========================;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:55969,Safety,avoid,avoid,55969,"mdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. Examples:. .. parsed-literal::. mul:2; mul:x // x must be equal to 2 or 4. .. _amdgpu_synid_vop3_operand_modifiers:. VOP3 Operand Modifiers; ----------------------. Operand modifiers are not used separately. They are applied to source operands. .. _amdgpu_synid_abs:. abs; ~~~. Computes the absolute value of its operand. Must be applied before :ref:`neg<amdgpu_synid_neg>`; (if any). Valid for floating-point operands only. ======================================== ====================================================; Syntax Description; ======================================== ====================================================; abs(<operand>) Get the absolute value of a floating-point operand.; \|<operand>| The same as above (an SP3 syntax).; ======================================== ====================================================. Note: avoid using SP3 syntax with operands specified as expressions because the trailing '|'; may be misinterpreted. Such operands should be enclosed into additional parentheses, as shown; in examples below. Examples:. .. parsed-literal::. abs(v36); \|v36|; abs(x|y) // ok; \|(x|y)| // additional parentheses are required. .. _amdgpu_synid_neg:. neg; ~~~. Computes the negative value of its operand. Must be applied after :ref:`abs<amdgpu_synid_abs>`; (if any). Valid for floating-point operands only. ================== ====================================================; Syntax Description; ================== ====================================================; neg(<operand>) Get the negative value of a floating-point operand.; An optional :ref:`abs<amdgpu_synid_abs>` modifier; may be applied to the operand before negation.; -<operand> The same as above (an SP3 syntax).; ================== ====================================================. Note: SP3 syntax is supported with limitations because of a potential ambiguity.; Currently, it is allo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:19504,Security,access,access,19504,"============= ===========================. .. _amdgpu_synid_nv:. nv; ~~. Specifies if the instruction is operating on non-volatile memory.; By default, memory is volatile. ======================================== ================================================; Syntax Description; ======================================== ================================================; nv Indicates that the instruction operates on; non-volatile memory.; ======================================== ================================================. .. _amdgpu_synid_slc:. slc; ~~~. Controls behavior of L2 cache. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; slc Set slc bit to 1.; ======================================== ================================================. .. _amdgpu_synid_tfe:. tfe; ~~~. Controls access to partially resident textures. The default value is off (0). ======================================== ================================================; Syntax Description; ======================================== ================================================; tfe Set tfe bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc0:. sc0; ~~~. For atomic opcodes, this modifier indicates that the instruction returns the value from memory; before the operation. For other opcodes, it is used together with :ref:`sc1<amdgpu_synid_sc1>`; to specify cache policy. ======================================== ================================================; Syntax Description; ======================================== ================================================; sc0 Set sc0 bit to 1.; ======================================== ================================================. .. _amdgpu_synid_sc1:. sc1; ~~~. This modifier is used together",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:38510,Security,access,accessing,38510,"controls lane 1 and so on. Each value may be specified as either; an :ref:`integer number<amdgpu_synid_integer_number>` or; an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. =============================================================== ===========================; Syntax Description; =============================================================== ===========================; dpp8:[{0..7},{0..7},{0..7},{0..7},{0..7},{0..7},{0..7},{0..7}] Select lanes to read from.; =============================================================== ===========================. Examples:. .. parsed-literal::. dpp8:[7,6,5,4,3,2,1,0]; dpp8:[0,1,0,1,0,1,0,1]. .. _amdgpu_synid_fi8:. fi; ~~. Controls interaction with inactive lanes for *dpp8* instructions. The default value is zero. Note: *inactive* lanes are those whose :ref:`exec<amdgpu_synid_exec>` mask bit is zero. ==================================== =====================================================; Syntax Description; ==================================== =====================================================; fi:0 Fetch zero when accessing data from inactive lanes.; fi:1 Fetch pre-existing values from inactive lanes.; ==================================== =====================================================. Note: numeric values may be specified as either; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. DPP Modifiers; -------------. .. _amdgpu_synid_dpp_ctrl:. dpp_ctrl; ~~~~~~~~. Specifies how data is shared between threads. This is a mandatory modifier.; There is no default value. Note: the lanes of a wavefront are organized in four *rows* and four *banks*. ======================================== ========================================================; Syntax Description; ======================================== ========================================================; quad_perm:[{0..3},{0..3},{0..3},{0..3}] Full permute of 4 threads.; row_mirro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst:45815,Security,access,accessing,45815,"f; row_mask:0b1010; row_mask:x|y. .. _amdgpu_synid_bank_mask:. bank_mask; ~~~~~~~~~. Controls which banks are enabled for data sharing. By default, all banks are enabled. Note: the lanes of a wavefront are organized in four *rows* and four *banks*.; (There are only two rows in *wave32* mode.). ================== ====================================================================; Syntax Description; ================== ====================================================================; bank_mask:{0..15} Specifies a *bank mask* as a positive; :ref:`integer number <amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`. Each of the 4 bits in the mask controls one bank; (0 - disabled, 1 - enabled).; ================== ====================================================================. Examples:. .. parsed-literal::. bank_mask:0x3; bank_mask:0b0011; bank_mask:x&y. .. _amdgpu_synid_bound_ctrl:. bound_ctrl; ~~~~~~~~~~. Controls data sharing when accessing an invalid lane. By default, data sharing with; invalid lanes is disabled. ======================================== ================================================; Syntax Description; ======================================== ================================================; bound_ctrl:1 Enables data sharing with invalid lanes. Accessing data from an invalid lane will; return zero. bound_ctrl:0 (GFX11+) Disables data sharing with invalid lanes.; ======================================== ================================================. .. WARNING:: For historical reasons, *bound_ctrl:0* has the same meaning as *bound_ctrl:1* for older architectures. .. _amdgpu_synid_fi16:. fi; ~~. Controls interaction with *inactive* lanes for *dpp16* instructions. The default value is zero. Note: *inactive* lanes are those whose :ref:`exec<amdgpu_synid_exec>` mask bit is zero. ======================================== ==================================================; Syntax Description; ==",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUModifierSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:6996,Availability,avail,available,6996," <N>, \ **a**\ <N+1>, ... **a**\ <K>\ **]** **[acc**\ <N>, \ **acc**\ <N+1>, ... **acc**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *accumulator* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; =================================================== ========================================================= ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* <= *K*.; * 0 <= *N* <= 255.; * 0 <= *K* <= 255.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. GFX90A and GFX940 have an additional alignment requirement:; pairs of *accumulator* registers must be even-aligned; (first register must be even). Examples:. .. parsed-literal::. a255; a[0]; a[0:1]; a[1:1]; a[0:3]; a[2*2]; a[1-1:2-1]; [a252]; [a252,a253,a254,a255]. acc0; acc[1]; [acc250]; [acc2,acc3]. .. _amdgpu_synid_s:. s; -. Scalar 32-bit registers. The number of available *scalar* registers depends on the GPU:. ======= ============================; GPU Number of *scalar* registers; ======= ============================; GFX7 104; GFX8 102; GFX9 102; GFX10+ 106; ======= ============================. A sequence of *scalar* registers may be used to operate with more than 32 bits of data.; Assembler currently supports tuples with 1 to 12, 16 and 32 *scalar* registers. Pairs of *scalar* registers must be even-aligned (first register must be even).; Sequences of 4 and more *scalar* registers must be quad-aligned. ======================================================== ====================================================================; Syntax Description; ======================================================== ====================================================================; **s**\ <N> A single 32-bit *scalar* register. *N* must be a decimal; :ref:`integer number<amdgpu_synid_integer_number>`. **s[**\ <N>\ **]** A single 32-bit *scalar* register. *N* may be sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:8885,Availability,avail,available,8885,"N* must be a decimal; :ref:`integer number<amdgpu_synid_integer_number>`. **s[**\ <N>\ **]** A single 32-bit *scalar* register. *N* may be specified as an; :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; **s[**\ <N>:<K>\ **]** A sequence of (\ *K-N+1*\ ) *scalar* registers. *N* and *K* may be specified as; :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. **[s**\ <N>, \ **s**\ <N+1>, ... **s**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *scalar* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; ======================================================== ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* must be properly aligned based on the sequence size.; * *N* <= *K*.; * 0 <= *N* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * 0 <= *K* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. Examples:. .. parsed-literal::. s0; s[0]; s[0:1]; s[1:1]; s[0:3]; s[2*2]; s[1-1:2-1]; [s4]; [s4,s5,s6,s7]. Examples of *scalar* registers with an invalid alignment:. .. parsed-literal::. s[1:2]; s[2:5]. .. _amdgpu_synid_trap:. trap; ----. A set of trap handler registers:. * :ref:`ttmp<amdgpu_synid_ttmp>`; * :ref:`tba<amdgpu_synid_tba>`; * :ref:`tma<amdgpu_synid_tma>`. .. _amdgpu_synid_ttmp:. ttmp; ----. Trap handler temporary scalar registers, 32-bits wide.; The number of available *ttmp* registers depends on the GPU:. ======= ===========================; GPU Number of *ttmp* registers; ======= ===========================; GFX7 12; GFX8 12; GFX9 16; GFX10+ 16; ======= ===========================. A sequence of *ttmp* registers may be used to operate with more than 32 bits of data.; Assembler cur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:8969,Availability,avail,available,8969,">\ **]** A single 32-bit *scalar* register. *N* may be specified as an; :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; **s[**\ <N>:<K>\ **]** A sequence of (\ *K-N+1*\ ) *scalar* registers. *N* and *K* may be specified as; :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`. **[s**\ <N>, \ **s**\ <N+1>, ... **s**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *scalar* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; ======================================================== ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* must be properly aligned based on the sequence size.; * *N* <= *K*.; * 0 <= *N* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * 0 <= *K* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. Examples:. .. parsed-literal::. s0; s[0]; s[0:1]; s[1:1]; s[0:3]; s[2*2]; s[1-1:2-1]; [s4]; [s4,s5,s6,s7]. Examples of *scalar* registers with an invalid alignment:. .. parsed-literal::. s[1:2]; s[2:5]. .. _amdgpu_synid_trap:. trap; ----. A set of trap handler registers:. * :ref:`ttmp<amdgpu_synid_ttmp>`; * :ref:`tba<amdgpu_synid_tba>`; * :ref:`tma<amdgpu_synid_tma>`. .. _amdgpu_synid_ttmp:. ttmp; ----. Trap handler temporary scalar registers, 32-bits wide.; The number of available *ttmp* registers depends on the GPU:. ======= ===========================; GPU Number of *ttmp* registers; ======= ===========================; GFX7 12; GFX8 12; GFX9 16; GFX10+ 16; ======= ===========================. A sequence of *ttmp* registers may be used to operate with more than 32 bits of data.; Assembler currently supports tuples with 1 to 12 and 16 *ttmp* registers. Pairs of *ttmp* registe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:9543,Availability,avail,available,9543,"er_number>`.; ======================================================== ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* must be properly aligned based on the sequence size.; * *N* <= *K*.; * 0 <= *N* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * 0 <= *K* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. Examples:. .. parsed-literal::. s0; s[0]; s[0:1]; s[1:1]; s[0:3]; s[2*2]; s[1-1:2-1]; [s4]; [s4,s5,s6,s7]. Examples of *scalar* registers with an invalid alignment:. .. parsed-literal::. s[1:2]; s[2:5]. .. _amdgpu_synid_trap:. trap; ----. A set of trap handler registers:. * :ref:`ttmp<amdgpu_synid_ttmp>`; * :ref:`tba<amdgpu_synid_tba>`; * :ref:`tma<amdgpu_synid_tma>`. .. _amdgpu_synid_ttmp:. ttmp; ----. Trap handler temporary scalar registers, 32-bits wide.; The number of available *ttmp* registers depends on the GPU:. ======= ===========================; GPU Number of *ttmp* registers; ======= ===========================; GFX7 12; GFX8 12; GFX9 16; GFX10+ 16; ======= ===========================. A sequence of *ttmp* registers may be used to operate with more than 32 bits of data.; Assembler currently supports tuples with 1 to 12 and 16 *ttmp* registers. Pairs of *ttmp* registers must be even-aligned (first register must be even).; Sequences of 4 and more *ttmp* registers must be quad-aligned. ============================================================= ====================================================================; Syntax Description; ============================================================= ====================================================================; **ttmp**\ <N> A single 32-bit *ttmp* register. *N* must be a decimal; :ref:`integer number<amdgpu_synid_integer_number>`.; **ttmp[**\ <N>\ **]** A single 32-bit *ttmp* register. *N* may be specified a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:11434,Availability,avail,available,11434,"ecimal; :ref:`integer number<amdgpu_synid_integer_number>`.; **ttmp[**\ <N>\ **]** A single 32-bit *ttmp* register. *N* may be specified as an; :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; **ttmp[**\ <N>:<K>\ **]** A sequence of (\ *K-N+1*\ ) *ttmp* registers. *N* and *K* may be specified as; :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`.; **[ttmp**\ <N>, \ **ttmp**\ <N+1>, ... **ttmp**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *ttmp* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; ============================================================= ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* must be properly aligned based on the sequence size.; * *N* <= *K*.; * 0 <= *N* < *TMAX*, where *TMAX* is the number of available *ttmp* registers.; * 0 <= *K* < *TMAX*, where *TMAX* is the number of available *ttmp* registers.; * *K-N+1* must be in the range from 1 to 12 or equal to 16. Examples:. .. parsed-literal::. ttmp0; ttmp[0]; ttmp[0:1]; ttmp[1:1]; ttmp[0:3]; ttmp[2*2]; ttmp[1-1:2-1]; [ttmp4]; [ttmp4,ttmp5,ttmp6,ttmp7]. Examples of *ttmp* registers with an invalid alignment:. .. parsed-literal::. ttmp[1:2]; ttmp[2:5]. .. _amdgpu_synid_tba:. tba; ---. Trap base address, 64-bits wide. Holds the pointer to the current; trap handler program. ================== ======================================================================= =============; Syntax Description Availability; ================== ======================================================================= =============; tba 64-bit *trap base address* register. GFX7, GFX8; [tba] 64-bit *trap base address* register (an SP3 syntax). GFX7, GFX8; [tba_lo,tba_hi] 64-bit *trap base address* register (an SP3 syntax). GFX7, GFX8; ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:11514,Availability,avail,available,11514,"** A single 32-bit *ttmp* register. *N* may be specified as an; :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; **ttmp[**\ <N>:<K>\ **]** A sequence of (\ *K-N+1*\ ) *ttmp* registers. *N* and *K* may be specified as; :ref:`integer numbers<amdgpu_synid_integer_number>`; or :ref:`absolute expressions<amdgpu_synid_absolute_expression>`.; **[ttmp**\ <N>, \ **ttmp**\ <N+1>, ... **ttmp**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *ttmp* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; ============================================================= ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* must be properly aligned based on the sequence size.; * *N* <= *K*.; * 0 <= *N* < *TMAX*, where *TMAX* is the number of available *ttmp* registers.; * 0 <= *K* < *TMAX*, where *TMAX* is the number of available *ttmp* registers.; * *K-N+1* must be in the range from 1 to 12 or equal to 16. Examples:. .. parsed-literal::. ttmp0; ttmp[0]; ttmp[0:1]; ttmp[1:1]; ttmp[0:3]; ttmp[2*2]; ttmp[1-1:2-1]; [ttmp4]; [ttmp4,ttmp5,ttmp6,ttmp7]. Examples of *ttmp* registers with an invalid alignment:. .. parsed-literal::. ttmp[1:2]; ttmp[2:5]. .. _amdgpu_synid_tba:. tba; ---. Trap base address, 64-bits wide. Holds the pointer to the current; trap handler program. ================== ======================================================================= =============; Syntax Description Availability; ================== ======================================================================= =============; tba 64-bit *trap base address* register. GFX7, GFX8; [tba] 64-bit *trap base address* register (an SP3 syntax). GFX7, GFX8; [tba_lo,tba_hi] 64-bit *trap base address* register (an SP3 syntax). GFX7, GFX8; ================== ================================================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16117,Availability,mask,mask,16117,"yntax).; [flat_scratch_lo,flat_scratch_hi] 64-bit *flat scratch* address register (an SP3 syntax).; ================================== ================================================================. High and low 32 bits of *flat scratch* address may be accessed as separate registers:. ========================= =========================================================================; Syntax Description; ========================= =========================================================================; flat_scratch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16152,Availability,mask,mask,16152,"atch* address register (an SP3 syntax).; ================================== ================================================================. High and low 32 bits of *flat scratch* address may be accessed as separate registers:. ========================= =========================================================================; Syntax Description; ========================= =========================================================================; flat_scratch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16233,Availability,avail,availability,16233,"====================================================. High and low 32 bits of *flat scratch* address may be accessed as separate registers:. ========================= =========================================================================; Syntax Description; ========================= =========================================================================; flat_scratch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16530,Availability,mask,mask,16530,"======== =========================================================================; Syntax Description; ========================= =========================================================================; flat_scratch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16574,Availability,mask,mask,16574,"========================================================; flat_scratch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16651,Availability,mask,mask,16651,"ch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ===========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16801,Availability,mask,mask,16801,"tch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ ==============================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:17075,Availability,mask,mask,17075,"==============================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc 64-bit *vector condition code* register.; [vcc] 64-bit *vector condition code* register (an SP3 syntax).; [vcc_lo,vcc_hi] 64-bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:17129,Availability,mask,mask,17129,"mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc 64-bit *vector condition code* register.; [vcc] 64-bit *vector condition code* register (an SP3 syntax).; [vcc_lo,vcc_hi] 64-bit *vector condition code* register (an SP3 syntax).; ================ =========================================================================. High",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:17184,Availability,mask,mask,17184,"ived an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc 64-bit *vector condition code* register.; [vcc] 64-bit *vector condition code* register (an SP3 syntax).; [vcc_lo,vcc_hi] 64-bit *vector condition code* register (an SP3 syntax).; ================ =========================================================================. High and low 32 bits of *vector condition code* may be accessed as ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:17256,Availability,mask,mask,17256,"nack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc 64-bit *vector condition code* register.; [vcc] 64-bit *vector condition code* register (an SP3 syntax).; [vcc_lo,vcc_hi] 64-bit *vector condition code* register (an SP3 syntax).; ================ =========================================================================. High and low 32 bits of *vector condition code* may be accessed as separate registers:. ================ =================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:17477,Availability,mask,mask,17477,"k 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc 64-bit *vector condition code* register.; [vcc] 64-bit *vector condition code* register (an SP3 syntax).; [vcc_lo,vcc_hi] 64-bit *vector condition code* register (an SP3 syntax).; ================ =========================================================================. High and low 32 bits of *vector condition code* may be accessed as separate registers:. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc_lo Low 32 bits of *vector condition code* register.; vcc_hi High 32 bits of *vector condition code* regis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19231,Availability,mask,mask,19231,"=======================================================; Syntax Description; ================ =========================================================================; vcc_lo Low 32 bits of *vector condition code* register.; vcc_hi High 32 bits of *vector condition code* register.; [vcc_lo] Low 32 bits of *vector condition code* register (an SP3 syntax).; [vcc_hi] High 32 bits of *vector condition code* register (an SP3 syntax).; ================ =========================================================================. .. _amdgpu_synid_m0:. m0; --. A 32-bit memory register. It has various uses,; including register indexing and bounds checking. =========== ===================================================; Syntax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19257,Availability,mask,mask,19257,"====== =========================================================================; vcc_lo Low 32 bits of *vector condition code* register.; vcc_hi High 32 bits of *vector condition code* register.; [vcc_lo] Low 32 bits of *vector condition code* register (an SP3 syntax).; [vcc_hi] High 32 bits of *vector condition code* register (an SP3 syntax).; ================ =========================================================================. .. _amdgpu_synid_m0:. m0; --. A 32-bit memory register. It has various uses,; including register indexing and bounds checking. =========== ===================================================; Syntax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *e",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19692,Availability,mask,mask,19692,"ax).; [vcc_hi] High 32 bits of *vector condition code* register (an SP3 syntax).; ================ =========================================================================. .. _amdgpu_synid_m0:. m0; --. A 32-bit memory register. It has various uses,; including register indexing and bounds checking. =========== ===================================================; Syntax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19732,Availability,mask,mask,19732,"==========================. .. _amdgpu_synid_m0:. m0; --. A 32-bit memory register. It has various uses,; including register indexing and bounds checking. =========== ===================================================; Syntax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19799,Availability,mask,mask,19799,"2-bit memory register. It has various uses,; including register indexing and bounds checking. =========== ===================================================; Syntax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19954,Availability,mask,mask,19954,"ax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A single bit flag indicating that the :ref:`exec<amdgpu_synid_exec>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:20230,Availability,mask,mask,20230,"=========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A single bit flag indicating that the :ref:`exec<amdgpu_synid_exec>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`exec_lo<amdgpu_synid_exec>`. .. _amdgpu_synid_scc:. scc; ---. A single bit flag indicating the result of a scalar compare operation. .. _amdgpu_synid_lds_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:20280,Availability,mask,mask,20280," bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A single bit flag indicating that the :ref:`exec<amdgpu_synid_exec>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`exec_lo<amdgpu_synid_exec>`. .. _amdgpu_synid_scc:. scc; ---. A single bit flag indicating the result of a scalar compare operation. .. _amdgpu_synid_lds_direct:. lds_direct; ----------. A special operand which supplies a 32-bit value; fetched from *LDS* memory using :ref:`m0<amdgpu_synid_m0>` as an a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:20331,Availability,mask,mask,20331,"and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A single bit flag indicating that the :ref:`exec<amdgpu_synid_exec>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`exec_lo<amdgpu_synid_exec>`. .. _amdgpu_synid_scc:. scc; ---. A single bit flag indicating the result of a scalar compare operation. .. _amdgpu_synid_lds_direct:. lds_direct; ----------. A special operand which supplies a 32-bit value; fetched from *LDS* memory using :ref:`m0<amdgpu_synid_m0>` as an address. .. _amdgpu_synid_null:. null; ----. This is a speci",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:20399,Availability,mask,mask,20399,". Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A single bit flag indicating that the :ref:`exec<amdgpu_synid_exec>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`exec_lo<amdgpu_synid_exec>`. .. _amdgpu_synid_scc:. scc; ---. A single bit flag indicating the result of a scalar compare operation. .. _amdgpu_synid_lds_direct:. lds_direct; ----------. A special operand which supplies a 32-bit value; fetched from *LDS* memory using :ref:`m0<amdgpu_synid_m0>` as an address. .. _amdgpu_synid_null:. null; ----. This is a special operand that may be used as a source or a destination. When used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:35020,Availability,error,error,35020,"=. This section describes what happens when a 64-bit; :ref:`integer number<amdgpu_synid_integer_number>`, a; :ref:`floating-point number<amdgpu_synid_floating-point_number>` or an; :ref:`expression<amdgpu_synid_expression>`; is used for an operand which has a different type or size. .. _amdgpu_synid_int_conv:. Conversion of Integer Values; ----------------------------. Instruction operands may be specified as 64-bit; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`.; These values are converted to the; :ref:`expected operand type<amdgpu_syn_instruction_type>`; using the following steps:. 1. *Validation*. Assembler checks if the input value may be truncated; without loss to the required *truncation width* (see the table below).; There are two cases when this operation is enabled:. * The truncated bits are all 0.; * The truncated bits are all 1 and the value after truncation has its MSB bit set. In all other cases, the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this conversion; is performed by either assembler or AMDGPU H/W (or both). ============== ================= =============== ====================================================================; Expected type Truncation Width Conversion Description; ============== ================= =============== ====================================================================; i16, u16, b16 16 num.u16 Truncate to 16 bits.; i32, u32, b32 32 num.u32 Truncate to 32 bits.; i64 32 {-1,num.i32} Truncate to 32 bits and then sign-extend the result to 64 bits.; u64, b64 32 {0,num.u32} Truncate to 32 bits and then zero-extend the result to 64 bits.; f16 16 num.u16 Use low 16 bits as an f16 value.; f32 32 num.u32 Use low 32 bits as an f32 value.; f64 32 {num.u32,0} Use low 32 bits of the number as high 32 bits; of the result; low 32 bits of the result are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:37757,Availability,error,error,37757,"); //; x = 0xffefffff //; s_bfe_i64 s[0:1], x, s3 // src0 = 0xffffffffffefffff; s_bfe_u64 s[0:1], x, s3 // src0 = 0x00000000ffefffff; v_ceil_f64_e32 v[0:1], x // src0 = 0xffefffff00000000 (-1.7976922776554302e308). Examples of disabled conversions:. .. parsed-literal::. // GFX9. v_add_u16 v0, 0x1ff00, v0 // truncated bits are not all 0 or 1; v_add_u16 v0, 0xffffffffffff00ff, v0 // truncated bits do not match MSB of the result. .. _amdgpu_synid_fp_conv:. Conversion of Floating-Point Values; -----------------------------------. Instruction operands may be specified as 64-bit; :ref:`floating-point numbers<amdgpu_synid_floating-point_number>`.; These values are converted to the; :ref:`expected operand type<amdgpu_syn_instruction_type>`; using the following steps:. 1. *Validation*. Assembler checks if the input f64 number can be converted; to the *required floating-point type* (see the table below) without overflow; or underflow. Precision lost is allowed. If this conversion is not possible,; the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this is; performed by either assembler or AMDGPU H/W (or both). ============== ================ ================= =================================================================; Expected type Required FP Type Conversion Description; ============== ================ ================= =================================================================; i16, u16, b16 f16 f16(num) Convert to f16 and use bits of the result as an integer value.; The value has to be encoded as a literal, or an error occurs.; Note that the value cannot be encoded as an inline constant.; i32, u32, b32 f32 f32(num) Convert to f32 and use bits of the result as an integer value.; i64, u64, b64 \- \- Conversion disabled.; f16 f16 f16(num) Convert to f16.; f32 f32 f32(num) Convert to f32.; f64 f64 {num.u32.hi,0} Use high 32 bits of the number as high 32 b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:38384,Availability,error,error,38384,"_number>`.; These values are converted to the; :ref:`expected operand type<amdgpu_syn_instruction_type>`; using the following steps:. 1. *Validation*. Assembler checks if the input f64 number can be converted; to the *required floating-point type* (see the table below) without overflow; or underflow. Precision lost is allowed. If this conversion is not possible,; the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this is; performed by either assembler or AMDGPU H/W (or both). ============== ================ ================= =================================================================; Expected type Required FP Type Conversion Description; ============== ================ ================= =================================================================; i16, u16, b16 f16 f16(num) Convert to f16 and use bits of the result as an integer value.; The value has to be encoded as a literal, or an error occurs.; Note that the value cannot be encoded as an inline constant.; i32, u32, b32 f32 f32(num) Convert to f32 and use bits of the result as an integer value.; i64, u64, b64 \- \- Conversion disabled.; f16 f16 f16(num) Convert to f16.; f32 f32 f32(num) Convert to f32.; f64 f64 {num.u32.hi,0} Use high 32 bits of the number as high 32 bits of the result;; zero-fill low 32 bits of the result. Note that the result may differ from the original number.; ============== ================ ================= =================================================================. Examples of enabled conversions:. .. parsed-literal::. // GFX9. v_add_f16 v0, 1.0, 0 // src0 = 0x3C00 (1.0); v_add_u16 v0, 1.0, 0 // src0 = 0x3C00; //; v_add_f32 v0, 1.0, 0 // src0 = 0x3F800000 (1.0); v_add_u32 v0, 1.0, 0 // src0 = 0x3F800000. // src0 before conversion:; // 1.7976931348623157e308 = 0x7fefffffffffffff; // src0 after conversion:; // 1.7976922776554302e308 = 0x7fefffff00000000; v_ceil_f64",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:22102,Energy Efficiency,efficient,efficient,22102," scc; ---. A single bit flag indicating the result of a scalar compare operation. .. _amdgpu_synid_lds_direct:. lds_direct; ----------. A special operand which supplies a 32-bit value; fetched from *LDS* memory using :ref:`m0<amdgpu_synid_m0>` as an address. .. _amdgpu_synid_null:. null; ----. This is a special operand that may be used as a source or a destination. When used as a destination, the result of the operation is discarded. When used as a source, it supplies zero value. .. _amdgpu_synid_constant:. inline constant; ---------------. An *inline constant* is an integer or a floating-point value; encoded as a part of an instruction. Compare *inline constants*; with :ref:`literals<amdgpu_synid_literal>`. Inline constants include:. * :ref:`Integer inline constants<amdgpu_synid_iconst>`;; * :ref:`Floating-point inline constants<amdgpu_synid_fconst>`;; * :ref:`Inline values<amdgpu_synid_ival>`. If a number may be encoded as either; a :ref:`literal<amdgpu_synid_literal>` or; a :ref:`constant<amdgpu_synid_constant>`,; the assembler selects the latter encoding as more efficient. .. _amdgpu_synid_iconst:. iconst; ~~~~~~. An :ref:`integer number<amdgpu_synid_integer_number>` or; an :ref:`absolute expression<amdgpu_synid_absolute_expression>`; encoded as an *inline constant*. Only a small fraction of integer numbers may be encoded as *inline constants*.; They are enumerated in the table below.; Other integer numbers are encoded as :ref:`literals<amdgpu_synid_literal>`. ================================== ====================================; Value Note; ================================== ====================================; {0..64} Positive integer inline constants.; {-16..-1} Negative integer inline constants.; ================================== ====================================. .. _amdgpu_synid_fconst:. fconst; ~~~~~~. A :ref:`floating-point number<amdgpu_synid_floating-point_number>`; encoded as an *inline constant*. Only a small fraction of floating-point numbers ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:25521,Energy Efficiency,efficient,efficient,25521,"== =============; Syntax Alternative Syntax (SP3) Note Availability; ===================== ========================= ================================================ =============; shared_base src_shared_base Base address of shared memory region. GFX9+; shared_limit src_shared_limit Address of the end of shared memory region. GFX9+; private_base src_private_base Base address of private memory region. GFX9+; private_limit src_private_limit Address of the end of private memory region. GFX9+; pops_exiting_wave_id src_pops_exiting_wave_id A dedicated counter for POPS. GFX9, GFX10; ===================== ========================= ================================================ =============. .. _amdgpu_synid_literal:. literal; -------. A *literal* is a 64-bit value encoded as a separate; 32-bit dword in the instruction stream. Compare *literals*; with :ref:`inline constants<amdgpu_synid_constant>`. If a number may be encoded as either; a :ref:`literal<amdgpu_synid_literal>` or; an :ref:`inline constant<amdgpu_synid_constant>`,; assembler selects the latter encoding as more efficient. Literals may be specified as; :ref:`integer numbers<amdgpu_synid_integer_number>`,; :ref:`floating-point numbers<amdgpu_synid_floating-point_number>`,; :ref:`absolute expressions<amdgpu_synid_absolute_expression>` or; :ref:`relocatable expressions<amdgpu_synid_relocatable_expression>`. An instruction may use only one literal,; but several operands may refer to the same literal. .. _amdgpu_synid_uimm8:. uimm8; -----. An 8-bit :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; The value must be in the range 0..0xFF. .. _amdgpu_synid_uimm32:. uimm32; ------. A 32-bit :ref:`integer number<amdgpu_synid_integer_number>`; or an :ref:`absolute expression<amdgpu_synid_absolute_expression>`.; The value must be in the range 0..0xFFFFFFFF. .. _amdgpu_synid_uimm20:. uimm20; ------. A 20-bit :ref:`integer number<amdgpu_synid_integer_numb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:7025,Integrability,depend,depends,7025," <N>, \ **a**\ <N+1>, ... **a**\ <K>\ **]** **[acc**\ <N>, \ **acc**\ <N+1>, ... **acc**\ <K>\ **]** A sequence of (\ *K-N+1*\ ) *accumulator* registers. Register indices must be specified as decimal; :ref:`integer numbers<amdgpu_synid_integer_number>`.; =================================================== ========================================================= ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* <= *K*.; * 0 <= *N* <= 255.; * 0 <= *K* <= 255.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. GFX90A and GFX940 have an additional alignment requirement:; pairs of *accumulator* registers must be even-aligned; (first register must be even). Examples:. .. parsed-literal::. a255; a[0]; a[0:1]; a[1:1]; a[0:3]; a[2*2]; a[1-1:2-1]; [a252]; [a252,a253,a254,a255]. acc0; acc[1]; [acc250]; [acc2,acc3]. .. _amdgpu_synid_s:. s; -. Scalar 32-bit registers. The number of available *scalar* registers depends on the GPU:. ======= ============================; GPU Number of *scalar* registers; ======= ============================; GFX7 104; GFX8 102; GFX9 102; GFX10+ 106; ======= ============================. A sequence of *scalar* registers may be used to operate with more than 32 bits of data.; Assembler currently supports tuples with 1 to 12, 16 and 32 *scalar* registers. Pairs of *scalar* registers must be even-aligned (first register must be even).; Sequences of 4 and more *scalar* registers must be quad-aligned. ======================================================== ====================================================================; Syntax Description; ======================================================== ====================================================================; **s**\ <N> A single 32-bit *scalar* register. *N* must be a decimal; :ref:`integer number<amdgpu_synid_integer_number>`. **s[**\ <N>\ **]** A single 32-bit *scalar* register. *N* may be sp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:9570,Integrability,depend,depends,9570,"er_number>`.; ======================================================== ====================================================================. Note: *N* and *K* must satisfy the following conditions:. * *N* must be properly aligned based on the sequence size.; * *N* <= *K*.; * 0 <= *N* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * 0 <= *K* < *SMAX*\ , where *SMAX* is the number of available *scalar* registers.; * *K-N+1* must be in the range from 1 to 12 or equal to 16 or 32. Examples:. .. parsed-literal::. s0; s[0]; s[0:1]; s[1:1]; s[0:3]; s[2*2]; s[1-1:2-1]; [s4]; [s4,s5,s6,s7]. Examples of *scalar* registers with an invalid alignment:. .. parsed-literal::. s[1:2]; s[2:5]. .. _amdgpu_synid_trap:. trap; ----. A set of trap handler registers:. * :ref:`ttmp<amdgpu_synid_ttmp>`; * :ref:`tba<amdgpu_synid_tba>`; * :ref:`tma<amdgpu_synid_tma>`. .. _amdgpu_synid_ttmp:. ttmp; ----. Trap handler temporary scalar registers, 32-bits wide.; The number of available *ttmp* registers depends on the GPU:. ======= ===========================; GPU Number of *ttmp* registers; ======= ===========================; GFX7 12; GFX8 12; GFX9 16; GFX10+ 16; ======= ===========================. A sequence of *ttmp* registers may be used to operate with more than 32 bits of data.; Assembler currently supports tuples with 1 to 12 and 16 *ttmp* registers. Pairs of *ttmp* registers must be even-aligned (first register must be even).; Sequences of 4 and more *ttmp* registers must be quad-aligned. ============================================================= ====================================================================; Syntax Description; ============================================================= ====================================================================; **ttmp**\ <N> A single 32-bit *ttmp* register. *N* must be a decimal; :ref:`integer number<amdgpu_synid_integer_number>`.; **ttmp[**\ <N>\ **]** A single 32-bit *ttmp* register. *N* may be specified a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:29788,Integrability,depend,depends,29788,"============================= ====================== ====================. .. _amdgpu_synid_expression:. Expressions; ===========. An expression is evaluated to a 64-bit integer.; Note that floating-point expressions are not supported. There are two kinds of expressions:. * :ref:`Absolute<amdgpu_synid_absolute_expression>`.; * :ref:`Relocatable<amdgpu_synid_relocatable_expression>`. .. _amdgpu_synid_absolute_expression:. Absolute Expressions; --------------------. The value of an absolute expression does not change after program relocation.; Absolute expressions must not include unassigned and relocatable values; such as labels. Absolute expressions are evaluated to 64-bit integer values and converted to; :ref:`expected operand type<amdgpu_syn_instruction_type>`; as described :ref:`here<amdgpu_synid_int_conv>`. Examples:. .. parsed-literal::. x = -1; y = x + 10. .. _amdgpu_synid_relocatable_expression:. Relocatable Expressions; -----------------------. The value of a relocatable expression depends on program relocation. Note that use of relocatable expressions is limited to branch targets; and 32-bit integer operands. A relocatable expression is evaluated to a 64-bit integer value,; which depends on operand kind and; :ref:`relocation type<amdgpu-relocation-records>` of symbol(s); used in the expression. For example, if an instruction refers to a label,; this reference is evaluated to an offset from the address after; the instruction to the label address:. .. parsed-literal::. label:; v_add_co_u32_e32 v0, vcc, label, v1 // 'label' operand is evaluated to -4. Note that values of relocatable expressions are usually unknown; at assembly time; they are resolved later by a linker and converted to; :ref:`expected operand type<amdgpu_syn_instruction_type>`; as described :ref:`here<amdgpu_synid_rl_conv>`. Operands and Operations; -----------------------. Expressions are composed of 64-bit integer operands and operations.; Operands include :ref:`integer numbers<amdgpu_synid_in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:29991,Integrability,depend,depends,29991,"orted. There are two kinds of expressions:. * :ref:`Absolute<amdgpu_synid_absolute_expression>`.; * :ref:`Relocatable<amdgpu_synid_relocatable_expression>`. .. _amdgpu_synid_absolute_expression:. Absolute Expressions; --------------------. The value of an absolute expression does not change after program relocation.; Absolute expressions must not include unassigned and relocatable values; such as labels. Absolute expressions are evaluated to 64-bit integer values and converted to; :ref:`expected operand type<amdgpu_syn_instruction_type>`; as described :ref:`here<amdgpu_synid_int_conv>`. Examples:. .. parsed-literal::. x = -1; y = x + 10. .. _amdgpu_synid_relocatable_expression:. Relocatable Expressions; -----------------------. The value of a relocatable expression depends on program relocation. Note that use of relocatable expressions is limited to branch targets; and 32-bit integer operands. A relocatable expression is evaluated to a 64-bit integer value,; which depends on operand kind and; :ref:`relocation type<amdgpu-relocation-records>` of symbol(s); used in the expression. For example, if an instruction refers to a label,; this reference is evaluated to an offset from the address after; the instruction to the label address:. .. parsed-literal::. label:; v_add_co_u32_e32 v0, vcc, label, v1 // 'label' operand is evaluated to -4. Note that values of relocatable expressions are usually unknown; at assembly time; they are resolved later by a linker and converted to; :ref:`expected operand type<amdgpu_syn_instruction_type>`; as described :ref:`here<amdgpu_synid_rl_conv>`. Operands and Operations; -----------------------. Expressions are composed of 64-bit integer operands and operations.; Operands include :ref:`integer numbers<amdgpu_synid_integer_number>`; and :ref:`symbols<amdgpu_synid_symbol>`. Expressions may also use ""."" which is a reference; to the current PC (program counter). :ref:`Unary<amdgpu_synid_expression_un_op>` and; :ref:`binary<amdgpu_synid_expressio",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:39992,Integrability,depend,depends,39992,"= ================ ================= =================================================================. Examples of enabled conversions:. .. parsed-literal::. // GFX9. v_add_f16 v0, 1.0, 0 // src0 = 0x3C00 (1.0); v_add_u16 v0, 1.0, 0 // src0 = 0x3C00; //; v_add_f32 v0, 1.0, 0 // src0 = 0x3F800000 (1.0); v_add_u32 v0, 1.0, 0 // src0 = 0x3F800000. // src0 before conversion:; // 1.7976931348623157e308 = 0x7fefffffffffffff; // src0 after conversion:; // 1.7976922776554302e308 = 0x7fefffff00000000; v_ceil_f64 v[0:1], 1.7976931348623157e308. v_add_f16 v1, 65500.0, v2 // ok for f16.; v_add_f32 v1, 65600.0, v2 // ok for f32, but would result in overflow for f16. Examples of disabled conversions:. .. parsed-literal::. // GFX9. v_add_f16 v1, 65600.0, v2 // overflow. .. _amdgpu_synid_rl_conv:. Conversion of Relocatable Values; --------------------------------. :ref:`Relocatable expressions<amdgpu_synid_relocatable_expression>`; may be used with 32-bit integer operands and jump targets. When the value of a relocatable expression is resolved by a linker, it is; converted as needed and truncated to the operand size. The conversion depends; on :ref:`relocation type<amdgpu-relocation-records>` and operand kind. For example, when a 32-bit operand of an instruction refers; to a relocatable expression *expr*, this reference is evaluated; to a 64-bit offset from the address after the; instruction to the address being referenced, *counted in bytes*.; Then the value is truncated to 32 bits and encoded as a literal:. .. parsed-literal::. expr = .; v_add_co_u32_e32 v0, vcc, expr, v1 // 'expr' operand is evaluated to -4; // and then truncated to 0xFFFFFFFC. As another example, when a branch instruction refers to a label,; this reference is evaluated to an offset from the address after the; instruction to the label address, *counted in dwords*.; Then the value is truncated to 16 bits:. .. parsed-literal::. label:; s_branch label // 'label' operand is evaluated to -1 and truncated to 0xFFFF; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:35671,Modifiability,extend,extend,35671,"Validation*. Assembler checks if the input value may be truncated; without loss to the required *truncation width* (see the table below).; There are two cases when this operation is enabled:. * The truncated bits are all 0.; * The truncated bits are all 1 and the value after truncation has its MSB bit set. In all other cases, the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this conversion; is performed by either assembler or AMDGPU H/W (or both). ============== ================= =============== ====================================================================; Expected type Truncation Width Conversion Description; ============== ================= =============== ====================================================================; i16, u16, b16 16 num.u16 Truncate to 16 bits.; i32, u32, b32 32 num.u32 Truncate to 32 bits.; i64 32 {-1,num.i32} Truncate to 32 bits and then sign-extend the result to 64 bits.; u64, b64 32 {0,num.u32} Truncate to 32 bits and then zero-extend the result to 64 bits.; f16 16 num.u16 Use low 16 bits as an f16 value.; f32 32 num.u32 Use low 32 bits as an f32 value.; f64 32 {num.u32,0} Use low 32 bits of the number as high 32 bits; of the result; low 32 bits of the result are zeroed.; ============== ================= =============== ====================================================================. Examples of enabled conversions:. .. parsed-literal::. // GFX9. v_add_u16 v0, -1, 0 // src0 = 0xFFFF; v_add_f16 v0, -1, 0 // src0 = 0xFFFF (NaN); //; v_add_u32 v0, -1, 0 // src0 = 0xFFFFFFFF; v_add_f32 v0, -1, 0 // src0 = 0xFFFFFFFF (NaN); //; v_add_u16 v0, 0xff00, v0 // src0 = 0xff00; v_add_u16 v0, 0xffffffffffffff00, v0 // src0 = 0xff00; v_add_u16 v0, -256, v0 // src0 = 0xff00; //; s_bfe_i64 s[0:1], 0xffefffff, s3 // src0 = 0xffffffffffefffff; s_bfe_u64 s[0:1], 0xffefffff, s3 // src0 = 0x00000000ffefffff; v_ceil_f64_e32 v[0:1], 0x",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:35760,Modifiability,extend,extend,35760,"quired *truncation width* (see the table below).; There are two cases when this operation is enabled:. * The truncated bits are all 0.; * The truncated bits are all 1 and the value after truncation has its MSB bit set. In all other cases, the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this conversion; is performed by either assembler or AMDGPU H/W (or both). ============== ================= =============== ====================================================================; Expected type Truncation Width Conversion Description; ============== ================= =============== ====================================================================; i16, u16, b16 16 num.u16 Truncate to 16 bits.; i32, u32, b32 32 num.u32 Truncate to 32 bits.; i64 32 {-1,num.i32} Truncate to 32 bits and then sign-extend the result to 64 bits.; u64, b64 32 {0,num.u32} Truncate to 32 bits and then zero-extend the result to 64 bits.; f16 16 num.u16 Use low 16 bits as an f16 value.; f32 32 num.u32 Use low 32 bits as an f32 value.; f64 32 {num.u32,0} Use low 32 bits of the number as high 32 bits; of the result; low 32 bits of the result are zeroed.; ============== ================= =============== ====================================================================. Examples of enabled conversions:. .. parsed-literal::. // GFX9. v_add_u16 v0, -1, 0 // src0 = 0xFFFF; v_add_f16 v0, -1, 0 // src0 = 0xFFFF (NaN); //; v_add_u32 v0, -1, 0 // src0 = 0xFFFFFFFF; v_add_f32 v0, -1, 0 // src0 = 0xFFFFFFFF (NaN); //; v_add_u16 v0, 0xff00, v0 // src0 = 0xff00; v_add_u16 v0, 0xffffffffffffff00, v0 // src0 = 0xff00; v_add_u16 v0, -256, v0 // src0 = 0xff00; //; s_bfe_i64 s[0:1], 0xffefffff, s3 // src0 = 0xffffffffffefffff; s_bfe_u64 s[0:1], 0xffefffff, s3 // src0 = 0x00000000ffefffff; v_ceil_f64_e32 v[0:1], 0xffefffff // src0 = 0xffefffff00000000 (-1.7976922776554302e308); //; x = 0xffefffff //; s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:31677,Performance,perform,performed,31677,"ssions are composed of 64-bit integer operands and operations.; Operands include :ref:`integer numbers<amdgpu_synid_integer_number>`; and :ref:`symbols<amdgpu_synid_symbol>`. Expressions may also use ""."" which is a reference; to the current PC (program counter). :ref:`Unary<amdgpu_synid_expression_un_op>` and; :ref:`binary<amdgpu_synid_expression_bin_op>`; operations produce 64-bit integer results. Syntax of Expressions; ---------------------. Syntax of expressions is shown below::. expr ::= expr binop expr | primaryexpr ;. primaryexpr ::= '(' expr ')' | symbol | number | '.' | unop primaryexpr ;. binop ::= '&&'; | '||'; | '|'; | '^'; | '&'; | '!'; | '=='; | '!='; | '<>'; | '<'; | '<='; | '>'; | '>='; | '<<'; | '>>'; | '+'; | '-'; | '*'; | '/'; | '%' ;. unop ::= '~'; | '+'; | '-'; | '!' ;. .. _amdgpu_synid_expression_bin_op:. Binary Operators; ----------------. Binary operators are described in the following table.; They operate on and produce 64-bit integers.; Operators with higher priority are performed first. ========== ========= ===============================================; Operator Priority Meaning; ========== ========= ===============================================; \* 5 Integer multiplication.; / 5 Integer division.; % 5 Integer signed remainder.; \+ 4 Integer addition.; \- 4 Integer subtraction.; << 3 Integer shift left.; >> 3 Logical shift right.; == 2 Equality comparison.; != 2 Inequality comparison.; <> 2 Inequality comparison.; < 2 Signed less than comparison.; <= 2 Signed less than or equal comparison.; > 2 Signed greater than comparison.; >= 2 Signed greater than or equal comparison.; \| 1 Bitwise or.; ^ 1 Bitwise xor.; & 1 Bitwise and.; && 0 Logical and.; || 0 Logical or.; ========== ========= ===============================================. .. _amdgpu_synid_expression_un_op:. Unary Operators; ---------------. Unary operators are described in the following table.; They operate on and produce 64-bit integers. ========== =============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:35175,Performance,perform,performed,35175,"; :ref:`expression<amdgpu_synid_expression>`; is used for an operand which has a different type or size. .. _amdgpu_synid_int_conv:. Conversion of Integer Values; ----------------------------. Instruction operands may be specified as 64-bit; :ref:`integer numbers<amdgpu_synid_integer_number>` or; :ref:`absolute expressions<amdgpu_synid_absolute_expression>`.; These values are converted to the; :ref:`expected operand type<amdgpu_syn_instruction_type>`; using the following steps:. 1. *Validation*. Assembler checks if the input value may be truncated; without loss to the required *truncation width* (see the table below).; There are two cases when this operation is enabled:. * The truncated bits are all 0.; * The truncated bits are all 1 and the value after truncation has its MSB bit set. In all other cases, the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this conversion; is performed by either assembler or AMDGPU H/W (or both). ============== ================= =============== ====================================================================; Expected type Truncation Width Conversion Description; ============== ================= =============== ====================================================================; i16, u16, b16 16 num.u16 Truncate to 16 bits.; i32, u32, b32 32 num.u32 Truncate to 32 bits.; i64 32 {-1,num.i32} Truncate to 32 bits and then sign-extend the result to 64 bits.; u64, b64 32 {0,num.u32} Truncate to 32 bits and then zero-extend the result to 64 bits.; f16 16 num.u16 Use low 16 bits as an f16 value.; f32 32 num.u32 Use low 32 bits as an f32 value.; f64 32 {num.u32,0} Use low 32 bits of the number as high 32 bits; of the result; low 32 bits of the result are zeroed.; ============== ================= =============== ====================================================================. Examples of enabled conversions:. .. parsed-litera",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:37901,Performance,perform,performed,37901,"000000 (-1.7976922776554302e308). Examples of disabled conversions:. .. parsed-literal::. // GFX9. v_add_u16 v0, 0x1ff00, v0 // truncated bits are not all 0 or 1; v_add_u16 v0, 0xffffffffffff00ff, v0 // truncated bits do not match MSB of the result. .. _amdgpu_synid_fp_conv:. Conversion of Floating-Point Values; -----------------------------------. Instruction operands may be specified as 64-bit; :ref:`floating-point numbers<amdgpu_synid_floating-point_number>`.; These values are converted to the; :ref:`expected operand type<amdgpu_syn_instruction_type>`; using the following steps:. 1. *Validation*. Assembler checks if the input f64 number can be converted; to the *required floating-point type* (see the table below) without overflow; or underflow. Precision lost is allowed. If this conversion is not possible,; the assembler triggers an error. 2. *Conversion*. The input value is converted to the expected type; as described in the table below. Depending on operand kind, this is; performed by either assembler or AMDGPU H/W (or both). ============== ================ ================= =================================================================; Expected type Required FP Type Conversion Description; ============== ================ ================= =================================================================; i16, u16, b16 f16 f16(num) Convert to f16 and use bits of the result as an integer value.; The value has to be encoded as a literal, or an error occurs.; Note that the value cannot be encoded as an inline constant.; i32, u32, b32 f32 f32(num) Convert to f32 and use bits of the result as an integer value.; i64, u64, b64 \- \- Conversion disabled.; f16 f16 f16(num) Convert to f16.; f32 f32 f32(num) Convert to f32.; f64 f64 {num.u32.hi,0} Use high 32 bits of the number as high 32 bits of the result;; zero-fill low 32 bits of the result. Note that the result may differ from the original number.; ============== ================ ================= ================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:3854,Security,access,access,3854,"== =================================================; **[Vm**, \ **Vn**, ... **Vk**\ **]** A sequence of 32-bit *vector* registers.; Each register may be specified using the syntax; defined :ref:`above<amdgpu_synid_v>`. In contrast with the standard syntax, registers; in *NSA* sequence are not required to have; consecutive indices. Moreover, the same register; may appear in the sequence more than once. GFX11+ has an additional limitation: if address; size occupies more than 5 dwords, registers; starting from the 5th element must be contiguous.; ===================================== =================================================. Examples:. .. parsed-literal::. [v32,v1,v[2]]; [v[32],v[1:1],[v2]]; [v4,v4,v4,v4]. .. _amdgpu_synid_v16:. v (16-bit); ----------. 16-bit vector registers. Each :ref:`32-bit vector register<amdgpu_synid_v>` is divided into two 16-bit low and high registers, so there are 512 16-bit vector registers. Only VOP3, VOP3P and VINTERP instructions may access all 512 registers (using :ref:`op_sel<amdgpu_synid_op_sel>` modifier).; VOP1, VOP2 and VOPC instructions may currently access only 128 low 16-bit registers using the syntax described below. .. WARNING:: This section is incomplete. The support of 16-bit registers in the assembler is still WIP. \; =================================================== ====================================================================; Syntax Description; =================================================== ====================================================================; **v**\<N> A single 16-bit *vector* register (low half).; =================================================== ====================================================================. Note: *N* must satisfy the following conditions:. * 0 <= *N* <= 127. Examples:. .. parsed-literal::. v127. .. _amdgpu_synid_a:. a; -. Accumulator registers. There are 256 32-bit accumulator registers. A sequence of *accumulator* registers may be used to operate with m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:3980,Security,access,access,3980,"registers.; Each register may be specified using the syntax; defined :ref:`above<amdgpu_synid_v>`. In contrast with the standard syntax, registers; in *NSA* sequence are not required to have; consecutive indices. Moreover, the same register; may appear in the sequence more than once. GFX11+ has an additional limitation: if address; size occupies more than 5 dwords, registers; starting from the 5th element must be contiguous.; ===================================== =================================================. Examples:. .. parsed-literal::. [v32,v1,v[2]]; [v[32],v[1:1],[v2]]; [v4,v4,v4,v4]. .. _amdgpu_synid_v16:. v (16-bit); ----------. 16-bit vector registers. Each :ref:`32-bit vector register<amdgpu_synid_v>` is divided into two 16-bit low and high registers, so there are 512 16-bit vector registers. Only VOP3, VOP3P and VINTERP instructions may access all 512 registers (using :ref:`op_sel<amdgpu_synid_op_sel>` modifier).; VOP1, VOP2 and VOPC instructions may currently access only 128 low 16-bit registers using the syntax described below. .. WARNING:: This section is incomplete. The support of 16-bit registers in the assembler is still WIP. \; =================================================== ====================================================================; Syntax Description; =================================================== ====================================================================; **v**\<N> A single 16-bit *vector* register (low half).; =================================================== ====================================================================. Note: *N* must satisfy the following conditions:. * 0 <= *N* <= 127. Examples:. .. parsed-literal::. v127. .. _amdgpu_synid_a:. a; -. Accumulator registers. There are 256 32-bit accumulator registers. A sequence of *accumulator* registers may be used to operate with more than 32 bits of data. Assembler currently supports tuples with 1 to 12, 16 and 32 *accumulator* registers. ===========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:12575,Security,access,accessed,12575,"he range from 1 to 12 or equal to 16. Examples:. .. parsed-literal::. ttmp0; ttmp[0]; ttmp[0:1]; ttmp[1:1]; ttmp[0:3]; ttmp[2*2]; ttmp[1-1:2-1]; [ttmp4]; [ttmp4,ttmp5,ttmp6,ttmp7]. Examples of *ttmp* registers with an invalid alignment:. .. parsed-literal::. ttmp[1:2]; ttmp[2:5]. .. _amdgpu_synid_tba:. tba; ---. Trap base address, 64-bits wide. Holds the pointer to the current; trap handler program. ================== ======================================================================= =============; Syntax Description Availability; ================== ======================================================================= =============; tba 64-bit *trap base address* register. GFX7, GFX8; [tba] 64-bit *trap base address* register (an SP3 syntax). GFX7, GFX8; [tba_lo,tba_hi] 64-bit *trap base address* register (an SP3 syntax). GFX7, GFX8; ================== ======================================================================= =============. High and low 32 bits of *trap base address* may be accessed as separate registers:. ================== ======================================================================= =============; Syntax Description Availability; ================== ======================================================================= =============; tba_lo Low 32 bits of *trap base address* register. GFX7, GFX8; tba_hi High 32 bits of *trap base address* register. GFX7, GFX8; [tba_lo] Low 32 bits of *trap base address* register (an SP3 syntax). GFX7, GFX8; [tba_hi] High 32 bits of *trap base address* register (an SP3 syntax). GFX7, GFX8; ================== ======================================================================= =============. .. _amdgpu_synid_tma:. tma; ---. Trap memory address, 64-bits wide. ================= ======================================================================= ==================; Syntax Description Availability; ================= ======================================================================= ===========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:13948,Security,access,accessed,13948,"of *trap base address* register. GFX7, GFX8; [tba_lo] Low 32 bits of *trap base address* register (an SP3 syntax). GFX7, GFX8; [tba_hi] High 32 bits of *trap base address* register (an SP3 syntax). GFX7, GFX8; ================== ======================================================================= =============. .. _amdgpu_synid_tma:. tma; ---. Trap memory address, 64-bits wide. ================= ======================================================================= ==================; Syntax Description Availability; ================= ======================================================================= ==================; tma 64-bit *trap memory address* register. GFX7, GFX8; [tma] 64-bit *trap memory address* register (an SP3 syntax). GFX7, GFX8; [tma_lo,tma_hi] 64-bit *trap memory address* register (an SP3 syntax). GFX7, GFX8; ================= ======================================================================= ==================. High and low 32 bits of *trap memory address* may be accessed as separate registers:. ================= ======================================================================= ==================; Syntax Description Availability; ================= ======================================================================= ==================; tma_lo Low 32 bits of *trap memory address* register. GFX7, GFX8; tma_hi High 32 bits of *trap memory address* register. GFX7, GFX8; [tma_lo] Low 32 bits of *trap memory address* register (an SP3 syntax). GFX7, GFX8; [tma_hi] High 32 bits of *trap memory address* register (an SP3 syntax). GFX7, GFX8; ================= ======================================================================= ==================. .. _amdgpu_synid_flat_scratch:. flat_scratch; ------------. Flat scratch address, 64-bits wide. Holds the base address of scratch memory. ================================== ================================================================; Syntax Description; ================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:15378,Security,access,accessed,15378," [tma_lo] Low 32 bits of *trap memory address* register (an SP3 syntax). GFX7, GFX8; [tma_hi] High 32 bits of *trap memory address* register (an SP3 syntax). GFX7, GFX8; ================= ======================================================================= ==================. .. _amdgpu_synid_flat_scratch:. flat_scratch; ------------. Flat scratch address, 64-bits wide. Holds the base address of scratch memory. ================================== ================================================================; Syntax Description; ================================== ================================================================; flat_scratch 64-bit *flat scratch* address register.; [flat_scratch] 64-bit *flat scratch* address register (an SP3 syntax).; [flat_scratch_lo,flat_scratch_hi] 64-bit *flat scratch* address register (an SP3 syntax).; ================================== ================================================================. High and low 32 bits of *flat scratch* address may be accessed as separate registers:. ========================= =========================================================================; Syntax Description; ========================= =========================================================================; flat_scratch_lo Low 32 bits of *flat scratch* address register.; flat_scratch_hi High 32 bits of *flat scratch* address register.; [flat_scratch_lo] Low 32 bits of *flat scratch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =======================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:16814,Security,access,accessed,16814,"tch* address register (an SP3 syntax).; [flat_scratch_hi] High 32 bits of *flat scratch* address register (an SP3 syntax).; ========================= =========================================================================. .. _amdgpu_synid_xnack:; .. _amdgpu_synid_xnack_mask:. xnack_mask; ----------. Xnack mask, 64-bits wide. Holds a 64-bit mask of which threads; received an *XNACK* due to a vector memory operation. For availability of *xnack* feature, refer to :ref:`this table<amdgpu-processors>`. ============================== =====================================================; Syntax Description; ============================== =====================================================; xnack_mask 64-bit *xnack mask* register.; [xnack_mask] 64-bit *xnack mask* register (an SP3 syntax).; [xnack_mask_lo,xnack_mask_hi] 64-bit *xnack mask* register (an SP3 syntax).; ============================== =====================================================. High and low 32 bits of *xnack mask* may be accessed as separate registers:. ===================== ==============================================================; Syntax Description; ===================== ==============================================================; xnack_mask_lo Low 32 bits of *xnack mask* register.; xnack_mask_hi High 32 bits of *xnack mask* register.; [xnack_mask_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ ==============================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:18168,Security,access,accessed,18168,"k_lo] Low 32 bits of *xnack mask* register (an SP3 syntax).; [xnack_mask_hi] High 32 bits of *xnack mask* register (an SP3 syntax).; ===================== ==============================================================. .. _amdgpu_synid_vcc:; .. _amdgpu_synid_vcc_lo:. vcc; ---. Vector condition code, 64-bits wide. A bit mask with one bit per thread;; it holds the result of a vector compare operation. Note that GFX10+ H/W does not use high 32 bits of *vcc* in *wave32* mode. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc 64-bit *vector condition code* register.; [vcc] 64-bit *vector condition code* register (an SP3 syntax).; [vcc_lo,vcc_hi] 64-bit *vector condition code* register (an SP3 syntax).; ================ =========================================================================. High and low 32 bits of *vector condition code* may be accessed as separate registers:. ================ =========================================================================; Syntax Description; ================ =========================================================================; vcc_lo Low 32 bits of *vector condition code* register.; vcc_hi High 32 bits of *vector condition code* register.; [vcc_lo] Low 32 bits of *vector condition code* register (an SP3 syntax).; [vcc_hi] High 32 bits of *vector condition code* register (an SP3 syntax).; ================ =========================================================================. .. _amdgpu_synid_m0:. m0; --. A 32-bit memory register. It has various uses,; including register indexing and bounds checking. =========== ===================================================; Syntax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ======================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:19967,Security,access,accessed,19967,"ax Description; =========== ===================================================; m0 A 32-bit *memory* register.; [m0] A 32-bit *memory* register (an SP3 syntax).; =========== ===================================================. .. _amdgpu_synid_exec:. exec; ----. Execute mask, 64-bits wide. A bit mask with one bit per thread,; which is applied to vector instructions and controls which threads execute; and which ignore the instruction. Note that GFX10+ H/W does not use high 32 bits of *exec* in *wave32* mode. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec 64-bit *execute mask* register.; [exec] 64-bit *execute mask* register (an SP3 syntax).; [exec_lo,exec_hi] 64-bit *execute mask* register (an SP3 syntax).; ===================== =================================================================. High and low 32 bits of *execute mask* may be accessed as separate registers:. ===================== =================================================================; Syntax Description; ===================== =================================================================; exec_lo Low 32 bits of *execute mask* register.; exec_hi High 32 bits of *execute mask* register.; [exec_lo] Low 32 bits of *execute mask* register (an SP3 syntax).; [exec_hi] High 32 bits of *execute mask* register (an SP3 syntax).; ===================== =================================================================. .. _amdgpu_synid_vccz:. vccz; ----. A single bit flag indicating that the :ref:`vcc<amdgpu_synid_vcc>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state of :ref:`vcc_lo<amdgpu_synid_vcc_lo>`. .. _amdgpu_synid_execz:. execz; -----. A single bit flag indicating that the :ref:`exec<amdgpu_synid_exec>`; is all zeros. Note: when GFX10+ operates in *wave32* mode, this register reflects; the state o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst:24317,Security,access,access,24317,"=============== ===================================================== ==================; 0.0 The same as integer constant 0. All GPUs; 0.5 Floating-point constant 0.5 All GPUs; 1.0 Floating-point constant 1.0 All GPUs; 2.0 Floating-point constant 2.0 All GPUs; 4.0 Floating-point constant 4.0 All GPUs; -0.5 Floating-point constant -0.5 All GPUs; -1.0 Floating-point constant -1.0 All GPUs; -2.0 Floating-point constant -2.0 All GPUs; -4.0 Floating-point constant -4.0 All GPUs; 0.1592 1.0/(2.0*pi). Use only for 16-bit operands. GFX8+; 0.15915494 1.0/(2.0*pi). Use only for 16- and 32-bit operands. GFX8+; 0.15915494309189532 1.0/(2.0*pi). GFX8+; ===================== ===================================================== ==================. .. WARNING:: Floating-point inline constants cannot be used with *16-bit integer* operands. \; Assembler encodes these values as literals. .. _amdgpu_synid_ival:. ival; ~~~~. A symbolic operand encoded as an *inline constant*.; These operands provide read-only access to H/W registers. ===================== ========================= ================================================ =============; Syntax Alternative Syntax (SP3) Note Availability; ===================== ========================= ================================================ =============; shared_base src_shared_base Base address of shared memory region. GFX9+; shared_limit src_shared_limit Address of the end of shared memory region. GFX9+; private_base src_private_base Base address of private memory region. GFX9+; private_limit src_private_limit Address of the end of private memory region. GFX9+; pops_exiting_wave_id src_pops_exiting_wave_id A dedicated counter for POPS. GFX9, GFX10; ===================== ========================= ================================================ =============. .. _amdgpu_synid_literal:. literal; -------. A *literal* is a 64-bit value encoded as a separate; 32-bit dword in the instruction stream. Compare *literals*; with :ref:`inline cons",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUOperandSyntax.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18547,Availability,fault,fault,18547,"``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ ==================================================. .. _amdgpu-target-id:. Target ID; ---------. AMDGPU supports target IDs. See `Clang Offload Bundler; <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_ for a general; description. The AMDGPU target specific information is:. **processor**; Is an AMDGPU processor or alternative processor name specified in; :ref:`amdgpu-processor-table`. The non-canonical form target ID allows both; the primary processor and alternative processor names. The canonical form; target ID only allow the primary processor ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:24028,Availability,avail,available,24028,"ss; space*. The generic address space uses the hardware flat address support for two fixed; ranges of virtual addresses (the private and local apertures), that are; outside the range of addressable global memory, to map from a flat address to; a private or local address. This uses FLAT instructions that can take a flat; address and access global, private (scratch), and group (LDS) memory depending; on if the address is within one of the aperture ranges. Flat access to scratch requires hardware aperture setup and setup in the; kernel prologue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat; access to LDS requires hardware aperture setup and M0 (GFX7-GFX8) register; setup (see :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a private or group address space address (termed a segment; address) and a flat address the base address of the corresponding aperture; can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline; constant registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``.; In 64-bit address mode the aperture sizes are 2^32 bytes and the base is; aligned to 2^32 which makes it easier to convert from flat to segment or; segment to flat. A global address space address has the same value when used as a flat address; so no conversion is needed. **Global and Constant**; The global and constant address spaces both use global virtual addresses,; which are the same virtual address space used by the CPU. However, some; virtual addresses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:24255,Availability,avail,available,24255,"he range of addressable global memory, to map from a flat address to; a private or local address. This uses FLAT instructions that can take a flat; address and access global, private (scratch), and group (LDS) memory depending; on if the address is within one of the aperture ranges. Flat access to scratch requires hardware aperture setup and setup in the; kernel prologue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat; access to LDS requires hardware aperture setup and M0 (GFX7-GFX8) register; setup (see :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a private or group address space address (termed a segment; address) and a flat address the base address of the corresponding aperture; can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline; constant registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``.; In 64-bit address mode the aperture sizes are 2^32 bytes and the base is; aligned to 2^32 which makes it easier to convert from flat to segment or; segment to flat. A global address space address has the same value when used as a flat address; so no conversion is needed. **Global and Constant**; The global and constant address spaces both use global virtual addresses,; which are the same virtual address space used by the CPU. However, some; virtual addresses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:37507,Availability,mask,mask,37507,"rmal; inputs. :ref:`llvm.sqrt <int_sqrt>` Implemented for double, float and half (and vectors). :ref:`llvm.log <int_log>` Implemented for float and half (and vectors). :ref:`llvm.exp <int_exp>` Implemented for float and half (and vectors). :ref:`llvm.log10 <int_log10>` Implemented for float and half (and vectors). :ref:`llvm.exp2 <int_exp2>` Implemented for float and half (and vectors of float or; half). Not implemented for double. Hardware provides; 1ULP accuracy for float, and 0.51ULP for half. Float; instruction does not natively support denormal; inputs. :ref:`llvm.stacksave.p5 <int_stacksave>` Implemented, must use the alloca address space.; :ref:`llvm.stackrestore.p5 <int_stackrestore>` Implemented, must use the alloca address space. :ref:`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42390,Availability,mask,mask,42390,"8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43819,Availability,mask,mask,43819,"A instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that spe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43963,Availability,mask,mask,43963,"be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44074,Availability,mask,masks,44074,"ructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:53077,Availability,avail,available,53077,"PU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the same as the ``ccc``. ``coldcc`` The cold calling convention. Mostly the same as the ``ccc``. ``amdgpu_cs`` Used for Mesa/AMDPAL compute shaders.; ..TODO::; Describe. ``amdgpu_cs_chain`` Similar to ``amdgpu_cs``, with differences described below. Functions with this calling convention cannot be called directly. They must; instead be launched via the ``llvm.amdgcn.cs.chain`` intrinsic. Arguments are passed in SGPRs, starting at s0, if they have the ``inreg``; attribute, and in VGPRs otherwise, starting at v8. Using more SGPRs or VGPRs; than available in the subtarget is not allowed. On subtargets that use; a scratch buffer descriptor (as opposed to ``scratch_{load,store}_*`` instructions),; the scratch buffer descriptor is passed in s[48:51]. This limits the; SGPR / ``inreg`` arguments to the equivalent of 48 dwords; using more; than that is not allowed. The return type must be void.; Varargs, sret, byval, byref, inalloca, preallocated are not supported. Values in scalar registers as well as v0-v7 are not preserved. Values in; VGPRs starting at v8 are not preserved for the active lanes, but must be; saved by the callee for inactive lanes when using WWM. Wave scratch is ""empty"" at function boundaries. There is no stack pointer input; or output value, but functions are free to use scratch starting from an initial; stack pointer. Calls to ``amdgpu_gfx`` functions are allowed and behave like they; do in ``amdgpu_cs`` functions. All counters (``lgkmcnt``, ``vmcnt``, ``storecnt``, etc.) are presumed in an; unknown state at function ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:61281,Availability,mask,mask,61281,. ===================================== ===== =============================; Name Value Description; ===================================== ===== =============================; ``EF_AMDGPU_FEATURE_XNACK_V2`` 0x01 Indicates if the ``xnack``; target feature is; enabled for all code; contained in the code object.; If the processor; does not support the; ``xnack`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ``EF_AMDGPU_FEATURE_TRAP_HANDLER_V2`` 0x02 Indicates if the trap; handler is enabled for all; code contained in the code; object. If the processor; does not support a trap; handler then must be 0.; See; :ref:`amdgpu-target-features`.; ===================================== ===== =============================. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V3; :name: amdgpu-elf-header-e_flags-table-v3. ================================= ===== =============================; Name Value Description; ================================= ===== =============================; ``EF_AMDGPU_MACH`` 0x0ff AMDGPU processor selection; mask for; ``EF_AMDGPU_MACH_xxx`` values; defined in; :ref:`amdgpu-ef-amdgpu-mach-table`.; ``EF_AMDGPU_FEATURE_XNACK_V3`` 0x100 Indicates if the ``xnack``; target feature is; enabled for all code; contained in the code object.; If the processor; does not support the; ``xnack`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ``EF_AMDGPU_FEATURE_SRAMECC_V3`` 0x200 Indicates if the ``sramecc``; target feature is; enabled for all code; contained in the code object.; If the processor; does not support the; ``sramecc`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ================================= ===== =============================. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V4 and After; :name: amdgpu-elf-header-e_flags-table-v4-onwards. ============================================ ===== ===================================; Name Value Description; =================,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:62339,Availability,mask,mask,62339,"GPU processor selection; mask for; ``EF_AMDGPU_MACH_xxx`` values; defined in; :ref:`amdgpu-ef-amdgpu-mach-table`.; ``EF_AMDGPU_FEATURE_XNACK_V3`` 0x100 Indicates if the ``xnack``; target feature is; enabled for all code; contained in the code object.; If the processor; does not support the; ``xnack`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ``EF_AMDGPU_FEATURE_SRAMECC_V3`` 0x200 Indicates if the ``sramecc``; target feature is; enabled for all code; contained in the code object.; If the processor; does not support the; ``sramecc`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ================================= ===== =============================. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V4 and After; :name: amdgpu-elf-header-e_flags-table-v4-onwards. ============================================ ===== ===================================; Name Value Description; ============================================ ===== ===================================; ``EF_AMDGPU_MACH`` 0x0ff AMDGPU processor selection; mask for; ``EF_AMDGPU_MACH_xxx`` values; defined in; :ref:`amdgpu-ef-amdgpu-mach-table`.; ``EF_AMDGPU_FEATURE_XNACK_V4`` 0x300 XNACK selection mask for; ``EF_AMDGPU_FEATURE_XNACK_*_V4``; values.; ``EF_AMDGPU_FEATURE_XNACK_UNSUPPORTED_V4`` 0x000 XNACK unsupported.; ``EF_AMDGPU_FEATURE_XNACK_ANY_V4`` 0x100 XNACK can have any value.; ``EF_AMDGPU_FEATURE_XNACK_OFF_V4`` 0x200 XNACK disabled.; ``EF_AMDGPU_FEATURE_XNACK_ON_V4`` 0x300 XNACK enabled.; ``EF_AMDGPU_FEATURE_SRAMECC_V4`` 0xc00 SRAMECC selection mask for; ``EF_AMDGPU_FEATURE_SRAMECC_*_V4``; values.; ``EF_AMDGPU_FEATURE_SRAMECC_UNSUPPORTED_V4`` 0x000 SRAMECC unsupported.; ``EF_AMDGPU_FEATURE_SRAMECC_ANY_V4`` 0x400 SRAMECC can have any value.; ``EF_AMDGPU_FEATURE_SRAMECC_OFF_V4`` 0x800 SRAMECC disabled,; ``EF_AMDGPU_FEATURE_SRAMECC_ON_V4`` 0xc00 SRAMECC enabled.; ============================================ ===== ===================================. .. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:62482,Availability,mask,mask,62482,"tained in the code object.; If the processor; does not support the; ``xnack`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ``EF_AMDGPU_FEATURE_SRAMECC_V3`` 0x200 Indicates if the ``sramecc``; target feature is; enabled for all code; contained in the code object.; If the processor; does not support the; ``sramecc`` target; feature then must; be 0.; See; :ref:`amdgpu-target-features`.; ================================= ===== =============================. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V4 and After; :name: amdgpu-elf-header-e_flags-table-v4-onwards. ============================================ ===== ===================================; Name Value Description; ============================================ ===== ===================================; ``EF_AMDGPU_MACH`` 0x0ff AMDGPU processor selection; mask for; ``EF_AMDGPU_MACH_xxx`` values; defined in; :ref:`amdgpu-ef-amdgpu-mach-table`.; ``EF_AMDGPU_FEATURE_XNACK_V4`` 0x300 XNACK selection mask for; ``EF_AMDGPU_FEATURE_XNACK_*_V4``; values.; ``EF_AMDGPU_FEATURE_XNACK_UNSUPPORTED_V4`` 0x000 XNACK unsupported.; ``EF_AMDGPU_FEATURE_XNACK_ANY_V4`` 0x100 XNACK can have any value.; ``EF_AMDGPU_FEATURE_XNACK_OFF_V4`` 0x200 XNACK disabled.; ``EF_AMDGPU_FEATURE_XNACK_ON_V4`` 0x300 XNACK enabled.; ``EF_AMDGPU_FEATURE_SRAMECC_V4`` 0xc00 SRAMECC selection mask for; ``EF_AMDGPU_FEATURE_SRAMECC_*_V4``; values.; ``EF_AMDGPU_FEATURE_SRAMECC_UNSUPPORTED_V4`` 0x000 SRAMECC unsupported.; ``EF_AMDGPU_FEATURE_SRAMECC_ANY_V4`` 0x400 SRAMECC can have any value.; ``EF_AMDGPU_FEATURE_SRAMECC_OFF_V4`` 0x800 SRAMECC disabled,; ``EF_AMDGPU_FEATURE_SRAMECC_ON_V4`` 0xc00 SRAMECC enabled.; ============================================ ===== ===================================. .. table:: AMDGPU ``EF_AMDGPU_MACH`` Values; :name: amdgpu-ef-amdgpu-mach-table. ==================================== ========== =============================; Name Value Description (see; :ref:`amdgpu-processor-table`); ======",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:62843,Availability,mask,mask,62843,"en must; be 0.; See; :ref:`amdgpu-target-features`.; ================================= ===== =============================. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V4 and After; :name: amdgpu-elf-header-e_flags-table-v4-onwards. ============================================ ===== ===================================; Name Value Description; ============================================ ===== ===================================; ``EF_AMDGPU_MACH`` 0x0ff AMDGPU processor selection; mask for; ``EF_AMDGPU_MACH_xxx`` values; defined in; :ref:`amdgpu-ef-amdgpu-mach-table`.; ``EF_AMDGPU_FEATURE_XNACK_V4`` 0x300 XNACK selection mask for; ``EF_AMDGPU_FEATURE_XNACK_*_V4``; values.; ``EF_AMDGPU_FEATURE_XNACK_UNSUPPORTED_V4`` 0x000 XNACK unsupported.; ``EF_AMDGPU_FEATURE_XNACK_ANY_V4`` 0x100 XNACK can have any value.; ``EF_AMDGPU_FEATURE_XNACK_OFF_V4`` 0x200 XNACK disabled.; ``EF_AMDGPU_FEATURE_XNACK_ON_V4`` 0x300 XNACK enabled.; ``EF_AMDGPU_FEATURE_SRAMECC_V4`` 0xc00 SRAMECC selection mask for; ``EF_AMDGPU_FEATURE_SRAMECC_*_V4``; values.; ``EF_AMDGPU_FEATURE_SRAMECC_UNSUPPORTED_V4`` 0x000 SRAMECC unsupported.; ``EF_AMDGPU_FEATURE_SRAMECC_ANY_V4`` 0x400 SRAMECC can have any value.; ``EF_AMDGPU_FEATURE_SRAMECC_OFF_V4`` 0x800 SRAMECC disabled,; ``EF_AMDGPU_FEATURE_SRAMECC_ON_V4`` 0xc00 SRAMECC enabled.; ============================================ ===== ===================================. .. table:: AMDGPU ``EF_AMDGPU_MACH`` Values; :name: amdgpu-ef-amdgpu-mach-table. ==================================== ========== =============================; Name Value Description (see; :ref:`amdgpu-processor-table`); ==================================== ========== =============================; ``EF_AMDGPU_MACH_NONE`` 0x000 *not specified*; ``EF_AMDGPU_MACH_R600_R600`` 0x001 ``r600``; ``EF_AMDGPU_MACH_R600_R630`` 0x002 ``r630``; ``EF_AMDGPU_MACH_R600_RS880`` 0x003 ``rs880``; ``EF_AMDGPU_MACH_R600_RV670`` 0x004 ``rv670``; ``EF_AMDGPU_MACH_R600_RV710`` 0x005 ``rv710``; ``EF_AMDG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:85348,Availability,avail,available,85348,"de object. For a file URI, if omitted it; defaults to the size of the file. It is required for a memory URI. **process_id**; Is the identity of the process owning the memory. For Linux it is the C; unsigned integral decimal literal for the process ID (PID). For example:. .. code::. file:///dir1/dir2/file1; file:///dir3/dir4/file2#offset=0x2000&size=3000; memory://1234#offset=0x20000&size=3000. .. _amdgpu-dwarf-debug-information:. DWARF Debug Information; =======================. .. warning::. This section describes **provisional support** for AMDGPU DWARF [DWARF]_ that; is not currently fully implemented and is subject to change. AMDGPU generates DWARF [DWARF]_ debugging information ELF sections (see; :ref:`amdgpu-elf-code-object`) which contain information that maps the code; object executable code and data to the source language constructs. It can be; used by tools such as debuggers and profilers. It uses features defined in; :doc:`AMDGPUDwarfExtensionsForHeterogeneousDebugging` that are made available in; DWARF Version 4 and DWARF Version 5 as an LLVM vendor extension. This section defines the AMDGPU target architecture specific DWARF mappings. .. _amdgpu-dwarf-register-identifier:. Register Identifier; -------------------. This section defines the AMDGPU target architecture register numbers used in; DWARF operation expressions (see DWARF Version 5 section 2.5 and; :ref:`amdgpu-dwarf-operation-expressions`) and Call Frame Information; instructions (see DWARF Version 5 section 6.4 and; :ref:`amdgpu-dwarf-call-frame-information`). A single code object can contain code for kernels that have different wavefront; sizes. The vector registers and some scalar registers are based on the wavefront; size. AMDGPU defines distinct DWARF registers for each wavefront size. This; simplifies the consumer of the DWARF so that each register has a fixed size,; rather than being dynamic according to the wavefront size mode. Similarly,; distinct DWARF registers are defined for those r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:92112,Availability,avail,available,92112,"MDGPU is defined in; :ref:`amdgpu-dwarf-memory-space-mapping-table`. .. table:: AMDGPU DWARF Memory Space Mapping; :name: amdgpu-dwarf-memory-space-mapping-table. =========================== ====== =================; DWARF AMDGPU; ---------------------------------- -----------------; Memory Space Name Value Memory Space; =========================== ====== =================; ``DW_MSPACE_LLVM_none`` 0x0000 Generic (Flat); ``DW_MSPACE_LLVM_global`` 0x0001 Global; ``DW_MSPACE_LLVM_constant`` 0x0002 Global; ``DW_MSPACE_LLVM_group`` 0x0003 Local (group/LDS); ``DW_MSPACE_LLVM_private`` 0x0004 Private (Scratch); ``DW_MSPACE_AMDGPU_region`` 0x8000 Region (GDS); =========================== ====== =================. The DWARF memory space values defined in the *DWARF Extensions For Heterogeneous; Debugging* section :ref:`amdgpu-dwarf-memory-spaces` are used. In addition, ``DW_ADDR_AMDGPU_region`` is encoded as a vendor extension. This is; available for use for the AMD extension for access to the hardware GDS memory; which is scratchpad memory allocated per device. For AMDGPU if no ``DW_AT_LLVM_memory_space`` attribute is present, then the; default memory space of ``DW_MSPACE_LLVM_none`` is used. See :ref:`amdgpu-dwarf-address-space-identifier` for information on the AMDGPU; mapping of DWARF memory spaces to DWARF address spaces, including address size; and NULL value. .. _amdgpu-dwarf-address-space-identifier:. Address Space Identifier; ------------------------. DWARF address spaces correspond to target architecture specific linear; addressable memory areas. See DWARF Version 5 section 2.12 and *DWARF Extensions; For Heterogeneous Debugging* section :ref:`amdgpu-dwarf-address-spaces`. The DWARF address space mapping used for AMDGPU is defined in; :ref:`amdgpu-dwarf-address-space-mapping-table`. .. table:: AMDGPU DWARF Address Space Mapping; :name: amdgpu-dwarf-address-space-mapping-table. ======================================= ===== ======= ======== ===================== =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:98967,Availability,mask,mask,98967," identifier is pushed by; the ``DW_OP_LLVM_push_lane`` DWARF expression operation. See DWARF Version 5; section 2.5 which is updated by *DWARF Extensions For Heterogeneous Debugging*; section :ref:`amdgpu-dwarf-operation-expressions`. For AMDGPU, the lane identifier corresponds to the hardware lane ID of a; wavefront. It is numbered from 0 to the wavefront size minus 1. Operation Expressions; ---------------------. DWARF expressions are used to compute program values and the locations of; program objects. See DWARF Version 5 section 2.5 and; :ref:`amdgpu-dwarf-operation-expressions`. DWARF location descriptions describe how to access storage which includes memory; and registers. When accessing storage on AMDGPU, bytes are ordered with least; significant bytes first, and bits are ordered within bytes with least; significant bits first. For AMDGPU CFI expressions, ``DW_OP_LLVM_select_bit_piece`` is used to describe; unwinding vector registers that are spilled under the execution mask to memory:; the zero-single location description is the vector register, and the one-single; location description is the spilled memory location description. The; ``DW_OP_LLVM_form_aspace_address`` is used to specify the address space of the; memory location description. In AMDGPU expressions, ``DW_OP_LLVM_select_bit_piece`` is used by the; ``DW_AT_LLVM_lane_pc`` attribute expression where divergent control flow is; controlled by the execution mask. An undefined location description together; with ``DW_OP_LLVM_extend`` is used to indicate the lane was not active on entry; to the subprogram. See :ref:`amdgpu-dwarf-dw-at-llvm-lane-pc` for an example. Debugger Information Entry Attributes; -------------------------------------. This section describes how certain debugger information entry attributes are; used by AMDGPU. See the sections in DWARF Version 5 section 3.3.5 and 3.1.1; which are updated by *DWARF Extensions For Heterogeneous Debugging* section; :ref:`amdgpu-dwarf-low-level-informa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:99420,Availability,mask,mask,99420,"size minus 1. Operation Expressions; ---------------------. DWARF expressions are used to compute program values and the locations of; program objects. See DWARF Version 5 section 2.5 and; :ref:`amdgpu-dwarf-operation-expressions`. DWARF location descriptions describe how to access storage which includes memory; and registers. When accessing storage on AMDGPU, bytes are ordered with least; significant bytes first, and bits are ordered within bytes with least; significant bits first. For AMDGPU CFI expressions, ``DW_OP_LLVM_select_bit_piece`` is used to describe; unwinding vector registers that are spilled under the execution mask to memory:; the zero-single location description is the vector register, and the one-single; location description is the spilled memory location description. The; ``DW_OP_LLVM_form_aspace_address`` is used to specify the address space of the; memory location description. In AMDGPU expressions, ``DW_OP_LLVM_select_bit_piece`` is used by the; ``DW_AT_LLVM_lane_pc`` attribute expression where divergent control flow is; controlled by the execution mask. An undefined location description together; with ``DW_OP_LLVM_extend`` is used to indicate the lane was not active on entry; to the subprogram. See :ref:`amdgpu-dwarf-dw-at-llvm-lane-pc` for an example. Debugger Information Entry Attributes; -------------------------------------. This section describes how certain debugger information entry attributes are; used by AMDGPU. See the sections in DWARF Version 5 section 3.3.5 and 3.1.1; which are updated by *DWARF Extensions For Heterogeneous Debugging* section; :ref:`amdgpu-dwarf-low-level-information` and; :ref:`amdgpu-dwarf-full-and-partial-compilation-unit-entries`. .. _amdgpu-dwarf-dw-at-llvm-lane-pc:. ``DW_AT_LLVM_lane_pc``; ~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_lane_pc`` attribute is used to specify the program; location of the separate lanes of a SIMT thread. If the lane is an active lane then this will be the same as the curre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:101622,Availability,mask,mask,101622," will be the; undefined location. A client debugger can check if the lane is part of a valid; work-group by checking that the lane is in the range of the associated; work-group within the grid, accounting for partial work-groups. If it is not,; then the debugger can omit any information for the lane. Otherwise, the debugger; may repeatedly unwind the stack and inspect the ``DW_AT_LLVM_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To cr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:101707,Availability,mask,mask,101707,"hat the lane is in the range of the associated; work-group within the grid, accounting for partial work-groups. If it is not,; then the debugger can omit any information for the lane. Otherwise, the debugger; may repeatedly unwind the stack and inspect the ``DW_AT_LLVM_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:101831,Availability,mask,mask,101831,"t,; then the debugger can omit any information for the lane. Otherwise, the debugger; may repeatedly unwind the stack and inspect the ``DW_AT_LLVM_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:101884,Availability,mask,mask,101884,"t,; then the debugger can omit any information for the lane. Otherwise, the debugger; may repeatedly unwind the stack and inspect the ``DW_AT_LLVM_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:101908,Availability,mask,mask,101908,"t,; then the debugger can omit any information for the lane. Otherwise, the debugger; may repeatedly unwind the stack and inspect the ``DW_AT_LLVM_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:101977,Availability,mask,mask,101977,"M_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by defining an artificial variable for the lane PC. The DWARF location; list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:102025,Availability,mask,mask,102025,"M_lane_pc`` of the; calling subprogram until it finds a non-undefined location. Conceptually the; lane only has the call frames that it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by defining an artificial variable for the lane PC. The DWARF location; list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:102106,Availability,mask,mask,102106,"t it has a non-undefined; ``DW_AT_LLVM_lane_pc``. The following example illustrates how the AMDGPU backend can generate a DWARF; location list expression for the nested ``IF/THEN/ELSE`` structures of the; following subprogram pseudo code for a target with 64 lanes per wavefront. .. code::; :number-lines:. SUBPROGRAM X; BEGIN; a;; IF (c1) THEN; b;; IF (c2) THEN; c;; ELSE; d;; ENDIF; e;; ELSE; f;; ENDIF; g;; END. The AMDGPU backend may generate the following pseudo LLVM MIR to manipulate the; execution mask (``EXEC``) to linearize the control flow. The condition is; evaluated to make a mask of the lanes for which the condition evaluates to true.; First the ``THEN`` region is executed by setting the ``EXEC`` mask to the; logical ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by defining an artificial variable for the lane PC. The DWARF location; list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_pc`` attribute on the subprogram's debugger information entry. A DWARF procedure is defined for each well nested structured control",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:104014,Availability,mask,mask,104014," list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_pc`` attribute on the subprogram's debugger information entry. A DWARF procedure is defined for each well nested structured control flow region; which provides the conceptual lane program location for a lane if it is not; active (namely it is divergent). The DWARF operation expression for each region; conceptually inherits the value of the immediately enclosing region and modifies; it according to the semantics of the region. For an ``IF/THEN/ELSE`` region the divergent program location is at the start of; the region for the ``THEN`` region since it is executed first. For the ``ELSE``; region the divergent program location is at the end of the ``IF/THEN/ELSE``; region since the ``THEN`` region has completed. The lane PC artificial variable is assigned at each region transition. It uses; the immediately enclosing region's DWARF procedure to compute the program; location for each lane assuming they are divergent, and then modifies the result; by inserting the current program location for each lane that the ``EXEC`` mask; indicates is active. By having separate DWARF procedures for each region, they can be reused to; define the value for any nested region. This reduces the total size of the DWARF; operation expressions. The following provides an example using pseudo LLVM MIR. .. code::; :number-lines:. $lex_start:; DEFINE_DWARF %__uint_64 = DW_TAG_base_type[; DW_AT_name = ""__uint64"";; DW_AT_byte_size = 8;; DW_AT_encoding = DW_ATE_unsigned;; ];; DEFINE_DWARF %__active_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__active_lane_pc"";; DW_AT_location = [; DW_OP_regx PC;; DW_OP_LLVM_extend 64, 64;; DW_OP_regval_type EXEC, %uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DEFINE_DWARF %__divergent_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc"";; DW_AT_location = [; DW_OP_LLVM_undefined;; DW_OP_LLVM_extend 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:107987,Availability,mask,masks,107987,"_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; e;; EXEC = ~EXEC & %1;; $lex_1_else:; DEFINE_DWARF %__divergent_lane_pc_1_else = DW_TAG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc_1_else"";; DW_AT_location = DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108340,Availability,mask,mask,108340,"; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subpr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109137,Availability,mask,mask,109137,"tries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EX",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109474,Availability,mask,mask,109474,"e; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109690,Availability,mask,mask,109690,"gram location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109793,Availability,mask,mask,109793,"gram location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109890,Availability,mask,mask,109890," An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110011,Availability,mask,mask,110011,"e DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110034,Availability,mask,mask,110034,"ather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110088,Availability,mask,mask,110088,"ather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110138,Availability,mask,mask,110138,"ather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110165,Availability,mask,mask,110165,"ather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:122795,Availability,avail,available,122795,"e. =================== ============== ========= ==============================; String Key Value Type Required? Description; =================== ============== ========= ==============================; ""ReqdWorkGroupSize"" sequence of If not 0, 0, 0 then all values; 3 integers must be >=1 and the dispatch; work-group size X, Y, Z must; correspond to the specified; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; ""WorkGroupSizeHint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; ""VecTypeHint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. ""RuntimeHandle"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""DynamicSharedPointer""; A group address space point",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:133493,Availability,avail,available,133493,"e of Sequence of maps of the; map kernel arguments. See; :ref:`amdgpu-amdhsa-code-object-kernel-argument-metadata-map-table-v3`; for the definition of the keys; included in that map.; "".reqd_workgroup_size"" sequence of If not 0, 0, 0 then all values; 3 integers must be >=1 and the dispatch; work-group size X, Y, Z must; correspond to the specified; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; "".workgroup_size_hint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; "".vec_type_hint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. "".device_enqueue_symbol"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:155420,Availability,avail,available,155420,"the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords being accessed; and hence requires fewer cache lines to be fetched. Multi-dword access is not; supported except by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the; apertures address can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`).",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:156231,Availability,avail,available,156231,"ept by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the; apertures address can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:156458,Availability,avail,available,156458,"irtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the; apertures address can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:190706,Availability,avail,available,190706,"basis which is why; its value cannot be included with the flat scratch init value which is per; queue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`).; 4. The VGPRs are set by SPI which only supports specifying either (X), (X, Y); or (X, Y, Z).; 5. Flat Scratch register pair initialization is described in; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. The global segment can be accessed either using buffer instructions (GFX6 which; has V# 64-bit address support), flat instructions (GFX7-GFX11), or global; instructions (GFX9-GFX11). If buffer operations are used, then the compiler can generate a V# with the; following properties:. * base address of 0; * no swizzle; * ATC: 1 if IOMMU present (such as APU); * ptr64: 1; * MTYPE set to support memory coherence that matches the runtime (such as CC for; APU and NC for dGPU). .. _amdgpu-amdhsa-kernarg-preload:. Preloaded Kernel Arguments; ++++++++++++++++++++++++++. On hardware that supports this feature, kernel arguments can be preloaded into; User SGPRs, up to the maximum number of User SGPRs available. The allocation of; Preload SGPRs occurs directly after the last enabled non-kernarg preload User; SGPR. (See :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The data preloaded is copied from the kernarg segment, the amount of data is; determined by the value specified in the kernarg_preload_spec_length field of; the kernel descriptor. This data is then loaded into consecutive User SGPRs. The; number of SGPRs receiving preloaded kernarg data corresponds with the value; given by kernarg_preload_spec_length. The preloading starts at the dword offset; within the kernarg segment, which is specified by the; kernarg_preload_spec_offset field. If the kernarg_preload_spec_length is non-zero, the CP firmware will append an; additional 256 bytes to the kernel_code_entry_byte_offset. This addition; facilitates the incorporation of a prologue to the kernel entry to handle cases; where code designed for kernarg preloading ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:192757,Availability,avail,available,192757,"he; start of the kernel entry will be skipped. .. _amdgpu-amdhsa-kernel-prolog:. Kernel Prolog; ~~~~~~~~~~~~~. The compiler performs initialization in the kernel prologue depending on the; target and information about things like stack usage in the kernel and called; functions. Some of this initialization requires the compiler to request certain; User and System SGPRs be present in the; :ref:`amdgpu-amdhsa-initial-kernel-execution-state` via the; :ref:`amdgpu-amdhsa-kernel-descriptor`. .. _amdgpu-amdhsa-kernel-prolog-cfi:. CFI; +++. 1. The CFI return address is undefined. 2. The CFI CFA is defined using an expression which evaluates to a location; description that comprises one memory location description for the; ``DW_ASPACE_AMDGPU_private_lane`` address space address ``0``. .. _amdgpu-amdhsa-kernel-prolog-m0:. M0; ++. GFX6-GFX8; The M0 register must be initialized with a value at least the total LDS size; if the kernel may access LDS via DS or flat operations. Total LDS size is; available in dispatch packet. For M0, it is also possible to use maximum; possible value of LDS for given target (0x7FFF for GFX6 and 0xFFFF for; GFX7-GFX8).; GFX9-GFX11; The M0 register is not used for range checking LDS accesses and so does not; need to be initialized in the prolog. .. _amdgpu-amdhsa-kernel-prolog-stack-pointer:. Stack Pointer; +++++++++++++. If the kernel has function calls it must set up the ABI stack pointer described; in :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions` by setting; SGPR32 to the unswizzled scratch offset of the address past the last local; allocation. .. _amdgpu-amdhsa-kernel-prolog-frame-pointer:. Frame Pointer; +++++++++++++. If the kernel needs a frame pointer for the reasons defined in; ``SIFrameLowering`` then SGPR33 is used and is always set to ``0`` in the; kernel prolog. If a frame pointer is not required then all uses of the frame; pointer are replaced with immediate ``0`` offsets. .. _amdgpu-amdhsa-kernel-prolog-flat-scratch",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:381365,Availability,error,error,381365,"times (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table`. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V2; :name: amdgpu-trap-handler-for-amdhsa-os-v2-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; ``debugtrap(arg)`` ``s_trap 0x01`` ``SGPR0-1``: Reserved for Finalizer HSA ``debugtrap``; ``queue_ptr`` intrinsic (not implemented).; ``VGPR0``:; ``arg``; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:381408,Availability,error,error,381408,"_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table`. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V2; :name: amdgpu-trap-handler-for-amdhsa-os-v2-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; ``debugtrap(arg)`` ``s_trap 0x01`` ``SGPR0-1``: Reserved for Finalizer HSA ``debugtrap``; ``queue_ptr`` intrinsic (not implemented).; ``VGPR0``:; ``arg``; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for-amdhsa-os-v3-table. =================== =============== =============== ================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:383089,Availability,error,error,383089,"x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for-amdhsa-os-v3-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:383132,Availability,error,error,383132," =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V3; :name: amdgpu-trap-handler-for-amdhsa-os-v3-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table. =================== =============== ==============",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:384897,Availability,error,error,384897,"ed.; =================== =============== =============== =======================================. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table. =================== =============== ================ ================= =======================================; Usage Code Sequence GFX6-GFX8 Inputs GFX9-GFX11 Inputs Description; =================== =============== ================ ================= =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: *none* Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== ================ ================= =======================================. .. _amdgpu-amdhsa-function-call-convention:. Call Convention; ~~~~~~",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:384940,Availability,error,error,384940,"========. .. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V4 and Above; :name: amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table. =================== =============== ================ ================= =======================================; Usage Code Sequence GFX6-GFX8 Inputs GFX9-GFX11 Inputs Description; =================== =============== ================ ================= =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; debugger breakpoint ``s_trap 0x01`` *none* *none* Reserved for debugger to use for; breakpoints. Causes wave to be halted; with the PC at the trap instruction.; The debugger is responsible to resume; the wave, including the instruction; that the breakpoint overwrote.; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: *none* Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it into the; error state. When the queue is put in; the error state, the waves executing; dispatches on the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== ================ ================= =======================================. .. _amdgpu-amdhsa-function-call-convention:. Call Convention; ~~~~~~~~~~~~~~~. .. note::. This section is currently incomplete and has inaccuracies. It is WI",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389911,Availability,avail,available,389911,"yte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:391533,Availability,avail,available,391533,"ll SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals in order to keep a; similar ratio independent of the number of allocated VGPRs. * GFX90A: All AGPR registers except the clobbered registers AGPR0-31.; * Lanes of all VGPRs that are inactive at the call site. For the AMDGPU backend, an inter-procedural register allocation (IPRA); optimization may mark some of clobbered SGPR and VGPR registers as; preserved if it can be determined that the called function does not change; their value. 2. The PC is set to the RA provided on entry.; 3. MODE register: *TBD*.; 4. All other registers are clobbered.; 5. Any necessary ``s_waitcnt`` has been performed to ensure memory accessed by; function is available to the caller. .. TODO::. - How are function results returned? The address of structured types is passed; by reference, but what about other types?. The function input arguments are made up of the formal arguments explicitly; declared by the source language function plus the implicit input arguments used; by the implementation. The source language input arguments are:. 1. Any source language implicit ``this`` or ``self`` argument comes first as a; pointer type.; 2. Followed by the function formal arguments in left to right source order. The source language result arguments are:. 1. The function result argument. The source language input or result struct type arguments that are less than or; equal to 16 bytes, are decomposed recursively into their base type fields, and; each field is passed as if a separate argument. For input arguments, if the; called function requires the struct to be in memory, for example because its; address is taken, then",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:396650,Availability,error,errors,396650,"from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 5. Dispatch id (2 SGPRs). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 6. Work-Group ID X (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 7. Work-Group ID Y (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 8. Work-Group ID Z (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argume",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:419470,Availability,avail,available,419470," Table; ################. Low 32 bits of the GPU address for an optional buffer in the ``.data``; section of the ELF. The high 32 bits of the address match the high 32 bits; of the shader's program counter. The buffer can be anything the shader compiler needs it for, and; allows each shader to have its own region of the ``.data`` section.; Typically, this could be a table of buffer SRD's and the data pointed to; by the buffer SRD's, but it could be a flat-address region of memory as; well. Its layout and usage are defined by the shader compiler. Each shader's table in the ``.data`` section is referenced by the symbol; ``_amdgpu_``\ *xs*\ ``_shdr_intrl_data`` where *xs* corresponds with the; hardware shader stage the data is for. E.g.,; ``_amdgpu_cs_shdr_intrl_data`` for the compute shader hardware stage. .. _amdgpu-amdpal-code-object-metadata-user-data-spill-table-section:. Spill Table; ###########. It is possible for a hardware shader to need access to more *user data; entries* than there are slots available in user data registers for one; or more hardware shader stages. In that case, the PAL runtime expects; the necessary *user data entries* to be spilled to GPU memory and use; one user data register to point to the spilled user data memory. The; value of the *user data entry* must then represent the location where; a shader expects to read the low 32-bits of the table's GPU virtual; address. The *spill table* itself represents a set of 32-bit values; managed by the PAL runtime in GPU-accessible memory that can be made; indirectly accessible to a hardware shader. Unspecified OS; --------------. This section provides code conventions used when the target triple OS is; empty (see :ref:`amdgpu-target-triples`). Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by AMDGPU backend for non-amdhsa OS, the runtime does; not install a trap handler. The ``llvm.trap`` and ``llvm.debugtrap``; instructions are handled as follows:. .. table:: AMDGPU Trap Handler for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:440894,Availability,error,error,440894,"code object version to be generated by the; assembler. If not present, a default value will be used. .amdhsa_kernel <name>; +++++++++++++++++++++. Creates a correctly aligned AMDHSA kernel descriptor and a symbol,; ``<name>.kd``, in the current location of the current section. Only valid when; the OS is ``amdhsa``. ``<name>`` must be a symbol that labels the first; instruction to execute, and does not need to be previously defined. Marks the beginning of a list of directives used to generate the bytes of a; kernel descriptor, as described in :ref:`amdgpu-amdhsa-kernel-descriptor`.; Directives which may appear in this list are described in; :ref:`amdhsa-kernel-directives-table`. Directives may appear in any order, must; be valid for the target being assembled for, and cannot be repeated. Directives; support the range of values specified by the field they reference in; :ref:`amdgpu-amdhsa-kernel-descriptor`. If a directive is not specified, it is; assumed to have its default value, unless it is marked as ""Required"", in which; case it is an error to omit the directive. This list of directives is; terminated by an ``.end_amdhsa_kernel`` directive. .. table:: AMDHSA Kernel Assembler Directives; :name: amdhsa-kernel-directives-table. ======================================================== =================== ============ ===================; Directive Default Supported On Description; ======================================================== =================== ============ ===================; ``.amdhsa_group_segment_fixed_size`` 0 GFX6-GFX12 Controls GROUP_SEGMENT_FIXED_SIZE in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`.; ``.amdhsa_private_segment_fixed_size`` 0 GFX6-GFX12 Controls PRIVATE_SEGMENT_FIXED_SIZE in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`.; ``.amdhsa_kernarg_size`` 0 GFX6-GFX12 Controls KERNARG_SIZE in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`.; ``.amdhsa_user_sgpr_count`` 0 GFX6-GFX12 Controls USER_SGPR_COUNT in COMPUTE_PGM_RSRC2; :ref:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:4144,Deployability,release,release,4144,,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43517,Deployability,pipeline,pipelines,43517,"ions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:91023,Deployability,update,updated,91023,"ing a SIMD or SIMT execution; model. If the wavefront size is 32 lanes then the wavefront 32 mode register; definitions are used. If the wavefront size is 64 lanes then the wavefront 64; mode register definitions are used. Some AMDGPU targets support executing in; both wavefront 32 and wavefront 64 mode. The register definitions corresponding; to the wavefront mode of the generated code will be used. If code is generated to execute in a 32-bit process address space, then the; 32-bit process address space register definitions are used. If code is generated; to execute in a 64-bit process address space, then the 64-bit process address; space register definitions are used. The ``amdgcn`` target only supports the; 64-bit process address space. .. _amdgpu-dwarf-memory-space-identifier:. Memory Space Identifier; -----------------------. The DWARF memory space represents the source language memory space. See DWARF; Version 5 section 2.12 which is updated by the *DWARF Extensions For; Heterogeneous Debugging* section :ref:`amdgpu-dwarf-memory-spaces`. The DWARF memory space mapping used for AMDGPU is defined in; :ref:`amdgpu-dwarf-memory-space-mapping-table`. .. table:: AMDGPU DWARF Memory Space Mapping; :name: amdgpu-dwarf-memory-space-mapping-table. =========================== ====== =================; DWARF AMDGPU; ---------------------------------- -----------------; Memory Space Name Value Memory Space; =========================== ====== =================; ``DW_MSPACE_LLVM_none`` 0x0000 Generic (Flat); ``DW_MSPACE_LLVM_global`` 0x0001 Global; ``DW_MSPACE_LLVM_constant`` 0x0002 Global; ``DW_MSPACE_LLVM_group`` 0x0003 Local (group/LDS); ``DW_MSPACE_LLVM_private`` 0x0004 Private (Scratch); ``DW_MSPACE_AMDGPU_region`` 0x8000 Region (GDS); =========================== ====== =================. The DWARF memory space values defined in the *DWARF Extensions For Heterogeneous; Debugging* section :ref:`amdgpu-dwarf-memory-spaces` are used. In addition, ``DW_ADDR_AMDGPU_region`` i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:98100,Deployability,update,updated,98100,"can be a private lane address which is dword aligned,; which can be shifted to multiply by the wavefront size, and then used to form a; private wavefront address that gives a location for a contiguous set of dwords,; one per lane, where the vector register dwords are spilled. The compiler knows; the wavefront size since it generates the code. Note that the type of the; address may have to be converted as the size of a; ``DW_ASPACE_AMDGPU_private_lane`` address may be smaller than the size of a; ``DW_ASPACE_AMDGPU_private_wave`` address. .. _amdgpu-dwarf-lane-identifier:. Lane identifier; ---------------. DWARF lane identifies specify a target architecture lane position for hardware; that executes in a SIMD or SIMT manner, and on which a source language maps its; threads of execution onto those lanes. The DWARF lane identifier is pushed by; the ``DW_OP_LLVM_push_lane`` DWARF expression operation. See DWARF Version 5; section 2.5 which is updated by *DWARF Extensions For Heterogeneous Debugging*; section :ref:`amdgpu-dwarf-operation-expressions`. For AMDGPU, the lane identifier corresponds to the hardware lane ID of a; wavefront. It is numbered from 0 to the wavefront size minus 1. Operation Expressions; ---------------------. DWARF expressions are used to compute program values and the locations of; program objects. See DWARF Version 5 section 2.5 and; :ref:`amdgpu-dwarf-operation-expressions`. DWARF location descriptions describe how to access storage which includes memory; and registers. When accessing storage on AMDGPU, bytes are ordered with least; significant bytes first, and bits are ordered within bytes with least; significant bits first. For AMDGPU CFI expressions, ``DW_OP_LLVM_select_bit_piece`` is used to describe; unwinding vector registers that are spilled under the execution mask to memory:; the zero-single location description is the vector register, and the one-single; location description is the spilled memory location description. The; ``DW_OP_LLVM_f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:99872,Deployability,update,updated,99872,"the execution mask to memory:; the zero-single location description is the vector register, and the one-single; location description is the spilled memory location description. The; ``DW_OP_LLVM_form_aspace_address`` is used to specify the address space of the; memory location description. In AMDGPU expressions, ``DW_OP_LLVM_select_bit_piece`` is used by the; ``DW_AT_LLVM_lane_pc`` attribute expression where divergent control flow is; controlled by the execution mask. An undefined location description together; with ``DW_OP_LLVM_extend`` is used to indicate the lane was not active on entry; to the subprogram. See :ref:`amdgpu-dwarf-dw-at-llvm-lane-pc` for an example. Debugger Information Entry Attributes; -------------------------------------. This section describes how certain debugger information entry attributes are; used by AMDGPU. See the sections in DWARF Version 5 section 3.3.5 and 3.1.1; which are updated by *DWARF Extensions For Heterogeneous Debugging* section; :ref:`amdgpu-dwarf-low-level-information` and; :ref:`amdgpu-dwarf-full-and-partial-compilation-unit-entries`. .. _amdgpu-dwarf-dw-at-llvm-lane-pc:. ``DW_AT_LLVM_lane_pc``; ~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_lane_pc`` attribute is used to specify the program; location of the separate lanes of a SIMT thread. If the lane is an active lane then this will be the same as the current program; location. If the lane is inactive, but was active on entry to the subprogram, then this is; the program location in the subprogram at which execution of the lane is; conceptual positioned. If the lane was not active on entry to the subprogram, then this will be the; undefined location. A client debugger can check if the lane is part of a valid; work-group by checking that the lane is in the range of the associated; work-group within the grid, accounting for partial work-groups. If it is not,; then the debugger can omit any information for the lane. Otherwise, the debugger; may repeatedly unwind the st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:107810,Deployability,update,update,107810,"_ref %__active_lane_pc;; ];; d;; EXEC = %3;; $lex_1_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; e;; EXEC = ~EXEC & %1;; $lex_1_else:; DEFINE_DWARF %__divergent_lane_pc_1_else = DW_TAG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc_1_else"";; DW_AT_location = DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108375,Deployability,update,update,108375,"; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subpr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109697,Deployability,update,update,109697,"gram location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110186,Deployability,update,updated,110186,"ather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:115177,Deployability,update,updated,115177,":ref:`ELF Header; <amdgpu-elf-header>`). See DWARF Version 5 section 6.2.2. .. TODO::. Should the ``isa`` state machine register be used to indicate if the code is; in wavefront32 or wavefront64 mode? Or used to specify the architecture ISA?. For AMDGPU the line number program header fields have the following values (see; DWARF Version 5 section 6.2.4):. ``address_size`` (ubyte); Matches the address size for the ``Global`` address space defined in; :ref:`amdgpu-dwarf-address-space-identifier`. ``segment_selector_size`` (ubyte); AMDGPU does not use a segment selector so this is 0. ``minimum_instruction_length`` (ubyte); For GFX9-GFX11 this is 4. ``maximum_operations_per_instruction`` (ubyte); For GFX9-GFX11 this is 1. Source text for online-compiled programs (for example, those compiled by the; OpenCL language runtime) may be embedded into the DWARF Version 5 line table.; See DWARF Version 5 section 6.2.4.1 which is updated by *DWARF Extensions For; Heterogeneous Debugging* section :ref:`DW_LNCT_LLVM_source; <amdgpu-dwarf-line-number-information-dw-lnct-llvm-source>`. The Clang option used to control source embedding in AMDGPU is defined in; :ref:`amdgpu-clang-debug-options-table`. .. table:: AMDGPU Clang Debug Options; :name: amdgpu-clang-debug-options-table. ==================== ==================================================; Debug Flag Description; ==================== ==================================================; -g[no-]embed-source Enable/disable embedding source text in DWARF; debug sections. Useful for environments where; source cannot be written to disk, such as; when performing online compilation.; ==================== ==================================================. For example:. ``-gembed-source``; Enable the embedded source. ``-gno-embed-source``; Disable the embedded source. 32-Bit and 64-Bit DWARF Formats; -------------------------------. See DWARF Version 5 section 7.4 and; :ref:`amdgpu-dwarf-32-bit-and-64-bit-dwarf-formats`. For AMDGPU:. *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151217,Deployability,release,release,151217,"A compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151408,Deployability,update,updated,151408,"the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers (VGPR) are set up as required by the machine code. The required; setup is defined in the :ref:`amdgpu-amdhsa-kernel-descriptor`. The ini",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157405,Deployability,release,releases,157405,"l-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match tho",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157638,Deployability,release,releases,157638,"he aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= ===============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160333,Deployability,configurat,configuration,160333,"to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160514,Deployability,configurat,configuration,160514,"uments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160694,Deployability,configurat,configuration,160694,"acket is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160895,Deployability,configurat,configuration,160895," the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be 0,; >449 1 bit ENABLE_SGPR_DISPATCH_PTR; >450 1 bit ENABLE_SGPR_QUEUE_PTR; >451 1 bit ENABLE_SGPR_KERNARG_SEGMENT_PTR; >452 1 bit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:161101,Deployability,configurat,configuration,161101," to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be 0,; >449 1 bit ENABLE_SGPR_DISPATCH_PTR; >450 1 bit ENABLE_SGPR_QUEUE_PTR; >451 1 bit ENABLE_SGPR_KERNARG_SEGMENT_PTR; >452 1 bit ENABLE_SGPR_DISPATCH_ID; >453 1 bit ENABLE_SGPR_FLAT_SCRATCH_INIT If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:171810,Deployability,install,installed,171810,"============; 0 1 bit ENABLE_PRIVATE_SEGMENT * Enable the setup of the; private segment.; * If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; does not specify; *Architected flat; scratch* then enable the; setup of the SGPR; wavefront scratch offset; system register (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`).; * If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; specifies *Architected; flat scratch* then enable; the setup of the; FLAT_SCRATCH register; pair (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.SCRATCH_EN``.; 5:1 5 bits USER_SGPR_COUNT The total number of SGPR; user data; registers requested. This; number must be greater than; or equal to the number of user; data registers enabled. Used by CP to set up; ``COMPUTE_PGM_RSRC2.USER_SGPR``.; 6 1 bit ENABLE_TRAP_HANDLER GFX6-GFX11; Must be 0. This bit represents; ``COMPUTE_PGM_RSRC2.TRAP_PRESENT``,; which is set by the CP if; the runtime has installed a; trap handler.; GFX12; Reserved, must be 0.; 7 1 bit ENABLE_SGPR_WORKGROUP_ID_X Enable the setup of the; system SGPR register for; the work-group id in the X; dimension (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.TGID_X_EN``.; 8 1 bit ENABLE_SGPR_WORKGROUP_ID_Y Enable the setup of the; system SGPR register for; the work-group id in the Y; dimension (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.TGID_Y_EN``.; 9 1 bit ENABLE_SGPR_WORKGROUP_ID_Z Enable the setup of the; system SGPR register for; the work-group id in the Z; dimension (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_RSRC2.TGID_Z_EN``.; 10 1 bit ENABLE_SGPR_WORKGROUP_INFO Enable the setup of the; system SGPR register for; work-group information (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Used by CP to set up; ``COMPUTE_PGM_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:177894,Deployability,pipeline,pipeline,177894,"0.; GFX11; Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..63; with a granularity of 128 bytes.; 10 1 bit TRAP_ON_START GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront starts execution by trapping into the trap handler. CP is responsible for filling in the trap on start bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_START`` according to what the runtime; requests.; 11 1 bit TRAP_ON_END GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront execution terminates by trapping into the trap handler. CP is responsible for filling in the trap on end bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_END`` according to what the runtime requests.; 30:12 19 bits Reserved, must be 0.; 31 1 bit IMAGE_OP GFX10; Reserved, must be 0.; GFX11; If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:178037,Deployability,pipeline,pipeline,178037,"0.; GFX11; Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..63; with a granularity of 128 bytes.; 10 1 bit TRAP_ON_START GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront starts execution by trapping into the trap handler. CP is responsible for filling in the trap on start bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_START`` according to what the runtime; requests.; 11 1 bit TRAP_ON_END GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront execution terminates by trapping into the trap handler. CP is responsible for filling in the trap on end bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_END`` according to what the runtime requests.; 30:12 19 bits Reserved, must be 0.; 31 1 bit IMAGE_OP GFX10; Reserved, must be 0.; GFX11; If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:178152,Deployability,pipeline,pipeline,178152,"ith a granularity of 128 bytes.; 10 1 bit TRAP_ON_START GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront starts execution by trapping into the trap handler. CP is responsible for filling in the trap on start bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_START`` according to what the runtime; requests.; 11 1 bit TRAP_ON_END GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront execution terminates by trapping into the trap handler. CP is responsible for filling in the trap on end bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_END`` according to what the runtime requests.; 30:12 19 bits Reserved, must be 0.; 31 1 bit IMAGE_OP GFX10; Reserved, must be 0.; GFX11; If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:179235,Deployability,pipeline,pipeline,179235,"==============. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bit IMAGE_OP If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: Floating Point Rounding Mode Enumeration Values; :name: amdgpu-amdhsa-floating-point-rounding-mode-enumeration-values-table. ====================================== ===== ==============================; Enumeration Name Value Description; ====================================== ===== ==============================; FLOAT_ROUND_MODE_NEAR_EVEN 0 Round Ties To Even; FLOAT_ROUND_MODE_PLUS_INFINITY 1 Round Toward +infinity; FLOAT_ROUND_MODE_MINUS_INFINITY 2 Round Toward -infinity; FLOAT_ROUND_MODE_ZERO 3 Round Toward 0; ====================================== ===== ==============================. .. table:: Extended FLT_ROUNDS En",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:179378,Deployability,pipeline,pipeline,179378,"==============. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bit IMAGE_OP If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: Floating Point Rounding Mode Enumeration Values; :name: amdgpu-amdhsa-floating-point-rounding-mode-enumeration-values-table. ====================================== ===== ==============================; Enumeration Name Value Description; ====================================== ===== ==============================; FLOAT_ROUND_MODE_NEAR_EVEN 0 Round Ties To Even; FLOAT_ROUND_MODE_PLUS_INFINITY 1 Round Toward +infinity; FLOAT_ROUND_MODE_MINUS_INFINITY 2 Round Toward -infinity; FLOAT_ROUND_MODE_ZERO 3 Round Toward 0; ====================================== ===== ==============================. .. table:: Extended FLT_ROUNDS En",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:179493,Deployability,pipeline,pipeline,179493,"===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bit IMAGE_OP If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: Floating Point Rounding Mode Enumeration Values; :name: amdgpu-amdhsa-floating-point-rounding-mode-enumeration-values-table. ====================================== ===== ==============================; Enumeration Name Value Description; ====================================== ===== ==============================; FLOAT_ROUND_MODE_NEAR_EVEN 0 Round Ties To Even; FLOAT_ROUND_MODE_PLUS_INFINITY 1 Round Toward +infinity; FLOAT_ROUND_MODE_MINUS_INFINITY 2 Round Toward -infinity; FLOAT_ROUND_MODE_ZERO 3 Round Toward 0; ====================================== ===== ==============================. .. table:: Extended FLT_ROUNDS Enumeration Values; :name: amdgpu-rounding-mode-enumeration-values-table. +------------------------+---------------+-------------------+--------------------+----",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:199541,Deployability,update,updated,199541,"P uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue ba",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204049,Deployability,release,release,204049,"store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204159,Deployability,release,release,204159,"store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205014,Deployability,release,release,205014,"l on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx9",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205159,Deployability,release,release,205159,"l on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx9",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205337,Deployability,release,release,205337,"optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multip",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205588,Deployability,release,release,205588,"====== ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209118,Deployability,release,release,209118,"work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219016,Deployability,release,release,219016,"ding to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219125,Deployability,release,release,219125," an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219465,Deployability,release,released,219465,"termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219517,Deployability,release,release,219517,"ures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219571,Deployability,release,release,219571,"validating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220277,Deployability,release,released,220277,"fter; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220326,Deployability,release,release,220326," before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220433,Deployability,release,release,220433,"mpleted before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220781,Deployability,release,released,220781,"e split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220831,Deployability,release,release,220831,"dently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; addr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220883,Deployability,release,release,220883,"cnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always gen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221572,Deployability,release,released,221572,"it.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221618,Deployability,release,release,221618," following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221675,Deployability,release,release,221675," following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:222456,Deployability,release,release,222456,"l; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224180,Deployability,release,released,224180,"bal/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224870,Deployability,release,released,224870,"cal; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225828,Deployability,release,released,225828,"l; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226865,Deployability,release,released,226865,"w that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory oper",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:228446,Deployability,release,release-fence-paired-atomic,228446,"ne* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:228514,Deployability,release,release,228514," need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229815,Deployability,release,release-fence-paired-atomic,229815,"ess space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_wa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229883,Deployability,release,release,229883,"; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; befor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231045,Deployability,release,release,231045,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231111,Deployability,release,release,231111,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231159,Deployability,release,release,231159,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231211,Deployability,release,release,231211,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232839,Deployability,release,release,232839,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232905,Deployability,release,release,232905,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232953,Deployability,release,release,232953,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:233005,Deployability,release,release,233005,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:233497,Deployability,release,release,233497," own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237590,Deployability,release,release,237590,"s. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256891,Deployability,release,release,256891," scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256988,Deployability,release,release,256988,"generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257125,Deployability,release,release,257125,"s is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_wai",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257706,Deployability,release,released,257706,"e stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257758,Deployability,release,release,257758,"omic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257880,Deployability,release,release,257880,"re atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258625,Deployability,release,released,258625,"n before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258677,Deployability,release,release,258677,"rforming the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259613,Deployability,release,released,259613,"ns; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259662,Deployability,release,release,259662,"re; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259757,Deployability,release,release,259757,"orms L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If Open",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259892,Deployability,release,release,259892,"kmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260482,Deployability,release,released,260482,".; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw rele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260532,Deployability,release,release,260532,"ompleted before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260652,Deployability,release,release,260652,"omicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261380,Deployability,release,released,261380,"icrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261430,Deployability,release,release,261430,"mpleted before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wave",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:262335,Deployability,release,released,262335,"ll; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:262381,Deployability,release,release,262381,"flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:262438,Deployability,release,release,262438,"flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:263521,Deployability,release,release,263521,"ution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory order",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:264722,Deployability,release,release,264722,"local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:267168,Deployability,release,released,267168,"paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_wai",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:268512,Deployability,release,released,268512," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:269745,Deployability,release,released,269745,"g; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:271005,Deployability,release,released,271005,"nvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:272236,Deployability,release,released,272236,"invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:273582,Deployability,release,released,273582,"vl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - Howe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:275668,Deployability,release,release-fence-paired-atomic,275668,"ce on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:275736,Deployability,release,release,275736,"obal/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:277473,Deployability,release,release-fence-paired-atomic,277473,"ess space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:277541,Deployability,release,release,277541,"; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:279354,Deployability,release,release-fence-paired-atomic,279354," fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:279422,Deployability,release,release,279422,"cnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281077,Deployability,release,release,281077,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281143,Deployability,release,release,281143,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281191,Deployability,release,release,281191,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:281243,Deployability,release,release,281243,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:282987,Deployability,release,release,282987,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:283053,Deployability,release,release,283053,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:283101,Deployability,release,release,283101,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:283153,Deployability,release,release,283153,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:283645,Deployability,release,release,283645," own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx942:. Memory Model GFX942; +++++++++++++++++++. For GFX942:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:286882,Deployability,update,updated,286882," is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:288177,Deployability,release,release,288177," not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory wri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:306620,Deployability,release,release,306620,"ccording to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_inv sc0=1 sc1=1. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buff",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:306779,Deployability,release,release,306779,"omic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_inv sc0=1 sc1=1. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; follo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:306916,Deployability,release,release,306916,"atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_inv sc0=1 sc1=1. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:307497,Deployability,release,released,307497," following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:307619,Deployability,release,release,307619,"re atomic release - singlethread - global 1. GFX940, GFX941; - wavefront - generic buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; complet",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:307741,Deployability,release,release,307741,"ffer/global/flat_store. store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc0=1; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:308659,Deployability,release,released,308659,"tore atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:308781,Deployability,release,release,308781," release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:309729,Deployability,release,released,309729,"d. 3. GFX940, GFX941; buffer/global/flat_store; sc0=1 sc1=1; GFX942; buffer/global/flat_store; sc1=1; store atomic release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:309791,Deployability,release,release,309791,"lease - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomic",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:309886,Deployability,release,release,309886,"back to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeba",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:310021,Deployability,release,release,310021,"mcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:310611,Deployability,release,released,310611,"pen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:310667,Deployability,release,release,310667," performing the; store that is being; released. 3. buffer/global/flat_store; sc0=1 sc1=1; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being rele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:310787,Deployability,release,release,310787,"w release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 3. buffer/global/flat_atomic sc1=1; atomicrmw release - system - global 1. buffer_wbl2 sc0=1",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:311688,Deployability,release,released,311688,"r/global/flat_atomic sc0=1; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 3. buffer/global/flat_atomic sc1=1; atomicrmw release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; perfor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:311744,Deployability,release,release,311744,"s space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. buffer_wbl2 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 3. buffer/global/flat_atomic sc1=1; atomicrmw release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - single",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:312661,Deployability,release,released,312661,"ons; to global and local; have completed; before performing; the atomicrmw that; is being released. 3. buffer/global/flat_atomic sc1=1; atomicrmw release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:312720,Deployability,release,release,312720,"crmw release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:312777,Deployability,release,release,312777,"crmw release - system - global 1. buffer_wbl2 sc0=1 sc1=1; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_atomic; sc0=1 sc1=1; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:313860,Deployability,release,release,313860,"ution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgk",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:315282,Deployability,release,release,315282,"local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:317691,Deployability,release,released,317691,"paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acq_rel - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before; the following; buffer_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:319025,Deployability,release,released,319025," execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If not TgSplit execution; mode, omit vmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; the following; buffer_inv and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:320420,Deployability,release,released,320420," local load; atomic value being; acquired. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:321682,Deployability,release,released,321682,"Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - global 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. buffer/global_atomic; sc1=1; 4. s_waitcnt vmcnt(0). - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:323015,Deployability,release,released,323015,"mic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. atomicrmw acq_rel - agent - generic 1. buffer_wbl2 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 3. flat_atomic; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 5. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); mu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:324363,Deployability,release,released,324363,"ust happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - system - generic 1. buffer_wbl2 sc0=1 sc1=1. - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and L2 writeback; have completed before; performing the; atomicrmw that is; being released. 3. flat_atomic sc1=1; 4. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 5. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:326378,Deployability,release,release-fence-paired-atomic,326378,"ce on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:326446,Deployability,release,release,326446,"obal/generic; load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_inv sc0=1. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. buffer_wbl2 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at agent scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:328386,Deployability,release,release-fence-paired-atomic,328386,"no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; se",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:328454,Deployability,release,release,328454,"t(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 3. buffer_inv sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. fence acq_rel - system *none* 1. buffer_wbl2 sc0=1 sc1=1. - If OpenCL and; address space is; local, omit.; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); mu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:330252,Deployability,release,release-fence-paired-atomic,330252,"no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:330320,Deployability,release,release,330320,"t(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_inv sc0=1 sc1=1. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; MTYPE NC global data.; MTYPE RW and CC memory will; never be stale due to the; memory probes. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:331923,Deployability,release,release,331923,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:331989,Deployability,release,release,331989,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:332037,Deployability,release,release,332037,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:332089,Deployability,release,release,332089,"lit execution mode; and vmcnt(0) if TgSplit; execution mode.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:333833,Deployability,release,release,333833,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:333899,Deployability,release,release,333899,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:333947,Deployability,release,release,333947,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:333999,Deployability,release,release,333999,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:334491,Deployability,release,release,334491," own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx10-gfx11:. Memory Model GFX10-GFX11; ++++++++++++++++++++++++. For GFX10-GFX11:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple work-group processors (WGP).; * Each WGP has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same; WGP. In CU wavefront execution mode the wave",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:338699,Deployability,release,release,338699,"ory L0 caches use an L1 cache shared by all WGPs on; the same SA. Therefore, no special action is required for coherence between; the wavefronts of a single work-group. However, a ``buffer_gl1_inv`` is; required for coherence between wavefronts executing in different work-groups; as they may be executing on different SAs that access different L1s.; * The L1 caches have independent quadrants to service disjoint ranges of virtual; addresses.; * Each L0 cache has a separate request queue per L1 quadrant. Therefore, the; vector and scalar memory operations performed by different wavefronts, whether; executing in the same or different work-groups (which may be executing on; different CUs accessing different L0s), can be reordered relative to each; other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is required to ensure; synchronization between vector memory operations of different wavefronts. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some tar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339524,Deployability,release,release,339524," between vector memory operations of different wavefronts. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between k",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:354777,Deployability,release,release,354777,"paired-atomic).; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; atomicrmw-no-return-value; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; caches. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:354886,Deployability,release,release,354886,"or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; caches. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:355759,Deployability,release,released,355759,"--------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:355811,Deployability,release,release,355811,"al 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; indepe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:356484,Deployability,release,released,356484,"neric; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlet",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:356520,Deployability,release,release,356520,"appen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrm",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:357368,Deployability,release,released,357368,"rn-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; me",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:357417,Deployability,release,release,357417,"rations have; completed before; performing the; store that is being; released. 2. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:357524,Deployability,release,release,357524,"re; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt vscnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:358404,Deployability,release,released,358404,"at is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:358454,Deployability,release,release,358454,". buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; follo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:359127,Deployability,release,released,359127," store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:359161,Deployability,release,release,359161," after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:360001,Deployability,release,released,360001,"ic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:360047,Deployability,release,release,360047,"ompleted before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:360104,Deployability,release,release,360104,"ompleted before; performing the; store that is being; released. 2. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:361492,Deployability,release,release,361492,"ce had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:364016,Deployability,release,released,364016," 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - If CU wavefront execution; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:365154,Deployability,release,released,365154,"; mode, omit.; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the; atomicrmw value; being acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - local 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - If OpenCL, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - Must happen before; the following; store.; - Ensures that all; global memory; operations have; completed before; performing the; store that is being; released. 2. ds_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:366404,Deployability,release,released,366404,"tomic value being; acquired. 4. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - If OpenCL omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store; atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_gl0_inv.; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:367679,Deployability,release,released,367679,".; - Ensures any; following global; data read is no; older than the load; atomic value being; acquired. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vm/vscnt(0). - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; st",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:368949,Deployability,release,released,368949,"ompleted before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load atomic; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vm/vscnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Use vmcnt(0) if atomic with; return and vscnt(0) if; atomic with no-return.; - Must happen before; following; buffer_gl*_inv.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 4. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:371229,Deployability,release,release-fence-paired-atomic,371229,"t happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcn",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:371297,Deployability,release,release,371297,"global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store atomic/; atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release.; - Must happen before; the following; buffer_gl0_inv.; - Ensures that the; acquire-fence-paired; atomic has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; acquire-fence-paired-atomic. 3. buffer_gl0_inv. - If CU wavefront execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0) & vscnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0) and vscnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen af",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:373209,Deployability,release,release-fence-paired-atomic,373209,"itcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the caches. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:373277,Deployability,release,release,373277,"nt(0); must happen after; any preceding; global/generic; load/load; atomic/; atomicrmw-with-return-value.; - s_waitcnt vscnt(0); must happen after; any preceding; global/generic; store/store atomic/; atomicrmw-no-return-value.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_gl*_inv.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the caches. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_gl0_inv;; buffer_gl1_inv. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit vmcnt(0) and; vscnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0), and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0) must; happen after; preceding; local/generic load; atomic/s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375319,Deployability,release,release,375319,"; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not nee",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375385,Deployability,release,release,375385,"; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not nee",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375433,Deployability,release,release,375433,"; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not nee",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:375485,Deployability,release,release,375485,"; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global/local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local. 1. s_waitcnt vmcnt(0) & vscnt(0). - If CU wavefront execution; mode, omit.; - Could be split into; separate s_waitcnt; vmcnt(0) and s_waitcnt; vscnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not nee",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:376996,Deployability,release,release,376996,"e; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:377062,Deployability,release,release,377062,"e; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:377110,Deployability,release,release,377110,"e; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:377162,Deployability,release,release,377162,"e; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); Must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0) & vscnt(0). - Could be split into; separate s_waitcnt; vmcnt(0), s_waitcnt; vscnt(0) and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; local load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:378959,Deployability,release,release,378959,"aitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379025,Deployability,release,release,379025,"aitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379073,Deployability,release,release,379073,"aitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379125,Deployability,release,release,379125,"aitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/; atomicrmw-with-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - s_waitcnt vscnt(0); Must happen after; preceding; global/generic store; atomic/; atomicrmw-no-return-value; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:379617,Deployability,release,release,379617," own s_waitcnt; vscnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-trap-handler-abi:. Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by the AMDGPU backend for HSA [HSA]_ compatible; runtimes (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:380385,Deployability,install,installs,380385,"ve already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-trap-handler-abi:. Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by the AMDGPU backend for HSA [HSA]_ compatible; runtimes (see :ref:`amdgpu-os`), the runtime installs a trap handler that; supports the ``s_trap`` instruction. For usage see:. - :ref:`amdgpu-trap-handler-for-amdhsa-os-v2-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v3-table`; - :ref:`amdgpu-trap-handler-for-amdhsa-os-v4-onwards-table`. .. table:: AMDGPU Trap Handler for AMDHSA OS Code Object V2; :name: amdgpu-trap-handler-for-amdhsa-os-v2-table. =================== =============== =============== =======================================; Usage Code Sequence Trap Handler Description; Inputs; =================== =============== =============== =======================================; reserved ``s_trap 0x00`` Reserved by hardware.; ``debugtrap(arg)`` ``s_trap 0x01`` ``SGPR0-1``: Reserved for Finalizer HSA ``debugtrap``; ``queue_ptr`` intrinsic (not implemented).; ``VGPR0``:; ``arg``; ``llvm.trap`` ``s_trap 0x02`` ``SGPR0-1``: Causes wave to be halted with the PC at; ``queue_ptr`` the trap instruction. The associated; queue is signalled to put it in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:385980,Deployability,update,updated,385980,"n the queue will be; terminated.; ``llvm.debugtrap`` ``s_trap 0x03`` *none* *none* - If debugger not enabled then behaves; as a no-operation. The trap handler; is entered and immediately returns to; continue execution of the wavefront.; - If the debugger is enabled, causes; the debug trap to be reported by the; debugger and the wavefront is put in; the halt state with the PC at the; instruction. The debugger must; increment the PC and resume the wave.; reserved ``s_trap 0x04`` Reserved.; reserved ``s_trap 0x05`` Reserved.; reserved ``s_trap 0x06`` Reserved.; reserved ``s_trap 0x07`` Reserved.; reserved ``s_trap 0x08`` Reserved.; reserved ``s_trap 0xfe`` Reserved.; reserved ``s_trap 0xff`` Reserved.; =================== =============== ================ ================= =======================================. .. _amdgpu-amdhsa-function-call-convention:. Call Convention; ~~~~~~~~~~~~~~~. .. note::. This section is currently incomplete and has inaccuracies. It is WIP that will; be updated as information is determined. See :ref:`amdgpu-dwarf-address-space-identifier` for information on swizzled; addresses. Unswizzled addresses are normal linear addresses. .. _amdgpu-amdhsa-function-call-convention-kernel-functions:. Kernel Functions; ++++++++++++++++. This section describes the call convention ABI for the outer kernel function. See :ref:`amdgpu-amdhsa-initial-kernel-execution-state` for the kernel call; convention. The following is not part of the AMDGPU kernel calling convention but describes; how the AMDGPU implements function calls:. 1. Clang decides the kernarg layout to match the *HSA Programmer's Language; Reference* [HSA]_. - All structs are passed directly.; - Lambda values are passed *TBA*. .. TODO::. - Does this really follow HSA rules? Or are structs >16 bytes passed; by-value struct?; - What is ABI for lambda values?. 4. The kernel performs certain setup in its prolog, as described in; :ref:`amdgpu-amdhsa-kernel-prolog`. .. _amdgpu-amdhsa-function-call-conv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:402832,Deployability,pipeline,pipelines,402832,"e-object-metadata-map-table`; and referenced tables. Additional information can be added to the maps. To avoid conflicts, any; key names should be prefixed by ""*vendor-name*."" where ``vendor-name``; can be the name of the vendor and specific vendor tool that generates the; information. The prefix is abbreviated to simply ""."" when it appears; within a map that has been added by the same *vendor-name*. .. table:: AMDPAL Code Object Metadata Map; :name: amdgpu-amdpal-code-object-metadata-map-table. =================== ============== ========= ======================================================================; String Key Value Type Required? Description; =================== ============== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:402868,Deployability,pipeline,pipeline,402868,"e-object-metadata-map-table`; and referenced tables. Additional information can be added to the maps. To avoid conflicts, any; key names should be prefixed by ""*vendor-name*."" where ``vendor-name``; can be the name of the vendor and specific vendor tool that generates the; information. The prefix is abbreviated to simply ""."" when it appears; within a map that has been added by the same *vendor-name*. .. table:: AMDPAL Code Object Metadata Map; :name: amdgpu-amdpal-code-object-metadata-map-table. =================== ============== ========= ======================================================================; String Key Value Type Required? Description; =================== ============== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:402928,Deployability,pipeline,pipeline-metadata-map-table,402928,"to the maps. To avoid conflicts, any; key names should be prefixed by ""*vendor-name*."" where ``vendor-name``; can be the name of the vendor and specific vendor tool that generates the; information. The prefix is abbreviated to simply ""."" when it appears; within a map that has been added by the same *vendor-name*. .. table:: AMDPAL Code Object Metadata Map; :name: amdgpu-amdpal-code-object-metadata-map-table. =================== ============== ========= ======================================================================; String Key Value Type Required? Description; =================== ============== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, use",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403218,Deployability,pipeline,pipeline-metadata-map-table,403218," it appears; within a map that has been added by the same *vendor-name*. .. table:: AMDPAL Code Object Metadata Map; :name: amdgpu-amdpal-code-object-metadata-map-table. =================== ============== ========= ======================================================================; String Key Value Type Required? Description; =================== ============== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403560,Deployability,pipeline,pipeline,403560,"======== ========= ======================================================================; ""amdpal.version"" sequence of Required PAL code object metadata (major, minor) version. The current values; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403778,Deployability,pipeline,pipeline,403778,"; 2 integers are defined by *Util::Abi::PipelineMetadata(Major|Minor)Version*.; ""amdpal.pipelines"" sequence of Required Per-pipeline metadata. See; map :ref:`amdgpu-amdpal-code-object-pipeline-metadata-map-table` for the; definition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:403960,Deployability,pipeline,pipeline,403960,"nition of the keys included in that map.; =================== ============== ========= ======================================================================. .. .. table:: AMDPAL Code Object Pipeline Metadata Map; :name: amdgpu-amdpal-code-object-pipeline-metadata-map-table. ====================================== ============== ========= ===================================================; String Key Value Type Required? Description; ====================================== ============== ========= ===================================================; "".name"" string Source name of the pipeline.; "".type"" string Pipeline type, e.g. VsPs. Values include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:404630,Deployability,configurat,configuration,404630,"es include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean Indicates whether or not the pipeline uses the; viewport array index feature. Pipelines which use; this feature can render into all 16 viewports,; whereas pipelines which do not use it are; restricted to viewport #0.; "".es_gs_lds_size"" integer Size in bytes of LDS space used internally for; handling data-passing between the ES and GS; shader stages. This can be zero if the data is; passed using off-chip buffers. This value should; be used to program all user-SGPRs which have been; marked with ""UserDataMapping::EsGsLdsSize""; (typically only the GS and VS HW stages will ever; have a user-SGPR so marked).; "".nggSubgroupSize"" integer Explicit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:404831,Deployability,pipeline,pipeline,404831,"egers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean Indicates whether or not the pipeline uses the; viewport array index feature. Pipelines which use; this feature can render into all 16 viewports,; whereas pipelines which do not use it are; restricted to viewport #0.; "".es_gs_lds_size"" integer Size in bytes of LDS space used internally for; handling data-passing between the ES and GS; shader stages. This can be zero if the data is; passed using off-chip buffers. This value should; be used to program all user-SGPRs which have been; marked with ""UserDataMapping::EsGsLdsSize""; (typically only the GS and VS HW stages will ever; have a user-SGPR so marked).; "".nggSubgroupSize"" integer Explicit maximum subgroup size for NGG shaders; (maximum number of threads in a subgroup).; "".num_interpolants"" integer Graphics only. Number of PS interpolants.; "".mesh_scratch_memory_size"" i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:404999,Deployability,pipeline,pipeline,404999,"e is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean Indicates whether or not the pipeline uses the; viewport array index feature. Pipelines which use; this feature can render into all 16 viewports,; whereas pipelines which do not use it are; restricted to viewport #0.; "".es_gs_lds_size"" integer Size in bytes of LDS space used internally for; handling data-passing between the ES and GS; shader stages. This can be zero if the data is; passed using off-chip buffers. This value should; be used to program all user-SGPRs which have been; marked with ""UserDataMapping::EsGsLdsSize""; (typically only the GS and VS HW stages will ever; have a user-SGPR so marked).; "".nggSubgroupSize"" integer Explicit maximum subgroup size for NGG shaders; (maximum number of threads in a subgroup).; "".num_interpolants"" integer Graphics only. Number of PS interpolants.; "".mesh_scratch_memory_size"" integer Max mesh shader scratch memory used.; "".api"" string Name of the client graphics API.; "".api_create_info"" binary Graphics API shader create info binary blob. Can; be defined by the driv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:405125,Deployability,pipeline,pipelines,405125,"der metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean Indicates whether or not the pipeline uses the; viewport array index feature. Pipelines which use; this feature can render into all 16 viewports,; whereas pipelines which do not use it are; restricted to viewport #0.; "".es_gs_lds_size"" integer Size in bytes of LDS space used internally for; handling data-passing between the ES and GS; shader stages. This can be zero if the data is; passed using off-chip buffers. This value should; be used to program all user-SGPRs which have been; marked with ""UserDataMapping::EsGsLdsSize""; (typically only the GS and VS HW stages will ever; have a user-SGPR so marked).; "".nggSubgroupSize"" integer Explicit maximum subgroup size for NGG shaders; (maximum number of threads in a subgroup).; "".num_interpolants"" integer Graphics only. Number of PS interpolants.; "".mesh_scratch_memory_size"" integer Max mesh shader scratch memory used.; "".api"" string Name of the client graphics API.; "".api_create_info"" binary Graphics API shader create info binary blob. Can; be defined by the driver using the compiler if; they want to be able to correlate API-specific; information used during creation at a later time.; =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:408990,Deployability,pipeline,pipeline,408990,"-------------------------------------------------------------+; |String Key |Value Type |Description |; +=============+==============+=======================================================================+; |- "".ls"" |map |See :ref:`amdgpu-amdpal-code-object-hardware-stage-metadata-map-table` |; |- "".hs"" | |for the definition of the keys included in that map. |; |- "".es"" | | |; |- "".gs"" | | |; |- "".vs"" | | |; |- "".ps"" | | |; |- "".cs"" | | |; +-------------+--------------+-----------------------------------------------------------------------+. .. .. table:: AMDPAL Code Object Hardware Stage Metadata Map; :name: amdgpu-amdpal-code-object-hardware-stage-metadata-map-table. ========================== ============== ========= ===============================================================; String Key Value Type Required? Description; ========================== ============== ========= ===============================================================; "".entry_point"" string The ELF symbol pointing to this pipeline's stage entry point.; "".scratch_memory_size"" integer Scratch memory size in bytes.; "".lds_size"" integer Local Data Share size in bytes.; "".perf_data_buffer_size"" integer Performance data buffer size in bytes.; "".vgpr_count"" integer Number of VGPRs used.; "".agpr_count"" integer Number of AGPRs used.; "".sgpr_count"" integer Number of SGPRs used.; "".vgpr_limit"" integer If non-zero, indicates the shader was compiled with a; directive to instruct the compiler to limit the VGPR usage to; be less than or equal to the specified value (only set if; different from HW default).; "".sgpr_limit"" integer SGPR count upper limit (only set if different from HW; default).; "".threadgroup_dimensions"" sequence of Thread-group X/Y/Z dimensions (Compute only).; 3 integers; "".wavefront_size"" integer Wavefront size (only set if different from HW default).; "".uses_uavs"" boolean The shader reads or writes UAVs.; "".uses_rovs"" boolean The shader reads or writes ROVs.; "".writes_uavs"" boolean The sh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:412804,Deployability,pipeline,pipeline,412804,"unt"" integer Number of VGPRs used by the shader.; "".sgpr_count"" integer Number of SGPRs used by the shader.; "".stack_frame_size_in_bytes"" integer Amount of stack size used by the shader.; "".shader_subtype"" string Shader subtype/kind. Values include:. - ""Unknown"". ============================= ============== =================================================================. .. .. table:: AMDPAL Code Object Register Map; :name: amdgpu-amdpal-code-object-register-map-table. ========================== ============== ====================================================================; 32-bit Integer Key Value Type Description; ========================== ============== ====================================================================; ``reg offset`` 32-bit integer ``reg offset`` is the dword offset into the GFXIP register space of; a GRBM register (i.e., driver accessible GPU register number, not; shader GPR register number). The driver is required to program each; specified register to the corresponding specified value when; executing this pipeline. Typically, the ``reg offsets`` are the; ``uint16_t`` offsets to each register as defined by the hardware; chip headers. The register is set to the provided value. However, a; ``reg offset`` that specifies a user data register (e.g.,; COMPUTE_USER_DATA_0) needs special treatment. See; :ref:`amdgpu-amdpal-code-object-user-data-section` section for more; information.; ========================== ============== ====================================================================. .. _amdgpu-amdpal-code-object-user-data-section:. User Data; +++++++++. Each hardware stage has a set of 32-bit physical SPI *user data registers*; (either 16 or 32 based on graphics IP and the stage) which can be; written from a command buffer and then loaded into SGPRs when waves are; launched via a subsequent dispatch or draw operation. This is the way; most arguments are passed from the application/runtime to a hardware; shader. PAL abstracts this ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:413814,Deployability,pipeline,pipeline,413814,"the ``reg offsets`` are the; ``uint16_t`` offsets to each register as defined by the hardware; chip headers. The register is set to the provided value. However, a; ``reg offset`` that specifies a user data register (e.g.,; COMPUTE_USER_DATA_0) needs special treatment. See; :ref:`amdgpu-amdpal-code-object-user-data-section` section for more; information.; ========================== ============== ====================================================================. .. _amdgpu-amdpal-code-object-user-data-section:. User Data; +++++++++. Each hardware stage has a set of 32-bit physical SPI *user data registers*; (either 16 or 32 based on graphics IP and the stage) which can be; written from a command buffer and then loaded into SGPRs when waves are; launched via a subsequent dispatch or draw operation. This is the way; most arguments are passed from the application/runtime to a hardware; shader. PAL abstracts this functionality by exposing a set of 128 *user data; entries* per pipeline a client can use to pass arguments from a command; buffer to one or more shaders in that pipeline. The ELF code object must; specify a mapping from virtualized *user data entries* to physical *user; data registers*, and PAL is responsible for implementing that mapping,; including spilling overflow *user data entries* to memory if needed. Since the *user data registers* are GRBM-accessible SPI registers, this; mapping is actually embedded in the ``.registers`` metadata entry. For; most registers, the value in that map is a literal 32-bit value that; should be written to the register by the driver. However, when the; register is a *user data register* (any USER_DATA register e.g.,; SPI_SHADER_USER_DATA_PS_5), the value is instead an encoding that tells; the driver to write either a *user data entry* value or one of several; driver-internal values to the register. This encoding is described in; the following table:. .. note::. Currently, *user data registers* 0 and 1 (e.g., SPI_SHADER_USER_D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:413912,Deployability,pipeline,pipeline,413912,"the ``reg offsets`` are the; ``uint16_t`` offsets to each register as defined by the hardware; chip headers. The register is set to the provided value. However, a; ``reg offset`` that specifies a user data register (e.g.,; COMPUTE_USER_DATA_0) needs special treatment. See; :ref:`amdgpu-amdpal-code-object-user-data-section` section for more; information.; ========================== ============== ====================================================================. .. _amdgpu-amdpal-code-object-user-data-section:. User Data; +++++++++. Each hardware stage has a set of 32-bit physical SPI *user data registers*; (either 16 or 32 based on graphics IP and the stage) which can be; written from a command buffer and then loaded into SGPRs when waves are; launched via a subsequent dispatch or draw operation. This is the way; most arguments are passed from the application/runtime to a hardware; shader. PAL abstracts this functionality by exposing a set of 128 *user data; entries* per pipeline a client can use to pass arguments from a command; buffer to one or more shaders in that pipeline. The ELF code object must; specify a mapping from virtualized *user data entries* to physical *user; data registers*, and PAL is responsible for implementing that mapping,; including spilling overflow *user data entries* to memory if needed. Since the *user data registers* are GRBM-accessible SPI registers, this; mapping is actually embedded in the ``.registers`` metadata entry. For; most registers, the value in that map is a literal 32-bit value that; should be written to the register by the driver. However, when the; register is a *user data register* (any USER_DATA register e.g.,; SPI_SHADER_USER_DATA_PS_5), the value is instead an encoding that tells; the driver to write either a *user data entry* value or one of several; driver-internal values to the register. This encoding is described in; the following table:. .. note::. Currently, *user data registers* 0 and 1 (e.g., SPI_SHADER_USER_D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416159,Deployability,pipeline,pipeline,416159,============= ===============================================================================; Value Name Description; ========== ================= ===============================================================================; 0..127 *User Data Entry* 32-bit value of user_data_entry[N] as specified via *CmdSetUserData()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the strea,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416273,Deployability,pipeline,pipeline,416273,======================; Value Name Description; ========== ================= ===============================================================================; 0..127 *User Data Entry* 32-bit value of user_data_entry[N] as specified via *CmdSetUserData()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per ,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416400,Deployability,pipeline,pipeline,416400,=============================; 0..127 *User Data Entry* 32-bit value of user_data_entry[N] as specified via *CmdSetUserData()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416519,Deployability,pipeline,pipeline,416519,Data()*; 0x10000000 GlobalTable 32-bit pointer to GPU memory containing the global internal table (should; always point to *user data register* 0).; 0x10000001 PerShaderTable 32-bit pointer to GPU memory containing the per-shader internal table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for o,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:416805,Deployability,pipeline,pipelines,416805,"ata-per-shader-table-section`; for more detail (should always point to *user data register* 1).; 0x10000002 SpillTable 32-bit pointer to GPU memory containing the user data spill table. See; :ref:`amdgpu-amdpal-code-object-metadata-user-data-spill-table-section` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:417085,Deployability,pipeline,pipeline,417085,"tion` for; more detail.; 0x10000003 BaseVertex Vertex offset (32-bit unsigned integer). Not needed if the pipeline doesn't; reference the draw index in the vertex shader. Only supported by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; and only used by the PS when UAV exports are used to replace color-target; exports to optimize specific shaders.; 0x10000011 NggCullingData 64-bit pointer to GPU memory containing the hardware register data needed by; some NGG pipelines to perform culling. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:417253,Deployability,pipeline,pipeline,417253,"orted by the first; stage in a graphics pipeline.; 0x10000004 BaseInstance Instance offset (32-bit unsigned integer). Only supported by the first stage in; a graphics pipeline.; 0x10000005 DrawIndex Draw index (32-bit unsigned integer). Only supported by the first stage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; and only used by the PS when UAV exports are used to replace color-target; exports to optimize specific shaders.; 0x10000011 NggCullingData 64-bit pointer to GPU memory containing the hardware register data needed by; some NGG pipelines to perform culling. This value contains the address of the; first of two consecutive registers which provide the full GPU address.; 0x10000015 FetchShaderPtr 64-bit pointer to GPU memory containing the f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:417519,Deployability,pipeline,pipeline,417519,"tage in a; graphics pipeline.; 0x10000006 Workgroup Thread group count (32-bit unsigned integer). Low half of a 64-bit address of; a buffer containing the grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; and only used by the PS when UAV exports are used to replace color-target; exports to optimize specific shaders.; 0x10000011 NggCullingData 64-bit pointer to GPU memory containing the hardware register data needed by; some NGG pipelines to perform culling. This value contains the address of the; first of two consecutive registers which provide the full GPU address.; 0x10000015 FetchShaderPtr 64-bit pointer to GPU memory containing the fetch shader subroutine.; ========== ================= ===============================================================================. .. _amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section:. Per-Shader Table; ################. Low 32 bits of the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:417669,Deployability,pipeline,pipeline,417669,"e grid dimensions for a Compute dispatch operation. The; high half of the address is stored in the next sequential user-SGPR. Only; supported by compute pipelines.; 0x1000000A EsGsLdsSize Indicates that PAL will program this user-SGPR to contain the amount of LDS; space used for the ES/GS pseudo-ring-buffer for passing data between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; and only used by the PS when UAV exports are used to replace color-target; exports to optimize specific shaders.; 0x10000011 NggCullingData 64-bit pointer to GPU memory containing the hardware register data needed by; some NGG pipelines to perform culling. This value contains the address of the; first of two consecutive registers which provide the full GPU address.; 0x10000015 FetchShaderPtr 64-bit pointer to GPU memory containing the fetch shader subroutine.; ========== ================= ===============================================================================. .. _amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section:. Per-Shader Table; ################. Low 32 bits of the GPU address for an optional buffer in the ``.data``; section of the ELF. The high 32 bits of the address match the high 32 bits; of the shader's program",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:418021,Deployability,pipeline,pipelines,418021,"between shader; stages.; 0x1000000B ViewId View id (32-bit unsigned integer) identifies a view of graphic; pipeline instancing.; 0x1000000C StreamOutTable 32-bit pointer to GPU memory containing the stream out target SRD table. This; can only appear for one shader stage per pipeline.; 0x1000000D PerShaderPerfData 32-bit pointer to GPU memory containing the per-shader performance data buffer.; 0x1000000F VertexBufferTable 32-bit pointer to GPU memory containing the vertex buffer SRD table. This can; only appear for one shader stage per pipeline.; 0x10000010 UavExportTable 32-bit pointer to GPU memory containing the UAV export SRD table. This can; only appear for one shader stage per pipeline (PS). These replace color targets; and are completely separate from any UAVs used by the shader. This is optional,; and only used by the PS when UAV exports are used to replace color-target; exports to optimize specific shaders.; 0x10000011 NggCullingData 64-bit pointer to GPU memory containing the hardware register data needed by; some NGG pipelines to perform culling. This value contains the address of the; first of two consecutive registers which provide the full GPU address.; 0x10000015 FetchShaderPtr 64-bit pointer to GPU memory containing the fetch shader subroutine.; ========== ================= ===============================================================================. .. _amdgpu-amdpal-code-object-metadata-user-data-per-shader-table-section:. Per-Shader Table; ################. Low 32 bits of the GPU address for an optional buffer in the ``.data``; section of the ELF. The high 32 bits of the address match the high 32 bits; of the shader's program counter. The buffer can be anything the shader compiler needs it for, and; allows each shader to have its own region of the ``.data`` section.; Typically, this could be a table of buffer SRD's and the data pointed to; by the buffer SRD's, but it could be a flat-address region of memory as; well. Its layout and usage are def",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:420317,Deployability,install,install,420317,"pal-code-object-metadata-user-data-spill-table-section:. Spill Table; ###########. It is possible for a hardware shader to need access to more *user data; entries* than there are slots available in user data registers for one; or more hardware shader stages. In that case, the PAL runtime expects; the necessary *user data entries* to be spilled to GPU memory and use; one user data register to point to the spilled user data memory. The; value of the *user data entry* must then represent the location where; a shader expects to read the low 32-bits of the table's GPU virtual; address. The *spill table* itself represents a set of 32-bit values; managed by the PAL runtime in GPU-accessible memory that can be made; indirectly accessible to a hardware shader. Unspecified OS; --------------. This section provides code conventions used when the target triple OS is; empty (see :ref:`amdgpu-target-triples`). Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by AMDGPU backend for non-amdhsa OS, the runtime does; not install a trap handler. The ``llvm.trap`` and ``llvm.debugtrap``; instructions are handled as follows:. .. table:: AMDGPU Trap Handler for Non-AMDHSA OS; :name: amdgpu-trap-handler-for-non-amdhsa-os-table. =============== =============== ===========================================; Usage Code Sequence Description; =============== =============== ===========================================; llvm.trap s_endpgm Causes wavefront to be terminated.; llvm.debugtrap *none* Compiler warning given that there is no; trap handler installed.; =============== =============== ===========================================. Source Languages; ================. .. _amdgpu-opencl:. OpenCL; ------. When the language is OpenCL the following differences occur:. 1. The OpenCL memory model is used (see :ref:`amdgpu-amdhsa-memory-model`).; 2. The AMDGPU backend appends additional arguments to the kernel's explicit; arguments for the AMDHSA OS (see; :ref:`opencl-kernel-implicit-argu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:420841,Deployability,install,installed,420841,"s to read the low 32-bits of the table's GPU virtual; address. The *spill table* itself represents a set of 32-bit values; managed by the PAL runtime in GPU-accessible memory that can be made; indirectly accessible to a hardware shader. Unspecified OS; --------------. This section provides code conventions used when the target triple OS is; empty (see :ref:`amdgpu-target-triples`). Trap Handler ABI; ~~~~~~~~~~~~~~~~. For code objects generated by AMDGPU backend for non-amdhsa OS, the runtime does; not install a trap handler. The ``llvm.trap`` and ``llvm.debugtrap``; instructions are handled as follows:. .. table:: AMDGPU Trap Handler for Non-AMDHSA OS; :name: amdgpu-trap-handler-for-non-amdhsa-os-table. =============== =============== ===========================================; Usage Code Sequence Description; =============== =============== ===========================================; llvm.trap s_endpgm Causes wavefront to be terminated.; llvm.debugtrap *none* Compiler warning given that there is no; trap handler installed.; =============== =============== ===========================================. Source Languages; ================. .. _amdgpu-opencl:. OpenCL; ------. When the language is OpenCL the following differences occur:. 1. The OpenCL memory model is used (see :ref:`amdgpu-amdhsa-memory-model`).; 2. The AMDGPU backend appends additional arguments to the kernel's explicit; arguments for the AMDHSA OS (see; :ref:`opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table`).; 3. Additional metadata is generated; (see :ref:`amdgpu-amdhsa-code-object-metadata`). .. table:: OpenCL kernel implicit arguments appended for AMDHSA OS; :name: opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table. ======== ==== ========= ===========================================; Position Byte Byte Description; Size Alignment; ======== ==== ========= ===========================================; 1 8 8 OpenCL Global Offset X; 2 8 8 OpenCL Global Offset Y; 3 8 8 OpenCL Glob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:430391,Deployability,update,updates,430391,"w_mask:0xa bank_mask:0x1 bound_ctrl:0. VOP3_DPP examples (Available on GFX11+):. .. code-block:: nasm. v_add_f32_e64_dpp v0, v1, v2 dpp8:[0,1,2,3,4,5,6,7]; v_sqrt_f32_e64_dpp v0, v1 row_shl:1 row_mask:0xa bank_mask:0x1 bound_ctrl:0; v_ldexp_f32 v0, v1, v2 dpp8:[0,1,2,3,4,5,6,7]. VOP_SDWA examples:. .. code-block:: nasm. v_mov_b32 v1, v2 dst_sel:BYTE_0 dst_unused:UNUSED_PRESERVE src0_sel:DWORD; v_min_u32 v200, v200, v1 dst_sel:WORD_1 dst_unused:UNUSED_PAD src0_sel:BYTE_1 src1_sel:DWORD; v_sin_f32 v0, v0 dst_unused:UNUSED_PAD src0_sel:WORD_1; v_fract_f32 v0, |v0| dst_sel:DWORD dst_unused:UNUSED_PAD src0_sel:WORD_1; v_cmpx_le_u32 vcc, v1, v2 src0_sel:BYTE_2 src1_sel:WORD_0. For full list of supported instructions, refer to ""Vector ALU instructions"". .. _amdgpu-amdhsa-assembler-predefined-symbols-v2:. Code Object V2 Predefined Symbols; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. The AMDGPU assembler defines and updates some symbols automatically. These; symbols do not affect code generation. .option.machine_version_major; +++++++++++++++++++++++++++++. Set to the GFX major generation number of the target being assembled for. For; example, when assembling for a ""GFX9"" target this will be set to the integer; value ""9"". The possible GFX major generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_minor; +++++++++++++++++++++++++++++. Set to the GFX minor generation number of the target being assembled for. For; example, when assembling for a ""GFX810"" target this will be set to the integer; value ""1"". The possible GFX minor generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_stepping; ++++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:431767,Deployability,update,updated,431767,"9"". The possible GFX major generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_minor; +++++++++++++++++++++++++++++. Set to the GFX minor generation number of the target being assembled for. For; example, when assembling for a ""GFX810"" target this will be set to the integer; value ""1"". The possible GFX minor generation numbers are presented in; :ref:`amdgpu-processors`. .option.machine_version_stepping; ++++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers are presented; in :ref:`amdgpu-processors`. .kernel.vgpr_count; ++++++++++++++++++. Set to zero each time a; :ref:`amdgpu-amdhsa-assembler-directive-amdgpu_hsa_kernel` directive is; encountered. At each instruction, if the current value of this symbol is less; than or equal to the maximum VGPR number explicitly referenced within that; instruction then the symbol value is updated to equal that VGPR number plus; one. .kernel.sgpr_count; ++++++++++++++++++. Set to zero each time a; :ref:`amdgpu-amdhsa-assembler-directive-amdgpu_hsa_kernel` directive is; encountered. At each instruction, if the current value of this symbol is less; than or equal to the maximum VGPR number explicitly referenced within that; instruction then the symbol value is updated to equal that SGPR number plus; one. .. _amdgpu-amdhsa-assembler-directives-v2:. Code Object V2 Directives; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. AMDGPU ABI defines auxiliary data in output code object. In assembly source,; one can specify them with assembler directives. .hsa_code_object_version major, minor; +++++++++++++++++++++++++++++++++++++. *major* and *minor* are integers that specify the version of the HSA code; object that will be generated by the assembler.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:432142,Deployability,update,updated,432142,"ed in; :ref:`amdgpu-processors`. .option.machine_version_stepping; ++++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers are presented; in :ref:`amdgpu-processors`. .kernel.vgpr_count; ++++++++++++++++++. Set to zero each time a; :ref:`amdgpu-amdhsa-assembler-directive-amdgpu_hsa_kernel` directive is; encountered. At each instruction, if the current value of this symbol is less; than or equal to the maximum VGPR number explicitly referenced within that; instruction then the symbol value is updated to equal that VGPR number plus; one. .kernel.sgpr_count; ++++++++++++++++++. Set to zero each time a; :ref:`amdgpu-amdhsa-assembler-directive-amdgpu_hsa_kernel` directive is; encountered. At each instruction, if the current value of this symbol is less; than or equal to the maximum VGPR number explicitly referenced within that; instruction then the symbol value is updated to equal that SGPR number plus; one. .. _amdgpu-amdhsa-assembler-directives-v2:. Code Object V2 Directives; ~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. AMDGPU ABI defines auxiliary data in output code object. In assembly source,; one can specify them with assembler directives. .hsa_code_object_version major, minor; +++++++++++++++++++++++++++++++++++++. *major* and *minor* are integers that specify the version of the HSA code; object that will be generated by the assembler. .hsa_code_object_isa [major, minor, stepping, vendor, arch]; +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++. *major*, *minor*, and *stepping* are all integers that describe the instruction; set architecture (ISA) version of the assembly program. *vendor* and *arch* are quoted strings. *vendor* should always be equal to; ""AMD"" and *arch* should always be equal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:436463,Deployability,update,updates,436463,"bject V2 generation is no longer supported by this version of LLVM. Here is an example of a minimal assembly source file, defining one HSA kernel:. .. code::; :number-lines:. .hsa_code_object_version 1,0; .hsa_code_object_isa. .hsatext; .globl hello_world; .p2align 8; .amdgpu_hsa_kernel hello_world. hello_world:. .amd_kernel_code_t; enable_sgpr_kernarg_segment_ptr = 1; is_ptr64 = 1; compute_pgm_rsrc1_vgprs = 0; compute_pgm_rsrc1_sgprs = 0; compute_pgm_rsrc2_user_sgpr = 2; compute_pgm_rsrc1_wgp_mode = 0; compute_pgm_rsrc1_mem_ordered = 0; compute_pgm_rsrc1_fwd_progress = 1; .end_amd_kernel_code_t. s_load_dwordx2 s[0:1], s[0:1] 0x0; v_mov_b32 v0, 3.14159; s_waitcnt lgkmcnt(0); v_mov_b32 v1, s0; v_mov_b32 v2, s1; flat_store_dword v[1:2], v0; s_endpgm; .Lfunc_end0:; .size hello_world, .Lfunc_end0-hello_world. .. _amdgpu-amdhsa-assembler-predefined-symbols-v3-onwards:. Code Object V3 and Above Predefined Symbols; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The AMDGPU assembler defines and updates some symbols automatically. These; symbols do not affect code generation. .amdgcn.gfx_generation_number; +++++++++++++++++++++++++++++. Set to the GFX major generation number of the target being assembled for. For; example, when assembling for a ""GFX9"" target this will be set to the integer; value ""9"". The possible GFX major generation numbers are presented in; :ref:`amdgpu-processors`. .amdgcn.gfx_generation_minor; ++++++++++++++++++++++++++++. Set to the GFX minor generation number of the target being assembled for. For; example, when assembling for a ""GFX810"" target this will be set to the integer; value ""1"". The possible GFX minor generation numbers are presented in; :ref:`amdgpu-processors`. .amdgcn.gfx_generation_stepping; +++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers are",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:437820,Deployability,update,updated,437820,"he integer; value ""9"". The possible GFX major generation numbers are presented in; :ref:`amdgpu-processors`. .amdgcn.gfx_generation_minor; ++++++++++++++++++++++++++++. Set to the GFX minor generation number of the target being assembled for. For; example, when assembling for a ""GFX810"" target this will be set to the integer; value ""1"". The possible GFX minor generation numbers are presented in; :ref:`amdgpu-processors`. .amdgcn.gfx_generation_stepping; +++++++++++++++++++++++++++++++. Set to the GFX stepping generation number of the target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers are presented; in :ref:`amdgpu-processors`. .. _amdgpu-amdhsa-assembler-symbol-next_free_vgpr:. .amdgcn.next_free_vgpr; ++++++++++++++++++++++. Set to zero before assembly begins. At each instruction, if the current value; of this symbol is less than or equal to the maximum VGPR number explicitly; referenced within that instruction then the symbol value is updated to equal; that VGPR number plus one. May be used to set the `.amdhsa_next_free_vgpr` directive in; :ref:`amdhsa-kernel-directives-table`. May be set at any time, e.g. manually set to zero at the start of each kernel. .. _amdgpu-amdhsa-assembler-symbol-next_free_sgpr:. .amdgcn.next_free_sgpr; ++++++++++++++++++++++. Set to zero before assembly begins. At each instruction, if the current value; of this symbol is less than or equal the maximum SGPR number explicitly; referenced within that instruction then the symbol value is updated to equal; that SGPR number plus one. May be used to set the `.amdhsa_next_free_spgr` directive in; :ref:`amdhsa-kernel-directives-table`. May be set at any time, e.g. manually set to zero at the start of each kernel. .. _amdgpu-amdhsa-assembler-directives-v3-onwards:. Code Object V3 and Above Directives; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Directives which begin with ``.amdgcn`` are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:438357,Deployability,update,updated,438357,"e target being assembled for.; For example, when assembling for a ""GFX704"" target this will be set to the; integer value ""4"". The possible GFX stepping generation numbers are presented; in :ref:`amdgpu-processors`. .. _amdgpu-amdhsa-assembler-symbol-next_free_vgpr:. .amdgcn.next_free_vgpr; ++++++++++++++++++++++. Set to zero before assembly begins. At each instruction, if the current value; of this symbol is less than or equal to the maximum VGPR number explicitly; referenced within that instruction then the symbol value is updated to equal; that VGPR number plus one. May be used to set the `.amdhsa_next_free_vgpr` directive in; :ref:`amdhsa-kernel-directives-table`. May be set at any time, e.g. manually set to zero at the start of each kernel. .. _amdgpu-amdhsa-assembler-symbol-next_free_sgpr:. .amdgcn.next_free_sgpr; ++++++++++++++++++++++. Set to zero before assembly begins. At each instruction, if the current value; of this symbol is less than or equal the maximum SGPR number explicitly; referenced within that instruction then the symbol value is updated to equal; that SGPR number plus one. May be used to set the `.amdhsa_next_free_spgr` directive in; :ref:`amdhsa-kernel-directives-table`. May be set at any time, e.g. manually set to zero at the start of each kernel. .. _amdgpu-amdhsa-assembler-directives-v3-onwards:. Code Object V3 and Above Directives; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. Directives which begin with ``.amdgcn`` are valid for all ``amdgcn``; architecture processors, and are not OS-specific. Directives which begin with; ``.amdhsa`` are specific to ``amdgcn`` architecture processors when the; ``amdhsa`` OS is specified. See :ref:`amdgpu-target-triples` and; :ref:`amdgpu-processors`. .. _amdgpu-assembler-directive-amdgcn-target:. .amdgcn_target <target-triple> ""-"" <target-id>; ++++++++++++++++++++++++++++++++++++++++++++++. Optional directive which declares the ``<target-triple>-<target-id>`` supported; by the containing assembler source file. Used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:25842,Energy Efficiency,allocate,allocated,25842," some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wave",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26028,Energy Efficiency,allocate,allocated,26028,"tions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26599,Energy Efficiency,allocate,allocates,26599,"g on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26940,Energy Efficiency,allocate,allocates,26940,"ace uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Scratch memory can be accessed in an interleaved manner using buffer; instructions with the scratch buffer descriptor and per wavefront scratch; offset, by the scratch instructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26988,Energy Efficiency,allocate,allocated,26988,"ace uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Scratch memory can be accessed in an interleaved manner using buffer; instructions with the scratch buffer descriptor and per wavefront scratch; offset, by the scratch instructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38245,Energy Efficiency,reduce,reduce,38245,":`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38699,Energy Efficiency,reduce,reduce,38699,"; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42359,Energy Efficiency,schedul,scheduling,42359,"fiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrie",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42485,Energy Efficiency,schedul,scheduled,42485,"e signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific propert",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42592,Energy Efficiency,schedul,scheduled,42592," of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42699,Energy Efficiency,schedul,scheduled,42699,"rforms; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42767,Energy Efficiency,schedul,scheduled,42767,"t values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42840,Energy Efficiency,schedul,scheduled,42840," used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42912,Energy Efficiency,schedul,scheduled,42912,"the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Ord",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42985,Energy Efficiency,schedul,scheduled,42985,"iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43059,Energy Efficiency,schedul,scheduled,43059,"lding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyon",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43129,Energy Efficiency,schedul,scheduled,43129,"e i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intri",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43204,Energy Efficiency,schedul,scheduled,43204,"ector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instructi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43280,Energy Efficiency,schedul,scheduled,43280," types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM re",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43375,Energy Efficiency,schedul,scheduled,43375,"arameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builti",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43447,Energy Efficiency,schedul,schedule,43447,"ions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43505,Energy Efficiency,schedul,scheduling,43505,"ions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43587,Energy Efficiency,schedul,scheduler,43587,"roducing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:43729,Energy Efficiency,schedul,schedule,43729,"duled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be scheduled across sched_barrier.; - 0x0080: All DS instructions may be scheduled across sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction sche",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44201,Energy Efficiency,schedul,scheduling,44201,"sched_barrier.; - 0x0100: All DS read instructions may be scheduled accoss sched_barrier.; - 0x0200: All DS write instructions may be scheduled across sched_barrier.; - 0x0400: All Transcendental (e.g. V_EXP) instructions may be scheduled across sched_barrier. llvm.amdgcn.sched_group_barrier Creates schedule groups with specific properties to create custom scheduling; pipelines. The ordering between groups is enforced by the instruction scheduler.; The intrinsic applies to the code that preceeds the intrinsic. The intrinsic; takes three values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44699,Energy Efficiency,schedul,scheduling,44699,"ree values that control the behavior of the schedule groups. - Mask : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors wh",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:44763,Energy Efficiency,schedul,scheduling,44763,"sk : Classify instruction groups using the llvm.amdgcn.sched_barrier mask values.; - Size : The number of instructions that are in the group.; - SyncID : Order is enforced between groups with matching values. The mask can include multiple instruction types. It is undefined behavior to set; values beyond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:45064,Energy Efficiency,schedul,scheduling,45064,"yond the range of valid masks. Combining multiple sched_group_barrier intrinsics enables an ordering of specific; instruction types during instruction scheduling. For example, the following enforces; a sequence of 1 VMEM read, followed by 1 VALU instruction, followed by 5 MFMA; instructions. | ``// 1 VMEM read``; | ``__builtin_amdgcn_sched_group_barrier(32, 1, 0)``; | ``// 1 VALU``; | ``__builtin_amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ============================================== ==========================================================. .. TODO::. List AMDGPU intrinsics. LLVM IR Attributes; ------------------. The AMDGPU backend supports the following LLVM IR attributes. .. table:: AMDGPU LLVM IR Attributes; :name: amdgpu-llvm-i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51423,Energy Efficiency,allocate,allocated,51423," to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51489,Energy Efficiency,allocate,allocated,51489,"ion. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the sa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51652,Energy Efficiency,allocate,allocated,51652,"-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the same as the ``ccc``. ``coldcc`` The cold calling convention. Mostly the same as the ``ccc``. ``a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:78304,Energy Efficiency,allocate,allocated,78304,"object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5` for the map keys defined for the; ``amdhsa`` OS. .. _amdgpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked shared object symbols. Seems undefined symbols; are marked as STT_NOTYPE. Kernel descriptor; Every HSA kernel has an associated kernel descriptor. It is the address of the; kernel descriptor that is used in the AQL dispatch packet used to invoke the; kernel, not the kernel entry point. The layout of the HSA kernel descriptor is; defined in :ref:`amdgpu-amdhsa-kernel-descriptor`. Kernel entry point; Every HSA kernel also has a symbol for its machine code entry ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:92218,Energy Efficiency,allocate,allocated,92218,"MDGPU is defined in; :ref:`amdgpu-dwarf-memory-space-mapping-table`. .. table:: AMDGPU DWARF Memory Space Mapping; :name: amdgpu-dwarf-memory-space-mapping-table. =========================== ====== =================; DWARF AMDGPU; ---------------------------------- -----------------; Memory Space Name Value Memory Space; =========================== ====== =================; ``DW_MSPACE_LLVM_none`` 0x0000 Generic (Flat); ``DW_MSPACE_LLVM_global`` 0x0001 Global; ``DW_MSPACE_LLVM_constant`` 0x0002 Global; ``DW_MSPACE_LLVM_group`` 0x0003 Local (group/LDS); ``DW_MSPACE_LLVM_private`` 0x0004 Private (Scratch); ``DW_MSPACE_AMDGPU_region`` 0x8000 Region (GDS); =========================== ====== =================. The DWARF memory space values defined in the *DWARF Extensions For Heterogeneous; Debugging* section :ref:`amdgpu-dwarf-memory-spaces` are used. In addition, ``DW_ADDR_AMDGPU_region`` is encoded as a vendor extension. This is; available for use for the AMD extension for access to the hardware GDS memory; which is scratchpad memory allocated per device. For AMDGPU if no ``DW_AT_LLVM_memory_space`` attribute is present, then the; default memory space of ``DW_MSPACE_LLVM_none`` is used. See :ref:`amdgpu-dwarf-address-space-identifier` for information on the AMDGPU; mapping of DWARF memory spaces to DWARF address spaces, including address size; and NULL value. .. _amdgpu-dwarf-address-space-identifier:. Address Space Identifier; ------------------------. DWARF address spaces correspond to target architecture specific linear; addressable memory areas. See DWARF Version 5 section 2.12 and *DWARF Extensions; For Heterogeneous Debugging* section :ref:`amdgpu-dwarf-address-spaces`. The DWARF address space mapping used for AMDGPU is defined in; :ref:`amdgpu-dwarf-address-space-mapping-table`. .. table:: AMDGPU DWARF Address Space Mapping; :name: amdgpu-dwarf-address-space-mapping-table. ======================================= ===== ======= ======== ===================== =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:95260,Energy Efficiency,allocate,allocated,95260,"size and NULL value. The ``DW_ASPACE_LLVM_none`` address space is the default target architecture; address space used in DWARF operations that do not specify an address space. It; therefore has to map to the global address space so that the ``DW_OP_addr*`` and; related operations can refer to addresses in the program code. The ``DW_ASPACE_AMDGPU_generic`` address space allows location expressions to; specify the flat address space. If the address corresponds to an address in the; local address space, then it corresponds to the wavefront that is executing the; focused thread of execution. If the address corresponds to an address in the; private address space, then it corresponds to the lane that is executing the; focused thread of execution for languages that are implemented using a SIMD or; SIMT execution model. .. note::. CUDA-like languages such as HIP that do not have address spaces in the; language type system, but do allow variables to be allocated in different; address spaces, need to explicitly specify the ``DW_ASPACE_AMDGPU_generic``; address space in the DWARF expression operations as the default address space; is the global address space. The ``DW_ASPACE_AMDGPU_local`` address space allows location expressions to; specify the local address space corresponding to the wavefront that is executing; the focused thread of execution. The ``DW_ASPACE_AMDGPU_private_lane`` address space allows location expressions; to specify the private address space corresponding to the lane that is executing; the focused thread of execution for languages that are implemented using a SIMD; or SIMT execution model. The ``DW_ASPACE_AMDGPU_private_wave`` address space allows location expressions; to specify the unswizzled private address space corresponding to the wavefront; that is executing the focused thread of execution. The wavefront view of private; memory is the per wavefront unswizzled backing memory layout defined in; :ref:`amdgpu-address-spaces`, such that address 0 corres",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:104162,Energy Efficiency,reduce,reduces,104162,"lane if it is not; active (namely it is divergent). The DWARF operation expression for each region; conceptually inherits the value of the immediately enclosing region and modifies; it according to the semantics of the region. For an ``IF/THEN/ELSE`` region the divergent program location is at the start of; the region for the ``THEN`` region since it is executed first. For the ``ELSE``; region the divergent program location is at the end of the ``IF/THEN/ELSE``; region since the ``THEN`` region has completed. The lane PC artificial variable is assigned at each region transition. It uses; the immediately enclosing region's DWARF procedure to compute the program; location for each lane assuming they are divergent, and then modifies the result; by inserting the current program location for each lane that the ``EXEC`` mask; indicates is active. By having separate DWARF procedures for each region, they can be reused to; define the value for any nested region. This reduces the total size of the DWARF; operation expressions. The following provides an example using pseudo LLVM MIR. .. code::; :number-lines:. $lex_start:; DEFINE_DWARF %__uint_64 = DW_TAG_base_type[; DW_AT_name = ""__uint64"";; DW_AT_byte_size = 8;; DW_AT_encoding = DW_ATE_unsigned;; ];; DEFINE_DWARF %__active_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__active_lane_pc"";; DW_AT_location = [; DW_OP_regx PC;; DW_OP_LLVM_extend 64, 64;; DW_OP_regval_type EXEC, %uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DEFINE_DWARF %__divergent_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc"";; DW_AT_location = [; DW_OP_LLVM_undefined;; DW_OP_LLVM_extend 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; a;; %1 = EXEC;; DBG_VALUE %1, $noreg, %__lex_1_save_exec;; %2 = c1;; $lex_1_start:; EXEC = %1 & %2;; $lex_1_then:; DEFINE_DWARF %__divergent_lane_pc_1_then = DW_TAG_dwarf_procedure[; DW_AT",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108154,Energy Efficiency,allocate,allocated,108154,"AG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc_1_else"";; DW_AT_location = DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108213,Energy Efficiency,allocate,allocate,108213,"nt_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-ac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:112011,Energy Efficiency,allocate,allocated,112011,"mation`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` string contains the following null-terminated UTF-8 string:. ::. [amd:v0.0]. The ``vX.Y`` specifies the major X and minor Y version number of the AMDGPU; extensions used in this CIE or to the FDEs that use it. The version number; conforms to [SEMVER]_. 2. ``address_size`` for the ``Global`` address space is defined in; :ref:`amdgpu-dwarf-address-space-identifier`. 3. ``segment_selector_size`` is 0 as AMDGPU does not use a segment selector. 4. ``code_alignment_factor`` is 4 bytes. .. TODO::. Add to :ref:`amdgpu-processor-table` table. 5. ``data_alignment_factor`` is 4 bytes. .. TODO::. Add to :ref:`amdgpu-processor-table` table. 6. ``return_address_register`` is ``PC_32`` for 32-bit processes and ``PC_64``; for 64-bit processes defined in :ref:`amdgpu-dwarf-register-identifier`. 7. ``initial_instructions`` Since a subprogram X with fewer registers can be; called from subprogram Y that has more allocated, X will not change any of; the extra registers as it cannot access them. Therefore, the default rule; for all columns is ``same value``. For AMDGPU the register number follows the numbering defined in; :ref:`amdgpu-dwarf-register-identifier`. For AMDGPU the instructions are variable size. A consumer can subtract 1 from; the return address to get the address of a byte within the call site; instructions. See DWARF Version 5 section 6.4.4. Accelerated Access; ------------------. See DWARF Version 5 section 6.1. Lookup By Name Section Header; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. See DWARF Version 5 section 6.1.1.4.1 and :ref:`amdgpu-dwarf-lookup-by-name`. For AMDGPU the lookup by name section header table:. ``augmentation_string_size`` (uword). Set to the length of the ``augmentation_string`` value which is always a; multiple of 4. ``augmentation_string`` (sequence of UTF-8 characters). Contains the following UTF-8 string null padded to a multiple of 4 bytes:. ::. [amdg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:122664,Energy Efficiency,allocate,allocates,122664,"l Attribute Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-attribute-metadata-map-v2-table. =================== ============== ========= ==============================; String Key Value Type Required? Description; =================== ============== ========= ==============================; ""ReqdWorkGroupSize"" sequence of If not 0, 0, 0 then all values; 3 integers must be >=1 and the dispatch; work-group size X, Y, Z must; correspond to the specified; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; ""WorkGroupSizeHint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; ""VecTypeHint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. ""RuntimeHandle"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:123466,Energy Efficiency,power,power,123466,"int"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. ""RuntimeHandle"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""DynamicSharedPointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""Sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""Image""; A global address space; pointer to a T# is passed in; the kernarg. ""Pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The Op",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:123833,Energy Efficiency,allocate,allocated,123833,"ide; enqueued kernels.; =================== ============== ========= ==============================. .. .. table:: AMDHSA Code Object V2 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-v2-table. ================= ============== ========= ================================; String Key Value Type Required? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""DynamicSharedPointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""Sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""Image""; A global address space; pointer to a T# is passed in; the kernarg. ""Pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHos",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:125651,Energy Efficiency,power,power,125651,"; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenCompletionAction""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""HiddenMultiGridSyncArg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How can Private or Region; ever happen?. ""AccQual"" string Kernel argument access; qualifier. Only present if; ""ValueKind"" is ""Image"" or; ""Pipe"". Values; are:. - ""ReadOnly""; - ""WriteOnly""; - ""ReadWrite"". .. TODO::. Does this apply to; GlobalBuffer?. ""ActualAccQual"" string The actual memory accesses; performed by the kernel on the; kernel argument. Only present if; ""ValueKind"" is ""GlobalBuffer"",; ""Image"", or ""Pipe"". This may be; more restrictive than indicated; by ""AccQual"" to reflect what the; kernel actual does. If not; present then the runtime must; assume what is implied by; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:127990,Energy Efficiency,allocate,allocated,127990,"es if the kernel argument; is volatile qualified. Only; present if ""ValueKind"" is; ""GlobalBuffer"". ""IsPipe"" boolean Indicates if the kernel argument; is pipe qualified. Only present; if ""ValueKind"" is ""Pipe"". .. TODO::. Can GlobalBuffer be pipe; qualified?. ================= ============== ========= ================================. .. .. table:: AMDHSA Code Object V2 Kernel Code Properties Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-code-properties-metadata-map-v2-table. ============================ ============== ========= =====================; String Key Value Type Required? Description; ============================ ============== ========= =====================; ""KernargSegmentSize"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; ""GroupSegmentFixedSize"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; ""PrivateSegmentFixedSize"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; ""KernargSegmentAlign"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; ""WavefrontSize"" integer Required Wavefront size. Must; be a power of 2.; ""NumSGPRs"" integer Required Number of scalar; registers used by a; wavefront for; GFX6-GFX11. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX10); and XNACK (for; GFX8-GFX10). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; ""NumVGPRs"" integer Required Number of vector; registers used by; each work-item for; GFX6-GFX11; ""MaxFlatWorkGroupSize"" integer Required Maximum flat; work-group si",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:128439,Energy Efficiency,power,power,128439,"a-code-object-kernel-code-properties-metadata-map-v2-table. ============================ ============== ========= =====================; String Key Value Type Required? Description; ============================ ============== ========= =====================; ""KernargSegmentSize"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; ""GroupSegmentFixedSize"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; ""PrivateSegmentFixedSize"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; ""KernargSegmentAlign"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; ""WavefrontSize"" integer Required Wavefront size. Must; be a power of 2.; ""NumSGPRs"" integer Required Number of scalar; registers used by a; wavefront for; GFX6-GFX11. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX10); and XNACK (for; GFX8-GFX10). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; ""NumVGPRs"" integer Required Number of vector; registers used by; each work-item for; GFX6-GFX11; ""MaxFlatWorkGroupSize"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; ""NumSpilledSGPRs"" integer Number of stores from; a scalar register to; a register allocator; created spill; location.; ""NumSpilledVGPRs"" integer Number of stores from; a vector register to; a register allocator; created spill; location.; ============================ ============== ========= =====================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:128512,Energy Efficiency,power,power,128512,"=============== ============== ========= =====================; String Key Value Type Required? Description; ============================ ============== ========= =====================; ""KernargSegmentSize"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; ""GroupSegmentFixedSize"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; ""PrivateSegmentFixedSize"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; ""KernargSegmentAlign"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; ""WavefrontSize"" integer Required Wavefront size. Must; be a power of 2.; ""NumSGPRs"" integer Required Number of scalar; registers used by a; wavefront for; GFX6-GFX11. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX10); and XNACK (for; GFX8-GFX10). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; ""NumVGPRs"" integer Required Number of vector; registers used by; each work-item for; GFX6-GFX11; ""MaxFlatWorkGroupSize"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; ""NumSpilledSGPRs"" integer Number of stores from; a scalar register to; a register allocator; created spill; location.; ""NumSpilledVGPRs"" integer Number of stores from; a vector register to; a register allocator; created spill; location.; ============================ ============== ========= =====================. .. _amdgpu-amdhsa-code-object-metadata-v3:. Code Object V3 Metadata; ++",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:133362,Energy Efficiency,allocate,allocates,133362," is the major; 2 integers version.; - The second integer is the; minor version.; "".args"" sequence of Sequence of maps of the; map kernel arguments. See; :ref:`amdgpu-amdhsa-code-object-kernel-argument-metadata-map-table-v3`; for the definition of the keys; included in that map.; "".reqd_workgroup_size"" sequence of If not 0, 0, 0 then all values; 3 integers must be >=1 and the dispatch; work-group size X, Y, Z must; correspond to the specified; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; "".workgroup_size_hint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; "".vec_type_hint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. "".device_enqueue_symbol"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Nu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:133839,Energy Efficiency,allocate,allocated,133839,"; values. Defaults to 0, 0, 0. Corresponds to the OpenCL; ``reqd_work_group_size``; attribute.; "".workgroup_size_hint"" sequence of The dispatch work-group size; 3 integers X, Y, Z is likely to be the; specified values. Corresponds to the OpenCL; ``work_group_size_hint``; attribute.; "".vec_type_hint"" string The name of a scalar or vector; type. Corresponds to the OpenCL; ``vec_type_hint`` attribute. "".device_enqueue_symbol"" string The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX9); and XNACK (for; GFX8-GFX9). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:134295,Energy Efficiency,power,power,134295,"The external symbol name; associated with a kernel.; OpenCL runtime allocates a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX9); and XNACK (for; GFX8-GFX9). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vector; registers required by; each work-item for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly.; "".agpr_count"" integer Required Number of accumulator; registers required by; each work-item for; GFX90A, GFX908.; "".max_flat_workgroup_size"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; Reqd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:134370,Energy Efficiency,power,power,134370,"es a; global buffer for the symbol; and saves the kernel's address; to it, which is used for; device side enqueueing. Only; available for device side; enqueued kernels.; "".kernarg_segment_size"" integer Required The size in bytes of; the kernarg segment; that holds the values; of the arguments to; the kernel.; "".group_segment_fixed_size"" integer Required The amount of group; segment memory; required by a; work-group in; bytes. This does not; include any; dynamically allocated; group segment memory; that may be added; when the kernel is; dispatched.; "".private_segment_fixed_size"" integer Required The amount of fixed; private address space; memory required for a; work-item in; bytes. If the kernel; uses a dynamic call; stack then additional; space must be added; to this value for the; call stack.; "".kernarg_segment_align"" integer Required The maximum byte; alignment of; arguments in the; kernarg segment. Must; be a power of 2.; "".wavefront_size"" integer Required Wavefront size. Must; be a power of 2.; "".sgpr_count"" integer Required Number of scalar; registers required by a; wavefront for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly. This; includes the special; SGPRs for VCC, Flat; Scratch (GFX7-GFX9); and XNACK (for; GFX8-GFX9). It does; not include the 16; SGPR added if a trap; handler is; enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vector; registers required by; each work-item for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly.; "".agpr_count"" integer Required Number of accumulator; registers required by; each work-item for; GFX90A, GFX908.; "".max_flat_workgroup_size"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; "".sgpr_spill_count"" integer Number of store",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:137141,Energy Efficiency,allocate,allocated,137141,"==============================. .. .. table:: AMDHSA Code Object V3 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-table-v3. ====================== ============== ========= ================================; String Key Value Type Required? Description; ====================== ============== ========= ================================; "".name"" string Kernel argument name.; "".type_name"" string Kernel argument type name.; "".size"" integer Required Kernel argument size in bytes.; "".offset"" integer Required Kernel argument offset in; bytes. The offset must be a; multiple of the alignment; required by the argument.; "".value_kind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""by_value""; The argument is copied; directly into the kernarg. ""global_buffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""dynamic_shared_pointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""image""; A global address space; pointer to a T# is passed in; the kernarg. ""pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""hidden_global_offset_x""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""hidden_global_offset_y""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""hidden_global_offset_z""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""hidden_none""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""hidden_printf_buffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive wit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:139034,Energy Efficiency,power,power,139034," space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_hostcall_buffer""; before Code Object V5. ""hidden_hostcall_buffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_printf_buffer""; before Code Object V5. ""hidden_default_queue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""hidden_completion_action""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""hidden_multigrid_sync_arg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. "".value_type"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. "".pointee_align"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; "".value_kind"" is; ""dynamic_shared_pointer"".; "".address_space"" string Kernel argument address space; qualifier. Only present if; "".value_kind"" is ""global_buffer"" or; ""dynamic_shared_pointer"". Values; are:. - ""private""; - ""global""; - ""constant""; - ""local""; - ""generic""; - ""region"". .. TODO::. Is ""global_buffer"" only ""global""; or ""constant""? Is; ""dynamic_shared_pointer"" always; ""local""? Can HCC allow ""generic""?; How can ""private"" or ""region""; ever happen?. "".access"" string Kernel argument access; qualifier. Only present if; "".value_kind"" is ""image"" or; ""pipe"". Values; are:. - ""read_only""; - ""write_only""; - ""read_write"". .. TODO::. Does this apply to; ""global_buffer""?. "".actual_access"" string The actual memory accesses; performed by the kernel on the; kernel argument. Only present if; "".value_kind"" is ""global_buffer"",; ""image"", or ""pipe"". This may be; more restrictive than indicated; by "".access"" to reflect what the; kernel actual does. If not; present then the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:147962,Energy Efficiency,allocate,allocated,147962," grid dimensionality; is 1 or 2, then must be 1. ""hidden_remainder_x""; The grid dispatch work group size of the partial work group; of the X dimension, if it exists. Must be zero if a partial; work group does not exist in the X dimension. ""hidden_remainder_y""; The grid dispatch work group size of the partial work group; of the Y dimension, if it exists. Must be zero if a partial; work group does not exist in the Y dimension. ""hidden_remainder_z""; The grid dispatch work group size of the partial work group; of the Z dimension, if it exists. Must be zero if a partial; work group does not exist in the Z dimension. ""hidden_grid_dims""; The grid dispatch dimensionality. This is the same value; as the AQL dispatch packet dimensionality. Must be a value; between 1 and 3. ""hidden_heap_v1""; A global address space pointer to an initialized memory; buffer that conforms to the requirements of the malloc/free; device library V1 version implementation. ""hidden_dynamic_lds_size""; Size of the dynamically allocated LDS memory is passed in the kernarg. ""hidden_private_base""; The high 32 bits of the flat addressing private aperture base.; Only used by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to cont",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149664,Energy Efficiency,allocate,allocate,149664,"evices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Progr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:150322,Energy Efficiency,allocate,allocated,150322,"s from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:154178,Energy Efficiency,allocate,allocated,154178," 32 0x00000000; Local group LDS 32 0xFFFFFFFF; Global global global 64 0x0000000000000000; Constant constant *same as 64 0x0000000000000000; global*; Generic flat flat 64 0x0000000000000000; Region N/A GDS 32 *not implemented; for AMDHSA*; ================= =========== ======== ======= ==================. The global and constant memory spaces both use global virtual addresses, which; are the same virtual address space used by the CPU. However, some virtual; addresses may only be accessible to the CPU, some only accessible by the GPU,; and some by both. Using the constant memory space indicates that the data will not change during; the execution of the kernel. This allows scalar read instructions to be; used. The vector and scalar L1 caches are invalidated of volatile data before; each kernel dispatch execution to allow constant memory to change values between; kernel dispatches. The local memory space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords bein",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:154483,Energy Efficiency,allocate,allocates,154483,"==. The global and constant memory spaces both use global virtual addresses, which; are the same virtual address space used by the CPU. However, some virtual; addresses may only be accessible to the CPU, some only accessible by the GPU,; and some by both. Using the constant memory space indicates that the data will not change during; the execution of the kernel. This allows scalar read instructions to be; used. The vector and scalar L1 caches are invalidated of volatile data before; each kernel dispatch execution to allow constant memory to change values between; kernel dispatches. The local memory space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords being accessed; and hence requires fewer cache lines to be fetched. Multi-dword access is not; supported except by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157275,Energy Efficiency,allocate,allocated,157275,"he; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:158278,Energy Efficiency,allocate,allocated,158278,"ucture allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= =============================== ============================; Bits Size Field Name Description; ======= ======= =============================== ============================; 31:0 4 bytes GROUP_SEGMENT_FIXED_SIZE The amount of fixed local; address space memory; required for a work-group; in bytes. This does not; include any dynamically; allocated local address; space memory that may be; added when the kernel is; dispatched.; 63:32 4 bytes PRIVATE_SEGMENT_FIXED_SIZE The amount of fixed; private address space; memory required for a; work-item in bytes. When; this cannot be predicted,; code object v4 and older; sets this value to be; higher than the minimum; requirement.; 95:64 4 bytes KERNARG_SIZE The size of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:158888,Energy Efficiency,allocate,allocated,158888,"amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= =============================== ============================; Bits Size Field Name Description; ======= ======= =============================== ============================; 31:0 4 bytes GROUP_SEGMENT_FIXED_SIZE The amount of fixed local; address space memory; required for a work-group; in bytes. This does not; include any dynamically; allocated local address; space memory that may be; added when the kernel is; dispatched.; 63:32 4 bytes PRIVATE_SEGMENT_FIXED_SIZE The amount of fixed; private address space; memory required for a; work-item in bytes. When; this cannot be predicted,; code object v4 and older; sets this value to be; higher than the minimum; requirement.; 95:64 4 bytes KERNARG_SIZE The size of the kernarg; memory pointed to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:164732,Energy Efficiency,allocate,allocated,164732,"X90A, GFX940; - vgprs_used 0..512; - vgprs_used = align(arch_vgprs, 4); + acc_vgprs; - max(0, ceil(vgprs_used / 8) - 1); GFX10-GFX11 (wavefront size 64); - max_vgpr 1..256; - max(0, ceil(vgprs_used / 4) - 1); GFX10-GFX11 (wavefront size 32); - max_vgpr 1..256; - max(0, ceil(vgprs_used / 8) - 1). Where vgprs_used is defined; as the highest VGPR number; explicitly referenced plus; one. Used by CP to set up; ``COMPUTE_PGM_RSRC1.VGPRS``. The; :ref:`amdgpu-assembler`; calculates this; automatically for the; selected processor from; values provided to the; `.amdhsa_kernel` directive; by the; `.amdhsa_next_free_vgpr`; nested directive (see; :ref:`amdhsa-kernel-directives-table`).; 9:6 4 bits GRANULATED_WAVEFRONT_SGPR_COUNT Number of scalar register; blocks used by a wavefront;; granularity is device; specific:. GFX6-GFX8; - sgprs_used 0..112; - max(0, ceil(sgprs_used / 8) - 1); GFX9; - sgprs_used 0..112; - 2 * max(0, ceil(sgprs_used / 16) - 1); GFX10-GFX11; Reserved, must be 0.; (128 SGPRs always; allocated.). Where sgprs_used is; defined as the highest; SGPR number explicitly; referenced plus one, plus; a target specific number; of additional special; SGPRs for VCC,; FLAT_SCRATCH (GFX7+) and; XNACK_MASK (GFX8+), and; any additional; target specific; limitations. It does not; include the 16 SGPRs added; if a trap handler is; enabled. The target specific; limitations and special; SGPR layout are defined in; the hardware; documentation, which can; be found in the; :ref:`amdgpu-processors`; table. Used by CP to set up; ``COMPUTE_PGM_RSRC1.SGPRS``. The; :ref:`amdgpu-assembler`; calculates this; automatically for the; selected processor from; values provided to the; `.amdhsa_kernel` directive; by the; `.amdhsa_next_free_sgpr`; and `.amdhsa_reserve_*`; nested directives (see; :ref:`amdhsa-kernel-directives-table`).; 11:10 2 bits PRIORITY Must be 0. Start executing wavefront; at the specified priority. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIORITY``.; 13:12 2 bit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:167618,Energy Efficiency,schedul,scheduled,167618,"are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 19:18 2 bits FLOAT_DENORM_MODE_16_64 Wavefront starts execution; with specified denorm mode; for half/double (16; and 64-bit) floating point; precision floating point; operations. Floating point denorm mode; values are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 20 1 bit PRIV Must be 0. Start executing wavefront; in privilege trap handler; mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIV``.; 21 1 bit ENABLE_DX10_CLAMP GFX9-GFX11; Wavefront starts execution; with DX10 clamp mode; enabled. Used by the vector; ALU to force DX10 style; treatment of NaN's (when; set, clamp NaN to zero,; otherwise pass NaN; through). Used by CP to set up; ``COMPUTE_PGM_RSRC1.DX10_CLAMP``.; WG_RR_EN GFX12; If 1, wavefronts are scheduled; in a round-robin fashion with; respect to the other wavefronts; of the SIMD. Otherwise, wavefronts; are scheduled in oldest age order. CP is responsible for filling in; ``COMPUTE_PGM_RSRC1.WG_RR_EN``.; 22 1 bit DEBUG_MODE Must be 0. Start executing wavefront; in single step mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.DEBUG_MODE``.; 23 1 bit ENABLE_IEEE_MODE GFX9-GFX11; Wavefront starts execution; with IEEE mode; enabled. Floating point; opcodes that support; exception flag gathering; will quiet and propagate; signaling-NaN inputs per; IEEE 754-2008. Min_dx10 and; max_dx10 become IEEE; 754-2008 compliant due to; signaling-NaN propagation; and quieting. Used by CP to set up; ``COMPUTE_PGM_RSRC1.IEEE_MODE``.; DISABLE_PERF GFX12; Reserved. Must be 0.; 24 1 bit BULKY Must be 0. Only one work-group allowed; to execute on a compute; unit. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.BULKY``.; 25 1 bit CDBG_USER Must be 0. Flag that can be used to; control debugging code. CP is r",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:167733,Energy Efficiency,schedul,scheduled,167733,"ed by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 19:18 2 bits FLOAT_DENORM_MODE_16_64 Wavefront starts execution; with specified denorm mode; for half/double (16; and 64-bit) floating point; precision floating point; operations. Floating point denorm mode; values are defined in; :ref:`amdgpu-amdhsa-floating-point-denorm-mode-enumeration-values-table`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FLOAT_MODE``.; 20 1 bit PRIV Must be 0. Start executing wavefront; in privilege trap handler; mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.PRIV``.; 21 1 bit ENABLE_DX10_CLAMP GFX9-GFX11; Wavefront starts execution; with DX10 clamp mode; enabled. Used by the vector; ALU to force DX10 style; treatment of NaN's (when; set, clamp NaN to zero,; otherwise pass NaN; through). Used by CP to set up; ``COMPUTE_PGM_RSRC1.DX10_CLAMP``.; WG_RR_EN GFX12; If 1, wavefronts are scheduled; in a round-robin fashion with; respect to the other wavefronts; of the SIMD. Otherwise, wavefronts; are scheduled in oldest age order. CP is responsible for filling in; ``COMPUTE_PGM_RSRC1.WG_RR_EN``.; 22 1 bit DEBUG_MODE Must be 0. Start executing wavefront; in single step mode. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.DEBUG_MODE``.; 23 1 bit ENABLE_IEEE_MODE GFX9-GFX11; Wavefront starts execution; with IEEE mode; enabled. Floating point; opcodes that support; exception flag gathering; will quiet and propagate; signaling-NaN inputs per; IEEE 754-2008. Min_dx10 and; max_dx10 become IEEE; 754-2008 compliant due to; signaling-NaN propagation; and quieting. Used by CP to set up; ``COMPUTE_PGM_RSRC1.IEEE_MODE``.; DISABLE_PERF GFX12; Reserved. Must be 0.; 24 1 bit BULKY Must be 0. Only one work-group allowed; to execute on a compute; unit. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.BULKY``.; 25 1 bit CDBG_USER Must be 0. Flag that can be used to; control debugging code. CP is responsible for; filling in; ``COMPUTE_PGM_RSRC1.CDBG_USER``.; 26 1 bit FP16_OVFL GFX6-GFX8; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:174018,Energy Efficiency,allocate,allocated,174018,"meration-values-table`; defines the values. Used by CP to set up; ``COMPUTE_PGM_RSRC2.TIDIG_CMP_CNT``.; 13 1 bit ENABLE_EXCEPTION_ADDRESS_WATCH Must be 0. Wavefront starts execution; with address watch; exceptions enabled which; are generated when L1 has; witnessed a thread access; an *address of; interest*. CP is responsible for; filling in the address; watch bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 14 1 bit ENABLE_EXCEPTION_MEMORY Must be 0. Wavefront starts execution; with memory violation; exceptions exceptions; enabled which are generated; when a memory violation has; occurred for this wavefront from; L1 or LDS; (write-to-read-only-memory,; mis-aligned atomic, LDS; address out of range,; illegal address, etc.). CP sets the memory; violation bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 23:15 9 bits GRANULATED_LDS_SIZE Must be 0. CP uses the rounded value; from the dispatch packet,; not this value, as the; dispatch may contain; dynamically allocated group; segment memory. CP writes; directly to; ``COMPUTE_PGM_RSRC2.LDS_SIZE``. Amount of group segment; (LDS) to allocate for each; work-group. Granularity is; device specific:. GFX6; roundup(lds-size / (64 * 4)); GFX7-GFX11; roundup(lds-size / (128 * 4)). 24 1 bit ENABLE_EXCEPTION_IEEE_754_FP Wavefront starts execution; _INVALID_OPERATION with specified exceptions; enabled. Used by CP to set up; ``COMPUTE_PGM_RSRC2.EXCP_EN``; (set from bits 0..6). IEEE 754 FP Invalid; Operation; 25 1 bit ENABLE_EXCEPTION_FP_DENORMAL FP Denormal one or more; _SOURCE input operands is a; denormal number; 26 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Division by; _DIVISION_BY_ZERO Zero; 27 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP FP Overflow; _OVERFLOW; 28 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Underflow; _UNDERFLOW; 29 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Inexact; _INEXACT; 30 1 bit ENABLE_EXCEPTION_INT_DIVIDE_BY Integer Divis",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:174141,Energy Efficiency,allocate,allocate,174141,"ont starts execution; with address watch; exceptions enabled which; are generated when L1 has; witnessed a thread access; an *address of; interest*. CP is responsible for; filling in the address; watch bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 14 1 bit ENABLE_EXCEPTION_MEMORY Must be 0. Wavefront starts execution; with memory violation; exceptions exceptions; enabled which are generated; when a memory violation has; occurred for this wavefront from; L1 or LDS; (write-to-read-only-memory,; mis-aligned atomic, LDS; address out of range,; illegal address, etc.). CP sets the memory; violation bit in; ``COMPUTE_PGM_RSRC2.EXCP_EN_MSB``; according to what the; runtime requests.; 23:15 9 bits GRANULATED_LDS_SIZE Must be 0. CP uses the rounded value; from the dispatch packet,; not this value, as the; dispatch may contain; dynamically allocated group; segment memory. CP writes; directly to; ``COMPUTE_PGM_RSRC2.LDS_SIZE``. Amount of group segment; (LDS) to allocate for each; work-group. Granularity is; device specific:. GFX6; roundup(lds-size / (64 * 4)); GFX7-GFX11; roundup(lds-size / (128 * 4)). 24 1 bit ENABLE_EXCEPTION_IEEE_754_FP Wavefront starts execution; _INVALID_OPERATION with specified exceptions; enabled. Used by CP to set up; ``COMPUTE_PGM_RSRC2.EXCP_EN``; (set from bits 0..6). IEEE 754 FP Invalid; Operation; 25 1 bit ENABLE_EXCEPTION_FP_DENORMAL FP Denormal one or more; _SOURCE input operands is a; denormal number; 26 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Division by; _DIVISION_BY_ZERO Zero; 27 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP FP Overflow; _OVERFLOW; 28 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Underflow; _UNDERFLOW; 29 1 bit ENABLE_EXCEPTION_IEEE_754_FP IEEE 754 FP Inexact; _INEXACT; 30 1 bit ENABLE_EXCEPTION_INT_DIVIDE_BY Integer Division by Zero; _ZERO (rcp_iflag_f32 instruction; only); 31 1 bit RESERVED Reserved, must be 0.; 32 **Total size 4 bytes.**; ======= ===============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:195423,Energy Efficiency,allocate,allocated,195423," and; Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. 1. The low word of Flat Scratch Init is the 32-bit byte offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to the base of scratch backing memory; being managed by SPI for the queue executing the kernel dispatch. This is; the same value used in the Scratch Segment Buffer V# base address. CP obtains this from the runtime. (The Scratch Segment Buffer base address; is ``SH_HIDDEN_PRIVATE_BASE_VIMID`` plus this offset.). The prolog must add the value of Scratch Wavefront Offset to get the; wavefront's byte scratch backing memory offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID``. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:199487,Energy Efficiency,allocate,allocated,199487,"P uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue ba",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200009,Energy Efficiency,efficient,efficient,200009,"inning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210614,Energy Efficiency,allocate,allocated,210614,"es. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. =========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:234705,Energy Efficiency,allocate,allocated,234705,",; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241120,Energy Efficiency,allocate,allocated,241120,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:284853,Energy Efficiency,allocate,allocated,284853,",; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx942:. Memory Model GFX942; +++++++++++++++++++. For GFX942:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` ins",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:291138,Energy Efficiency,allocate,allocated,291138,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX940, GFX941, GFX942; are defined in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx940-gfx941-gfx942-table`. .. table:: AMDHSA Memory Model Code Sequences GFX940, GFX941, GFX942; :name: amdgpu-amdhsa-memory-model",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:387214,Energy Efficiency,allocate,allocated,387214,"++++. This section describes the call convention ABI for the outer kernel function. See :ref:`amdgpu-amdhsa-initial-kernel-execution-state` for the kernel call; convention. The following is not part of the AMDGPU kernel calling convention but describes; how the AMDGPU implements function calls:. 1. Clang decides the kernarg layout to match the *HSA Programmer's Language; Reference* [HSA]_. - All structs are passed directly.; - Lambda values are passed *TBA*. .. TODO::. - Does this really follow HSA rules? Or are structs >16 bytes passed; by-value struct?; - What is ABI for lambda values?. 4. The kernel performs certain setup in its prolog, as described in; :ref:`amdgpu-amdhsa-kernel-prolog`. .. _amdgpu-amdhsa-function-call-convention-non-kernel-functions:. Non-Kernel Functions; ++++++++++++++++++++. This section describes the call convention ABI for functions other than the; outer kernel function. If a kernel has function calls then scratch is always allocated and used for; the call stack which grows from low address to high address using the swizzled; scratch address space. On entry to a function:. 1. SGPR0-3 contain a V# with the following properties (see; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`):. * Base address pointing to the beginning of the wavefront scratch backing; memory.; * Swizzled with dword element size and stride of wavefront size elements. 2. The FLAT_SCRATCH register pair is setup. See; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; 3. GFX6-GFX8: M0 register set to the size of LDS in bytes. See; :ref:`amdgpu-amdhsa-kernel-prolog-m0`.; 4. The EXEC register is set to the lanes active on entry to the function.; 5. MODE register: *TBD*; 6. VGPR0-31 and SGPR4-29 are used to pass function input arguments as described; below.; 7. SGPR30-31 return address (RA). The code address that the function must; return to when it completes. The value is undefined if the function is *no; return*.; 8. SGPR32 is used for the stack pointer (SP). It is ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389362,Energy Efficiency,allocate,allocated,389362,"ry. The unswizzled SP can be used with buffer instructions as an unswizzled SGPR; offset with the scratch V# in SGPR0-3 to access the stack in a swizzled; manner. The unswizzled SP value can be converted into the swizzled SP value by:. | swizzled SP = unswizzled SP / wavefront size. This may be used to obtain the private address space address of stack; objects and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389536,Energy Efficiency,allocate,allocate,389536,"he swizzled SP value by:. | swizzled SP = unswizzled SP / wavefront size. This may be used to obtain the private address space address of stack; objects and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SG",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389679,Energy Efficiency,allocate,allocated,389679,"and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; *",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:390955,Energy Efficiency,allocate,allocated,390955,"as been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are considered clobbered registers.; 2. The following registers are preserved and have the same value as on entry:. * FLAT_SCRATCH; * EXEC; * GFX6-GFX8: M0; * All SGPR registers except the clobbered registers of SGPR4-31.; * VGPR40-47; * VGPR56-63; * VGPR72-79; * VGPR88-95; * VGPR104-111; * VGPR120-127; * VGPR136-143; * VGPR152-159; * VGPR168-175; * VGPR184-191; * VGPR200-207; * VGPR216-223; * VGPR232-239; * VGPR248-255. .. note::. Except the argument registers, the VGPRs clobbered and the preserved; registers are intermixed at regular intervals in order to keep a; similar ratio independent of the number of allocated VGPRs. * GFX90A: All AGPR registers except the clobbered registers AGPR0-31.; * Lanes of all VGPRs that are inactive at the call site. For the AMDGPU backend, an inter-procedural register allocation (IPRA); optimization may mark some of clobbered SGPR and VGPR registers as; preserved if it can be determined that the called function does not change; their value. 2. The PC is set to the RA provided on entry.; 3. MODE register: *TBD*.; 4. All other registers are clobbered.; 5. Any necessary ``s_waitcnt`` has been performed to ensure memory accessed by; function is available to the caller. .. TODO::. - How are function results returned? The address of structured types is passed; by reference, but what about other types?. The function input arguments are made up of the formal arguments explicitly; declared by the source language function plus the implicit input arguments used; by the implementation. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397047,Energy Efficiency,allocate,allocated,397047,"-register-set-up-order-table`. 7. Work-Group ID Y (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 8. Work-Group ID Z (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397157,Energy Efficiency,allocate,allocated,397157,"ee; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 8. Work-Group ID Z (1 SGPR). The value comes from the initial kernel execution state. See; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack align",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:397357,Energy Efficiency,allocate,allocated,397357,"rder-table`. 9. Implicit Argument Ptr (2 SGPRs). The value is computed by adding an offset to Kernarg Segment Ptr to get the; global address space pointer to the first kernarg implicit argument. The input and result arguments are assigned in order in the following manner:. .. note::. There are likely some errors and omissions in the following description that; need correction. .. TODO::. Check the Clang source code to decipher how function arguments and return; results are handled. Also see the AMDGPU specific values used. * VGPR arguments are assigned to consecutive VGPRs starting at VGPR0 up to; VGPR31. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. .. TODO::. How are overly aligned structures allocated on the stack?. * SGPR arguments are assigned to consecutive SGPRs starting at SGPR0 up to; SGPR29. If there are more arguments than will fit in these registers, the remaining; arguments are allocated on the stack in order on naturally aligned; addresses. Note that decomposed struct type arguments may have some fields passed in; registers and some in memory. .. TODO::. So, a struct which can pass some fields as decomposed register arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:398673,Energy Efficiency,allocate,allocated,398673,"er arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment. 3. Allocating SGPR arguments on the stack are not supported. 4. No CFI is currently generated. See; :ref:`amdgpu-dwarf-call-frame-information`. .. note::. CFI will be generated that defines the CFA as the unswizzled address; relative to the wave scratch base in the unswizzled private address space; of the lowest address stack allocated local variable. ``DW_AT_frame_base`` will be defined as the swizzled address in the; swizzled private address space by dividing the CFA by the wavefront size; (since CFA is always at least dword aligned which matches the scratch; swizzle element size). If no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:398991,Energy Efficiency,allocate,allocated,398991,"`; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment. 3. Allocating SGPR arguments on the stack are not supported. 4. No CFI is currently generated. See; :ref:`amdgpu-dwarf-call-frame-information`. .. note::. CFI will be generated that defines the CFA as the unswizzled address; relative to the wave scratch base in the unswizzled private address space; of the lowest address stack allocated local variable. ``DW_AT_frame_base`` will be defined as the swizzled address in the; swizzled private address space by dividing the CFA by the wavefront size; (since CFA is always at least dword aligned which matches the scratch; swizzle element size). If no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemented by setting up the arguments at positive offsets; from SP. Then SP is incremented to account for the known frame size before; the call and decremented after the call. .. note::. The CFI will reflect the changed calculation needed to compute the CFA; from SP. 7. 4 byte spill slots are used in the stack frame. One slot is allocated for an; emergency spill slot. Buffer instructions are used for stack accesses and; not the ``flat_scratch`` instruction. .. TODO::. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:399924,Energy Efficiency,allocate,allocated,399924,"f no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemented by setting up the arguments at positive offsets; from SP. Then SP is incremented to account for the known frame size before; the call and decremented after the call. .. note::. The CFI will reflect the changed calculation needed to compute the CFA; from SP. 7. 4 byte spill slots are used in the stack frame. One slot is allocated for an; emergency spill slot. Buffer instructions are used for stack accesses and; not the ``flat_scratch`` instruction. .. TODO::. Explain when the emergency spill slot is used. .. TODO::. Possible broken issues:. - Stack arguments must be aligned to required alignment.; - Stack is aligned to max(16, max formal argument alignment); - Direct argument < 64 bits should check register budget.; - Register budget calculation should respect ``inreg`` for SGPR.; - SGPR overflow is not handled.; - struct with 1 member unpeeling is not checking size of member.; - ``sret`` is after ``this`` pointer.; - Caller is not implementing stack realignment: need an extra pointer.; - Should say AMDGPU passes FP rather than SP.; - Should CFI define CFA as address of locals or arguments. Difference is; apparent when have implemented dynamic alignment.; - If ``SCRATCH`` instruction could allow negative offsets, then can make FP be; highest address of stack frame and use negative offset for locals. Would; allow S",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:434502,Energy Efficiency,power,power,434502,"A_KERNEL. .amd_kernel_code_t; ++++++++++++++++++. This directive marks the beginning of a list of key / value pairs that are used; to specify the amd_kernel_code_t object that will be emitted by the assembler.; The list must be terminated by the *.end_amd_kernel_code_t* directive. For any; amd_kernel_code_t values that are unspecified a default value will be used. The; default value for all keys is 0, with the following exceptions:. - *amd_code_version_major* defaults to 1.; - *amd_kernel_code_version_minor* defaults to 2.; - *amd_machine_kind* defaults to 1.; - *amd_machine_version_major*, *machine_version_minor*, and; *amd_machine_version_stepping* are derived from the value of the -mcpu option; that is passed to the assembler.; - *kernel_code_entry_byte_offset* defaults to 256.; - *wavefront_size* defaults 6 for all targets before GFX10. For GFX10 onwards; defaults to 6 if target feature ``wavefrontsize64`` is enabled, otherwise 5.; Note that wavefront size is specified as a power of two, so a value of **n**; means a size of 2^ **n**.; - *call_convention* defaults to -1.; - *kernarg_segment_alignment*, *group_segment_alignment*, and; *private_segment_alignment* default to 4. Note that alignments are specified; as a power of 2, so a value of **n** means an alignment of 2^ **n**.; - *enable_tg_split* defaults to 1 if target feature ``tgsplit`` is enabled for; GFX90A onwards.; - *enable_wgp_mode* defaults to 1 if target feature ``cumode`` is disabled for; GFX10 onwards.; - *enable_mem_ordered* defaults to 1 for GFX10 onwards. The *.amd_kernel_code_t* directive must be placed immediately after the; function label and before any instructions. For a full list of amd_kernel_code_t keys, refer to AMDGPU ABI document,; comments in lib/Target/AMDGPU/AmdKernelCodeT.h and test/CodeGen/AMDGPU/hsa.s. .. _amdgpu-amdhsa-assembler-example-v2:. Code Object V2 Example Source Code; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:434747,Energy Efficiency,power,power,434747,"end_amd_kernel_code_t* directive. For any; amd_kernel_code_t values that are unspecified a default value will be used. The; default value for all keys is 0, with the following exceptions:. - *amd_code_version_major* defaults to 1.; - *amd_kernel_code_version_minor* defaults to 2.; - *amd_machine_kind* defaults to 1.; - *amd_machine_version_major*, *machine_version_minor*, and; *amd_machine_version_stepping* are derived from the value of the -mcpu option; that is passed to the assembler.; - *kernel_code_entry_byte_offset* defaults to 256.; - *wavefront_size* defaults 6 for all targets before GFX10. For GFX10 onwards; defaults to 6 if target feature ``wavefrontsize64`` is enabled, otherwise 5.; Note that wavefront size is specified as a power of two, so a value of **n**; means a size of 2^ **n**.; - *call_convention* defaults to -1.; - *kernarg_segment_alignment*, *group_segment_alignment*, and; *private_segment_alignment* default to 4. Note that alignments are specified; as a power of 2, so a value of **n** means an alignment of 2^ **n**.; - *enable_tg_split* defaults to 1 if target feature ``tgsplit`` is enabled for; GFX90A onwards.; - *enable_wgp_mode* defaults to 1 if target feature ``cumode`` is disabled for; GFX10 onwards.; - *enable_mem_ordered* defaults to 1 for GFX10 onwards. The *.amd_kernel_code_t* directive must be placed immediately after the; function label and before any instructions. For a full list of amd_kernel_code_t keys, refer to AMDGPU ABI document,; comments in lib/Target/AMDGPU/AmdKernelCodeT.h and test/CodeGen/AMDGPU/hsa.s. .. _amdgpu-amdhsa-assembler-example-v2:. Code Object V2 Example Source Code; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. Here is an example of a minimal assembly source file, defining one HSA kernel:. .. code::; :number-lines:. .hsa_code_object_version 1,0; .hsa_code_object_isa. .hsatext; .globl hello_world; .p2align 8; .amdgpu_hsa_kernel hello_w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:23491,Integrability,depend,depending,23491,"AMDHSA*; Local 3 group LDS 32 0xFFFFFFFF; Constant 4 constant *same as global* 64 0x0000000000000000; Private 5 private scratch 32 0xFFFFFFFF; Constant 32-bit 6 *TODO* 0x00000000; Buffer Fat Pointer (experimental) 7 *TODO*; Buffer Resource (experimental) 8 *TODO*; Buffer Strided Pointer (experimental) 9 *TODO*; Streamout Registers 128 N/A GS_REGS; ===================================== =============== =========== ================ ======= ============================. **Generic**; The generic address space is supported unless the *Target Properties* column; of :ref:`amdgpu-processor-table` specifies *Does not support generic address; space*. The generic address space uses the hardware flat address support for two fixed; ranges of virtual addresses (the private and local apertures), that are; outside the range of addressable global memory, to map from a flat address to; a private or local address. This uses FLAT instructions that can take a flat; address and access global, private (scratch), and group (LDS) memory depending; on if the address is within one of the aperture ranges. Flat access to scratch requires hardware aperture setup and setup in the; kernel prologue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat; access to LDS requires hardware aperture setup and M0 (GFX7-GFX8) register; setup (see :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a private or group address space address (termed a segment; address) and a flat address the base address of the corresponding aperture; can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline; constant registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``.; In 64-bit address mode the aperture sizes are 2^32 bytes and the base is; aligned to 2^32 which makes it easie",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:31692,Integrability,synchroniz,synchronization,31692,"inter**. Additionally, it contains an index into the buffer, which; allows the direct addressing of structured elements. These components appear; in that order, i.e., the descriptor comes first, then the 32-bit offset; followed by the 32-bit index. The bits in the buffer descriptor must meet the following requirements:; the stride is the size of a structured element, the ""add tid"" flag must be 0,; and the swizzle enable bits must be off. **Streamout Registers**; Dedicated registers used by the GS NGG Streamout Instructions. The register; file is modelled as a memory in a distinct address space because it is indexed; by an address-like offset in place of named registers, and because register; accesses affect LGKMcnt. This is an internal address space used only by the; compiler. Do not use this address space for IR pointers. .. _amdgpu-memory-scopes:. Memory Scopes; -------------. This section provides LLVM memory synchronization scopes supported by the AMDGPU; backend memory model when the target triple OS is ``amdhsa`` (see; :ref:`amdgpu-amdhsa-memory-model` and :ref:`amdgpu-target-triples`). The memory model supported is based on the HSA memory model [HSA]_ which is; based in turn on HRF-indirect with scope inclusion [HRF]_. The happens-before; relation is transitive over the synchronizes-with relation independent of scope; and synchronizes-with allows the memory scope instances to be inclusive (see; table :ref:`amdgpu-amdhsa-llvm-sync-scopes-table`). This is different to the OpenCL [OpenCL]_ memory model which does not have scope; inclusion and requires the memory scopes to exactly match. However, this; is conservatively correct for OpenCL. .. table:: AMDHSA LLVM Sync Scopes; :name: amdgpu-amdhsa-llvm-sync-scopes-table. ======================= ===================================================; LLVM Sync Scope Description; ======================= ===================================================; *none* The default: ``system``. Synchronizes with, and participat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:32064,Integrability,synchroniz,synchronizes-with,32064," element, the ""add tid"" flag must be 0,; and the swizzle enable bits must be off. **Streamout Registers**; Dedicated registers used by the GS NGG Streamout Instructions. The register; file is modelled as a memory in a distinct address space because it is indexed; by an address-like offset in place of named registers, and because register; accesses affect LGKMcnt. This is an internal address space used only by the; compiler. Do not use this address space for IR pointers. .. _amdgpu-memory-scopes:. Memory Scopes; -------------. This section provides LLVM memory synchronization scopes supported by the AMDGPU; backend memory model when the target triple OS is ``amdhsa`` (see; :ref:`amdgpu-amdhsa-memory-model` and :ref:`amdgpu-target-triples`). The memory model supported is based on the HSA memory model [HSA]_ which is; based in turn on HRF-indirect with scope inclusion [HRF]_. The happens-before; relation is transitive over the synchronizes-with relation independent of scope; and synchronizes-with allows the memory scope instances to be inclusive (see; table :ref:`amdgpu-amdhsa-llvm-sync-scopes-table`). This is different to the OpenCL [OpenCL]_ memory model which does not have scope; inclusion and requires the memory scopes to exactly match. However, this; is conservatively correct for OpenCL. .. table:: AMDHSA LLVM Sync Scopes; :name: amdgpu-amdhsa-llvm-sync-scopes-table. ======================= ===================================================; LLVM Sync Scope Description; ======================= ===================================================; *none* The default: ``system``. Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``.; - ``agent`` and executed by a thread on the same; agent.; - ``workgroup`` and executed by a thread in the; same work-group.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:32117,Integrability,synchroniz,synchronizes-with,32117," element, the ""add tid"" flag must be 0,; and the swizzle enable bits must be off. **Streamout Registers**; Dedicated registers used by the GS NGG Streamout Instructions. The register; file is modelled as a memory in a distinct address space because it is indexed; by an address-like offset in place of named registers, and because register; accesses affect LGKMcnt. This is an internal address space used only by the; compiler. Do not use this address space for IR pointers. .. _amdgpu-memory-scopes:. Memory Scopes; -------------. This section provides LLVM memory synchronization scopes supported by the AMDGPU; backend memory model when the target triple OS is ``amdhsa`` (see; :ref:`amdgpu-amdhsa-memory-model` and :ref:`amdgpu-target-triples`). The memory model supported is based on the HSA memory model [HSA]_ which is; based in turn on HRF-indirect with scope inclusion [HRF]_. The happens-before; relation is transitive over the synchronizes-with relation independent of scope; and synchronizes-with allows the memory scope instances to be inclusive (see; table :ref:`amdgpu-amdhsa-llvm-sync-scopes-table`). This is different to the OpenCL [OpenCL]_ memory model which does not have scope; inclusion and requires the memory scopes to exactly match. However, this; is conservatively correct for OpenCL. .. table:: AMDHSA LLVM Sync Scopes; :name: amdgpu-amdhsa-llvm-sync-scopes-table. ======================= ===================================================; LLVM Sync Scope Description; ======================= ===================================================; *none* The default: ``system``. Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``.; - ``agent`` and executed by a thread on the same; agent.; - ``workgroup`` and executed by a thread in the; same work-group.; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:34481,Integrability,synchroniz,synchronizes,34481,"same work-group.; - ``wavefront`` and executed by a thread in the; same wavefront. ``workgroup`` Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent`` or ``workgroup`` and; executed by a thread in the same work-group.; - ``wavefront`` and executed by a thread in the; same wavefront. ``wavefront`` Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent``, ``workgroup`` or; ``wavefront`` and executed by a thread in the; same wavefront. ``singlethread`` Only synchronizes with and participates in; modification and seq_cst total orderings with,; other operations (except image operations) running; in the same thread for all address spaces (for; example, in signal handlers). ``one-as`` Same as ``system`` but only synchronizes with other; operations within the same address space. ``agent-one-as`` Same as ``agent`` but only synchronizes with other; operations within the same address space. ``workgroup-one-as`` Same as ``workgroup`` but only synchronizes with; other operations within the same address space. ``wavefront-one-as`` Same as ``wavefront`` but only synchronizes with; other operations within the same address space. ``singlethread-one-as`` Same as ``singlethread`` but only synchronizes with; other operations within the same address space.; ======================= ===================================================. LLVM IR Intrinsics; ------------------. The AMDGPU backend implements the following LLVM IR intrinsics. *This section is WIP.*. .. table:: AMDGPU LLVM IR Intrinsics; :name: amdgpu-llvm-ir-intrinsics-table. ================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:34737,Integrability,synchroniz,synchronizes,34737,"ings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent`` or ``workgroup`` and; executed by a thread in the same work-group.; - ``wavefront`` and executed by a thread in the; same wavefront. ``wavefront`` Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent``, ``workgroup`` or; ``wavefront`` and executed by a thread in the; same wavefront. ``singlethread`` Only synchronizes with and participates in; modification and seq_cst total orderings with,; other operations (except image operations) running; in the same thread for all address spaces (for; example, in signal handlers). ``one-as`` Same as ``system`` but only synchronizes with other; operations within the same address space. ``agent-one-as`` Same as ``agent`` but only synchronizes with other; operations within the same address space. ``workgroup-one-as`` Same as ``workgroup`` but only synchronizes with; other operations within the same address space. ``wavefront-one-as`` Same as ``wavefront`` but only synchronizes with; other operations within the same address space. ``singlethread-one-as`` Same as ``singlethread`` but only synchronizes with; other operations within the same address space.; ======================= ===================================================. LLVM IR Intrinsics; ------------------. The AMDGPU backend implements the following LLVM IR intrinsics. *This section is WIP.*. .. table:: AMDGPU LLVM IR Intrinsics; :name: amdgpu-llvm-ir-intrinsics-table. ============================================== ==========================================================; LLVM Intrinsic Description; ============================================== ======",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:34848,Integrability,synchroniz,synchronizes,34848,"hat accesses private); provided the other operation's sync scope is:. - ``system``, ``agent`` or ``workgroup`` and; executed by a thread in the same work-group.; - ``wavefront`` and executed by a thread in the; same wavefront. ``wavefront`` Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent``, ``workgroup`` or; ``wavefront`` and executed by a thread in the; same wavefront. ``singlethread`` Only synchronizes with and participates in; modification and seq_cst total orderings with,; other operations (except image operations) running; in the same thread for all address spaces (for; example, in signal handlers). ``one-as`` Same as ``system`` but only synchronizes with other; operations within the same address space. ``agent-one-as`` Same as ``agent`` but only synchronizes with other; operations within the same address space. ``workgroup-one-as`` Same as ``workgroup`` but only synchronizes with; other operations within the same address space. ``wavefront-one-as`` Same as ``wavefront`` but only synchronizes with; other operations within the same address space. ``singlethread-one-as`` Same as ``singlethread`` but only synchronizes with; other operations within the same address space.; ======================= ===================================================. LLVM IR Intrinsics; ------------------. The AMDGPU backend implements the following LLVM IR intrinsics. *This section is WIP.*. .. table:: AMDGPU LLVM IR Intrinsics; :name: amdgpu-llvm-ir-intrinsics-table. ============================================== ==========================================================; LLVM Intrinsic Description; ============================================== ==========================================================; llvm.amdgcn.sqrt Provides direct access to v_sqrt_f64, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:34967,Integrability,synchroniz,synchronizes,34967," executed by a thread in the same work-group.; - ``wavefront`` and executed by a thread in the; same wavefront. ``wavefront`` Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent``, ``workgroup`` or; ``wavefront`` and executed by a thread in the; same wavefront. ``singlethread`` Only synchronizes with and participates in; modification and seq_cst total orderings with,; other operations (except image operations) running; in the same thread for all address spaces (for; example, in signal handlers). ``one-as`` Same as ``system`` but only synchronizes with other; operations within the same address space. ``agent-one-as`` Same as ``agent`` but only synchronizes with other; operations within the same address space. ``workgroup-one-as`` Same as ``workgroup`` but only synchronizes with; other operations within the same address space. ``wavefront-one-as`` Same as ``wavefront`` but only synchronizes with; other operations within the same address space. ``singlethread-one-as`` Same as ``singlethread`` but only synchronizes with; other operations within the same address space.; ======================= ===================================================. LLVM IR Intrinsics; ------------------. The AMDGPU backend implements the following LLVM IR intrinsics. *This section is WIP.*. .. table:: AMDGPU LLVM IR Intrinsics; :name: amdgpu-llvm-ir-intrinsics-table. ============================================== ==========================================================; LLVM Intrinsic Description; ============================================== ==========================================================; llvm.amdgcn.sqrt Provides direct access to v_sqrt_f64, v_sqrt_f32 and v_sqrt_f16; (on targets with half support). Performs sqrt function. llvm.amdgcn.log Provides direct ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:35086,Integrability,synchroniz,synchronizes,35086,"ront`` Synchronizes with, and participates in modification; and seq_cst total orderings with, other operations; (except image operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent``, ``workgroup`` or; ``wavefront`` and executed by a thread in the; same wavefront. ``singlethread`` Only synchronizes with and participates in; modification and seq_cst total orderings with,; other operations (except image operations) running; in the same thread for all address spaces (for; example, in signal handlers). ``one-as`` Same as ``system`` but only synchronizes with other; operations within the same address space. ``agent-one-as`` Same as ``agent`` but only synchronizes with other; operations within the same address space. ``workgroup-one-as`` Same as ``workgroup`` but only synchronizes with; other operations within the same address space. ``wavefront-one-as`` Same as ``wavefront`` but only synchronizes with; other operations within the same address space. ``singlethread-one-as`` Same as ``singlethread`` but only synchronizes with; other operations within the same address space.; ======================= ===================================================. LLVM IR Intrinsics; ------------------. The AMDGPU backend implements the following LLVM IR intrinsics. *This section is WIP.*. .. table:: AMDGPU LLVM IR Intrinsics; :name: amdgpu-llvm-ir-intrinsics-table. ============================================== ==========================================================; LLVM Intrinsic Description; ============================================== ==========================================================; llvm.amdgcn.sqrt Provides direct access to v_sqrt_f64, v_sqrt_f32 and v_sqrt_f16; (on targets with half support). Performs sqrt function. llvm.amdgcn.log Provides direct access to v_log_f32 and v_log_f16; (on targets with half support). Performs log2 function. llvm.amdgcn.exp2 Provides di",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:35211,Integrability,synchroniz,synchronizes,35211,"age operations) for all address spaces; (except private, or generic that accesses private); provided the other operation's sync scope is:. - ``system``, ``agent``, ``workgroup`` or; ``wavefront`` and executed by a thread in the; same wavefront. ``singlethread`` Only synchronizes with and participates in; modification and seq_cst total orderings with,; other operations (except image operations) running; in the same thread for all address spaces (for; example, in signal handlers). ``one-as`` Same as ``system`` but only synchronizes with other; operations within the same address space. ``agent-one-as`` Same as ``agent`` but only synchronizes with other; operations within the same address space. ``workgroup-one-as`` Same as ``workgroup`` but only synchronizes with; other operations within the same address space. ``wavefront-one-as`` Same as ``wavefront`` but only synchronizes with; other operations within the same address space. ``singlethread-one-as`` Same as ``singlethread`` but only synchronizes with; other operations within the same address space.; ======================= ===================================================. LLVM IR Intrinsics; ------------------. The AMDGPU backend implements the following LLVM IR intrinsics. *This section is WIP.*. .. table:: AMDGPU LLVM IR Intrinsics; :name: amdgpu-llvm-ir-intrinsics-table. ============================================== ==========================================================; LLVM Intrinsic Description; ============================================== ==========================================================; llvm.amdgcn.sqrt Provides direct access to v_sqrt_f64, v_sqrt_f32 and v_sqrt_f16; (on targets with half support). Performs sqrt function. llvm.amdgcn.log Provides direct access to v_log_f32 and v_log_f16; (on targets with half support). Performs log2 function. llvm.amdgcn.exp2 Provides direct access to v_exp_f32 and v_exp_f16; (on targets with half support). Performs exp2 function. :ref:`llvm.frexp <int_frex",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:37710,Integrability,depend,depending,37710,"p>` Implemented for float and half (and vectors). :ref:`llvm.log10 <int_log10>` Implemented for float and half (and vectors). :ref:`llvm.exp2 <int_exp2>` Implemented for float and half (and vectors of float or; half). Not implemented for double. Hardware provides; 1ULP accuracy for float, and 0.51ULP for half. Float; instruction does not natively support denormal; inputs. :ref:`llvm.stacksave.p5 <int_stacksave>` Implemented, must use the alloca address space.; :ref:`llvm.stackrestore.p5 <int_stackrestore>` Implemented, must use the alloca address space. :ref:`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:46629,Integrability,depend,depending,46629,"the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ============================================== ==========================================================. .. TODO::. List AMDGPU intrinsics. LLVM IR Attributes; ------------------. The AMDGPU backend supports the following LLVM IR attributes. .. table:: AMDGPU LLVM IR Attributes; :name: amdgpu-llvm-ir-attributes-table. ======================================= ==========================================================; LLVM Attribute Description; ======================================= ==========================================================; ""amdgpu-flat-work-group-size""=""min,max"" Specify the minimum and maximum flat work group sizes that; will be specified when the kernel is dispatched. Generated; by the ``amdgpu_flat_work_group_size`` CLANG attribute [CLANG-ATTR]_.; The IR implied default value is 1,1024. Clang may emit this attribute; with more restrictive bounds depending on language defaults.; If the actual block or workgroup size exceeds the limit at any point during; the execution, the behavior is undefined. For example, even if there is; only one active thread but the thread local id exceeds the limit, the; behavior is undefined. ""amdgpu-implicitarg-num-bytes""=""n"" Number of kernel argument bytes to add to the kernel; argument block size for the implicit arguments. This; varies by OS and language (for OpenCL see; :ref:`opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table`).; ""amdgpu-num-sgpr""=""n"" Specifies the number of SGPRs to use. Generated by; the ``amdgpu_num_sgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-num-vgpr""=""n"" Specifies the number of VGPRs to use. Generated by the; ``amdgpu_num_vgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-waves-per-eu""=""m,n"" Specify the minimum and maximum number of waves per; execution unit. Generated by the ``amdgpu_waves_per_eu``; CLANG attribute [CLANG-ATTR]_. This is an optimizat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:48296,Integrability,depend,depend,48296,"G-ATTR]_.; ""amdgpu-num-vgpr""=""n"" Specifies the number of VGPRs to use. Generated by the; ``amdgpu_num_vgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-waves-per-eu""=""m,n"" Specify the minimum and maximum number of waves per; execution unit. Generated by the ``amdgpu_waves_per_eu``; CLANG attribute [CLANG-ATTR]_. This is an optimization hint,; and the backend may not be able to satisfy the request. If; the specified range is incompatible with the function's; ""amdgpu-flat-work-group-size"" value, the implied occupancy; bounds by the workgroup size takes precedence. ""amdgpu-ieee"" true/false. GFX6-GFX11 Only; Specify whether the function expects the IEEE field of the; mode register to be set on entry. Overrides the default for; the calling convention.; ""amdgpu-dx10-clamp"" true/false. GFX6-GFX11 Only; Specify whether the function expects the DX10_CLAMP field of; the mode register to be set on entry. Overrides the default; for the calling convention. ""amdgpu-no-workitem-id-x"" Indicates the function does not depend on the value of the; llvm.amdgcn.workitem.id.x intrinsic. If a function is marked with this; attribute, or reached through a call site marked with this attribute,; the value returned by the intrinsic is undefined. The backend can; generally infer this during code generation, so typically there is no; benefit to frontends marking functions with this. ""amdgpu-no-workitem-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.y intrinsic. ""amdgpu-no-workitem-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.z intrinsic. ""amdgpu-no-workgroup-id-x"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.x intrinsic. ""amdgpu-no-workgroup-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.y intrinsic. ""amdgpu-no-workgroup-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.z intrinsic. ""amdgpu-no-dispatch-ptr"" The same as amdgp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:50764,Integrability,synchroniz,synchronization,50764,"unlike the other ABI hint; attributes, the queue pointer may be required in situations where the; intrinsic call does not directly appear in the program. Some subtargets; require the queue pointer for to handle some addrspacecasts, as well; as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no fur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:69319,Integrability,depend,depend,69319,"-note-records` for the note records supported by the AMDGPU; backend. ``.rela``\ *name*, ``.rela.dyn``; For relocatable code objects, *name* is the name of the section that the; relocation records apply. For example, ``.rela.text`` is the section name for; relocation records associated with the ``.text`` section. For linked shared code objects, ``.rela.dyn`` contains all the relocation; records from each of the relocatable code object's ``.rela``\ *name* sections. See :ref:`amdgpu-relocation-records` for the relocation records supported by; the AMDGPU backend. ``.text``; The executable machine code for the kernels and functions they call. Generated; as position independent code. See :ref:`amdgpu-code-conventions` for; information on conventions used in the isa generation. .. _amdgpu-note-records:. Note Records; ------------. The AMDGPU backend code object contains ELF note records in the ``.note``; section. The set of generated notes and their semantics depend on the code; object version; see :ref:`amdgpu-note-records-v2` and; :ref:`amdgpu-note-records-v3-onwards`. As required by ``ELFCLASS32`` and ``ELFCLASS64``, minimal zero-byte padding; must be generated after the ``name`` field to ensure the ``desc`` field is 4; byte aligned. In addition, minimal zero-byte padding must be generated to; ensure the ``desc`` field size is a multiple of 4 bytes. The ``sh_addralign``; field of the ``.note`` section must be at least 4 to indicate at least 8 byte; alignment. .. _amdgpu-note-records-v2:. Code Object V2 Note Records; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. The AMDGPU backend code object uses the following ELF note record in the; ``.note`` section when compiling for code object V2. The note record vendor field is ""AMD"". Additional note records may be present, but any which are not documented here; are deprecated and should not be used. .. table:: AMDGPU Code Object V2 ELF Note Records; :name: amd",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:80342,Integrability,depend,depends,80342,"l for its machine code entry point. .. _amdgpu-relocation-records:. Relocation Records; ------------------. The AMDGPU backend generates ``Elf64_Rela`` relocation records for; AMDHSA or ``Elf64_Rel`` relocation records for Mesa/AMDPAL. Supported; relocatable fields are:. ``word32``; This specifies a 32-bit field occupying 4 bytes with arbitrary byte; alignment. These values use the same byte order as other word values in the; AMDGPU architecture. ``word64``; This specifies a 64-bit field occupying 8 bytes with arbitrary byte; alignment. These values use the same byte order as other word values in the; AMDGPU architecture. Following notations are used for specifying relocation calculations:. **A**; Represents the addend used to compute the value of the relocatable field. If; the addend field is smaller than 64 bits then it is zero-extended to 64 bits; for use in the calculations below. (In practice this only affects ``_HI``; relocation types on Mesa/AMDPAL, where the addend comes from the 32-bit field; but the result of the calculation depends on the high part of the full 64-bit; address.). **G**; Represents the offset into the global offset table at which the relocation; entry's symbol will reside during execution. **GOT**; Represents the address of the global offset table. **P**; Represents the place (section offset for ``et_rel`` or address for ``et_dyn``); of the storage unit being relocated (computed using ``r_offset``). **S**; Represents the value of the symbol whose index resides in the relocation; entry. Relocations not using this must specify a symbol index of; ``STN_UNDEF``. **B**; Represents the base address of a loaded executable or shared object which is; the difference between the ELF address and the actual load address.; Relocations using this are only valid in executable or shared objects. The following relocation types are supported:. .. table:: AMDGPU ELF Relocation Records; :name: amdgpu-elf-relocation-records-table. ========================== =====",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:117363,Integrability,depend,depends,117363,"eaders; ------------. For AMDGPU the following values apply for each of the unit headers described in; DWARF Version 5 sections 7.5.1.1, 7.5.1.2, and 7.5.1.3:. ``address_size`` (ubyte); Matches the address size for the ``Global`` address space defined in; :ref:`amdgpu-dwarf-address-space-identifier`. .. _amdgpu-code-conventions:. Code Conventions; ================. This section provides code conventions used for each supported target triple OS; (see :ref:`amdgpu-target-triples`). AMDHSA; ------. This section provides code conventions used when the target triple OS is; ``amdhsa`` (see :ref:`amdgpu-target-triples`). .. _amdgpu-amdhsa-code-object-metadata:. Code Object Metadata; ~~~~~~~~~~~~~~~~~~~~. The code object metadata specifies extensible metadata associated with the code; objects executed on HSA [HSA]_ compatible runtimes (see :ref:`amdgpu-os`). The; encoding and semantics of this metadata depends on the code object version; see; :ref:`amdgpu-amdhsa-code-object-metadata-v2`,; :ref:`amdgpu-amdhsa-code-object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5`. Code object metadata is specified in a note record (see; :ref:`amdgpu-note-records`) and is required when the target triple OS is; ``amdhsa`` (see :ref:`amdgpu-target-triples`). It must contain the minimum; information necessary to support the HSA compatible runtime kernel queries. For; example, the segment sizes needed in a dispatch packet. In addition, a; high-level language runtime may require other information to be included. For; example, the AMD OpenCL runtime records kernel argument information. .. _amdgpu-amdhsa-code-object-metadata-v2:. Code Object V2 Metadata; +++++++++++++++++++++++. .. warning::; Code object V2 generation is no longer supported by this version of LLVM. Code object V2 metadata is specified by the ``NT_AMD_HSA_METADATA`` note record; (see :ref:`amdgpu-note-records-v2`). The metadata is specified as a YAML formatted string ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:125392,Integrability,synchroniz,synchronization,125392,"global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenCompletionAction""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""HiddenMultiGridSyncArg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How can Private or Region; ever happen?. ""AccQual"" string Kernel argument access; qualifier. Only present if; ""ValueKind"" is ""Image"" or; ""Pipe"". Values; are:. - ""ReadOnly""; - ""WriteOnly""; - ""ReadWrite"". .. TODO::. Does this apply to; GlobalBuffer?. ""ActualAccQual"" string The actual memory accesses; performe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:138771,Integrability,synchroniz,synchronization,138771,"hidden_global_offset_z""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""hidden_none""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""hidden_printf_buffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_hostcall_buffer""; before Code Object V5. ""hidden_hostcall_buffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_printf_buffer""; before Code Object V5. ""hidden_default_queue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""hidden_completion_action""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""hidden_multigrid_sync_arg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. "".value_type"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. "".pointee_align"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; "".value_kind"" is; ""dynamic_shared_pointer"".; "".address_space"" string Kernel argument address space; qualifier. Only present if; "".value_kind"" is ""global_buffer"" or; ""dynamic_shared_pointer"". Values; are:. - ""private""; - ""global""; - ""constant""; - ""local""; - ""generic""; - ""region"". .. TODO::. Is ""global_buffer"" only ""global""; or ""constant""? Is; ""dynamic_shared_pointer"" always; ""local""? Can HCC allow ""generic""?; How can ""private"" or ""region""; ever happen?. "".access"" string Kernel argument access; qualifier. Only present if; "".value_kind"" is ""image"" or; ""pipe"". Values; are:. - ""read_only""; - ""write_only""; - ""read_write"". .. TODO::. Does this apply to; ""global_buffer""?. "".actual_access"" ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:148924,Integrability,interface,interface,148924,"e""; Size of the dynamically allocated LDS memory is passed in the kernarg. ""hidden_private_base""; The high 32 bits of the flat addressing private aperture base.; Only used by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:155749,Integrability,depend,depending,155749,"here are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords being accessed; and hence requires fewer cache lines to be fetched. Multi-dword access is not; supported except by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the; apertures address can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:191932,Integrability,depend,depending,191932,"s; determined by the value specified in the kernarg_preload_spec_length field of; the kernel descriptor. This data is then loaded into consecutive User SGPRs. The; number of SGPRs receiving preloaded kernarg data corresponds with the value; given by kernarg_preload_spec_length. The preloading starts at the dword offset; within the kernarg segment, which is specified by the; kernarg_preload_spec_offset field. If the kernarg_preload_spec_length is non-zero, the CP firmware will append an; additional 256 bytes to the kernel_code_entry_byte_offset. This addition; facilitates the incorporation of a prologue to the kernel entry to handle cases; where code designed for kernarg preloading is executed on hardware equipped with; incompatible firmware. If hardware has compatible firmware the 256 bytes at the; start of the kernel entry will be skipped. .. _amdgpu-amdhsa-kernel-prolog:. Kernel Prolog; ~~~~~~~~~~~~~. The compiler performs initialization in the kernel prologue depending on the; target and information about things like stack usage in the kernel and called; functions. Some of this initialization requires the compiler to request certain; User and System SGPRs be present in the; :ref:`amdgpu-amdhsa-initial-kernel-execution-state` via the; :ref:`amdgpu-amdhsa-kernel-descriptor`. .. _amdgpu-amdhsa-kernel-prolog-cfi:. CFI; +++. 1. The CFI return address is undefined. 2. The CFI CFA is defined using an expression which evaluates to a location; description that comprises one memory location description for the; ``DW_ASPACE_AMDGPU_private_lane`` address space address ``0``. .. _amdgpu-amdhsa-kernel-prolog-m0:. M0; ++. GFX6-GFX8; The M0 register must be initialized with a value at least the total LDS size; if the kernel may access LDS via DS or flat operations. Total LDS size is; available in dispatch packet. For M0, it is also possible to use maximum; possible value of LDS for given target (0x7FFF for GFX6 and 0xFFFF for; GFX7-GFX8).; GFX9-GFX11; The M0 register is not used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200966,Integrability,synchroniz,synchronization,200966,"V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the memory model specify the order of; instructions that a single thread must execute. The ``s_waitcnt`` and cache; management instructions such as ``buffer_wbinvl1_vol`` are defined with respect; to other memory instructions executed by the same thread. This allows them to be; moved earlier or later which can allow them to be combined with other instances; of the same instruction, or hoisted/sunk out of loops to improve performance.; Only the instructions related to the memory model are given; additional; ``s_waitcnt`` instructions are required to ensure registers are defined before; being used. These may be able to be combined with the memory model ``s_waitcnt``; instructions as described above. The AMDGPU backend supports the following memory models:. HSA Memory Model [HSA]_; The HSA memory model uses a single happens-before relation for all address; spaces (see :ref:`amdgpu-address-spaces`).; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:203620,Integrability,synchroniz,synchronization,203620," the; OpenCL memory. The target triple environment is used to determine if the; source language is OpenCL (see :ref:`amdgpu-opencl`). ``ds/flat_load/store/atomic`` instructions to local memory are termed LDS; operations. ``buffer/global/flat_load/store/atomic`` instructions to global memory are; termed vector memory operations. Private address space uses ``buffer_load/store`` using the scratch V#; (GFX6-GFX8), or ``scratch_load/store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ =======================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:207178,Integrability,synchroniz,synchronization,207178,"For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coheren",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208868,Integrability,synchroniz,synchronization,208868,"r for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scal",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235351,Integrability,synchroniz,synchronization,235351,"ferent SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237340,Integrability,synchroniz,synchronization,237340,"tem. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:285499,Integrability,synchroniz,synchronization,285499,"ferent SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cac",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287926,Integrability,synchroniz,synchronization,287926,"t scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is c",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:336342,Integrability,synchroniz,synchronization,336342,"r a single work-group are executed in the same; WGP. In CU wavefront execution mode the wavefronts may be executed by; different SIMDs in the same CU. In WGP wavefront execution mode the; wavefronts may be executed by different SIMDs in different CUs in the same; WGP.; * Each WGP has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a WGP are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; WGP. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations.; Completion of load/store/sample operations are reported to a wavefront in; execution order of other load/store/sample operations performed by that; wavefront.; * The vector memory operations access a vector L0 cache. There is a single L0; cache per CU. Each SIMD of a CU accesses the same L0 cache. Therefore, no; special action is required for coherence between the lanes of a single; wavefront. However, a ``buffer_gl0_inv`` is required for coherence between; wavefronts executing in the same work-group as they may be executing on SIMDs; of different CUs that access different L0s. A ``buffer_gl0_inv`` is also; required for coherence between wavefronts executing in different work-groups; as they may be executing on different WGPs.; * The scalar memory operations access a scalar L0 cache shared by all wavefr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:338445,Integrability,synchroniz,synchronization,338445,"not coherent. However, scalar; operations are used in a restricted way so do not impact the memory model. See; :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory L0 caches use an L1 cache shared by all WGPs on; the same SA. Therefore, no special action is required for coherence between; the wavefronts of a single work-group. However, a ``buffer_gl1_inv`` is; required for coherence between wavefronts executing in different work-groups; as they may be executing on different SAs that access different L1s.; * The L1 caches have independent quadrants to service disjoint ranges of virtual; addresses.; * Each L0 cache has a separate request queue per L1 quadrant. Therefore, the; vector and scalar memory operations performed by different wavefronts, whether; executing in the same or different work-groups (which may be executing on; different CUs accessing different L0s), can be reordered relative to each; other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is required to ensure; synchronization between vector memory operations of different wavefronts. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:339294,Integrability,synchroniz,synchronization,339294,"ng on; different CUs accessing different L0s), can be reordered relative to each; other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is required to ensure; synchronization between vector memory operations of different wavefronts. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L1 caches use an L2 cache shared by all SAs on the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each L1 quadrant of a single SA accesses a different L2 channel. Each L1; quadrant has a separate request queue per L2 channel. Therefore, the vector; and scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is cohe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:342453,Integrability,synchroniz,synchronization,342453,"accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC (non-coherent). Since the private address space is only accessed; by a single thread, and is always write-before-read, there is never a need to; invalidate these entries from the L0 or L1 caches. Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` and; :ref:`amdgpu-target-features`. The code sequences used to implement the memory model for GFX10-GFX11 are defined in; table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table`. .. table:: AMDHSA Memory Model Code Sequences GFX10-GFX11; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table. ============ ============ ============== ========== ================================; LLVM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:342906,Integrability,synchroniz,synchronization,342906," Wavefronts are executed in native mode with in-order reporting of loads and; sample instructions. In this mode vmcnt reports completion of load, atomic with; return and sample instructions in order, and the vscnt reports the completion of; store and atomic without return in order. See ``MEM_ORDERED`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`. Wavefronts can be executed in WGP or CU wavefront execution mode:. * In WGP wavefront execution mode the wavefronts of a work-group are executed; on the SIMDs of both CUs of the WGP. Therefore, explicit management of the per; CU L0 caches is required for work-group synchronization. Also accesses to L1; at work-group scope need to be explicitly ordered as the accesses from; different CUs are not ordered.; * In CU wavefront execution mode the wavefronts of a work-group are executed on; the SIMDs of a single CU of the WGP. Therefore, all global memory access by; the work-group access the same L0 which in turn ensures L1 accesses are; ordered and so do not require explicit management of the caches for; work-group synchronization. See ``WGP_MODE`` field in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table` and; :ref:`amdgpu-target-features`. The code sequences used to implement the memory model for GFX10-GFX11 are defined in; table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table`. .. table:: AMDHSA Memory Model Code Sequences GFX10-GFX11; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx10-gfx11-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX10-GFX11; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:422036,Integrability,synchroniz,synchronization,422036,"s OpenCL the following differences occur:. 1. The OpenCL memory model is used (see :ref:`amdgpu-amdhsa-memory-model`).; 2. The AMDGPU backend appends additional arguments to the kernel's explicit; arguments for the AMDHSA OS (see; :ref:`opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table`).; 3. Additional metadata is generated; (see :ref:`amdgpu-amdhsa-code-object-metadata`). .. table:: OpenCL kernel implicit arguments appended for AMDHSA OS; :name: opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table. ======== ==== ========= ===========================================; Position Byte Byte Description; Size Alignment; ======== ==== ========= ===========================================; 1 8 8 OpenCL Global Offset X; 2 8 8 OpenCL Global Offset Y; 3 8 8 OpenCL Global Offset Z; 4 8 8 OpenCL address of printf buffer; 5 8 8 OpenCL address of virtual queue used by; enqueue_kernel.; 6 8 8 OpenCL address of AqlWrap struct used by; enqueue_kernel.; 7 8 8 Pointer argument used for Multi-gird; synchronization.; ======== ==== ========= ===========================================. .. _amdgpu-hcc:. HCC; ---. When the language is HCC the following differences occur:. 1. The HSA memory model is used (see :ref:`amdgpu-amdhsa-memory-model`). .. _amdgpu-assembler:. Assembler; ---------. AMDGPU backend has LLVM-MC based assembler which is currently in development.; It supports AMDGCN GFX6-GFX11. This section describes general syntax for instructions and operands. Instructions; ~~~~~~~~~~~~. An instruction has the following :doc:`syntax<AMDGPUInstructionSyntax>`:. | ``<``\ *opcode*\ ``> <``\ *operand0*\ ``>, <``\ *operand1*\ ``>,...; <``\ *modifier0*\ ``> <``\ *modifier1*\ ``>...``. :doc:`Operands<AMDGPUOperandSyntax>` are comma-separated while; :doc:`modifiers<AMDGPUModifierSyntax>` are space-separated. The order of operands and modifiers is fixed.; Most modifiers are optional and may be omitted. Links to detailed instruction syntax description may be found in the foll",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:37951,Modifiability,extend,extended,37951,"at, and 0.51ULP for half. Float; instruction does not natively support denormal; inputs. :ref:`llvm.stacksave.p5 <int_stacksave>` Implemented, must use the alloca address space.; :ref:`llvm.stackrestore.p5 <int_stackrestore>` Implemented, must use the alloca address space. :ref:`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If targe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:45600,Modifiability,extend,extended,45600,"p level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ============================================== ==========================================================. .. TODO::. List AMDGPU intrinsics. LLVM IR Attributes; ------------------. The AMDGPU backend supports the following LLVM IR attributes. .. table:: AMDGPU LLVM IR Attributes; :name: amdgpu-llvm-ir-attributes-table. ======================================= ==========================================================; LLVM Attribute Description; ======================================= ==========================================================; ""amdgpu-flat-work-group-size""=""min,max"" Specify the minimum and maximum flat work group sizes that; will be specified when the kernel is dispatched. Generated; by the ``amdgpu_flat_work_group_size`` CLANG attribute [CLANG-ATTR]_.; The IR implied default value is 1,1024. Clang may emit this attribute; with more restrictive bounds de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:45732,Modifiability,extend,extended,45732,"p level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ============================================== ==========================================================. .. TODO::. List AMDGPU intrinsics. LLVM IR Attributes; ------------------. The AMDGPU backend supports the following LLVM IR attributes. .. table:: AMDGPU LLVM IR Attributes; :name: amdgpu-llvm-ir-attributes-table. ======================================= ==========================================================; LLVM Attribute Description; ======================================= ==========================================================; ""amdgpu-flat-work-group-size""=""min,max"" Specify the minimum and maximum flat work group sizes that; will be specified when the kernel is dispatched. Generated; by the ``amdgpu_flat_work_group_size`` CLANG attribute [CLANG-ATTR]_.; The IR implied default value is 1,1024. Clang may emit this attribute; with more restrictive bounds de",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51709,Modifiability,variab,variables,51709,"c to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the same as the ``ccc``. ``coldcc`` The cold calling convention. Mostly the same as the ``ccc``. ``amdgpu_cs`` Used for Mesa/AMDPAL compute shaders.; ..TODO::; Describe. ``amdg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51785,Modifiability,variab,variables,51785,"ibute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==========================================================. Calling Conventions; -------------------. The AMDGPU backend supports the following calling conventions:. .. table:: AMDGPU Calling Conventions; :name: amdgpu-cc. =============================== ==========================================================; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the same as the ``ccc``. ``coldcc`` The cold calling convention. Mostly the same as the ``ccc``. ``amdgpu_cs`` Used for Mesa/AMDPAL compute shaders.; ..TODO::; Describe. ``amdgpu_cs_chain`` Similar to ``amdgpu_cs``, with differences described below. Functions with this calli",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:77854,Modifiability,variab,variable,77854,"ote Record Enumeration Values; :name: amdgpu-elf-note-record-enumeration-values-table-v3-onwards. ============================== =====; Name Value; ============================== =====; *reserved* 0-31; ``NT_AMDGPU_METADATA`` 32; ============================== =====. ``NT_AMDGPU_METADATA``; Specifies extensible metadata associated with an AMDGPU code object. It is; encoded as a map in the Message Pack [MsgPack]_ binary data format. See; :ref:`amdgpu-amdhsa-code-object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5` for the map keys defined for the; ``amdhsa`` OS. .. _amdgpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:78068,Modifiability,variab,variable,78068,"A`` 32; ============================== =====. ``NT_AMDGPU_METADATA``; Specifies extensible metadata associated with an AMDGPU code object. It is; encoded as a map in the Message Pack [MsgPack]_ binary data format. See; :ref:`amdgpu-amdhsa-code-object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5` for the map keys defined for the; ``amdhsa`` OS. .. _amdgpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked shared object symbols. Seems undefined symbols; are marked as STT_NOTYPE. Kernel descriptor; Every HSA kernel has an associated kernel descriptor. It is the address of the; kernel descriptor that is used in the AQL dispa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:78170,Modifiability,variab,variable,78170,"code object. It is; encoded as a map in the Message Pack [MsgPack]_ binary data format. See; :ref:`amdgpu-amdhsa-code-object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5` for the map keys defined for the; ``amdhsa`` OS. .. _amdgpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked shared object symbols. Seems undefined symbols; are marked as STT_NOTYPE. Kernel descriptor; Every HSA kernel has an associated kernel descriptor. It is the address of the; kernel descriptor that is used in the AQL dispatch packet used to invoke the; kernel, not the kernel entry point. The layout of the HSA kernel descriptor is; defined in :ref:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:78187,Modifiability,variab,variables,78187,"code object. It is; encoded as a map in the Message Pack [MsgPack]_ binary data format. See; :ref:`amdgpu-amdhsa-code-object-metadata-v3`,; :ref:`amdgpu-amdhsa-code-object-metadata-v4` and; :ref:`amdgpu-amdhsa-code-object-metadata-v5` for the map keys defined for the; ``amdhsa`` OS. .. _amdgpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked shared object symbols. Seems undefined symbols; are marked as STT_NOTYPE. Kernel descriptor; Every HSA kernel has an associated kernel descriptor. It is the address of the; kernel descriptor that is used in the AQL dispatch packet used to invoke the; kernel, not the kernel entry point. The layout of the HSA kernel descriptor is; defined in :ref:",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:80133,Modifiability,extend,extended,80133," entry point. The layout of the HSA kernel descriptor is; defined in :ref:`amdgpu-amdhsa-kernel-descriptor`. Kernel entry point; Every HSA kernel also has a symbol for its machine code entry point. .. _amdgpu-relocation-records:. Relocation Records; ------------------. The AMDGPU backend generates ``Elf64_Rela`` relocation records for; AMDHSA or ``Elf64_Rel`` relocation records for Mesa/AMDPAL. Supported; relocatable fields are:. ``word32``; This specifies a 32-bit field occupying 4 bytes with arbitrary byte; alignment. These values use the same byte order as other word values in the; AMDGPU architecture. ``word64``; This specifies a 64-bit field occupying 8 bytes with arbitrary byte; alignment. These values use the same byte order as other word values in the; AMDGPU architecture. Following notations are used for specifying relocation calculations:. **A**; Represents the addend used to compute the value of the relocatable field. If; the addend field is smaller than 64 bits then it is zero-extended to 64 bits; for use in the calculations below. (In practice this only affects ``_HI``; relocation types on Mesa/AMDPAL, where the addend comes from the 32-bit field; but the result of the calculation depends on the high part of the full 64-bit; address.). **G**; Represents the offset into the global offset table at which the relocation; entry's symbol will reside during execution. **GOT**; Represents the address of the global offset table. **P**; Represents the place (section offset for ``et_rel`` or address for ``et_dyn``); of the storage unit being relocated (computed using ``r_offset``). **S**; Represents the value of the symbol whose index resides in the relocation; entry. Relocations not using this must specify a symbol index of; ``STN_UNDEF``. **B**; Represents the base address of a loaded executable or shared object which is; the difference between the ELF address and the actual load address.; Relocations using this are only valid in executable or shared objects. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:86516,Modifiability,config,configured,86516,"tecture specific DWARF mappings. .. _amdgpu-dwarf-register-identifier:. Register Identifier; -------------------. This section defines the AMDGPU target architecture register numbers used in; DWARF operation expressions (see DWARF Version 5 section 2.5 and; :ref:`amdgpu-dwarf-operation-expressions`) and Call Frame Information; instructions (see DWARF Version 5 section 6.4 and; :ref:`amdgpu-dwarf-call-frame-information`). A single code object can contain code for kernels that have different wavefront; sizes. The vector registers and some scalar registers are based on the wavefront; size. AMDGPU defines distinct DWARF registers for each wavefront size. This; simplifies the consumer of the DWARF so that each register has a fixed size,; rather than being dynamic according to the wavefront size mode. Similarly,; distinct DWARF registers are defined for those registers that vary in size; according to the process address size. This allows a consumer to treat a; specific AMDGPU processor as a single architecture regardless of how it is; configured at run time. The compiler explicitly specifies the DWARF registers; that match the mode in which the code it is generating will be executed. DWARF registers are encoded as numbers, which are mapped to architecture; registers. The mapping for AMDGPU is defined in; :ref:`amdgpu-dwarf-register-mapping-table`. All AMDGPU targets use the same; mapping. .. table:: AMDGPU DWARF Register Mapping; :name: amdgpu-dwarf-register-mapping-table. ============== ================= ======== ==================================; DWARF Register AMDGPU Register Bit Size Description; ============== ================= ======== ==================================; 0 PC_32 32 Program Counter (PC) when; executing in a 32-bit process; address space. Used in the CFI to; describe the PC of the calling; frame.; 1 EXEC_MASK_32 32 Execution Mask Register when; executing in wavefront 32 mode.; 2-15 *Reserved* *Reserved for highly accessed; registers using DWARF shortc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:95244,Modifiability,variab,variables,95244,"size and NULL value. The ``DW_ASPACE_LLVM_none`` address space is the default target architecture; address space used in DWARF operations that do not specify an address space. It; therefore has to map to the global address space so that the ``DW_OP_addr*`` and; related operations can refer to addresses in the program code. The ``DW_ASPACE_AMDGPU_generic`` address space allows location expressions to; specify the flat address space. If the address corresponds to an address in the; local address space, then it corresponds to the wavefront that is executing the; focused thread of execution. If the address corresponds to an address in the; private address space, then it corresponds to the lane that is executing the; focused thread of execution for languages that are implemented using a SIMD or; SIMT execution model. .. note::. CUDA-like languages such as HIP that do not have address spaces in the; language type system, but do allow variables to be allocated in different; address spaces, need to explicitly specify the ``DW_ASPACE_AMDGPU_generic``; address space in the DWARF expression operations as the default address space; is the global address space. The ``DW_ASPACE_AMDGPU_local`` address space allows location expressions to; specify the local address space corresponding to the wavefront that is executing; the focused thread of execution. The ``DW_ASPACE_AMDGPU_private_lane`` address space allows location expressions; to specify the private address space corresponding to the lane that is executing; the focused thread of execution for languages that are implemented using a SIMD; or SIMT execution model. The ``DW_ASPACE_AMDGPU_private_wave`` address space allows location expressions; to specify the unswizzled private address space corresponding to the wavefront; that is executing the focused thread of execution. The wavefront view of private; memory is the per wavefront unswizzled backing memory layout defined in; :ref:`amdgpu-address-spaces`, such that address 0 corres",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:102861,Modifiability,variab,variable,102861," ``AND`` of the current ``EXEC`` mask with the condition mask. Then the; ``ELSE`` region is executed by negating the ``EXEC`` mask and logical ``AND`` of; the saved ``EXEC`` mask at the start of the region. After the ``IF/THEN/ELSE``; region the ``EXEC`` mask is restored to the value it had at the beginning of the; region. This is shown below. Other approaches are possible, but the basic; concept is the same. .. code::; :number-lines:. $lex_start:; a;; %1 = EXEC; %2 = c1; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by defining an artificial variable for the lane PC. The DWARF location; list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_pc`` attribute on the subprogram's debugger information entry. A DWARF procedure is defined for each well nested structured control flow region; which provides the conceptual lane program location for a lane if it is not; active (namely it is divergent). The DWARF operation expression for each region; conceptually inherits the value of the immediately enclosing region and modifies; it according to the semantics of the region. For an ``IF/THEN/ELSE`` region the divergent program location is at the start of; the region for the ``THEN`` region since it is executed first. For the ``ELSE``; region the divergent program location is at the end of the ``IF/THEN/ELSE``; region since the ``THEN`` region has completed. The lane PC artificial variable is assigned at each region transition. It uses; the immediately enclosing region's DWARF procedure to compute the pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:103301,Modifiability,inherit,inherits,103301,"; $lex_1_start:; EXEC = %1 & %2; $if_1_then:; b;; %3 = EXEC; %4 = c2; $lex_1_1_start:; EXEC = %3 & %4; $lex_1_1_then:; c;; EXEC = ~EXEC & %3; $lex_1_1_else:; d;; EXEC = %3; $lex_1_1_end:; e;; EXEC = ~EXEC & %1; $lex_1_else:; f;; EXEC = %1; $lex_1_end:; g;; $lex_end:. To create the DWARF location list expression that defines the location; description of a vector of lane program locations, the LLVM MIR ``DBG_VALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by defining an artificial variable for the lane PC. The DWARF location; list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_pc`` attribute on the subprogram's debugger information entry. A DWARF procedure is defined for each well nested structured control flow region; which provides the conceptual lane program location for a lane if it is not; active (namely it is divergent). The DWARF operation expression for each region; conceptually inherits the value of the immediately enclosing region and modifies; it according to the semantics of the region. For an ``IF/THEN/ELSE`` region the divergent program location is at the start of; the region for the ``THEN`` region since it is executed first. For the ``ELSE``; region the divergent program location is at the end of the ``IF/THEN/ELSE``; region since the ``THEN`` region has completed. The lane PC artificial variable is assigned at each region transition. It uses; the immediately enclosing region's DWARF procedure to compute the program; location for each lane assuming they are divergent, and then modifies the result; by inserting the current program location for each lane that the ``EXEC`` mask; indicates is active. By having separate DWARF procedures for each region, they can be reused to; define the value for any nested region. This reduces the total size of the DWARF; operation expressions. The following provides an example using pseudo LLVM MIR. .. code::; :number-lines:. $lex_start:; DEFINE_D",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:103726,Modifiability,variab,variable,103726,"ALUE``; pseudo instruction can be used to annotate the linearized control flow. This can; be done by defining an artificial variable for the lane PC. The DWARF location; list expression created for it is used as the value of the; ``DW_AT_LLVM_lane_pc`` attribute on the subprogram's debugger information entry. A DWARF procedure is defined for each well nested structured control flow region; which provides the conceptual lane program location for a lane if it is not; active (namely it is divergent). The DWARF operation expression for each region; conceptually inherits the value of the immediately enclosing region and modifies; it according to the semantics of the region. For an ``IF/THEN/ELSE`` region the divergent program location is at the start of; the region for the ``THEN`` region since it is executed first. For the ``ELSE``; region the divergent program location is at the end of the ``IF/THEN/ELSE``; region since the ``THEN`` region has completed. The lane PC artificial variable is assigned at each region transition. It uses; the immediately enclosing region's DWARF procedure to compute the program; location for each lane assuming they are divergent, and then modifies the result; by inserting the current program location for each lane that the ``EXEC`` mask; indicates is active. By having separate DWARF procedures for each region, they can be reused to; define the value for any nested region. This reduces the total size of the DWARF; operation expressions. The following provides an example using pseudo LLVM MIR. .. code::; :number-lines:. $lex_start:; DEFINE_DWARF %__uint_64 = DW_TAG_base_type[; DW_AT_name = ""__uint64"";; DW_AT_byte_size = 8;; DW_AT_encoding = DW_ATE_unsigned;; ];; DEFINE_DWARF %__active_lane_pc = DW_TAG_dwarf_procedure[; DW_AT_name = ""__active_lane_pc"";; DW_AT_location = [; DW_OP_regx PC;; DW_OP_LLVM_extend 64, 64;; DW_OP_regval_type EXEC, %uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DEFINE_DWARF %__divergent_lane_pc = DW_TAG_dwarf_pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:107902,Modifiability,variab,variables,107902,"_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; e;; EXEC = ~EXEC & %1;; $lex_1_else:; DEFINE_DWARF %__divergent_lane_pc_1_else = DW_TAG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc_1_else"";; DW_AT_location = DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/T",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108140,Modifiability,variab,variables,108140,"AG_dwarf_procedure[; DW_AT_name = ""__divergent_lane_pc_1_else"";; DW_AT_location = DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_addrx &lex_1_end;; DW_OP_stack_value;; DW_OP_LLVM_extend 64, 64;; DW_OP_call_ref %__lex_1_save_exec;; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:108357,Modifiability,variab,variables,108357,"; DW_OP_deref_type 64, %__uint_64;; DW_OP_LLVM_select_bit_piece 64, 64;; ];; ];; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc, DIExpression[; DW_OP_call_ref %__divergent_lane_pc_1_else;; DW_OP_call_ref %__active_lane_pc;; ];; f;; EXEC = %1;; $lex_1_end:; DBG_VALUE $noreg, $noreg, %DW_AT_LLVM_lane_pc DIExpression[; DW_OP_call_ref %__divergent_lane_pc;; DW_OP_call_ref %__active_lane_pc;; ];; g;; $lex_end:. The DWARF procedure ``%__active_lane_pc`` is used to update the lane pc elements; that are active, with the current program location. Artificial variables %__lex_1_save_exec and %__lex_1_1_save_exec are created for; the execution masks saved on entry to a region. Using the ``DBG_VALUE`` pseudo; instruction, location list entries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subpr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109031,Modifiability,variab,variable,109031,"tries will be created that describe where the; artificial variables are allocated at any given program location. The compiler; may allocate them to registers or spill them to memory. The DWARF procedures for each region use the values of the saved execution mask; artificial variables to only update the lanes that are active on entry to the; region. All other lanes retain the value of the enclosing region where they were; last active. If they were not active on entry to the subprogram, then will have; the undefined location description. Other structured control flow regions can be handled similarly. For example,; loops would set the divergent program location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EX",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109982,Modifiability,variab,variable,109982,"e DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110050,Modifiability,variab,variable,110050,"ather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:110253,Modifiability,variab,variable,110253,"e``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEMVER]_. Call Frame Information; ----------------------. DWARF Call Frame Information (CFI) describes how a consumer can virtually; *unwind* call frames in a running process or core dump. See DWARF Version 5; section 6.4 and :ref:`amdgpu-dwarf-call-frame-information`. For AMDGPU, the Common Information Entry (CIE) fields have the following values:. 1. ``augmentation`` string contains the following null-terminated UTF-8 string:. ::. [amd:v0.0]. The ``vX.Y`` specifies the major X and minor Y version number of the AMDGPU; extens",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:112296,Modifiability,variab,variable,112296," or to the FDEs that use it. The version number; conforms to [SEMVER]_. 2. ``address_size`` for the ``Global`` address space is defined in; :ref:`amdgpu-dwarf-address-space-identifier`. 3. ``segment_selector_size`` is 0 as AMDGPU does not use a segment selector. 4. ``code_alignment_factor`` is 4 bytes. .. TODO::. Add to :ref:`amdgpu-processor-table` table. 5. ``data_alignment_factor`` is 4 bytes. .. TODO::. Add to :ref:`amdgpu-processor-table` table. 6. ``return_address_register`` is ``PC_32`` for 32-bit processes and ``PC_64``; for 64-bit processes defined in :ref:`amdgpu-dwarf-register-identifier`. 7. ``initial_instructions`` Since a subprogram X with fewer registers can be; called from subprogram Y that has more allocated, X will not change any of; the extra registers as it cannot access them. Therefore, the default rule; for all columns is ``same value``. For AMDGPU the register number follows the numbering defined in; :ref:`amdgpu-dwarf-register-identifier`. For AMDGPU the instructions are variable size. A consumer can subtract 1 from; the return address to get the address of a byte within the call site; instructions. See DWARF Version 5 section 6.4.4. Accelerated Access; ------------------. See DWARF Version 5 section 6.1. Lookup By Name Section Header; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. See DWARF Version 5 section 6.1.1.4.1 and :ref:`amdgpu-dwarf-lookup-by-name`. For AMDGPU the lookup by name section header table:. ``augmentation_string_size`` (uword). Set to the length of the ``augmentation_string`` value which is always a; multiple of 4. ``augmentation_string`` (sequence of UTF-8 characters). Contains the following UTF-8 string null padded to a multiple of 4 bytes:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of this index. The version number conforms to; [SEMVER]_. .. note::. This is different to the DWARF Version 5 definition that requires the first; 4 characters to be the vendor ID",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160333,Modifiability,config,configuration,160333,"to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160514,Modifiability,config,configuration,160514,"uments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160694,Modifiability,config,configuration,160694,"acket is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *A",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:160895,Modifiability,config,configuration,160895," the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be 0,; >449 1 bit ENABLE_SGPR_DISPATCH_PTR; >450 1 bit ENABLE_SGPR_QUEUE_PTR; >451 1 bit ENABLE_SGPR_KERNARG_SEGMENT_PTR; >452 1 bit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:161101,Modifiability,config,configuration,161101," to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC1``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc1-gfx6-gfx12-table`.; 447:416 4 bytes COMPUTE_PGM_RSRC2 Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC2``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table`.; 458:448 7 bits *See separate bits below.* Enable the setup of the; SGPR user data registers; (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The total number of SGPR; user data registers; requested must not exceed; 16 and match value in; ``compute_pgm_rsrc2.user_sgpr.user_sgpr_count``.; Any requests beyond 16; will be ignored.; >448 1 bit ENABLE_SGPR_PRIVATE_SEGMENT If the *Target Properties*; _BUFFER column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be 0,; >449 1 bit ENABLE_SGPR_DISPATCH_PTR; >450 1 bit ENABLE_SGPR_QUEUE_PTR; >451 1 bit ENABLE_SGPR_KERNARG_SEGMENT_PTR; >452 1 bit ENABLE_SGPR_DISPATCH_ID; >453 1 bit ENABLE_SGPR_FLAT_SCRATCH_INIT If the *Target Properties*; column of; :ref:`amdgpu-processor-table`; specifies *Architected flat; scratch* then not supported; and must be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209508,Modifiability,variab,variables,209508,"; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238230,Modifiability,config,configured,238230,"CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``bu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239996,Modifiability,variab,variables,239996," DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:287317,Modifiability,config,configured,287317,"t CUs and so a ``buffer_inv sc0`` is required which will invalidate; the L1 cache. * A ``buffer_inv sc0`` is required to invalidate the L1 cache for coherence; between wavefronts executing in different work-groups as they may be; executing on different CUs. * Atomic read-modify-write instructions implicitly bypass the L1 cache.; Therefore, they do not use the sc0 bit for coherence and instead use it to; indicate if the instruction returns the original value being updated. They; do use sc1 to indicate system or agent scope coherence. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache. * The gfx942 can be configured as a number of smaller agents with each having; a single L2 shared by all CUs on the same agent, or as fewer (possibly one); larger agents with groups of CUs on each agent each sharing separate L2; caches.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel for its associated L2.; Therefore, the vector and scalar memory operations performed by wavefronts; executing with different L1 caches and the same L2 cache can be reordered; relative to each other.; * A ``s_waitcnt vmcnt(0)`` is required to ensure synchronization between; vector memory operations of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:288933,Modifiability,config,configured,288933,"ons of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289008,Modifiability,config,configured,289008,"ons of different CUs. It ensures a previous vector; memory operation has completed before executing a subsequent vector memory; or LDS operation and so can be used to meet the requirements of acquire and; release.; * An L2 cache can be kept coherent with other L2 caches by using the MTYPE RW; (read-write) for memory local to the L2, and MTYPE NC (non-coherent) with; the PTE C-bit set for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289359,Modifiability,config,configured,289359,"l memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289439,Modifiability,config,configured,289439,"l memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by the PTE C-bit.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:289637,Modifiability,config,configured,289637," be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter.; * To ensure coherence of local memory writes of CUs with different L1 caches; in the same agent a ``buffer_wbl2`` is required. It does nothing if the; agent is configured to have a single L2, or will writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted bef",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:290014,Modifiability,variab,variables,290014,"writeback dirty L2 cache; lines if configured to have multiple L2 caches.; * To ensure coherence of local memory writes of CUs in different agents a; ``buffer_wbl2 sc1`` is required. It will writeback dirty L2 cache lines.; * To ensure coherence of local memory reads of CUs with different L1 caches; in the same agent a ``buffer_inv sc1`` is required. It does nothing if the; agent is configured to have a single L2, or will invalidate non-local L2; cache lines if configured to have multiple L2 caches.; * To ensure coherence of local memory reads of CUs in different agents a; ``buffer_inv sc0 sc1`` is required. It will invalidate non-local L2 cache; lines if configured to have multiple L2 caches. * PCIe access from the GPU to the CPU can be kept coherent by using the MTYPE; UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:340187,Modifiability,variab,variables,340187,"may be executing on different SAs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0) & vscnt(0)`` is; required to ensure synchronization between vector memory operations of; different SAs. It ensures a previous vector memory operation has completed; before executing a subsequent vector memory and so can be used to meet the; requirements of acquire, release and sequential consistency.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence.; * On GFX10.3 and GFX11 a memory attached last level (MALL) cache exists for GPU memory.; The MALL cache is fully coherent with GPU memory and has no impact on system; coherence. All agents (GPU and CPU) access GPU memory through the MALL cache. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:389378,Modifiability,variab,variables,389378,"ry. The unswizzled SP can be used with buffer instructions as an unswizzled SGPR; offset with the scratch V# in SGPR0-3 to access the stack in a swizzled; manner. The unswizzled SP value can be converted into the swizzled SP value by:. | swizzled SP = unswizzled SP / wavefront size. This may be used to obtain the private address space address of stack; objects and to convert this address to a flat address by adding the flat; scratch aperture base address. The swizzled SP value is always 4 bytes aligned for the ``r600``; architecture and 16 byte aligned for the ``amdgcn`` architecture. .. note::. The ``amdgcn`` value is selected to avoid dynamic stack alignment for the; OpenCL language which has the largest base type defined as 16 bytes. On entry, the swizzled SP value is the address of the first function; argument passed on the stack. Other stack passed arguments are positive; offsets from the entry swizzled SP value. The function may use positive offsets beyond the last stack passed argument; for stack allocated local variables and register spill slots. If necessary,; the function may align these to greater alignment than 16 bytes. After these; the function may dynamically allocate space for such things as runtime sized; ``alloca`` local allocations. If the function calls another function, it will place any stack allocated; arguments after the last local allocation and adjust SGPR32 to the address; after the last local allocation. 9. All other registers are unspecified.; 10. Any necessary ``s_waitcnt`` has been performed to ensure memory is available; to the function.; 11. Use pass-by-reference (byref) in stead of pass-by-value (byval) for struct; arguments in C ABI. Callee is responsible for allocating stack memory and; copying the value of the struct if modified. Note that the backend still; supports byval for struct arguments. On exit from a function:. 1. VGPR0-31 and SGPR4-29 are used to pass function result arguments as; described below. Any registers used are ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:398689,Modifiability,variab,variable,398689,"er arguments, will; pass the rest as decomposed stack elements? But an argument that will not start; in registers will not be decomposed and will be passed as a non-decomposed; stack value?. The following is not part of the AMDGPU function calling convention but; describes how the AMDGPU implements function calls:. 1. SGPR33 is used as a frame pointer (FP) if necessary. Like the SP it is an; unswizzled scratch address. It is only needed if runtime sized ``alloca``; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment. 3. Allocating SGPR arguments on the stack are not supported. 4. No CFI is currently generated. See; :ref:`amdgpu-dwarf-call-frame-information`. .. note::. CFI will be generated that defines the CFA as the unswizzled address; relative to the wave scratch base in the unswizzled private address space; of the lowest address stack allocated local variable. ``DW_AT_frame_base`` will be defined as the swizzled address in the; swizzled private address space by dividing the CFA by the wavefront size; (since CFA is always at least dword aligned which matches the scratch; swizzle element size). If no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemen",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:399094,Modifiability,variab,variables,399094,"`; are used, or for the reasons defined in ``SIFrameLowering``.; 2. Runtime stack alignment is supported. SGPR34 is used as a base pointer (BP); to access the incoming stack arguments in the function. The BP is needed; only when the function requires the runtime stack alignment. 3. Allocating SGPR arguments on the stack are not supported. 4. No CFI is currently generated. See; :ref:`amdgpu-dwarf-call-frame-information`. .. note::. CFI will be generated that defines the CFA as the unswizzled address; relative to the wave scratch base in the unswizzled private address space; of the lowest address stack allocated local variable. ``DW_AT_frame_base`` will be defined as the swizzled address in the; swizzled private address space by dividing the CFA by the wavefront size; (since CFA is always at least dword aligned which matches the scratch; swizzle element size). If no dynamic stack alignment was performed, the stack allocated arguments; are accessed as negative offsets relative to ``DW_AT_frame_base``, and the; local variables and register spill slots are accessed as positive offsets; relative to ``DW_AT_frame_base``. 5. Function argument passing is implemented by copying the input physical; registers to virtual registers on entry. The register allocator can spill if; necessary. These are copied back to physical registers at call sites. The; net effect is that each function call can have these values in entirely; distinct locations. The IPRA can help avoid shuffling argument registers.; 6. Call sites are implemented by setting up the arguments at positive offsets; from SP. Then SP is incremented to account for the known frame size before; the call and decremented after the call. .. note::. The CFI will reflect the changed calculation needed to compute the CFA; from SP. 7. 4 byte spill slots are used in the stack frame. One slot is allocated for an; emergency spill slot. Buffer instructions are used for stack accesses and; not the ``flat_scratch`` instruction. .. TODO::. ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:404630,Modifiability,config,configuration,404630,"es include:. - ""VsPs""; - ""Gs""; - ""Cs""; - ""Ngg""; - ""Tess""; - ""GsTess""; - ""NggTess"". "".internal_pipeline_hash"" sequence of Required Internal compiler hash for this pipeline. Lower; 2 integers 64 bits is the ""stable"" portion of the hash, used; for e.g. shader replacement lookup. Upper 64 bits; is the ""unique"" portion of the hash, used for; e.g. pipeline cache lookup. The value is; implementation defined, and can not be relied on; between different builds of the compiler.; "".shaders"" map Per-API shader metadata. See; :ref:`amdgpu-amdpal-code-object-shader-map-table`; for the definition of the keys included in that; map.; "".hardware_stages"" map Per-hardware stage metadata. See; :ref:`amdgpu-amdpal-code-object-hardware-stage-map-table`; for the definition of the keys included in that; map.; "".shader_functions"" map Per-shader function metadata. See; :ref:`amdgpu-amdpal-code-object-shader-function-map-table`; for the definition of the keys included in that; map.; "".registers"" map Required Hardware register configuration. See; :ref:`amdgpu-amdpal-code-object-register-map-table`; for the definition of the keys included in that; map.; "".user_data_limit"" integer Number of user data entries accessed by this; pipeline.; "".spill_threshold"" integer The user data spill threshold. 0xFFFF for; NoUserDataSpilling.; "".uses_viewport_array_index"" boolean Indicates whether or not the pipeline uses the; viewport array index feature. Pipelines which use; this feature can render into all 16 viewports,; whereas pipelines which do not use it are; restricted to viewport #0.; "".es_gs_lds_size"" integer Size in bytes of LDS space used internally for; handling data-passing between the ES and GS; shader stages. This can be zero if the data is; passed using off-chip buffers. This value should; be used to program all user-SGPRs which have been; marked with ""UserDataMapping::EsGsLdsSize""; (typically only the GS and VS HW stages will ever; have a user-SGPR so marked).; "".nggSubgroupSize"" integer Explicit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:2415,Performance,load,loader,2415, ``r600`` AMD GPUs HD2XXX-HD6XXX for graphics and compute shaders.; ``amdgcn`` AMD GPUs GCN GFX6 onwards for graphics and compute shaders.; ============ ==============================================================. .. table:: AMDGPU Vendors; :name: amdgpu-vendor-table. ============ ==============================================================; Vendor Description; ============ ==============================================================; ``amd`` Can be used for all AMD GPU usage.; ``mesa3d`` Can be used if the OS is ``mesa3d``.; ============ ==============================================================. .. table:: AMDGPU Operating Systems; :name: amdgpu-os. ============== ============================================================; OS Description; ============== ============================================================; *<empty>* Defaults to the *unknown* OS.; ``amdhsa`` Compute kernels executed on HSA [HSA]_ compatible runtimes; such as:. - AMD's ROCm™ runtime [AMD-ROCm]_ using the *rocm-amdhsa*; loader on Linux. See *AMD ROCm Platform Release Notes*; [AMD-ROCm-Release-Notes]_ for supported hardware and; software.; - AMD's PAL runtime using the *pal-amdhsa* loader on; Windows. ``amdpal`` Graphic shaders and compute kernels executed on AMD's PAL; runtime using the *pal-amdpal* loader on Windows and Linux; Pro.; ``mesa3d`` Graphic shaders and compute kernels executed on AMD's Mesa; 3D runtime using the *mesa-mesa3d* loader on Linux.; ============== ============================================================. .. table:: AMDGPU Environments; :name: amdgpu-environment-table. ============ ==============================================================; Environment Description; ============ ==============================================================; *<empty>* Default.; ============ ==============================================================. .. _amdgpu-processors:. Processors; ----------. Use the Clang options ``-mcpu=<target-id>`` or ``--offload-arch=<tar,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:2579,Performance,load,loader,2579,==========================================. .. table:: AMDGPU Vendors; :name: amdgpu-vendor-table. ============ ==============================================================; Vendor Description; ============ ==============================================================; ``amd`` Can be used for all AMD GPU usage.; ``mesa3d`` Can be used if the OS is ``mesa3d``.; ============ ==============================================================. .. table:: AMDGPU Operating Systems; :name: amdgpu-os. ============== ============================================================; OS Description; ============== ============================================================; *<empty>* Defaults to the *unknown* OS.; ``amdhsa`` Compute kernels executed on HSA [HSA]_ compatible runtimes; such as:. - AMD's ROCm™ runtime [AMD-ROCm]_ using the *rocm-amdhsa*; loader on Linux. See *AMD ROCm Platform Release Notes*; [AMD-ROCm-Release-Notes]_ for supported hardware and; software.; - AMD's PAL runtime using the *pal-amdhsa* loader on; Windows. ``amdpal`` Graphic shaders and compute kernels executed on AMD's PAL; runtime using the *pal-amdpal* loader on Windows and Linux; Pro.; ``mesa3d`` Graphic shaders and compute kernels executed on AMD's Mesa; 3D runtime using the *mesa-mesa3d* loader on Linux.; ============== ============================================================. .. table:: AMDGPU Environments; :name: amdgpu-environment-table. ============ ==============================================================; Environment Description; ============ ==============================================================; *<empty>* Default.; ============ ==============================================================. .. _amdgpu-processors:. Processors; ----------. Use the Clang options ``-mcpu=<target-id>`` or ``--offload-arch=<target-id>`` to; specify the AMDGPU processor together with optional target features. See; :ref:`amdgpu-target-id` and :ref:`amdgpu-target-features` for AMD GPU target; specifi,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:2700,Performance,load,loader,2700,============ ==============================================================; Vendor Description; ============ ==============================================================; ``amd`` Can be used for all AMD GPU usage.; ``mesa3d`` Can be used if the OS is ``mesa3d``.; ============ ==============================================================. .. table:: AMDGPU Operating Systems; :name: amdgpu-os. ============== ============================================================; OS Description; ============== ============================================================; *<empty>* Defaults to the *unknown* OS.; ``amdhsa`` Compute kernels executed on HSA [HSA]_ compatible runtimes; such as:. - AMD's ROCm™ runtime [AMD-ROCm]_ using the *rocm-amdhsa*; loader on Linux. See *AMD ROCm Platform Release Notes*; [AMD-ROCm-Release-Notes]_ for supported hardware and; software.; - AMD's PAL runtime using the *pal-amdhsa* loader on; Windows. ``amdpal`` Graphic shaders and compute kernels executed on AMD's PAL; runtime using the *pal-amdpal* loader on Windows and Linux; Pro.; ``mesa3d`` Graphic shaders and compute kernels executed on AMD's Mesa; 3D runtime using the *mesa-mesa3d* loader on Linux.; ============== ============================================================. .. table:: AMDGPU Environments; :name: amdgpu-environment-table. ============ ==============================================================; Environment Description; ============ ==============================================================; *<empty>* Default.; ============ ==============================================================. .. _amdgpu-processors:. Processors; ----------. Use the Clang options ``-mcpu=<target-id>`` or ``--offload-arch=<target-id>`` to; specify the AMDGPU processor together with optional target features. See; :ref:`amdgpu-target-id` and :ref:`amdgpu-target-features` for AMD GPU target; specific information. Every processor supports every OS ABI (see :ref:`amdgpu-os`) with the following excep,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:2841,Performance,load,loader,2841,==========================================; ``amd`` Can be used for all AMD GPU usage.; ``mesa3d`` Can be used if the OS is ``mesa3d``.; ============ ==============================================================. .. table:: AMDGPU Operating Systems; :name: amdgpu-os. ============== ============================================================; OS Description; ============== ============================================================; *<empty>* Defaults to the *unknown* OS.; ``amdhsa`` Compute kernels executed on HSA [HSA]_ compatible runtimes; such as:. - AMD's ROCm™ runtime [AMD-ROCm]_ using the *rocm-amdhsa*; loader on Linux. See *AMD ROCm Platform Release Notes*; [AMD-ROCm-Release-Notes]_ for supported hardware and; software.; - AMD's PAL runtime using the *pal-amdhsa* loader on; Windows. ``amdpal`` Graphic shaders and compute kernels executed on AMD's PAL; runtime using the *pal-amdpal* loader on Windows and Linux; Pro.; ``mesa3d`` Graphic shaders and compute kernels executed on AMD's Mesa; 3D runtime using the *mesa-mesa3d* loader on Linux.; ============== ============================================================. .. table:: AMDGPU Environments; :name: amdgpu-environment-table. ============ ==============================================================; Environment Description; ============ ==============================================================; *<empty>* Default.; ============ ==============================================================. .. _amdgpu-processors:. Processors; ----------. Use the Clang options ``-mcpu=<target-id>`` or ``--offload-arch=<target-id>`` to; specify the AMDGPU processor together with optional target features. See; :ref:`amdgpu-target-id` and :ref:`amdgpu-target-features` for AMD GPU target; specific information. Every processor supports every OS ABI (see :ref:`amdgpu-os`) with the following exceptions:. * ``amdhsa`` is not supported in ``r600`` architecture (see :ref:`amdgpu-architecture-table`). .. table:: AMDGPU Processo,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:15605,Performance,perform,performance,15605,"ked; work-item Add product; IDs names. ``gfx1151`` ``amdgcn`` APU - cumode - Architected *TBA*; - wavefrontsize64 flat; scratch .. TODO::; - Packed; work-item Add product; IDs names. ``gfx1200`` ``amdgcn`` dGPU - cumode - Architected *TBA*; - wavefrontsize64 flat; scratch .. TODO::; - Packed; work-item Add product; IDs names. ``gfx1201`` ``amdgcn`` dGPU - cumode - Architected *TBA*; - wavefrontsize64 flat; scratch .. TODO::; - Packed; work-item Add product; IDs names. =========== =============== ============ ===== ================= =============== =============== ======================. .. _amdgpu-target-features:. Target Features; ---------------. Target features control how code is generated to support certain; processor specific features. Not all target features are supported by; all processors. The runtime must ensure that the features supported by; the device used to execute the code match the features enabled when; generating the code. A mismatch of features may result in incorrect; execution, or a reduction in performance. The target features supported by each processor is listed in; :ref:`amdgpu-processor-table`. Target features are controlled by exactly one of the following Clang; options:. ``-mcpu=<target-id>`` or ``--offload-arch=<target-id>``. The ``-mcpu`` and ``--offload-arch`` can specify the target feature as; optional components of the target ID. If omitted, the target feature has the; ``any`` value. See :ref:`amdgpu-target-id`. ``-m[no-]<target-feature>``. Target features not specified by the target ID are specified using a; separate option. These target features can have an ``on`` or ``off``; value. ``on`` is specified by omitting the ``no-`` prefix, and; ``off`` is specified by including the ``no-`` prefix. The default; if not specified is ``off``. For example:. ``-mcpu=gfx908:xnack+``; Enable the ``xnack`` feature.; ``-mcpu=gfx908:xnack-``; Disable the ``xnack`` feature.; ``-mcumode``; Enable the ``cumode`` feature.; ``-mno-cumode``; Disable the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:17260,Performance,load,loaded,17260," ``no-`` prefix, and; ``off`` is specified by including the ``no-`` prefix. The default; if not specified is ``off``. For example:. ``-mcpu=gfx908:xnack+``; Enable the ``xnack`` feature.; ``-mcpu=gfx908:xnack-``; Disable the ``xnack`` feature.; ``-mcumode``; Enable the ``cumode`` feature.; ``-mno-cumode``; Disable the ``cumode`` feature. .. table:: AMDGPU Target Features; :name: amdgpu-target-features-table. =============== ============================ ==================================================; Target Feature Clang Option to Control Description; Name; =============== ============================ ==================================================; cumode - ``-m[no-]cumode`` Control the wavefront execution mode used; when generating code for kernels. When disabled; native WGP wavefront execution mode is used,; when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and execut",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:17405,Performance,load,loaded,17405,"08:xnack+``; Enable the ``xnack`` feature.; ``-mcpu=gfx908:xnack-``; Disable the ``xnack`` feature.; ``-mcumode``; Enable the ``cumode`` feature.; ``-mno-cumode``; Disable the ``cumode`` feature. .. table:: AMDGPU Target Features; :name: amdgpu-target-features-table. =============== ============================ ==================================================; Target Feature Clang Option to Control Description; Name; =============== ============================ ==================================================; cumode - ``-m[no-]cumode`` Control the wavefront execution mode used; when generating code for kernels. When disabled; native WGP wavefront execution mode is used,; when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:17534,Performance,load,loaded,17534,"de`` feature.; ``-mno-cumode``; Disable the ``cumode`` feature. .. table:: AMDGPU Target Features; :name: amdgpu-target-features-table. =============== ============================ ==================================================; Target Feature Clang Option to Control Description; Name; =============== ============================ ==================================================; cumode - ``-m[no-]cumode`` Control the wavefront execution mode used; when generating code for kernels. When disabled; native WGP wavefront execution mode is used,; when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device,",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18086,Performance,load,loaded,18086,"when enabled CU wavefront execution mode is used; (see :ref:`amdgpu-amdhsa-memory-model`). sramecc - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ =================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18236,Performance,load,loaded,18236,"only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for SRAMECC. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ ==================================================. .. _amdgpu-target-id:. Target ID; ---------. AMDGPU supports target IDs. See `Clang Offload Bundler; <https://clang.llvm.org/docs",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18370,Performance,load,loaded,18370,"V2 to V3, generate; code that can be loaded and executed in a process; with SRAMECC enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of SRAMECC. tgsplit ``-m[no-]tgsplit`` Enable/disable generating code that assumes; work-groups are launched in threadgroup split mode.; When enabled the waves of a work-group may be; launched in different CUs. wavefrontsize64 - ``-m[no-]wavefrontsize64`` Control the wavefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ ==================================================. .. _amdgpu-target-id:. Target ID; ---------. AMDGPU supports target IDs. See `Clang Offload Bundler; <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_ for a general; description. The AMDGPU target specific information is:. **processor**; Is an AMDGPU processo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:18945,Performance,perform,performant,18945,"vefront size used when; generating code for kernels. When disabled; native wavefront size 32 is used, when enabled; wavefront size 64 is used. xnack - ``-mcpu`` If specified, generate code that can only be; - ``--offload-arch`` loaded and executed in a process that has a; matching setting for XNACK replay. If not specified for code object V2 to V3, generate; code that can be loaded and executed in a process; with XNACK replay enabled. If not specified for code object V4 or above, generate; code that can be loaded and executed in a process; with either setting of XNACK replay. XNACK replay can be used for demand paging and; page migration. If enabled in the device, then if; a page fault occurs the code may execute; incorrectly unless generated with XNACK replay; enabled, or generated for code object V4 or above without; specifying XNACK replay. Executing code that was; generated with XNACK replay enabled, or generated; for code object V4 or above without specifying XNACK replay,; on a device that does not have XNACK replay; enabled will execute correctly but may be less; performant than code generated for XNACK replay; disabled.; =============== ============================ ==================================================. .. _amdgpu-target-id:. Target ID; ---------. AMDGPU supports target IDs. See `Clang Offload Bundler; <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_ for a general; description. The AMDGPU target specific information is:. **processor**; Is an AMDGPU processor or alternative processor name specified in; :ref:`amdgpu-processor-table`. The non-canonical form target ID allows both; the primary processor and alternative processor names. The canonical form; target ID only allow the primary processor name. **target-feature**; Is a target feature name specified in :ref:`amdgpu-target-features-table` that; is supported by the processor. The target features supported by each processor; is specified in :ref:`amdgpu-processor-table`. Those that can b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:21004,Performance,perform,perform,21004,"non-canonical form target ID allows the target features to be; specified in any order. The canonical form target ID requires the target; features to be specified in alphabetic order. .. _amdgpu-target-id-v2-v3:. Code Object V2 to V3 Target ID; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~. The target ID syntax for code object V2 to V3 is the same as defined in `Clang; Offload Bundler <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_ except; when used in the :ref:`amdgpu-assembler-directive-amdgcn-target` assembler; directive and the bundle entry ID. In those cases it has the following BNF; syntax:. .. code::. <target-id> ::== <processor> ( ""+"" <target-feature> )*. Where a target feature is omitted if *Off* and present if *On* or *Any*. .. note::. The code object V2 to V3 cannot represent *Any* and treats it the same as; *On*. .. _amdgpu-embedding-bundled-objects:. Embedding Bundled Code Objects; ------------------------------. AMDGPU supports the HIP and OpenMP languages that perform code object embedding; as described in `Clang Offload Bundler; <https://clang.llvm.org/docs/ClangOffloadBundler.html>`_. .. note::. The target ID syntax used for code object V2 to V3 for a bundle entry ID; differs from that used elsewhere. See :ref:`amdgpu-target-id-v2-v3`. .. _amdgpu-address-spaces:. Address Spaces; --------------. The AMDGPU architecture supports a number of memory address spaces. The address; space names use the OpenCL standard names, with some additions. The AMDGPU address spaces correspond to target architecture specific LLVM; address space numbers used in LLVM IR. The AMDGPU address spaces are described in; :ref:`amdgpu-address-spaces-table`. Only 64-bit process address spaces are; supported for the ``amdgcn`` target. .. table:: AMDGPU Address Spaces; :name: amdgpu-address-spaces-table. ===================================== =============== =========== ================ ======= ============================; .. 64-Bit Process Address Space; -----------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:24074,Performance,queue,queue,24074,"ss; space*. The generic address space uses the hardware flat address support for two fixed; ranges of virtual addresses (the private and local apertures), that are; outside the range of addressable global memory, to map from a flat address to; a private or local address. This uses FLAT instructions that can take a flat; address and access global, private (scratch), and group (LDS) memory depending; on if the address is within one of the aperture ranges. Flat access to scratch requires hardware aperture setup and setup in the; kernel prologue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat; access to LDS requires hardware aperture setup and M0 (GFX7-GFX8) register; setup (see :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a private or group address space address (termed a segment; address) and a flat address the base address of the corresponding aperture; can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline; constant registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``.; In 64-bit address mode the aperture sizes are 2^32 bytes and the base is; aligned to 2^32 which makes it easier to convert from flat to segment or; segment to flat. A global address space address has the same value when used as a flat address; so no conversion is needed. **Global and Constant**; The global and constant address spaces both use global virtual addresses,; which are the same virtual address space used by the CPU. However, some; virtual addresses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:25154,Performance,load,loaded,25154,"-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline; constant registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``.; In 64-bit address mode the aperture sizes are 2^32 bytes and the base is; aligned to 2^32 which makes it easier to convert from flat to segment or; segment to flat. A global address space address has the same value when used as a flat address; so no conversion is needed. **Global and Constant**; The global and constant address spaces both use global virtual addresses,; which are the same virtual address space used by the CPU. However, some; virtual addresses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belongin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:25339,Performance,cache,caches,25339,"2^32 bytes and the base is; aligned to 2^32 which makes it easier to convert from flat to segment or; segment to flat. A global address space address has the same value when used as a flat address; so no conversion is needed. **Global and Constant**; The global and constant address spaces both use global virtual addresses,; which are the same virtual address space used by the CPU. However, some; virtual addresses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:25804,Performance,perform,performance,25804,"sses may only be accessible to the CPU, some only accessible; by the GPU, and some by both. Using the constant address space indicates that the data will not change; during the execution of the kernel. This allows scalar read instructions to; be used. As the constant address space could only be modified on the host; side, a generic pointer loaded from the constant address space is safe to be; assumed as a global pointer since only the device global memory is visible; and managed on the host side. The vector and scalar L1 caches are invalidated; of volatile data before each kernel dispatch execution to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by anot",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:26406,Performance,perform,performance,26406,"ion to allow constant; memory to change values between kernel dispatches. **Region**; The region address space uses the hardware Global Data Store (GDS). All; wavefronts executing on the same device will access the same memory for any; given region address. However, the same region address accessed by wavefronts; executing on different devices will access different memory. It is higher; performance than global memory. It is allocated by the runtime. The data; store (DS) instructions can be used to access it. **Local**; The local address space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates the wavefronts of a; work-group, and freed when all the wavefronts of a work-group have; terminated. All wavefronts belonging to the same work-group will access the; same memory for any given local address. However, the same local address; accessed by wavefronts belonging to different work-groups will access; different memory. It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:27454,Performance,cache,cache,27454," It is higher performance than global memory. The data store; (DS) instructions can be used to access it. **Private**; The private address space uses the hardware scratch memory support which; automatically allocates memory when it creates a wavefront and frees it when; a wavefronts terminates. The memory accessed by a lane of a wavefront for any; given private address will be different to the memory accessed by another lane; of the same or different wavefront for the same private address. If a kernel dispatch uses scratch, then the hardware allocates memory from a; pool of backing memory allocated by the runtime for each wavefront. The lanes; of the wavefront access this using dword (4 byte) interleaving. The mapping; used from private address to backing memory address is:. ``wavefront-scratch-base +; ((private-address / 4) * wavefront-size * 4) +; (wavefront-lane-id * 4) + (private-address % 4)``. If each lane of a wavefront accesses the same private address, the; interleaving results in adjacent dwords being accessed and hence requires; fewer cache lines to be fetched. There are different ways that the wavefront scratch base address is; determined by a wavefront (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). Scratch memory can be accessed in an interleaved manner using buffer; instructions with the scratch buffer descriptor and per wavefront scratch; offset, by the scratch instructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates the stack values in other lanes of a wavefront,; such as by ``addrspacecast``-ing stack pointers to generic ones and taking offsets; that reach other lanes or by explicitly constructing the scratch buffer descriptor,; triggers undefined behavior when it modifies the scratch values of other lanes.; The compiler may assume that such modifications do not occur.; When using code object V5 ``LIBOMPTARGET_STACK_SIZE`` may be used to pro",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:28857,Performance,load,load,28857,"ructions, or by flat instructions. Multi-dword; access is not supported except by flat and scratch instructions in; GFX9-GFX11. Code that manipulates the stack values in other lanes of a wavefront,; such as by ``addrspacecast``-ing stack pointers to generic ones and taking offsets; that reach other lanes or by explicitly constructing the scratch buffer descriptor,; triggers undefined behavior when it modifies the scratch values of other lanes.; The compiler may assume that such modifications do not occur.; When using code object V5 ``LIBOMPTARGET_STACK_SIZE`` may be used to provide the; private segment size in bytes, for cases where a dynamic stack is used. **Constant 32-bit**; *TODO*. **Buffer Fat Pointer**; The buffer fat pointer is an experimental address space that is currently; unsupported in the backend. It exposes a non-integral pointer that is in; the future intended to support the modelling of 128-bit buffer descriptors; plus a 32-bit offset into the buffer (in total encapsulating a 160-bit; *pointer*), allowing normal LLVM load/store/atomic operations to be used to; model the buffer descriptors used heavily in graphics workloads targeting; the backend. The buffer descriptor used to construct a buffer fat pointer must be *raw*:; the stride must be 0, the ""add tid"" flag must be 0, the swizzle enable bits; must be off, and the extent must be measured in bytes. (On subtargets where; bounds checking may be disabled, buffer fat pointers may choose to enable; it or not). **Buffer Resource**; The buffer resource pointer, in address space 8, is the newer form; for representing buffer descriptors in AMDGPU IR, replacing their; previous representation as `<4 x i32>`. It is a non-integral pointer; that represents a 128-bit buffer descriptor resource (`V#`). Since, in general, a buffer resource supports complex addressing modes that cannot; be easily represented in LLVM (such as implicit swizzled access to structured; buffers), it is **illegal** to perform non-trivial a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:29788,Performance,perform,perform,29788,"scriptors; plus a 32-bit offset into the buffer (in total encapsulating a 160-bit; *pointer*), allowing normal LLVM load/store/atomic operations to be used to; model the buffer descriptors used heavily in graphics workloads targeting; the backend. The buffer descriptor used to construct a buffer fat pointer must be *raw*:; the stride must be 0, the ""add tid"" flag must be 0, the swizzle enable bits; must be off, and the extent must be measured in bytes. (On subtargets where; bounds checking may be disabled, buffer fat pointers may choose to enable; it or not). **Buffer Resource**; The buffer resource pointer, in address space 8, is the newer form; for representing buffer descriptors in AMDGPU IR, replacing their; previous representation as `<4 x i32>`. It is a non-integral pointer; that represents a 128-bit buffer descriptor resource (`V#`). Since, in general, a buffer resource supports complex addressing modes that cannot; be easily represented in LLVM (such as implicit swizzled access to structured; buffers), it is **illegal** to perform non-trivial address computations, such as; ``getelementptr`` operations, on buffer resources. They may be passed to; AMDGPU buffer intrinsics, and they may be converted to and from ``i128``. Casting a buffer resource to a buffer fat pointer is permitted and adds an offset; of 0. Buffer resources can be created from 64-bit pointers (which should be either; generic or global) using the `llvm.amdgcn.make.buffer.rsrc` intrinsic, which; takes the pointer, which becomes the base of the resource,; the 16-bit stride (and swzizzle control) field stored in bits `63:48` of a `V#`,; the 32-bit NumRecords/extent field (bits `95:64`), and the 32-bit flags field; (bits `127:96`). The specific interpretation of these fields varies by the; target architecture and is detailed in the ISA descriptions. **Buffer Strided Pointer**; The buffer index pointer is an experimental address space. It represents; a 128-bit buffer descriptor and a 32-bit offset, ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38217,Performance,perform,performed,38217,"krestore.p5 <int_stackrestore>` Implemented, must use the alloca address space. :ref:`llvm.get.fpmode.i32 <int_get_fpmode>` The natural floating-point mode type is i32. This; implemented by extracting relevant bits out of the MODE; register with s_getreg_b32. The first 10 bits are the; core floating-point mode. Bits 12:18 are the exception; mask. On gfx9+, bit 23 is FP16_OVFL. Bitfields not; relevant to floating-point instructions are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides d",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:38588,Performance,perform,performed,38588,"ons are 0s. :ref:`llvm.get.rounding<int_get_rounding>` AMDGPU supports two separately controllable rounding; modes depending on the floating-point type. One; controls float, and the other controls both double and; half operations. If both modes are the same, returns; one of the standard return values. If the modes are; different, returns one of :ref:`12 extended values; <amdgpu-rounding-mode-enumeration-values-table>`; describing the two modes. To nearest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:39042,Performance,perform,performed,39042,"arest, ties away from zero is not a supported; mode. The raw rounding mode values in the MODE; register do not exactly match the FLT_ROUNDS values,; so a conversion is performed. llvm.amdgcn.wave.reduce.umin Performs an arithmetic unsigned min reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets whi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:39249,Performance,perform,performs,39249,"n reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:39504,Performance,perform,performs,39504,"6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.wave.reduce.umax Performs an arithmetic unsigned max reduction on the unsigned values; provided by each lane in the wavefront.; Intrinsic takes a hint for reduction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:39794,Performance,perform,performs,39794,"ction strategy using second operand; 0: Target default preference,; 1: `Iterative strategy`, and; 2: `DPP`.; If target does not support the DPP operations (e.g. gfx6/7),; reduction will be performed using default iterative strategy.; Intrinsic is currently only implemented for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signednes",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:40085,Performance,perform,performs,40085," for i32. llvm.amdgcn.udot2 Provides direct access to v_dot2_u32_u16 across targets which; support such instructions. This performs unsigned dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output. llvm.amdgcn.udot4 Provides direct access to v_dot4_u32_u8 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:40443,Performance,perform,performs,40443,"is performs unsigned dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.udot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs unsigned dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output. llvm.amdgcn.sdot2 Provides direct access to v_dot2_i32_i16 across targets which; support such instructions. This performs signed dot product; with two v2i16 operands, summed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:41083,Performance,perform,performs,41083,"mmed with the third i32 operand. The; i1 fourth operand is used to clamp the output.; When applicable (e.g. no clamping), this is lowered into; v_dot2c_i32_i16 for targets which support it. llvm.amdgcn.sdot4 Provides direct access to v_dot4_i32_i8 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 4 8bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot4c_i32_i8 for targets which support it.; RDNA3 does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operan",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:41694,Performance,perform,performs,41694," does not offer v_dot4_i32_i8, and rather offers; v_dot4_i32_iu8 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sdot8 Provides direct access to v_dot8_u32_u4 across targets which; support such instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU in",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:42006,Performance,perform,performs,42006,"ch instructions. This performs signed dot product; with two i32 operands (holding a vector of 8 4bit values), summed; with the third i32 operand. The i1 fourth operand is used to clamp; the output.; When applicable (i.e. no clamping / operand modifiers), this is lowered; into v_dot8c_i32_i4 for targets which support it.; RDNA3 does not offer v_dot8_i32_i4, and rather offers; v_dot4_i32_iu4 which has operands to hold the signedness of the; vector operands. Thus, this intrinsic lowers to the signed version; of this instruction for gfx11 targets. llvm.amdgcn.sudot4 Provides direct access to v_dot4_i32_iu8 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 4 8bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sudot8 Provides direct access to v_dot8_i32_iu4 on gfx11 targets. This performs; dot product with two i32 operands (holding a vector of 8 4bit values), summed; with the fifth i32 operand. The i1 sixth operand is used to clamp; the output. The i1s preceding the vector operands decide the signedness. llvm.amdgcn.sched_barrier Controls the types of instructions that may be allowed to cross the intrinsic; during instruction scheduling. The parameter is a mask for the instruction types; that can cross the intrinsic. - 0x0000: No instructions may be scheduled across sched_barrier.; - 0x0001: All, non-memory, non-side-effect producing instructions may be; scheduled across sched_barrier, *i.e.* allow ALU instructions to pass.; - 0x0002: VALU instructions may be scheduled across sched_barrier.; - 0x0004: SALU instructions may be scheduled across sched_barrier.; - 0x0008: MFMA/WMMA instructions may be scheduled across sched_barrier.; - 0x0010: All VMEM instructions may be scheduled across sched_barrier.; - 0x0020: VMEM read instructions may be scheduled across sched_barrier.; - 0x0040: VMEM write instructions may be sc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:45409,Performance,perform,performs,45409,"amdgcn_sched_group_barrier(2, 1, 0)``; | ``// 5 MFMA``; | ``__builtin_amdgcn_sched_group_barrier(8, 5, 0)``. llvm.amdgcn.iglp_opt An **experimental** intrinsic for instruction group level parallelism. The intrinsic; implements predefined intruction scheduling orderings. The intrinsic applies to the; surrounding scheduling region. The intrinsic takes a value that specifies the; strategy. The compiler implements two strategies. 0. Interleave DS and MFMA instructions for small GEMM kernels.; 1. Interleave DS and MFMA instructions for single wave small GEMM kernels. Only one iglp_opt intrinsic may be used in a scheduling region. The iglp_opt intrinsic; cannot be combined with sched_barrier or sched_group_barrier. The iglp_opt strategy implementations are subject to change. llvm.amdgcn.atomic.cond.sub.u32 Provides direct access to flat_atomic_cond_sub_u32, global_atomic_cond_sub_u32; and ds_cond_sub_u32 based on address space on gfx12 targets. This; performs subtraction only if the memory value is greater than or; equal to the data value. llvm.amdgcn.s.getpc Provides access to the s_getpc_b64 instruction, but with the return value; sign-extended from the width of the underlying PC hardware register even on; processors where the s_getpc_b64 instruction returns a zero-extended value. ============================================== ==========================================================. .. TODO::. List AMDGPU intrinsics. LLVM IR Attributes; ------------------. The AMDGPU backend supports the following LLVM IR attributes. .. table:: AMDGPU LLVM IR Attributes; :name: amdgpu-llvm-ir-attributes-table. ======================================= ==========================================================; LLVM Attribute Description; ======================================= ==========================================================; ""amdgpu-flat-work-group-size""=""min,max"" Specify the minimum and maximum flat work group sizes that; will be specified when the kernel is dispatched. Gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:47605,Performance,optimiz,optimization,47605,"ng on language defaults.; If the actual block or workgroup size exceeds the limit at any point during; the execution, the behavior is undefined. For example, even if there is; only one active thread but the thread local id exceeds the limit, the; behavior is undefined. ""amdgpu-implicitarg-num-bytes""=""n"" Number of kernel argument bytes to add to the kernel; argument block size for the implicit arguments. This; varies by OS and language (for OpenCL see; :ref:`opencl-kernel-implicit-arguments-appended-for-amdhsa-os-table`).; ""amdgpu-num-sgpr""=""n"" Specifies the number of SGPRs to use. Generated by; the ``amdgpu_num_sgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-num-vgpr""=""n"" Specifies the number of VGPRs to use. Generated by the; ``amdgpu_num_vgpr`` CLANG attribute [CLANG-ATTR]_.; ""amdgpu-waves-per-eu""=""m,n"" Specify the minimum and maximum number of waves per; execution unit. Generated by the ``amdgpu_waves_per_eu``; CLANG attribute [CLANG-ATTR]_. This is an optimization hint,; and the backend may not be able to satisfy the request. If; the specified range is incompatible with the function's; ""amdgpu-flat-work-group-size"" value, the implied occupancy; bounds by the workgroup size takes precedence. ""amdgpu-ieee"" true/false. GFX6-GFX11 Only; Specify whether the function expects the IEEE field of the; mode register to be set on entry. Overrides the default for; the calling convention.; ""amdgpu-dx10-clamp"" true/false. GFX6-GFX11 Only; Specify whether the function expects the DX10_CLAMP field of; the mode register to be set on entry. Overrides the default; for the calling convention. ""amdgpu-no-workitem-id-x"" Indicates the function does not depend on the value of the; llvm.amdgcn.workitem.id.x intrinsic. If a function is marked with this; attribute, or reached through a call site marked with this attribute,; the value returned by the intrinsic is undefined. The backend can; generally infer this during code generation, so typically there is no; benefit to frontends marking fun",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:49598,Performance,queue,queue-ptr,49598,"marking functions with this. ""amdgpu-no-workitem-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.y intrinsic. ""amdgpu-no-workitem-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.z intrinsic. ""amdgpu-no-workgroup-id-x"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.x intrinsic. ""amdgpu-no-workgroup-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.y intrinsic. ""amdgpu-no-workgroup-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.z intrinsic. ""amdgpu-no-dispatch-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.ptr intrinsic. ""amdgpu-no-implicitarg-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.implicitarg.ptr intrinsic. ""amdgpu-no-dispatch-id"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.id intrinsic. ""amdgpu-no-queue-ptr"" Similar to amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.queue.ptr intrinsic. Note that unlike the other ABI hint; attributes, the queue pointer may be required in situations where the; intrinsic call does not directly appear in the program. Some subtargets; require the queue pointer for to handle some addrspacecasts, as well; as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdg",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:49673,Performance,queue,queue,49673,"d-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.y intrinsic. ""amdgpu-no-workitem-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.z intrinsic. ""amdgpu-no-workgroup-id-x"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.x intrinsic. ""amdgpu-no-workgroup-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.y intrinsic. ""amdgpu-no-workgroup-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.z intrinsic. ""amdgpu-no-dispatch-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.ptr intrinsic. ""amdgpu-no-implicitarg-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.implicitarg.ptr intrinsic. ""amdgpu-no-dispatch-id"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.id intrinsic. ""amdgpu-no-queue-ptr"" Similar to amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.queue.ptr intrinsic. Note that unlike the other ABI hint; attributes, the queue pointer may be required in situations where the; intrinsic call does not directly appear in the program. Some subtargets; require the queue pointer for to handle some addrspacecasts, as well; as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-imp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:49747,Performance,queue,queue,49747,"gpu-no-workitem-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workitem.id.z intrinsic. ""amdgpu-no-workgroup-id-x"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.x intrinsic. ""amdgpu-no-workgroup-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.y intrinsic. ""amdgpu-no-workgroup-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.z intrinsic. ""amdgpu-no-dispatch-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.ptr intrinsic. ""amdgpu-no-implicitarg-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.implicitarg.ptr intrinsic. ""amdgpu-no-dispatch-id"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.id intrinsic. ""amdgpu-no-queue-ptr"" Similar to amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.queue.ptr intrinsic. Note that unlike the other ABI hint; attributes, the queue pointer may be required in situations where the; intrinsic call does not directly appear in the program. Some subtargets; require the queue pointer for to handle some addrspacecasts, as well; as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchroniza",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:49887,Performance,queue,queue,49887,"-id-x"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.x intrinsic. ""amdgpu-no-workgroup-id-y"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.y intrinsic. ""amdgpu-no-workgroup-id-z"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.workgroup.id.z intrinsic. ""amdgpu-no-dispatch-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.ptr intrinsic. ""amdgpu-no-implicitarg-ptr"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.implicitarg.ptr intrinsic. ""amdgpu-no-dispatch-id"" The same as amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.dispatch.id intrinsic. ""amdgpu-no-queue-ptr"" Similar to amdgpu-no-workitem-id-x, except for the; llvm.amdgcn.queue.ptr intrinsic. Note that unlike the other ABI hint; attributes, the queue pointer may be required in situations where the; intrinsic call does not directly appear in the program. Some subtargets; require the queue pointer for to handle some addrspacecasts, as well; as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:50890,Performance,queue,queue,50890,"as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==============================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:51007,Performance,queue,queue,51007,"as the llvm.amdgcn.is.shared, llvm.amdgcn.is.private, llvm.trap, and; llvm.debug intrinsics. ""amdgpu-no-hostcall-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to the hostcall buffer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-heap-ptr"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the pointer to an initialized memory buffer; that conforms to the requirements of the malloc/free device library V1; version implementation. If this attribute is absent, then the; amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-multigrid-sync-arg"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the multigrid synchronization pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-default-queue"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the default queue pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-no-completion-action"" Similar to amdgpu-no-implicitarg-ptr, except specific to the implicit; kernel argument that holds the completion action pointer. If this; attribute is absent, then the amdgpu-no-implicitarg-ptr is also removed. ""amdgpu-lds-size""=""min[,max]"" Min is the minimum number of bytes that will be allocated in the Local; Data Store at address zero. Variables are allocated within this frame; using absolute symbol metadata, primarily by the AMDGPULowerModuleLDS; pass. Optional max is the maximum number of bytes that will be allocated.; Note that min==max indicates that no further variables can be added to; the frame. This is an internal detail of how LDS variables are lowered,; language front ends should not set this attribute. ======================================= ==============================================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:53198,Performance,load,load,53198,"=============; Calling Convention Description; =============================== ==========================================================; ``ccc`` The C calling convention. Used by default.; See :ref:`amdgpu-amdhsa-function-call-convention-non-kernel-functions`; for more details. ``fastcc`` The fast calling convention. Mostly the same as the ``ccc``. ``coldcc`` The cold calling convention. Mostly the same as the ``ccc``. ``amdgpu_cs`` Used for Mesa/AMDPAL compute shaders.; ..TODO::; Describe. ``amdgpu_cs_chain`` Similar to ``amdgpu_cs``, with differences described below. Functions with this calling convention cannot be called directly. They must; instead be launched via the ``llvm.amdgcn.cs.chain`` intrinsic. Arguments are passed in SGPRs, starting at s0, if they have the ``inreg``; attribute, and in VGPRs otherwise, starting at v8. Using more SGPRs or VGPRs; than available in the subtarget is not allowed. On subtargets that use; a scratch buffer descriptor (as opposed to ``scratch_{load,store}_*`` instructions),; the scratch buffer descriptor is passed in s[48:51]. This limits the; SGPR / ``inreg`` arguments to the equivalent of 48 dwords; using more; than that is not allowed. The return type must be void.; Varargs, sret, byval, byref, inalloca, preallocated are not supported. Values in scalar registers as well as v0-v7 are not preserved. Values in; VGPRs starting at v8 are not preserved for the active lanes, but must be; saved by the callee for inactive lanes when using WWM. Wave scratch is ""empty"" at function boundaries. There is no stack pointer input; or output value, but functions are free to use scratch starting from an initial; stack pointer. Calls to ``amdgpu_gfx`` functions are allowed and behave like they; do in ``amdgpu_cs`` functions. All counters (``lgkmcnt``, ``vmcnt``, ``storecnt``, etc.) are presumed in an; unknown state at function entry. A function may have multiple exits (e.g. one chain exit and one plain ``ret void``; for when the wave ends), but",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:55872,Performance,load,loaded,55872," AMD graphics targets. Functions with this calling convention; cannot be used as entry points.; ..TODO::; Describe. ``amdgpu_gs`` Used for Mesa/AMDPAL geometry shaders.; ..TODO::; Describe. ``amdgpu_hs`` Used for Mesa/AMDPAL hull shaders (= tessellation control shaders).; ..TODO::; Describe. ``amdgpu_kernel`` See :ref:`amdgpu-amdhsa-function-call-convention-kernel-functions`. ``amdgpu_ls`` Used for AMDPAL vertex shader if tessellation is in use.; ..TODO::; Describe. ``amdgpu_ps`` Used for Mesa/AMDPAL pixel shaders.; ..TODO::; Describe. ``amdgpu_vs`` Used for Mesa/AMDPAL last shader stage before rasterization (vertex; shader if tessellation and geometry are not in use, or otherwise; copy shader if one is needed).; ..TODO::; Describe. =============================== ==========================================================. .. _amdgpu-elf-code-object:. ELF Code Object; ===============. The AMDGPU backend generates a standard ELF [ELF]_ relocatable code object that; can be linked by ``lld`` to produce a standard ELF shared code object which can; be loaded and executed on an AMDGPU target. .. _amdgpu-elf-header:. Header; ------. The AMDGPU backend uses the following ELF header:. .. table:: AMDGPU ELF Header; :name: amdgpu-elf-header-table. ========================== ===============================; Field Value; ========================== ===============================; ``e_ident[EI_CLASS]`` ``ELFCLASS64``; ``e_ident[EI_DATA]`` ``ELFDATA2LSB``; ``e_ident[EI_OSABI]`` - ``ELFOSABI_NONE``; - ``ELFOSABI_AMDGPU_HSA``; - ``ELFOSABI_AMDGPU_PAL``; - ``ELFOSABI_AMDGPU_MESA3D``; ``e_ident[EI_ABIVERSION]`` - ``ELFABIVERSION_AMDGPU_HSA_V2``; - ``ELFABIVERSION_AMDGPU_HSA_V3``; - ``ELFABIVERSION_AMDGPU_HSA_V4``; - ``ELFABIVERSION_AMDGPU_HSA_V5``; - ``ELFABIVERSION_AMDGPU_PAL``; - ``ELFABIVERSION_AMDGPU_MESA3D``; ``e_type`` - ``ET_REL``; - ``ET_DYN``; ``e_machine`` ``EM_AMDGPU``; ``e_entry`` 0; ``e_flags`` See :ref:`amdgpu-elf-header-e_flags-v2-table`,; :ref:`amdgpu-elf-header-e_flag",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:59352,Performance,load,loader,59352,n of LLVM. * ``ELFABIVERSION_AMDGPU_HSA_V3`` is used to specify the version of AMD HSA; runtime ABI for code object V3. Can no longer be emitted by this version of LLVM. * ``ELFABIVERSION_AMDGPU_HSA_V4`` is used to specify the version of AMD HSA; runtime ABI for code object V4. Specify using the Clang option; ``-mcode-object-version=4``. * ``ELFABIVERSION_AMDGPU_HSA_V5`` is used to specify the version of AMD HSA; runtime ABI for code object V5. Specify using the Clang option; ``-mcode-object-version=5``. This is the default code object; version if not specified. * ``ELFABIVERSION_AMDGPU_PAL`` is used to specify the version of AMD PAL; runtime ABI. * ``ELFABIVERSION_AMDGPU_MESA3D`` is used to specify the version of AMD MESA; 3D runtime ABI. ``e_type``; Can be one of the following values:. ``ET_REL``; The type produced by the AMDGPU backend compiler as it is relocatable code; object. ``ET_DYN``; The type produced by the linker as it is a shared code object. The AMD HSA runtime loader requires a ``ET_DYN`` code object. ``e_machine``; The value ``EM_AMDGPU`` is used for the machine for all processors supported; by the ``r600`` and ``amdgcn`` architectures (see; :ref:`amdgpu-processor-table`). The specific processor is specified in the; ``NT_AMD_HSA_ISA_VERSION`` note record for code object V2 (see; :ref:`amdgpu-note-records-v2`) and in the ``EF_AMDGPU_MACH`` bit field of the; ``e_flags`` for code object V3 and above (see; :ref:`amdgpu-elf-header-e_flags-table-v3` and; :ref:`amdgpu-elf-header-e_flags-table-v4-onwards`). ``e_entry``; The entry point is 0 as the entry points for individual kernels must be; selected in order to invoke them through AQL packets. ``e_flags``; The AMDGPU backend uses the following ELF header flags:. .. table:: AMDGPU ELF Header ``e_flags`` for Code Object V2; :name: amdgpu-elf-header-e_flags-v2-table. ===================================== ===== =============================; Name Value Description; ===================================== ===== ==,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:68316,Performance,load,loader,68316,"HF_ALLOC`` + ``SHF_WRITE``; ``.debug_``\ *\** ``SHT_PROGBITS`` *none*; ``.dynamic`` ``SHT_DYNAMIC`` ``SHF_ALLOC``; ``.dynstr`` ``SHT_PROGBITS`` ``SHF_ALLOC``; ``.dynsym`` ``SHT_PROGBITS`` ``SHF_ALLOC``; ``.got`` ``SHT_PROGBITS`` ``SHF_ALLOC`` + ``SHF_WRITE``; ``.hash`` ``SHT_HASH`` ``SHF_ALLOC``; ``.note`` ``SHT_NOTE`` *none*; ``.rela``\ *name* ``SHT_RELA`` *none*; ``.rela.dyn`` ``SHT_RELA`` *none*; ``.rodata`` ``SHT_PROGBITS`` ``SHF_ALLOC``; ``.shstrtab`` ``SHT_STRTAB`` *none*; ``.strtab`` ``SHT_STRTAB`` *none*; ``.symtab`` ``SHT_SYMTAB`` *none*; ``.text`` ``SHT_PROGBITS`` ``SHF_ALLOC`` + ``SHF_EXECINSTR``; ================== ================ =================================. These sections have their standard meanings (see [ELF]_) and are only generated; if needed. ``.debug``\ *\**; The standard DWARF sections. See :ref:`amdgpu-dwarf-debug-information` for; information on the DWARF produced by the AMDGPU backend. ``.dynamic``, ``.dynstr``, ``.dynsym``, ``.hash``; The standard sections used by a dynamic loader. ``.note``; See :ref:`amdgpu-note-records` for the note records supported by the AMDGPU; backend. ``.rela``\ *name*, ``.rela.dyn``; For relocatable code objects, *name* is the name of the section that the; relocation records apply. For example, ``.rela.text`` is the section name for; relocation records associated with the ``.text`` section. For linked shared code objects, ``.rela.dyn`` contains all the relocation; records from each of the relocatable code object's ``.rela``\ *name* sections. See :ref:`amdgpu-relocation-records` for the relocation records supported by; the AMDGPU backend. ``.text``; The executable machine code for the kernels and functions they call. Generated; as position independent code. See :ref:`amdgpu-code-conventions` for; information on conventions used in the isa generation. .. _amdgpu-note-records:. Note Records; ------------. The AMDGPU backend code object contains ELF note records in the ``.note``; section. The set of generated not",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:72751,Performance,load,loader,72751,"has a value less than or equal to 2. ``NT_AMD_HSA_HSAIL``; Specifies the HSAIL properties used by the HSAIL Finalizer. The description; field has the following layout:. .. code:: c. struct amdgpu_hsa_note_hsail_s {; uint32_t hsail_major_version;; uint32_t hsail_minor_version;; uint8_t profile;; uint8_t machine_model;; uint8_t default_float_round;; };. ``NT_AMD_HSA_ISA_VERSION``; Specifies the target ISA version. The description field has the following layout:. .. code:: c. struct amdgpu_hsa_note_isa_s {; uint16_t vendor_name_size;; uint16_t architecture_name_size;; uint32_t major;; uint32_t minor;; uint32_t stepping;; char vendor_and_architecture_name[1];; };. ``vendor_name_size`` and ``architecture_name_size`` are the length of the; vendor and architecture names respectively, including the NUL character. ``vendor_and_architecture_name`` contains the NUL terminates string for the; vendor, immediately followed by the NUL terminated string for the; architecture. This note record is used by the HSA runtime loader. Code object V2 only supports a limited number of processors and has fixed; settings for target features. See; :ref:`amdgpu-elf-note-record-supported_processors-v2-table` for a list of; processors and the corresponding target ID. In the table the note record ISA; name is a concatenation of the vendor name, architecture name, major, minor,; and stepping separated by a "":"". The target ID column shows the processor name and fixed target features used; by the LLVM compiler. The LLVM compiler does not generate a; ``NT_AMD_HSA_HSAIL`` note record. A code object generated by the Finalizer also uses code object V2 and always; generates a ``NT_AMD_HSA_HSAIL`` note record. The processor name and; ``sramecc`` target feature is as shown in; :ref:`amdgpu-elf-note-record-supported_processors-v2-table` but the ``xnack``; target feature is specified by the ``EF_AMDGPU_FEATURE_XNACK_V2`` ``e_flags``; bit. ``NT_AMD_HSA_ISA_NAME``; Specifies the target ISA name as a non-NUL term",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:73795,Performance,load,loader,73795,"only supports a limited number of processors and has fixed; settings for target features. See; :ref:`amdgpu-elf-note-record-supported_processors-v2-table` for a list of; processors and the corresponding target ID. In the table the note record ISA; name is a concatenation of the vendor name, architecture name, major, minor,; and stepping separated by a "":"". The target ID column shows the processor name and fixed target features used; by the LLVM compiler. The LLVM compiler does not generate a; ``NT_AMD_HSA_HSAIL`` note record. A code object generated by the Finalizer also uses code object V2 and always; generates a ``NT_AMD_HSA_HSAIL`` note record. The processor name and; ``sramecc`` target feature is as shown in; :ref:`amdgpu-elf-note-record-supported_processors-v2-table` but the ``xnack``; target feature is specified by the ``EF_AMDGPU_FEATURE_XNACK_V2`` ``e_flags``; bit. ``NT_AMD_HSA_ISA_NAME``; Specifies the target ISA name as a non-NUL terminated string. This note record is not used by the HSA runtime loader. See the ``NT_AMD_HSA_ISA_VERSION`` note record description of the code object; V2's limited support of processors and fixed settings for target features. See :ref:`amdgpu-elf-note-record-supported_processors-v2-table` for a mapping; from the string to the corresponding target ID. If the ``xnack`` target; feature is supported and enabled, the string produced by the LLVM compiler; will may have a ``+xnack`` appended. The Finlizer did not do the appending and; instead used the ``EF_AMDGPU_FEATURE_XNACK_V2`` ``e_flags`` bit. ``NT_AMD_HSA_METADATA``; Specifies extensible metadata associated with the code objects executed on HSA; [HSA]_ compatible runtimes (see :ref:`amdgpu-os`). It is required when the; target triple OS is ``amdhsa`` (see :ref:`amdgpu-target-triples`). See; :ref:`amdgpu-amdhsa-code-object-metadata-v2` for the syntax of the code object; metadata string. .. table:: AMDGPU Code Object V2 Supported Processors and Fixed Target Feature Settings; :name",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:78466,Performance,load,loader,78466,"gpu-symbols:. Symbols; -------. Symbols include the following:. .. table:: AMDGPU ELF Symbols; :name: amdgpu-elf-symbols-table. ===================== ================== ================ ==================; Name Type Section Description; ===================== ================== ================ ==================; *link-name* ``STT_OBJECT`` - ``.data`` Global variable; - ``.rodata``; - ``.bss``; *link-name*\ ``.kd`` ``STT_OBJECT`` - ``.rodata`` Kernel descriptor; *link-name* ``STT_FUNC`` - ``.text`` Kernel entry point; *link-name* ``STT_OBJECT`` - SHN_AMDGPU_LDS Global variable in LDS; ===================== ================== ================ ==================. Global variable; Global variables both used and defined by the compilation unit. If the symbol is defined in the compilation unit then it is allocated in the; appropriate section according to if it has initialized data or is readonly. If the symbol is external then its section is ``STN_UNDEF`` and the loader; will resolve relocations using the definition provided by another code object; or explicitly defined by the runtime. If the symbol resides in local/group memory (LDS) then its section is the; special processor specific section name ``SHN_AMDGPU_LDS``, and the; ``st_value`` field describes alignment requirements as it does for common; symbols. .. TODO::. Add description of linked shared object symbols. Seems undefined symbols; are marked as STT_NOTYPE. Kernel descriptor; Every HSA kernel has an associated kernel descriptor. It is the address of the; kernel descriptor that is used in the AQL dispatch packet used to invoke the; kernel, not the kernel entry point. The layout of the HSA kernel descriptor is; defined in :ref:`amdgpu-amdhsa-kernel-descriptor`. Kernel entry point; Every HSA kernel also has a symbol for its machine code entry point. .. _amdgpu-relocation-records:. Relocation Records; ------------------. The AMDGPU backend generates ``Elf64_Rela`` relocation records for; AMDHSA or ``Elf64_Rel`` rel",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:80942,Performance,load,loaded,80942,"alculations:. **A**; Represents the addend used to compute the value of the relocatable field. If; the addend field is smaller than 64 bits then it is zero-extended to 64 bits; for use in the calculations below. (In practice this only affects ``_HI``; relocation types on Mesa/AMDPAL, where the addend comes from the 32-bit field; but the result of the calculation depends on the high part of the full 64-bit; address.). **G**; Represents the offset into the global offset table at which the relocation; entry's symbol will reside during execution. **GOT**; Represents the address of the global offset table. **P**; Represents the place (section offset for ``et_rel`` or address for ``et_dyn``); of the storage unit being relocated (computed using ``r_offset``). **S**; Represents the value of the symbol whose index resides in the relocation; entry. Relocations not using this must specify a symbol index of; ``STN_UNDEF``. **B**; Represents the base address of a loaded executable or shared object which is; the difference between the ELF address and the actual load address.; Relocations using this are only valid in executable or shared objects. The following relocation types are supported:. .. table:: AMDGPU ELF Relocation Records; :name: amdgpu-elf-relocation-records-table. ========================== ======= ===== ========== ==============================; Relocation Type Kind Value Field Calculation; ========================== ======= ===== ========== ==============================; ``R_AMDGPU_NONE`` 0 *none* *none*; ``R_AMDGPU_ABS32_LO`` Static, 1 ``word32`` (S + A) & 0xFFFFFFFF; Dynamic; ``R_AMDGPU_ABS32_HI`` Static, 2 ``word32`` (S + A) >> 32; Dynamic; ``R_AMDGPU_ABS64`` Static, 3 ``word64`` S + A; Dynamic; ``R_AMDGPU_REL32`` Static 4 ``word32`` S + A - P; ``R_AMDGPU_REL64`` Static 5 ``word64`` S + A - P; ``R_AMDGPU_ABS32`` Static, 6 ``word32`` S + A; Dynamic; ``R_AMDGPU_GOTPCREL`` Static 7 ``word32`` G + GOT + A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT +",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:81041,Performance,load,load,81041,"alculations:. **A**; Represents the addend used to compute the value of the relocatable field. If; the addend field is smaller than 64 bits then it is zero-extended to 64 bits; for use in the calculations below. (In practice this only affects ``_HI``; relocation types on Mesa/AMDPAL, where the addend comes from the 32-bit field; but the result of the calculation depends on the high part of the full 64-bit; address.). **G**; Represents the offset into the global offset table at which the relocation; entry's symbol will reside during execution. **GOT**; Represents the address of the global offset table. **P**; Represents the place (section offset for ``et_rel`` or address for ``et_dyn``); of the storage unit being relocated (computed using ``r_offset``). **S**; Represents the value of the symbol whose index resides in the relocation; entry. Relocations not using this must specify a symbol index of; ``STN_UNDEF``. **B**; Represents the base address of a loaded executable or shared object which is; the difference between the ELF address and the actual load address.; Relocations using this are only valid in executable or shared objects. The following relocation types are supported:. .. table:: AMDGPU ELF Relocation Records; :name: amdgpu-elf-relocation-records-table. ========================== ======= ===== ========== ==============================; Relocation Type Kind Value Field Calculation; ========================== ======= ===== ========== ==============================; ``R_AMDGPU_NONE`` 0 *none* *none*; ``R_AMDGPU_ABS32_LO`` Static, 1 ``word32`` (S + A) & 0xFFFFFFFF; Dynamic; ``R_AMDGPU_ABS32_HI`` Static, 2 ``word32`` (S + A) >> 32; Dynamic; ``R_AMDGPU_ABS64`` Static, 3 ``word64`` S + A; Dynamic; ``R_AMDGPU_REL32`` Static 4 ``word32`` S + A - P; ``R_AMDGPU_REL64`` Static 5 ``word64`` S + A - P; ``R_AMDGPU_ABS32`` Static, 6 ``word32`` S + A; Dynamic; ``R_AMDGPU_GOTPCREL`` Static 7 ``word32`` G + GOT + A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT +",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:82574,Performance,load,loader,82574,"_HI`` Static, 2 ``word32`` (S + A) >> 32; Dynamic; ``R_AMDGPU_ABS64`` Static, 3 ``word64`` S + A; Dynamic; ``R_AMDGPU_REL32`` Static 4 ``word32`` S + A - P; ``R_AMDGPU_REL64`` Static 5 ``word64`` S + A - P; ``R_AMDGPU_ABS32`` Static, 6 ``word32`` S + A; Dynamic; ``R_AMDGPU_GOTPCREL`` Static 7 ``word32`` G + GOT + A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT + A - P) & 0xFFFFFFFF; ``R_AMDGPU_GOTPCREL32_HI`` Static 9 ``word32`` (G + GOT + A - P) >> 32; ``R_AMDGPU_REL32_LO`` Static 10 ``word32`` (S + A - P) & 0xFFFFFFFF; ``R_AMDGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:82660,Performance,load,loaded-code-object-path-uniform-resource-identifier,82660,"ord64`` S + A; Dynamic; ``R_AMDGPU_REL32`` Static 4 ``word32`` S + A - P; ``R_AMDGPU_REL64`` Static 5 ``word64`` S + A - P; ``R_AMDGPU_ABS32`` Static, 6 ``word32`` S + A; Dynamic; ``R_AMDGPU_GOTPCREL`` Static 7 ``word32`` G + GOT + A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT + A - P) & 0xFFFFFFFF; ``R_AMDGPU_GOTPCREL32_HI`` Static 9 ``word32`` (G + GOT + A - P) >> 32; ``R_AMDGPU_REL32_LO`` Static 10 ``word32`` (S + A - P) & 0xFFFFFFFF; ``R_AMDGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:82856,Performance,load,loader,82856,"+ A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT + A - P) & 0xFFFFFFFF; ``R_AMDGPU_GOTPCREL32_HI`` Static 9 ``word32`` (G + GOT + A - P) >> 32; ``R_AMDGPU_REL32_LO`` Static 10 ``word32`` (S + A - P) & 0xFFFFFFFF; ``R_AMDGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:82940,Performance,load,loaded,82940,"+ A - P; ``R_AMDGPU_GOTPCREL32_LO`` Static 8 ``word32`` (G + GOT + A - P) & 0xFFFFFFFF; ``R_AMDGPU_GOTPCREL32_HI`` Static 9 ``word32`` (G + GOT + A - P) >> 32; ``R_AMDGPU_REL32_LO`` Static 10 ``word32`` (S + A - P) & 0xFFFFFFFF; ``R_AMDGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:83039,Performance,load,loaded,83039,"rd32`` (G + GOT + A - P) >> 32; ``R_AMDGPU_REL32_LO`` Static 10 ``word32`` (S + A - P) & 0xFFFFFFFF; ``R_AMDGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expression ``[a-zA-Z0-9/_.~-]`` is; encoded as two uppercase hexadecimal digits proceeded by ""%"". Directories in; the path are separa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:83117,Performance,load,loaded,83117,"DGPU_REL32_HI`` Static 11 ``word32`` (S + A - P) >> 32; *reserved* 12; ``R_AMDGPU_RELATIVE64`` Dynamic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expression ``[a-zA-Z0-9/_.~-]`` is; encoded as two uppercase hexadecimal digits proceeded by ""%"". Directories in; the path are separated by ""/"". **offset**; Is a 0-based byte offset to the start of the code object. For a file URI, it; is f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:83212,Performance,load,loaded,83212,"ic 13 ``word64`` B + A; ``R_AMDGPU_REL16`` Static 14 ``word16`` ((S + A - P) - 4) / 4; ========================== ======= ===== ========== ==============================. ``R_AMDGPU_ABS32_LO`` and ``R_AMDGPU_ABS32_HI`` are only supported by; the ``mesa3d`` OS, which does not support ``R_AMDGPU_ABS64``. There is no current OS loader support for 32-bit programs and so; ``R_AMDGPU_ABS32`` is not used. .. _amdgpu-loaded-code-object-path-uniform-resource-identifier:. Loaded Code Object Path Uniform Resource Identifier (URI); ---------------------------------------------------------. The AMD GPU code object loader represents the path of the ELF shared object from; which the code object was loaded as a textual Uniform Resource Identifier (URI).; Note that the code object is the in memory loaded relocated form of the ELF; shared object. Multiple code objects may be loaded at different memory; addresses in the same process from the same ELF shared object. The loaded code object path URI syntax is defined by the following BNF syntax:. .. code::. code_object_uri ::== file_uri | memory_uri; file_uri ::== ""file://"" file_path [ range_specifier ]; memory_uri ::== ""memory://"" process_id range_specifier; range_specifier ::== [ ""#"" | ""?"" ] ""offset="" number ""&"" ""size="" number; file_path ::== URI_ENCODED_OS_FILE_PATH; process_id ::== DECIMAL_NUMBER; number ::== HEX_NUMBER | DECIMAL_NUMBER | OCTAL_NUMBER. **number**; Is a C integral literal where hexadecimal values are prefixed by ""0x"" or ""0X"",; and octal values by ""0"". **file_path**; Is the file's path specified as a URI encoded UTF-8 string. In URI encoding,; every character that is not in the regular expression ``[a-zA-Z0-9/_.~-]`` is; encoded as two uppercase hexadecimal digits proceeded by ""%"". Directories in; the path are separated by ""/"". **offset**; Is a 0-based byte offset to the start of the code object. For a file URI, it; is from the start of the file specified by the ``file_path``, and if omitted; defaults to 0. For a memor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:109738,Performance,perform,perform,109738,"gram location for the region at the end of the; loop. Any lanes active will be in the loop, and any lanes not active must have; exited the loop. An ``IF/THEN/ELSEIF/ELSEIF/...`` region can be treated as a nest of; ``IF/THEN/ELSE`` regions. The DWARF procedures can use the active lane artificial variable described in; :ref:`amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane` rather than the actual; ``EXEC`` mask in order to support whole or quad wavefront mode. .. _amdgpu-dwarf-amdgpu-dw-at-llvm-active-lane:. ``DW_AT_LLVM_active_lane``; ~~~~~~~~~~~~~~~~~~~~~~~~~~. The ``DW_AT_LLVM_active_lane`` attribute on a subprogram debugger information; entry is used to specify the lanes that are conceptually active for a SIMT; thread. The execution mask may be modified to implement whole or quad wavefront mode; operations. For example, all lanes may need to temporarily be made active to; execute a whole wavefront operation. Such regions would save the ``EXEC`` mask,; update it to enable the necessary lanes, perform the operations, and then; restore the ``EXEC`` mask from the saved value. While executing the whole; wavefront region, the conceptual execution mask is the saved value, not the; ``EXEC`` value. This is handled by defining an artificial variable for the active lane mask. The; active lane mask artificial variable would be the actual ``EXEC`` mask for; normal regions, and the saved execution mask for regions where the mask is; temporarily updated. The location list expression created for this artificial; variable is used to define the value of the ``DW_AT_LLVM_active_lane``; attribute. ``DW_AT_LLVM_augmentation``; ~~~~~~~~~~~~~~~~~~~~~~~~~~~. For AMDGPU, the ``DW_AT_LLVM_augmentation`` attribute of a compilation unit; debugger information entry has the following value for the augmentation string:. ::. [amdgpu:v0.0]. The ""vX.Y"" specifies the major X and minor Y version number of the AMDGPU; extensions used in the DWARF of the compilation unit. The version number; conforms to [SEM",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:115860,Performance,perform,performing,115860,"``minimum_instruction_length`` (ubyte); For GFX9-GFX11 this is 4. ``maximum_operations_per_instruction`` (ubyte); For GFX9-GFX11 this is 1. Source text for online-compiled programs (for example, those compiled by the; OpenCL language runtime) may be embedded into the DWARF Version 5 line table.; See DWARF Version 5 section 6.2.4.1 which is updated by *DWARF Extensions For; Heterogeneous Debugging* section :ref:`DW_LNCT_LLVM_source; <amdgpu-dwarf-line-number-information-dw-lnct-llvm-source>`. The Clang option used to control source embedding in AMDGPU is defined in; :ref:`amdgpu-clang-debug-options-table`. .. table:: AMDGPU Clang Debug Options; :name: amdgpu-clang-debug-options-table. ==================== ==================================================; Debug Flag Description; ==================== ==================================================; -g[no-]embed-source Enable/disable embedding source text in DWARF; debug sections. Useful for environments where; source cannot be written to disk, such as; when performing online compilation.; ==================== ==================================================. For example:. ``-gembed-source``; Enable the embedded source. ``-gno-embed-source``; Disable the embedded source. 32-Bit and 64-Bit DWARF Formats; -------------------------------. See DWARF Version 5 section 7.4 and; :ref:`amdgpu-dwarf-32-bit-and-64-bit-dwarf-formats`. For AMDGPU:. * For the ``amdgcn`` target architecture only the 64-bit process address space; is supported. * The producer can generate either 32-bit or 64-bit DWARF format. LLVM generates; the 32-bit DWARF format. Unit Headers; ------------. For AMDGPU the following values apply for each of the unit headers described in; DWARF Version 5 sections 7.5.1.1, 7.5.1.2, and 7.5.1.3:. ``address_size`` (ubyte); Matches the address size for the ``Global`` address space defined in; :ref:`amdgpu-dwarf-address-space-identifier`. .. _amdgpu-code-conventions:. Code Conventions; ================. This section",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:124183,Performance,queue,queue,124183,"? Description; ================= ============== ========= ================================; ""Name"" string Kernel argument name.; ""TypeName"" string Kernel argument type name.; ""Size"" integer Required Kernel argument size in bytes.; ""Align"" integer Required Kernel argument alignment in; bytes. Must be a power of two.; ""ValueKind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""ByValue""; The argument is copied; directly into the kernarg. ""GlobalBuffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""DynamicSharedPointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""Sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""Image""; A global address space; pointer to a T# is passed in; the kernarg. ""Pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenComp",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:125074,Performance,queue,queue,125074," an OpenCL pipe is passed in; the kernarg. ""Queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""HiddenGlobalOffsetX""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""HiddenGlobalOffsetY""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""HiddenGlobalOffsetZ""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""HiddenNone""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""HiddenPrintfBuffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenHostcallBuffer"". ""HiddenHostcallBuffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""HiddenPrintfBuffer"". ""HiddenDefaultQueue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""HiddenCompletionAction""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""HiddenMultiGridSyncArg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:126368,Performance,perform,performed,126368,"e pointer for; multi-grid synchronization is; passed in the kernarg. ""ValueType"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. ""PointeeAlign"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; ""ValueKind"" is; ""DynamicSharedPointer"".; ""AddrSpaceQual"" string Kernel argument address space; qualifier. Only present if; ""ValueKind"" is ""GlobalBuffer"" or; ""DynamicSharedPointer"". Values; are:. - ""Private""; - ""Global""; - ""Constant""; - ""Local""; - ""Generic""; - ""Region"". .. TODO::. Is GlobalBuffer only Global; or Constant? Is; DynamicSharedPointer always; Local? Can HCC allow Generic?; How can Private or Region; ever happen?. ""AccQual"" string Kernel argument access; qualifier. Only present if; ""ValueKind"" is ""Image"" or; ""Pipe"". Values; are:. - ""ReadOnly""; - ""WriteOnly""; - ""ReadWrite"". .. TODO::. Does this apply to; GlobalBuffer?. ""ActualAccQual"" string The actual memory accesses; performed by the kernel on the; kernel argument. Only present if; ""ValueKind"" is ""GlobalBuffer"",; ""Image"", or ""Pipe"". This may be; more restrictive than indicated; by ""AccQual"" to reflect what the; kernel actual does. If not; present then the runtime must; assume what is implied by; ""AccQual"" and ""IsConst"". Values; are:. - ""ReadOnly""; - ""WriteOnly""; - ""ReadWrite"". ""IsConst"" boolean Indicates if the kernel argument; is const qualified. Only present; if ""ValueKind"" is; ""GlobalBuffer"". ""IsRestrict"" boolean Indicates if the kernel argument; is restrict qualified. Only; present if ""ValueKind"" is; ""GlobalBuffer"". ""IsVolatile"" boolean Indicates if the kernel argument; is volatile qualified. Only; present if ""ValueKind"" is; ""GlobalBuffer"". ""IsPipe"" boolean Indicates if the kernel argument; is pipe qualified. Only present; if ""ValueKind"" is ""Pipe"". .. TODO::. Can GlobalBuffer be pipe; qualified?. ================= ============== ========= ================================. .. .. table:: AMDHSA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:135709,Performance,load,loading,135709,"enabled. It is not; rounded up to the; allocation; granularity.; "".vgpr_count"" integer Required Number of vector; registers required by; each work-item for; GFX6-GFX9. A register; is required if it is; used explicitly, or; if a higher numbered; register is used; explicitly.; "".agpr_count"" integer Required Number of accumulator; registers required by; each work-item for; GFX90A, GFX908.; "".max_flat_workgroup_size"" integer Required Maximum flat; work-group size; supported by the; kernel in work-items.; Must be >=1 and; consistent with; ReqdWorkGroupSize if; not 0, 0, 0.; "".sgpr_spill_count"" integer Number of stores from; a scalar register to; a register allocator; created spill; location.; "".vgpr_spill_count"" integer Number of stores from; a vector register to; a register allocator; created spill; location.; "".kind"" string The kind of the kernel; with the following; values:. ""normal""; Regular kernels. ""init""; These kernels must be; invoked after loading; the containing code; object and must; complete before any; normal and fini; kernels in the same; code object are; invoked. ""fini""; These kernels must be; invoked before; unloading the; containing code object; and after all init and; normal kernels in the; same code object have; been invoked and; completed. If omitted, ""normal"" is; assumed.; =================================== ============== ========= ================================. .. .. table:: AMDHSA Code Object V3 Kernel Argument Metadata Map; :name: amdgpu-amdhsa-code-object-kernel-argument-metadata-map-table-v3. ====================== ============== ========= ================================; String Key Value Type Required? Description; ====================== ============== ========= ================================; "".name"" string Kernel argument name.; "".type_name"" string Kernel argument type name.; "".size"" integer Required Kernel argument size in bytes.; "".offset"" integer Required Kernel argument offset in; bytes. The offset must be a; multiple of the alignme",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:137422,Performance,queue,queue,137422,"==============================; "".name"" string Kernel argument name.; "".type_name"" string Kernel argument type name.; "".size"" integer Required Kernel argument size in bytes.; "".offset"" integer Required Kernel argument offset in; bytes. The offset must be a; multiple of the alignment; required by the argument.; "".value_kind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""by_value""; The argument is copied; directly into the kernarg. ""global_buffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""dynamic_shared_pointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""image""; A global address space; pointer to a T# is passed in; the kernarg. ""pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""hidden_global_offset_x""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""hidden_global_offset_y""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""hidden_global_offset_z""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""hidden_none""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""hidden_printf_buffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_hostcall_buffer""; before Code Object V5. ""hidden_hostcall_buffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_printf_buffer""; before Code Object V5. ""hidden_default_queue""; A global address space pointer; to the OpenCL device enqueue; queue that should be use",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:137491,Performance,queue,queue,137491,"==============================; "".name"" string Kernel argument name.; "".type_name"" string Kernel argument type name.; "".size"" integer Required Kernel argument size in bytes.; "".offset"" integer Required Kernel argument offset in; bytes. The offset must be a; multiple of the alignment; required by the argument.; "".value_kind"" string Required Kernel argument kind that; specifies how to set up the; corresponding argument.; Values include:. ""by_value""; The argument is copied; directly into the kernarg. ""global_buffer""; A global address space pointer; to the buffer data is passed; in the kernarg. ""dynamic_shared_pointer""; A group address space pointer; to dynamically allocated LDS; is passed in the kernarg. ""sampler""; A global address space; pointer to a S# is passed in; the kernarg. ""image""; A global address space; pointer to a T# is passed in; the kernarg. ""pipe""; A global address space pointer; to an OpenCL pipe is passed in; the kernarg. ""queue""; A global address space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""hidden_global_offset_x""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""hidden_global_offset_y""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""hidden_global_offset_z""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""hidden_none""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""hidden_printf_buffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_hostcall_buffer""; before Code Object V5. ""hidden_hostcall_buffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_printf_buffer""; before Code Object V5. ""hidden_default_queue""; A global address space pointer; to the OpenCL device enqueue; queue that should be use",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:138448,Performance,queue,queue,138448,"ess space pointer; to an OpenCL device enqueue; queue is passed in the; kernarg. ""hidden_global_offset_x""; The OpenCL grid dispatch; global offset for the X; dimension is passed in the; kernarg. ""hidden_global_offset_y""; The OpenCL grid dispatch; global offset for the Y; dimension is passed in the; kernarg. ""hidden_global_offset_z""; The OpenCL grid dispatch; global offset for the Z; dimension is passed in the; kernarg. ""hidden_none""; An argument that is not used; by the kernel. Space needs to; be left for it, but it does; not need to be set up. ""hidden_printf_buffer""; A global address space pointer; to the runtime printf buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_hostcall_buffer""; before Code Object V5. ""hidden_hostcall_buffer""; A global address space pointer; to the runtime hostcall buffer; is passed in kernarg. Mutually; exclusive with; ""hidden_printf_buffer""; before Code Object V5. ""hidden_default_queue""; A global address space pointer; to the OpenCL device enqueue; queue that should be used by; the kernel by default is; passed in the kernarg. ""hidden_completion_action""; A global address space pointer; to help link enqueued kernels into; the ancestor tree for determining; when the parent kernel has finished. ""hidden_multigrid_sync_arg""; A global address space pointer for; multi-grid synchronization is; passed in the kernarg. "".value_type"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. "".pointee_align"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; "".value_kind"" is; ""dynamic_shared_pointer"".; "".address_space"" string Kernel argument address space; qualifier. Only present if; "".value_kind"" is ""global_buffer"" or; ""dynamic_shared_pointer"". Values; are:. - ""private""; - ""global""; - ""constant""; - ""local""; - ""generic""; - ""region"". .. TODO::. Is ""global_buffer"" only ""global""; or ""constant""? Is; ""dynamic_shared_pointer"" always; ""lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:139789,Performance,perform,performed,139789,"s; passed in the kernarg. "".value_type"" string Unused and deprecated. This should no longer; be emitted, but is accepted for compatibility. "".pointee_align"" integer Alignment in bytes of pointee; type for pointer type kernel; argument. Must be a power; of 2. Only present if; "".value_kind"" is; ""dynamic_shared_pointer"".; "".address_space"" string Kernel argument address space; qualifier. Only present if; "".value_kind"" is ""global_buffer"" or; ""dynamic_shared_pointer"". Values; are:. - ""private""; - ""global""; - ""constant""; - ""local""; - ""generic""; - ""region"". .. TODO::. Is ""global_buffer"" only ""global""; or ""constant""? Is; ""dynamic_shared_pointer"" always; ""local""? Can HCC allow ""generic""?; How can ""private"" or ""region""; ever happen?. "".access"" string Kernel argument access; qualifier. Only present if; "".value_kind"" is ""image"" or; ""pipe"". Values; are:. - ""read_only""; - ""write_only""; - ""read_write"". .. TODO::. Does this apply to; ""global_buffer""?. "".actual_access"" string The actual memory accesses; performed by the kernel on the; kernel argument. Only present if; "".value_kind"" is ""global_buffer"",; ""image"", or ""pipe"". This may be; more restrictive than indicated; by "".access"" to reflect what the; kernel actual does. If not; present then the runtime must; assume what is implied by; "".access"" and "".is_const"" . Values; are:. - ""read_only""; - ""write_only""; - ""read_write"". "".is_const"" boolean Indicates if the kernel argument; is const qualified. Only present; if "".value_kind"" is; ""global_buffer"". "".is_restrict"" boolean Indicates if the kernel argument; is restrict qualified. Only; present if "".value_kind"" is; ""global_buffer"". "".is_volatile"" boolean Indicates if the kernel argument; is volatile qualified. Only; present if "".value_kind"" is; ""global_buffer"". "".is_pipe"" boolean Indicates if the kernel argument; is pipe qualified. Only present; if "".value_kind"" is ""pipe"". .. TODO::. Can ""global_buffer"" be pipe; qualified?. ====================== ============== ========= ===================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:148576,Performance,queue,queue,148576," group does not exist in the Z dimension. ""hidden_grid_dims""; The grid dispatch dimensionality. This is the same value; as the AQL dispatch packet dimensionality. Must be a value; between 1 and 3. ""hidden_heap_v1""; A global address space pointer to an initialized memory; buffer that conforms to the requirements of the malloc/free; device library V1 version implementation. ""hidden_dynamic_lds_size""; Size of the dynamically allocated LDS memory is passed in the kernarg. ""hidden_private_base""; The high 32 bits of the flat addressing private aperture base.; Only used by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149053,Performance,queue,queues,149053,"by GFX8 to allow conversion between private segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_shared_base""; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149274,Performance,queue,queue,149274,"; The high 32 bits of the flat addressing shared aperture base.; Only used by GFX8 to allow conversion between shared segment; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149420,Performance,queue,queues,149420,"; and flat addresses. See :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. ""hidden_queue_ptr""; A global memory address space pointer to the ROCm runtime; ``struct amd_queue_t`` structure for the HSA queue of the; associated dispatch AQL packet. It is only required for pre-GFX9; devices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compati",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149680,Performance,queue,queue,149680,"evices for the trap handler ABI (see :ref:`amdgpu-amdhsa-trap-handler-abi`). ====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Progr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149761,Performance,queue,queue,149761,"====================== ============== ========= ================================. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149823,Performance,perform,performed,149823,"==========. .. Kernel Dispatch; ~~~~~~~~~~~~~~~. The HSA architected queuing language (AQL) defines a user space memory interface; that can be used to control the dispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:149940,Performance,queue,queue,149940,"ispatch of kernels, in an agent independent; way. An agent can have zero or more AQL queues created for it using an HSA; compatible runtime (see :ref:`amdgpu-os`), in which AQL packets (all of which; are 64 bytes) can be placed. See the *HSA Platform System Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:150211,Performance,load,loaded,150211,"m Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:150287,Performance,queue,queue,150287,"m Architecture; Specification* [HSA]_ for the AQL queue mechanics and packet layouts. The packet processor of a kernel agent is responsible for detecting and; dispatching HSA kernels from the AQL queues associated with it. For AMD GPUs the; packet processor is implemented by the hardware command processor (CP),; asynchronous dispatch controller (ADC) and shader processor input controller; (SPI). An HSA compatible runtime can be used to allocate an AQL queue object. It uses; the kernel mode driver to initialize and register the AQL queue with CP. To dispatch a kernel the following actions are performed. This can occur in the; CPU host program, or from an HSA kernel executing on a GPU. 1. A pointer to an AQL queue for the kernel agent on which the kernel is to be; executed is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151024,Performance,queue,queue,151024,"cuted is obtained.; 2. A pointer to the kernel descriptor (see; :ref:`amdgpu-amdhsa-kernel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151121,Performance,queue,queue,151121,"rnel-descriptor`) of the kernel to execute is obtained.; It must be for a kernel that is contained in a code object that was loaded; by an HSA compatible runtime on the kernel agent with which the AQL queue is; associated.; 3. Space is allocated for the kernel arguments using the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151393,Performance,queue,queue,151393,"the HSA compatible runtime; allocator for a memory region with the kernarg property for the kernel agent; that will execute the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers (VGPR) are set up as required by the machine code. The required; setup is defined in the :ref:`amdgpu-amdhsa-kernel-descriptor`. The ini",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:151457,Performance,queue,queue,151457," the kernel. It must be at least 16-byte aligned.; 4. Kernel argument values are assigned to the kernel argument memory; allocation. The layout is defined in the *HSA Programmer's Language; Reference* [HSA]_. For AMDGPU the kernel execution directly accesses the; kernel argument memory in the same way constant memory is accessed. (Note; that the HSA specification allows an implementation to copy the kernel; argument contents to another location that is accessed by the kernel.); 5. An AQL kernel dispatch packet is created on the AQL queue. The HSA compatible; runtime api uses 64-bit atomic operations to reserve space in the AQL queue; for the packet. The packet must be set up, and the final write must use an; atomic store release to set the packet kind to ensure the packet contents are; visible to the kernel agent. AQL defines a doorbell signal mechanism to; notify the kernel agent that the AQL queue has been updated. These rules, and; the layout of the AQL queue and kernel dispatch packet is defined in the *HSA; System Architecture Specification* [HSA]_.; 6. A kernel dispatch packet includes information about the actual dispatch,; such as grid and work-group size, together with information from the code; object about the kernel, such as segment sizes. The HSA compatible runtime; queries on the kernel symbol can be used to obtain the code object values; which are recorded in the :ref:`amdgpu-amdhsa-code-object-metadata`.; 7. CP executes micro-code and is responsible for detecting and setting up the; GPU to execute the wavefronts of a kernel dispatch.; 8. CP ensures that when the a wavefront starts executing the kernel machine; code, the scalar general purpose registers (SGPR) and vector general purpose; registers (VGPR) are set up as required by the machine code. The required; setup is defined in the :ref:`amdgpu-amdhsa-kernel-descriptor`. The initial; register state is defined in; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`.; 9. The prolog of the kernel mach",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:153941,Performance,cache,caches,153941,"== ======= ==================; Memory Space Name HSA Segment Hardware Address NULL Value; Name Name Size; ================= =========== ======== ======= ==================; Private private scratch 32 0x00000000; Local group LDS 32 0xFFFFFFFF; Global global global 64 0x0000000000000000; Constant constant *same as 64 0x0000000000000000; global*; Generic flat flat 64 0x0000000000000000; Region N/A GDS 32 *not implemented; for AMDHSA*; ================= =========== ======== ======= ==================. The global and constant memory spaces both use global virtual addresses, which; are the same virtual address space used by the CPU. However, some virtual; addresses may only be accessible to the CPU, some only accessible by the GPU,; and some by both. Using the constant memory space indicates that the data will not change during; the execution of the kernel. This allows scalar read instructions to be; used. The vector and scalar L1 caches are invalidated of volatile data before; each kernel dispatch execution to allow constant memory to change values between; kernel dispatches. The local memory space uses the hardware Local Data Store (LDS) which is; automatically allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:155236,Performance,cache,cache,155236,"lly allocated when the hardware creates work-groups of wavefronts, and; freed when all the wavefronts of a work-group have terminated. The data store; (DS) instructions can be used to access it. The private memory space uses the hardware scratch memory support. If the kernel; uses scratch, then the hardware allocates memory that is accessed using; wavefront lane dword (4 byte) interleaving. The mapping used from private; address to physical address is:. ``wavefront-scratch-base +; (private-address * wavefront-size * 4) +; (wavefront-lane-id * 4)``. There are different ways that the wavefront scratch base address is determined; by a wavefront (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). This; memory can be accessed in an interleaved manner using buffer instruction with; the scratch buffer descriptor and per wavefront scratch offset, by the scratch; instructions, or by flat instructions. If each lane of a wavefront accesses the; same private address, the interleaving results in adjacent dwords being accessed; and hence requires fewer cache lines to be fetched. Multi-dword access is not; supported except by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:156277,Performance,queue,queue,156277,"ept by flat and scratch instructions in GFX9-GFX11. The generic address space uses the hardware flat address support available in; GFX7-GFX11. This uses two fixed ranges of virtual addresses (the private and; local apertures), that are outside the range of addressible global memory, to; map from a flat address to a private or local address. FLAT instructions can take a flat address and access global, private (scratch); and group (LDS) memory depending on if the address is within one of the; aperture ranges. Flat access to scratch requires hardware aperture setup and; setup in the kernel prologue (see; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`). Flat access to LDS requires; hardware aperture setup and M0 (GFX7-GFX8) register setup (see; :ref:`amdgpu-amdhsa-kernel-prolog-m0`). To convert between a segment address and a flat address the base address of the; apertures address can be used. For GFX7-GFX8 these are available in the; :ref:`amdgpu-amdhsa-hsa-aql-queue` the address of which can be obtained with; Queue Ptr SGPR (see :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). For; GFX9-GFX11 the aperture base addresses are directly available as inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessib",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157478,Performance,queue,queue,157478,"s inline constant; registers ``SRC_SHARED_BASE/LIMIT`` and ``SRC_PRIVATE_BASE/LIMIT``. In 64 bit; address mode the aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kern",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:157528,Performance,queue,queue,157528,"he aperture sizes are 2^32 bytes and the base is aligned to 2^32; which makes it easier to convert from flat to segment or segment to flat. Image and Samplers; ~~~~~~~~~~~~~~~~~~. Image and sample handles created by an HSA compatible runtime (see; :ref:`amdgpu-os`) are 64-bit addresses of a hardware 32-byte V# and 48 byte S#; object respectively. In order to support the HSA ``query_sampler`` operations; two extra dwords are used to store the HSA BRIG enumeration values for the; queries that are not trivially deducible from the S# representation. HSA Signals; ~~~~~~~~~~~. HSA signal handles created by an HSA compatible runtime (see :ref:`amdgpu-os`); are 64-bit addresses of a structure allocated in memory accessible from both the; CPU and GPU. The structure is defined by the runtime and subject to change; between releases. For example, see [AMD-ROCm-github]_. .. _amdgpu-amdhsa-hsa-aql-queue:. HSA AQL Queue; ~~~~~~~~~~~~~. The HSA AQL queue structure is defined by an HSA compatible runtime (see; :ref:`amdgpu-os`) and subject to change between releases. For example, see; [AMD-ROCm-github]_. For some processors it contains fields needed to implement; certain language features such as the flat address aperture bases. It also; contains fields used by CP such as managing the allocation of scratch memory. .. _amdgpu-amdhsa-kernel-descriptor:. Kernel Descriptor; ~~~~~~~~~~~~~~~~~. A kernel descriptor consists of the information needed by CP to initiate the; execution of a kernel, including the entry point address of the machine code; that implements the kernel. Code Object V3 Kernel Descriptor; ++++++++++++++++++++++++++++++++. CP microcode requires the Kernel descriptor to be allocated on 64-byte; alignment. The fields used by CP for code objects before V3 also match those specified in; :ref:`amdgpu-amdhsa-kernel-descriptor-v3-table`. .. table:: Code Object V3 Kernel Descriptor; :name: amdgpu-amdhsa-kernel-descriptor-v3-table. ======= ======= ===============================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:159831,Performance,optimiz,optimize,159831,"k-group; in bytes. This does not; include any dynamically; allocated local address; space memory that may be; added when the kernel is; dispatched.; 63:32 4 bytes PRIVATE_SEGMENT_FIXED_SIZE The amount of fixed; private address space; memory required for a; work-item in bytes. When; this cannot be predicted,; code object v4 and older; sets this value to be; higher than the minimum; requirement.; 95:64 4 bytes KERNARG_SIZE The size of the kernarg; memory pointed to by the; AQL dispatch packet. The; kernarg memory is used to; pass arguments to the; kernel. * If the kernarg pointer in; the dispatch packet is NULL; then there are no kernel; arguments.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is 0 then the kernarg; memory size is; unspecified.; * If the kernarg pointer in; the dispatch packet is; not NULL and this value; is not 0 then the value; specifies the kernarg; memory size in bytes. It; is recommended to provide; a value as it may be used; by CP to optimize making; the kernarg memory; visible to the kernel; code. 127:96 4 bytes Reserved, must be 0.; 191:128 8 bytes KERNEL_CODE_ENTRY_BYTE_OFFSET Byte offset (possibly; negative) from base; address of kernel; descriptor to kernel's; entry point instruction; which must be 256 byte; aligned.; 351:272 20 Reserved, must be 0.; bytes; 383:352 4 bytes COMPUTE_PGM_RSRC3 GFX6-GFX9; Reserved, must be 0.; GFX90A, GFX940; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx90a-table`.; GFX10-GFX11; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx10-gfx11-table`.; GFX12; Compute Shader (CS); program settings used by; CP to set up; ``COMPUTE_PGM_RSRC3``; configuration; register. See; :ref:`amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table`.; 415:384 4 bytes COMPUTE_PGM_RSRC1 Compute Shader (CS)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:169598,Performance,load,load,169598,"; filling in; ``COMPUTE_PGM_RSRC1.CDBG_USER``.; 26 1 bit FP16_OVFL GFX6-GFX8; Reserved, must be 0.; GFX9-GFX11; Wavefront starts execution; with specified fp16 overflow; mode. - If 0, fp16 overflow generates; +/-INF values.; - If 1, fp16 overflow that is the; result of an +/-INF input value; or divide by 0 produces a +/-INF,; otherwise clamps computed; overflow to +/-MAX_FP16 as; appropriate. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FP16_OVFL``.; 28:27 2 bits Reserved, must be 0.; 29 1 bit WGP_MODE GFX6-GFX9; Reserved, must be 0.; GFX10-GFX11; - If 0 execute work-groups in; CU wavefront execution mode.; - If 1 execute work-groups on; in WGP wavefront execution mode. See :ref:`amdgpu-amdhsa-memory-model`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.WGP_MODE``.; 30 1 bit MEM_ORDERED GFX6-GFX9; Reserved, must be 0.; GFX10-GFX11; Controls the behavior of the; s_waitcnt's vmcnt and vscnt; counters. - If 0 vmcnt reports completion; of load and atomic with return; out of order with sample; instructions, and the vscnt; reports the completion of; store and atomic without; return in order.; - If 1 vmcnt reports completion; of load, atomic with return; and sample instructions in; order, and the vscnt reports; the completion of store and; atomic without return in order. Used by CP to set up; ``COMPUTE_PGM_RSRC1.MEM_ORDERED``.; 31 1 bit FWD_PROGRESS GFX6-GFX9; Reserved, must be 0.; GFX10-GFX11; - If 0 execute SIMD wavefronts; using oldest first policy.; - If 1 execute SIMD wavefronts to; ensure wavefronts will make some; forward progress. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FWD_PROGRESS``.; 32 **Total size 4 bytes**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc2 for GFX6-GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Siz",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:169789,Performance,load,load,169789,"16 overflow generates; +/-INF values.; - If 1, fp16 overflow that is the; result of an +/-INF input value; or divide by 0 produces a +/-INF,; otherwise clamps computed; overflow to +/-MAX_FP16 as; appropriate. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FP16_OVFL``.; 28:27 2 bits Reserved, must be 0.; 29 1 bit WGP_MODE GFX6-GFX9; Reserved, must be 0.; GFX10-GFX11; - If 0 execute work-groups in; CU wavefront execution mode.; - If 1 execute work-groups on; in WGP wavefront execution mode. See :ref:`amdgpu-amdhsa-memory-model`. Used by CP to set up; ``COMPUTE_PGM_RSRC1.WGP_MODE``.; 30 1 bit MEM_ORDERED GFX6-GFX9; Reserved, must be 0.; GFX10-GFX11; Controls the behavior of the; s_waitcnt's vmcnt and vscnt; counters. - If 0 vmcnt reports completion; of load and atomic with return; out of order with sample; instructions, and the vscnt; reports the completion of; store and atomic without; return in order.; - If 1 vmcnt reports completion; of load, atomic with return; and sample instructions in; order, and the vscnt reports; the completion of store and; atomic without return in order. Used by CP to set up; ``COMPUTE_PGM_RSRC1.MEM_ORDERED``.; 31 1 bit FWD_PROGRESS GFX6-GFX9; Reserved, must be 0.; GFX10-GFX11; - If 0 execute SIMD wavefronts; using oldest first policy.; - If 1 execute SIMD wavefronts to; ensure wavefronts will make some; forward progress. Used by CP to set up; ``COMPUTE_PGM_RSRC1.FWD_PROGRESS``.; 32 **Total size 4 bytes**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc2 for GFX6-GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 0 1 bit ENABLE_PRIVATE_SEGMENT * En",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:177992,Performance,perform,performed,177992,"0.; GFX11; Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..63; with a granularity of 128 bytes.; 10 1 bit TRAP_ON_START GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront starts execution by trapping into the trap handler. CP is responsible for filling in the trap on start bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_START`` according to what the runtime; requests.; 11 1 bit TRAP_ON_END GFX10; Reserved, must be 0.; GFX11; Must be 0. If 1, wavefront execution terminates by trapping into the trap handler. CP is responsible for filling in the trap on end bit in; ``COMPUTE_PGM_RSRC3.TRAP_ON_END`` according to what the runtime requests.; 30:12 19 bits Reserved, must be 0.; 31 1 bit IMAGE_OP GFX10; Reserved, must be 0.; GFX11; If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:179333,Performance,perform,performed,179333,"==============. .. .. table:: compute_pgm_rsrc3 for GFX12; :name: amdgpu-amdhsa-compute_pgm_rsrc3-gfx12-table. ======= ======= =============================== ===========================================================================; Bits Size Field Name Description; ======= ======= =============================== ===========================================================================; 3:0 4 bits RESERVED Reserved, must be 0.; 11:4 8 bits INST_PREF_SIZE Number of instruction bytes to prefetch, starting at the kernel's entry; point instruction, before wavefront starts execution. The value is 0..255; with a granularity of 128 bytes.; 12 1 bit RESERVED Reserved, must be 0.; 13 1 bit GLG_EN If 1, group launch guarantee will be enabled for this dispatch; 30:14 17 bits RESERVED Reserved, must be 0.; 31 1 bit IMAGE_OP If 1, the kernel execution contains image instructions. If executed as; part of a graphics pipeline, image read instructions will stall waiting; for any necessary ``WAIT_SYNC`` fence to be performed in order to; indicate that earlier pipeline stages have completed writing to the; image. Not used for compute kernels that are not part of a graphics pipeline and; must be 0.; 32 **Total size 4 bytes.**; ======= ===================================================================================================================. .. .. table:: Floating Point Rounding Mode Enumeration Values; :name: amdgpu-amdhsa-floating-point-rounding-mode-enumeration-values-table. ====================================== ===== ==============================; Enumeration Name Value Description; ====================================== ===== ==============================; FLOAT_ROUND_MODE_NEAR_EVEN 0 Round Ties To Even; FLOAT_ROUND_MODE_PLUS_INFINITY 1 Round Toward +infinity; FLOAT_ROUND_MODE_MINUS_INFINITY 2 Round Toward -infinity; FLOAT_ROUND_MODE_ZERO 3 Round Toward 0; ====================================== ===== ==============================. .. table:: Extended FLT_ROUNDS En",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:184614,Performance,queue,queue,184614,"``enable_sgpr_*`` bit fields, in which case only the first 16 are; actually initialized. These are then immediately followed by the System SGPRs; that are set up by ADC/SPI and can have different values for each wavefront of; the grid dispatch. SGPR register initial state is defined in; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. .. table:: SGPR Register Set Up Order; :name: amdgpu-amdhsa-sgpr-register-set-up-order-table. ========== ========================== ====== ==============================; SGPR Order Name Number Description; (kernel descriptor enable of; field) SGPRs; ========== ========================== ====== ==============================; First Private Segment Buffer 4 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; _segment_buffer); then Dispatch Ptr 2 64-bit address of AQL dispatch; (enable_sgpr_dispatch_ptr) packet for kernel dispatch; actually executing.; then Queue Ptr 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:184655,Performance,queue,queued,184655,"``enable_sgpr_*`` bit fields, in which case only the first 16 are; actually initialized. These are then immediately followed by the System SGPRs; that are set up by ADC/SPI and can have different values for each wavefront of; the grid dispatch. SGPR register initial state is defined in; :ref:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. .. table:: SGPR Register Set Up Order; :name: amdgpu-amdhsa-sgpr-register-set-up-order-table. ========== ========================== ====== ==============================; SGPR Order Name Number Description; (kernel descriptor enable of; field) SGPRs; ========== ========================== ====== ==============================; First Private Segment Buffer 4 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; _segment_buffer); then Dispatch Ptr 2 64-bit address of AQL dispatch; (enable_sgpr_dispatch_ptr) packet for kernel dispatch; actually executing.; then Queue Ptr 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:184855,Performance,load,load,184855,"f:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. .. table:: SGPR Register Set Up Order; :name: amdgpu-amdhsa-sgpr-register-set-up-order-table. ========== ========================== ====== ==============================; SGPR Order Name Number Description; (kernel descriptor enable of; field) SGPRs; ========== ========================== ====== ==============================; First Private Segment Buffer 4 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; _segment_buffer); then Dispatch Ptr 2 64-bit address of AQL dispatch; (enable_sgpr_dispatch_ptr) packet for kernel dispatch; actually executing.; then Queue Ptr 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:184876,Performance,load,loading,184876,"f:`amdgpu-amdhsa-sgpr-register-set-up-order-table`. .. table:: SGPR Register Set Up Order; :name: amdgpu-amdhsa-sgpr-register-set-up-order-table. ========== ========================== ====== ==============================; SGPR Order Name Number Description; (kernel descriptor enable of; field) SGPRs; ========== ========================== ====== ==============================; First Private Segment Buffer 4 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; _segment_buffer); then Dispatch Ptr 2 64-bit address of AQL dispatch; (enable_sgpr_dispatch_ptr) packet for kernel dispatch; actually executing.; then Queue Ptr 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:185512,Performance,load,load,185512," 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for; _X) wavefront.; then Work-Group Id Y 1 32-bit work-group id in Y; (enable_sgpr_workgroup_id dimension of grid for; _Y) wavefront.; then Work-Group Id Z 1 32-bit work-group id in Z; (enable_sgpr_workgroup_id dimension of grid for; _Z) wavefront.; then Work-Group Info 1 {first_wavefront, 14'b0000,; (enable_sgpr_workgroup ordered_append_term[10:0],; _info) threadgroup_size_in_wavefronts[5:0]}; then Scratch Wavefront Offset 1 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _segment_wavefront_offset) and; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; ========== ========================== ====== ================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:185533,Performance,load,loading,185533," 2 64-bit address of amd_queue_t; (enable_sgpr_queue_ptr) object for AQL queue on which; the dispatch packet was; queued.; then Kernarg Segment Ptr 2 64-bit address of Kernarg; (enable_sgpr_kernarg segment. This is directly; _segment_ptr) copied from the; kernarg_address in the kernel; dispatch packet. Having CP load it once avoids; loading it at the beginning of; every wavefront.; then Dispatch Id 2 64-bit Dispatch ID of the; (enable_sgpr_dispatch_id) dispatch packet being; executed.; then Flat Scratch Init 2 See; (enable_sgpr_flat_scratch :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _init); then Preloaded Kernargs N/A See; (kernarg_preload_spec :ref:`amdgpu-amdhsa-kernarg-preload`.; _length); then Private Segment Size 1 The 32-bit byte size of a; (enable_sgpr_private single work-item's memory; _segment_size) allocation. This is the; value from the kernel; dispatch packet Private; Segment Byte Size rounded up; by CP to a multiple of; DWORD. Having CP load it once avoids; loading it at the beginning of; every wavefront. This is not used for; GFX7-GFX8 since it is the same; value as the second SGPR of; Flat Scratch Init. However, it; may be needed for GFX9-GFX11 which; changes the meaning of the; Flat Scratch Init value.; then Work-Group Id X 1 32-bit work-group id in X; (enable_sgpr_workgroup_id dimension of grid for; _X) wavefront.; then Work-Group Id Y 1 32-bit work-group id in Y; (enable_sgpr_workgroup_id dimension of grid for; _Y) wavefront.; then Work-Group Id Z 1 32-bit work-group id in Z; (enable_sgpr_workgroup_id dimension of grid for; _Z) wavefront.; then Work-Group Info 1 {first_wavefront, 14'b0000,; (enable_sgpr_workgroup ordered_append_term[10:0],; _info) threadgroup_size_in_wavefronts[5:0]}; then Scratch Wavefront Offset 1 See; (enable_sgpr_private :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`.; _segment_wavefront_offset) and; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`.; ========== ========================== ====== ================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:189741,Performance,queue,queue,189741," Name Description; ======= ======= ================ =========================================; 0:9 10 bits Work-Item Id X Work-item id in X; dimension of work-group for; wavefront lane. Always initialized. 10:19 10 bits Work-Item Id Y Work-item id in Y; dimension of work-group for; wavefront lane. Initialized if enable_vgpr_workitem_id >; 0, otherwise set to 0.; 20:29 10 bits Work-Item Id Z Work-item id in Z; dimension of work-group for; wavefront lane. Initialized if enable_vgpr_workitem_id >; 1, otherwise set to 0.; 30:31 2 bits Reserved, set to 0.; ======= ======= ================ =========================================. The setting of registers is done by GPU CP/ADC/SPI hardware as follows:. 1. SGPRs before the Work-Group Ids are set by CP using the 16 User Data; registers.; 2. Work-group Id registers X, Y, Z are set by ADC which supports any; combination including none.; 3. Scratch Wavefront Offset is set by SPI in a per wavefront basis which is why; its value cannot be included with the flat scratch init value which is per; queue (see :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`).; 4. The VGPRs are set by SPI which only supports specifying either (X), (X, Y); or (X, Y, Z).; 5. Flat Scratch register pair initialization is described in; :ref:`amdgpu-amdhsa-kernel-prolog-flat-scratch`. The global segment can be accessed either using buffer instructions (GFX6 which; has V# 64-bit address support), flat instructions (GFX7-GFX11), or global; instructions (GFX9-GFX11). If buffer operations are used, then the compiler can generate a V# with the; following properties:. * base address of 0; * no swizzle; * ATC: 1 if IOMMU present (such as APU); * ptr64: 1; * MTYPE set to support memory coherence that matches the runtime (such as CC for; APU and NC for dGPU). .. _amdgpu-amdhsa-kernarg-preload:. Preloaded Kernel Arguments; ++++++++++++++++++++++++++. On hardware that supports this feature, kernel arguments can be preloaded into; User SGPRs, up to the maximum number of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:191078,Performance,load,loaded,191078,"h; has V# 64-bit address support), flat instructions (GFX7-GFX11), or global; instructions (GFX9-GFX11). If buffer operations are used, then the compiler can generate a V# with the; following properties:. * base address of 0; * no swizzle; * ATC: 1 if IOMMU present (such as APU); * ptr64: 1; * MTYPE set to support memory coherence that matches the runtime (such as CC for; APU and NC for dGPU). .. _amdgpu-amdhsa-kernarg-preload:. Preloaded Kernel Arguments; ++++++++++++++++++++++++++. On hardware that supports this feature, kernel arguments can be preloaded into; User SGPRs, up to the maximum number of User SGPRs available. The allocation of; Preload SGPRs occurs directly after the last enabled non-kernarg preload User; SGPR. (See :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). The data preloaded is copied from the kernarg segment, the amount of data is; determined by the value specified in the kernarg_preload_spec_length field of; the kernel descriptor. This data is then loaded into consecutive User SGPRs. The; number of SGPRs receiving preloaded kernarg data corresponds with the value; given by kernarg_preload_spec_length. The preloading starts at the dword offset; within the kernarg segment, which is specified by the; kernarg_preload_spec_offset field. If the kernarg_preload_spec_length is non-zero, the CP firmware will append an; additional 256 bytes to the kernel_code_entry_byte_offset. This addition; facilitates the incorporation of a prologue to the kernel entry to handle cases; where code designed for kernarg preloading is executed on hardware equipped with; incompatible firmware. If hardware has compatible firmware the 256 bytes at the; start of the kernel entry will be skipped. .. _amdgpu-amdhsa-kernel-prolog:. Kernel Prolog; ~~~~~~~~~~~~~. The compiler performs initialization in the kernel prologue depending on the; target and information about things like stack usage in the kernel and called; functions. Some of this initialization requires the compi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:191885,Performance,perform,performs,191885,"s; determined by the value specified in the kernarg_preload_spec_length field of; the kernel descriptor. This data is then loaded into consecutive User SGPRs. The; number of SGPRs receiving preloaded kernarg data corresponds with the value; given by kernarg_preload_spec_length. The preloading starts at the dword offset; within the kernarg segment, which is specified by the; kernarg_preload_spec_offset field. If the kernarg_preload_spec_length is non-zero, the CP firmware will append an; additional 256 bytes to the kernel_code_entry_byte_offset. This addition; facilitates the incorporation of a prologue to the kernel entry to handle cases; where code designed for kernarg preloading is executed on hardware equipped with; incompatible firmware. If hardware has compatible firmware the 256 bytes at the; start of the kernel entry will be skipped. .. _amdgpu-amdhsa-kernel-prolog:. Kernel Prolog; ~~~~~~~~~~~~~. The compiler performs initialization in the kernel prologue depending on the; target and information about things like stack usage in the kernel and called; functions. Some of this initialization requires the compiler to request certain; User and System SGPRs be present in the; :ref:`amdgpu-amdhsa-initial-kernel-execution-state` via the; :ref:`amdgpu-amdhsa-kernel-descriptor`. .. _amdgpu-amdhsa-kernel-prolog-cfi:. CFI; +++. 1. The CFI return address is undefined. 2. The CFI CFA is defined using an expression which evaluates to a location; description that comprises one memory location description for the; ``DW_ASPACE_AMDGPU_private_lane`` address space address ``0``. .. _amdgpu-amdhsa-kernel-prolog-m0:. M0; ++. GFX6-GFX8; The M0 register must be initialized with a value at least the total LDS size; if the kernel may access LDS via DS or flat operations. Total LDS size is; available in dispatch packet. For M0, it is also possible to use maximum; possible value of LDS for given target (0x7FFF for GFX6 and 0xFFFF for; GFX7-GFX8).; GFX9-GFX11; The M0 register is not used",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:194658,Performance,queue,queue,194658,"nel prolog. If a frame pointer is not required then all uses of the frame; pointer are replaced with immediate ``0`` offsets. .. _amdgpu-amdhsa-kernel-prolog-flat-scratch:. Flat Scratch; ++++++++++++. There are different methods used for initializing flat scratch:. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Does not support generic address space*:. Flat scratch is not supported and there is no flat scratch register pair. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Offset flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI). Initialization uses Flat Scratch Init and; Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. 1. The low word of Flat Scratch Init is the 32-bit byte offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to the base of scratch backing memory; being managed by SPI for the queue executing the kernel dispatch. This is; the same value used in the Scratch Segment Buffer V# base address. CP obtains this from the runtime. (The Scratch Segment Buffer base address; is ``SH_HIDDEN_PRIVATE_BASE_VIMID`` plus this offset.). The prolog must add the value of Scratch Wavefront Offset to get the; wavefront's byte scratch backing memory offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID``. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:196000,Performance,queue,queue,196000,"front Offset to get the; wavefront's byte scratch backing memory offset from; ``SH_HIDDEN_PRIVATE_BASE_VIMID``. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH SIZE; in flat memory instructions. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Absolute flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI which are in SGPRn-4/SGPRn-3). Initialization; uses Flat Scratch Init and Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:196048,Performance,load,loads,196048,"lso be used as an offset with Private; segment address when using the Scratch Segment Buffer. Since FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH SIZE; in flat memory instructions. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Absolute flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI which are in SGPRn-4/SGPRn-3). Initialization; uses Flat Scratch Init and Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch backing; memory being managed by SPI for the queue executing the kernel dispatch. CP obtains this from the runtime. The kernel prolog must add the v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:196167,Performance,load,load,196167,"FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH SIZE; in flat memory instructions. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Absolute flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI which are in SGPRn-4/SGPRn-3). Initialization; uses Flat Scratch Init and Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch backing; memory being managed by SPI for the queue executing the kernel dispatch. CP obtains this from the runtime. The kernel prolog must add the value of the wave's Scratch Wavefront Offset; and move the result as a 64-bit value to the FLAT_SCRAT",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:196188,Performance,load,loading,196188,"FLAT_SCRATCH_LO is in units of 256 bytes, the offset must be right; shifted by 8 before moving into FLAT_SCRATCH_HI. FLAT_SCRATCH_HI corresponds to SGPRn-4 on GFX7, and SGPRn-6 on GFX8 (where; SGPRn is the highest numbered SGPR allocated to the wavefront).; FLAT_SCRATCH_HI is multiplied by 256 (as it is in units of 256 bytes) and; added to ``SH_HIDDEN_PRIVATE_BASE_VIMID`` to calculate the per wavefront; FLAT SCRATCH BASE in flat memory instructions that access the scratch; aperture.; 2. The second word of Flat Scratch Init is 32-bit byte size of a single; work-items scratch memory usage. CP obtains this from the runtime, and it is always a multiple of DWORD. CP; checks that the value in the kernel dispatch packet Private Segment Byte; Size is not larger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH SIZE; in flat memory instructions. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Absolute flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI which are in SGPRn-4/SGPRn-3). Initialization; uses Flat Scratch Init and Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch backing; memory being managed by SPI for the queue executing the kernel dispatch. CP obtains this from the runtime. The kernel prolog must add the value of the wave's Scratch Wavefront Offset; and move the result as a 64-bit value to the FLAT_SCRAT",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:196993,Performance,queue,queue,196993,"rger and requests the runtime to increase the queue's scratch; size if necessary. CP directly loads from the kernel dispatch packet Private Segment Byte Size; field and rounds up to a multiple of DWORD. Having CP load it once avoids; loading it at the beginning of every wavefront. The kernel prolog code must move it to FLAT_SCRATCH_LO which is SGPRn-3 on; GFX7 and SGPRn-5 on GFX8. FLAT_SCRATCH_LO is used as the FLAT SCRATCH SIZE; in flat memory instructions. * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Absolute flat scratch*:. If the kernel or any function it calls may use flat operations to access; scratch memory, the prolog code must set up the FLAT_SCRATCH register pair; (FLAT_SCRATCH_LO/FLAT_SCRATCH_HI which are in SGPRn-4/SGPRn-3). Initialization; uses Flat Scratch Init and Scratch Wavefront Offset SGPR registers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch backing; memory being managed by SPI for the queue executing the kernel dispatch. CP obtains this from the runtime. The kernel prolog must add the value of the wave's Scratch Wavefront Offset; and move the result as a 64-bit value to the FLAT_SCRATCH SGPR register pair; which is SGPRn-6 and SGPRn-5. It is used as the FLAT SCRATCH BASE in flat; memory instructions. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer (see; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`). * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Architected flat scratch*:. If ENABLE_PRIVATE_SEGMENT is enabled in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table` then the FLAT_SCRATCH; register pair will be initialized to the 64-bit address of the base of scratch; backing memory being managed by SPI for the queue executing the kernel; dispatch plus the value of the wave's Scratch Wavefront Offset fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:197862,Performance,queue,queue,197862,"ers (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`):. The Flat Scratch Init is the 64-bit address of the base of scratch backing; memory being managed by SPI for the queue executing the kernel dispatch. CP obtains this from the runtime. The kernel prolog must add the value of the wave's Scratch Wavefront Offset; and move the result as a 64-bit value to the FLAT_SCRATCH SGPR register pair; which is SGPRn-6 and SGPRn-5. It is used as the FLAT SCRATCH BASE in flat; memory instructions. The Scratch Wavefront Offset must also be used as an offset with Private; segment address when using the Scratch Segment Buffer (see; :ref:`amdgpu-amdhsa-kernel-prolog-private-segment-buffer`). * If the *Target Properties* column of :ref:`amdgpu-processor-table`; specifies *Architected flat scratch*:. If ENABLE_PRIVATE_SEGMENT is enabled in; :ref:`amdgpu-amdhsa-compute_pgm_rsrc2-gfx6-gfx12-table` then the FLAT_SCRATCH; register pair will be initialized to the 64-bit address of the base of scratch; backing memory being managed by SPI for the queue executing the kernel; dispatch plus the value of the wave's Scratch Wavefront Offset for use as the; flat scratch base in flat memory instructions. .. _amdgpu-amdhsa-kernel-prolog-private-segment-buffer:. Private Segment Buffer; ++++++++++++++++++++++. If the *Target Properties* column of :ref:`amdgpu-processor-table` specifies; *Architected flat scratch* then a Private Segment Buffer is not supported.; Instead the flat SCRATCH instructions are used. Otherwise, Private Segment Buffer SGPR register is used to initialize 4 SGPRs; that are used as a V# to access scratch. CP uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:198906,Performance,optimiz,optimizations,198906," Wavefront Offset for use as the; flat scratch base in flat memory instructions. .. _amdgpu-amdhsa-kernel-prolog-private-segment-buffer:. Private Segment Buffer; ++++++++++++++++++++++. If the *Target Properties* column of :ref:`amdgpu-processor-table` specifies; *Architected flat scratch* then a Private Segment Buffer is not supported.; Instead the flat SCRATCH instructions are used. Otherwise, Private Segment Buffer SGPR register is used to initialize 4 SGPRs; that are used as a V# to access scratch. CP uses the value provided by the; runtime. It is used, together with Scratch Wavefront Offset as an offset, to; access the private memory space using a segment address. See; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`. The scratch V# is a four-aligned SGPR and always selected for the kernel as; follows:. - If it is known during instruction selection that there is stack usage,; SGPR0-3 is reserved for use as the scratch V#. Stack usage is assumed if; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:199918,Performance,perform,perform,199918,"f; optimizations are disabled (``-O0``), if stack objects already exist (for; locals, etc.), or if there are any function calls. - Otherwise, four high numbered SGPRs beginning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200083,Performance,perform,perform,200083,"inning at a four-aligned SGPR index; are reserved for the tentative scratch V#. These will be used if it is; determined that spilling is needed. - If no use is made of the tentative scratch V#, then it is unreserved,; and the register count is determined ignoring it.; - If use is made of the tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:200437,Performance,queue,queue,200437,"tentative scratch V#, then its register numbers; are shifted to the first four-aligned SGPR index after the highest one; allocated by the register allocator, and all uses are updated. The; register count includes them in the shifted location.; - In either case, if the processor has the SGPR allocation bug, the; tentative allocation is not shifted or unreserved in order to ensure; the register count is higher to workaround the bug. .. note::. This approach of using a tentative scratch V# and shifting the register; numbers if used avoids having to perform register allocation a second; time if the tentative V# is eliminated. This is more efficient and; avoids the problem that the second register allocation may perform; spilling which will fail as there is no longer a scratch V#. When the kernel prolog code is being emitted it is known whether the scratch V#; described above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the memory model specify the order of; instructions that a single thread must execute. The ``s_waitcnt`` and cache; management instructions such as ``buffer_wbinvl1_vol`` are defined with respect; to other memory instructions executed by the same thread. This allows them to be; moved earlier or la",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:201178,Performance,cache,cache,201178,"ibed above is actually used. If it is, the prolog code must set it up by; copying the Private Segment Buffer to the scratch V# registers and then adding; the Private Segment Wavefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the memory model specify the order of; instructions that a single thread must execute. The ``s_waitcnt`` and cache; management instructions such as ``buffer_wbinvl1_vol`` are defined with respect; to other memory instructions executed by the same thread. This allows them to be; moved earlier or later which can allow them to be combined with other instances; of the same instruction, or hoisted/sunk out of loops to improve performance.; Only the instructions related to the memory model are given; additional; ``s_waitcnt`` instructions are required to ensure registers are defined before; being used. These may be able to be combined with the memory model ``s_waitcnt``; instructions as described above. The AMDGPU backend supports the following memory models:. HSA Memory Model [HSA]_; The HSA memory model uses a single happens-before relation for all address; spaces (see :ref:`amdgpu-address-spaces`).; OpenCL Memory Model [OpenCL]_; The OpenCL memory model which has separate happens-before relations for the; global and local address spaces. Only a fence specifying both global and; local address space, and seq_cst instructions join the relationships. Since; t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:201494,Performance,perform,performance,201494,"avefront Offset to the queue base address in the V#. The; result is a V# with a base address pointing to the beginning of the wavefront; scratch backing memory. The Private Segment Buffer is always requested, but the Private Segment; Wavefront Offset is only requested if it is used (see; :ref:`amdgpu-amdhsa-initial-kernel-execution-state`). .. _amdgpu-amdhsa-memory-model:. Memory Model; ~~~~~~~~~~~~. This section describes the mapping of the LLVM memory model onto AMDGPU machine; code (see :ref:`memmodel`). The AMDGPU backend supports the memory synchronization scopes specified in; :ref:`amdgpu-memory-scopes`. The code sequences used to implement the memory model specify the order of; instructions that a single thread must execute. The ``s_waitcnt`` and cache; management instructions such as ``buffer_wbinvl1_vol`` are defined with respect; to other memory instructions executed by the same thread. This allows them to be; moved earlier or later which can allow them to be combined with other instances; of the same instruction, or hoisted/sunk out of loops to improve performance.; Only the instructions related to the memory model are given; additional; ``s_waitcnt`` instructions are required to ensure registers are defined before; being used. These may be able to be combined with the memory model ``s_waitcnt``; instructions as described above. The AMDGPU backend supports the following memory models:. HSA Memory Model [HSA]_; The HSA memory model uses a single happens-before relation for all address; spaces (see :ref:`amdgpu-address-spaces`).; OpenCL Memory Model [OpenCL]_; The OpenCL memory model which has separate happens-before relations for the; global and local address spaces. Only a fence specifying both global and; local address space, and seq_cst instructions join the relationships. Since; the LLVM ``memfence`` instruction does not allow an address space to be; specified the OpenCL fence has to conservatively assume both local and; global address space was specifi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:202428,Performance,optimiz,optimizations,202428,"e instructions related to the memory model are given; additional; ``s_waitcnt`` instructions are required to ensure registers are defined before; being used. These may be able to be combined with the memory model ``s_waitcnt``; instructions as described above. The AMDGPU backend supports the following memory models:. HSA Memory Model [HSA]_; The HSA memory model uses a single happens-before relation for all address; spaces (see :ref:`amdgpu-address-spaces`).; OpenCL Memory Model [OpenCL]_; The OpenCL memory model which has separate happens-before relations for the; global and local address spaces. Only a fence specifying both global and; local address space, and seq_cst instructions join the relationships. Since; the LLVM ``memfence`` instruction does not allow an address space to be; specified the OpenCL fence has to conservatively assume both local and; global address space was specified. However, optimizations can often be; done to eliminate the additional ``s_waitcnt`` instructions when there are; no intervening memory instructions which access the corresponding address; space. The code sequences in the table indicate what can be omitted for the; OpenCL memory. The target triple environment is used to determine if the; source language is OpenCL (see :ref:`amdgpu-opencl`). ``ds/flat_load/store/atomic`` instructions to local memory are termed LDS; operations. ``buffer/global/flat_load/store/atomic`` instructions to global memory are; termed vector memory operations. Private address space uses ``buffer_load/store`` using the scratch V#; (GFX6-GFX8), or ``scratch_load/store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:203501,Performance,perform,perform,203501,"tcnt`` instructions when there are; no intervening memory instructions which access the corresponding address; space. The code sequences in the table indicate what can be omitted for the; OpenCL memory. The target triple environment is used to determine if the; source language is OpenCL (see :ref:`amdgpu-opencl`). ``ds/flat_load/store/atomic`` instructions to local memory are termed LDS; operations. ``buffer/global/flat_load/store/atomic`` instructions to global memory are; termed vector memory operations. Private address space uses ``buffer_load/store`` using the scratch V#; (GFX6-GFX8), or ``scratch_load/store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-ta",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:203986,Performance,load,load,203986,"emory operations. Private address space uses ``buffer_load/store`` using the scratch V#; (GFX6-GFX8), or ``scratch_load/store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204094,Performance,load,load,204094,"store`` (GFX9-GFX11). Since only a single thread; is accessing the memory, atomic memory orderings are not meaningful, and all; accesses are treated as non-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204226,Performance,optimiz,optimization,204226,"n-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204317,Performance,optimiz,optimization-constraints-table,204317,"n-atomic. Constant address space uses ``buffer/global_load`` instructions (or equivalent; scalar memory instructions). Since the constant address space contents do not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204469,Performance,optimiz,optimization-constraints-table,204469,"o not; change during the execution of a kernel dispatch it is not legal to perform; stores, and atomic memory orderings are not meaningful, and all accesses are; treated as non-atomic. A memory synchronization scope wider than work-group is not meaningful for the; group (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204754,Performance,load,load,204754," (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204794,Performance,load,load,204794," (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204799,Performance,load,load,204799," (LDS) address space and is treated as work-group. The memory model does not support the region address space which is treated as; non-atomic. Acquire memory ordering is not meaningful on store atomic instructions and is; treated as non-atomic. Release memory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:204920,Performance,load,load,204920,"ory ordering is not meaningful on load atomic instructions and is; treated a non-atomic. Acquire-release memory ordering is not meaningful on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sec",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205070,Performance,load,load,205070,"l on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx9",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205075,Performance,load,load,205075,"l on load or store atomic; instructions and is treated as acquire and release respectively. The memory order also adds the single thread optimization constraints defined in; table; :ref:`amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table`. .. table:: AMDHSA Memory Model Single Thread Optimization Constraints; :name: amdgpu-amdhsa-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx9",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205362,Performance,load,load,205362,"-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205451,Performance,load,load,205451,"-memory-model-single-thread-optimization-constraints-table. ============ ==============================================================; LLVM Memory Optimization Constraints; Ordering; ============ ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:205640,Performance,load,load,205640,"====== ==============================================================; unordered *none*; monotonic *none*; acquire - If a load atomic/atomicrmw then no following load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved before the acquire.; - If a fence then same as load atomic, plus no preceding; associated fence-paired-atomic can be moved after the fence.; release - If a store atomic/atomicrmw then no preceding load/load; atomic/store/store atomic/atomicrmw/fence instruction can be; moved after the release.; - If a fence then same as store atomic, plus no following; associated fence-paired-atomic can be moved before the; fence.; acq_rel Same constraints as both acquire and release.; seq_cst - If a load atomic then same constraints as acquire, plus no; preceding sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved after the; seq_cst.; - If a store atomic then the same constraints as release, plus; no following sequentially consistent load atomic/store; atomic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a C",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:206638,Performance,perform,performed,206638,"omic/atomicrmw/fence instruction can be moved before the; seq_cst.; - If an atomicrmw/fence then same constraints as acq_rel.; ============ ==============================================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:206818,Performance,queue,queues,206818,"===============================================. The code sequences used to implement the memory model are defined in the; following sections:. * :ref:`amdgpu-amdhsa-memory-model-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is requir",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:206885,Performance,perform,performed,206885,"odel-gfx6-gfx9`; * :ref:`amdgpu-amdhsa-memory-model-gfx90a`; * :ref:`amdgpu-amdhsa-memory-model-gfx942`; * :ref:`amdgpu-amdhsa-memory-model-gfx10-gfx11`. .. _amdgpu-amdhsa-memory-model-gfx6-gfx9:. Memory Model GFX6-GFX9; ++++++++++++++++++++++. For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence betw",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:207311,Performance,perform,performed,207311,"For GFX6-GFX9:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coheren",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:207380,Performance,perform,performed,207380,"s for a single work-group are executed in the same CU but may be; executed by different SIMDs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operation",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:207745,Performance,cache,cache,207745,"is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208137,Performance,cache,cache,208137,"itcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208213,Performance,cache,caches,208213,"ions and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208424,Performance,cache,cache,208424," and; completion is reported to a wavefront in execution order. The exception is; that for GFX7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208478,Performance,cache,cache,208478,"7-GFX9 ``flat_load/store/atomic`` instructions can report out of; vector memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` varia",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208593,Performance,queue,queue,208593," memory order if they access LDS memory, and out of LDS operation order; if they access global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:208664,Performance,perform,performed,208664,"ons access a single vector L1 cache shared by all; SIMDs a CU. Therefore, no special action is required for coherence between the; lanes of a single wavefront, or for coherence between wavefronts in the same; work-group. A ``buffer_wbinvl1_vol`` is required for coherence between; wavefronts executing in different work-groups as they may be executing on; different CUs.; * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209137,Performance,cache,cache,209137,"ctor L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent.; * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be us",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209592,Performance,cache,cache,209592,"te request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209640,Performance,cache,caches,209640,"te request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:209670,Performance,cache,caches,209670,"ich may be executing on different CUs) of an agent can be; reordered relative to each other. A ``s_waitcnt vmcnt(0)`` is required to; ensure synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache can be kept coherent with other agents on some targets, or ranges; of virtual addresses can be set up to bypass it to ensure system coherence. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210529,Performance,cache,cache,210529,"nel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory M",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210710,Performance,cache,cache,210710,"es. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. =========",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210874,Performance,cache,cache,210874,"tes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:210905,Performance,cache,cache,210905,"tes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== =",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:211253,Performance,cache,cache,211253,"turn since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:211270,Performance,cache,cache,211270,"on call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any followin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:211343,Performance,cache,cache,211343,"on call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU the kernarg backing memory is allocated in host memory accessed as; MTYPE UC (uncached) to avoid needing to invalidate the L2 cache. This also; causes it to be treated as non-volatile and so is not invalidated by; ``*_vol``.; * On APU the kernarg backing memory it is accessed as MTYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any followin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:212018,Performance,load,load,212018,"TYPE CC (cache coherent); and so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:212335,Performance,load,load,212335,` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX6-GFX9 are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; --------------------------------------------------,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:212447,Performance,load,load,212447,dhsa-memory-model-code-sequences-gfx6-gfx9-table`. .. table:: AMDHSA Memory Model Code Sequences GFX6-GFX9; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx6-gfx9-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - gene,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:212800,Performance,load,load,212800,ine Code; Ordering Sync Scope Address GFX6-GFX9; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup;,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:213061,Performance,load,load,213061, *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ----------------------,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:213345,Performance,load,load,213345,ile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:213466,Performance,load,load,213466,"d *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214093,Performance,load,load,214093,"---------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214200,Performance,load,load,214200,"ered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214264,Performance,load,load,214264,"---------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214429,Performance,load,load,214429,"avefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214434,Performance,load,load,214434,"avefront - local; - workgroup - generic; load atomic monotonic - agent - global 1. buffer/global/flat_load; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214548,Performance,load,load,214548,"d; - system - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acqu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214584,Performance,load,load,214584,"al 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; - system; store atomic monotonic - singlethread - local 1. ds_store; - wavefront; - workgroup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - wor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214751,Performance,load,load,214751,"roup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214797,Performance,cache,cache,214797,"roup; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214880,Performance,load,load,214880,"ric; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214885,Performance,load,load,214885,"ric; - workgroup; - agent; - system; atomicrmw monotonic - singlethread - local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214937,Performance,load,loads,214937,"local 1. ds_atomic; - wavefront; - workgroup; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:214976,Performance,load,load,214976,"e Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215230,Performance,cache,cache,215230," load atomic acquire - workgroup - global 1. buffer/global_load; load atomic acquire - workgroup - local 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215313,Performance,load,load,215313,"cal 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215318,Performance,load,load,215318,"cal 1. ds/flat_load; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215369,Performance,load,loads,215369,"; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. load atomic acquire - agent - global 1. buffer/global_load; - system glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215745,Performance,load,load,215745,"sures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singleth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:215750,Performance,load,load,215750,"sures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - agent - generic 1. flat_load glc=1; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singleth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216110,Performance,cache,cache,216110," - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence fla",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216193,Performance,load,load,216193,"lat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any precedin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216198,Performance,load,load,216198,"lat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any precedin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216249,Performance,load,loads,216249,"_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216539,Performance,cache,cache,216539,"eneric; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; atomicrmw acquire - workgroup - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216622,Performance,load,load,216622," - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216627,Performance,load,load,216627," - local 1. ds/flat_atomic; - generic 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:216678,Performance,load,loads,216678,", omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. atomicrmw acquire - agent - global 1. buffer/global_atomic; - system 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:217197,Performance,load,load,217197,"ing loads; will not see stale; global data. atomicrmw acquire - agent - generic 1. flat_atomic; - system 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:217401,Performance,load,load,217401,"L, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:217406,Performance,load,load,217406,"L, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unor",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218075,Performance,load,load,218075,"nd global; flags are; specified.; - Must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; s",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218298,Performance,load,load,218298,"ed-atomic).; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218589,Performance,cache,cache,218589,"tomic. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218781,Performance,load,load,218781,"onservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218786,Performance,load,load,218786,"onservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:218857,Performance,load,loads,218857," into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; foll",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219261,Performance,load,load,219261,"pen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219272,Performance,load,load,219272,"pen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219428,Performance,perform,performing,219428,"termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219949,Performance,load,load,219949,"-----------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:219960,Performance,load,load,219960,"-----------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220072,Performance,load,load,220072,"global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_wait",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220083,Performance,load,load,220083,"global/ds/flat_store; - wavefront - local; - generic; store atomic release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_wait",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220240,Performance,perform,performing,220240,"fter; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to local have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220569,Performance,load,load,220569,"omic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220580,Performance,load,load,220580,"omic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:220740,Performance,perform,performing,220740,"e split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221226,Performance,load,load,221226,"ry have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an eq",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221237,Performance,load,load,221237,"ry have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an eq",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221349,Performance,load,load,221349," singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221360,Performance,load,load,221360," singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw release - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic; - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensu",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:221531,Performance,perform,performing,221531,"it.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:222092,Performance,load,load,222092," to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:222097,Performance,load,load,222097," to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:222402,Performance,perform,performing,222402,"tomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; fence release - singlethread *none* *none*; - wavefront; fence release - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal o",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223140,Performance,load,load,223140,"ic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; comple",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223151,Performance,load,load,223151,"ic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; comple",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223263,Performance,load,load,223263," ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223274,Performance,load,load,223274," ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; to local have; completed before; performing the; following; fence-paired-atomic. fence release - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - loc",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223564,Performance,perform,performing,223564," is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223968,Performance,load,load,223968,"; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:223979,Performance,load,load,223979,"; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224139,Performance,perform,performing,224139,"bal/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; any following store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic v",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224365,Performance,load,load,224365,"c/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224370,Performance,load,load,224370,"c/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224486,Performance,load,load,224486,"ermed the; fence-paired-atomic).; - Ensures that all; memory operations; have; completed before; performing the; following; fence-paired-atomic. **Acquire-Release Atomic**; ------------------------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any pr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224658,Performance,load,load,224658,"---------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224669,Performance,load,load,224669,"---------------------------------------------------------------------; atomicrmw acq_rel - singlethread - global 1. buffer/global/ds/flat_atomic; - wavefront - local; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224829,Performance,perform,performing,224829,"cal; - generic; atomicrmw acq_rel - workgroup - global 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224994,Performance,load,load,224994,"c/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; inv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:224999,Performance,load,load,224999,"c/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; inv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225113,Performance,load,load,225113,"perations; to local have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic. atomicrmw acq_rel - workgroup - local 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225492,Performance,load,load,225492," local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225503,Performance,load,load,225503," local load; atomic value being; acquired. atomicrmw acq_rel - workgroup - generic 1. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225615,Performance,load,load,225615,"mit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0);",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225626,Performance,load,load,225626,"mit.; - Must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0);",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:225787,Performance,perform,performing,225787,"l; memory operations; to local have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226006,Performance,cache,cache,226006,"g; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226089,Performance,load,load,226089," data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226094,Performance,load,load,226094," data read is no; older than a local load; atomic value being; acquired. atomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226145,Performance,load,loads,226145,"tomicrmw acq_rel - agent - global 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; glob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226529,Performance,load,load,226529,"store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conserva",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226540,Performance,load,load,226540,"store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conserva",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226652,Performance,load,load,226652,"/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226663,Performance,load,load,226663,"/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:226824,Performance,perform,performing,226824,"w that is; being released. 2. buffer/global_atomic; 3. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory oper",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227080,Performance,cache,cache,227080," before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; u",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227163,Performance,load,load,227163,"; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227168,Performance,load,load,227168,"; will not see stale; global data. atomicrmw acq_rel - agent - generic 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227219,Performance,load,loads,227219,"s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensur",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227628,Performance,load,load,227628," preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address spa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227633,Performance,load,load,227633," preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address spa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227731,Performance,load,load,227731," following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227736,Performance,load,load,227736," following; atomicrmw.; - Ensures that all; memory operations; to global have; completed before; performing the; atomicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227853,Performance,perform,performing,227853,"omicrmw that is; being released. 2. flat_atomic; 3. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:227952,Performance,load,load,227952,"w has; completed before; invalidating the; cache. 4. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acq_rel - singlethread *none* *none*; - wavefront; fence acq_rel - workgroup *none* 1. s_waitcnt lgkmcnt(0). - If OpenCL and; address space is; not generic, omit.; - However,; since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Must happen after; any preceding; local/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that all; memory operations; to local have; completed before; performing any; following global; memory operations.; - Ensures that the; preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229042,Performance,load,load,229042,"ng; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229053,Performance,load,load,229053,"ng; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before following; global memory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229165,Performance,load,load,229165,"emory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consiste",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229176,Performance,load,load,229176,"emory; operations. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; local/generic store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consiste",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229326,Performance,load,load,229326,"tronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all inst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229524,Performance,cache,cache,229524,"tronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. fence acq_rel - agent *none* 1. s_waitcnt lgkmcnt(0) &; - system vmcnt(0). - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all inst",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229968,Performance,load,load,229968,"es.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:229973,Performance,load,load,229973,"es.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230044,Performance,load,loads,230044,"ore/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/relea",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230251,Performance,load,load,230251,"ures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230339,Performance,load,load,230339,"ures that the; preceding; global/local/generic; load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. Th",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230430,Performance,load,load,230430,"he; acquire-fence-paired-atomic); has completed; before invalidating; the cache. This; satisfies the; requirements of; acquire.; - Ensures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have alre",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230554,Performance,load,load,230554,"ures that all; previous memory; operations have; completed before a; following; global/local/generic; store; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; release-fence-paired-atomic).; This satisfies the; requirements of; release. 2. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions eve",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:230992,Performance,load,load,230992,"eneric; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. This; satisfies the; requirements of; acquire. **Sequential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231076,Performance,load,load,231076,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231232,Performance,load,load,231232,"uential Consistent Atomic**; ------------------------------------------------------------------------------------; load atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local load atomic acquire,; - generic except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231365,Performance,load,load,231365,"ns even; for OpenCL.*; load atomic seq_cst - workgroup - global 1. s_waitcnt lgkmcnt(0); - generic. - Must; happen after; preceding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; orderin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231519,Performance,load,load,231519,"ding; local/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; n",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231601,Performance,load,load,231601,"that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231665,Performance,load,load,231665,"that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:231746,Performance,load,load,231746,"d.); - Ensures any; preceding; sequential; consistent local; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232066,Performance,load,load,232066,"uire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232349,Performance,load,load,232349,"d to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; load atomic seq_cst - workgroup - local *Same as corresponding; load atomic acquire,; except must generate; all instructions even; for OpenCL.*. load atomic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instru",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232786,Performance,load,load,232786,"mic seq_cst - agent - global 1. s_waitcnt lgkmcnt(0) &; - system - generic vmcnt(0). - Could be split into; separate s_waitcnt; vmcnt(0); and s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:232870,Performance,load,load,232870,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:233026,Performance,load,load,233026,"em to be; independently moved; according to the; following rules.; - s_waitcnt lgkmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:233159,Performance,load,load,233159,"s have their; own s_waitcnt; lgkmcnt(0) and so do; not need to be; considered.); - s_waitcnt vmcnt(0); must happen after; preceding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader ar",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:233313,Performance,load,load,233313,"ding; global/generic load; atomic/store; atomic/atomicrmw; with memory; ordering of seq_cst; and with equal or; wider sync scope.; (Note that seq_cst; fences have their; own s_waitcnt; vmcnt(0) and so do; not need to be; considered.); - Ensures any; preceding; sequential; consistent global; memory instructions; have completed; before executing; this sequentially; consistent; instruction. This; prevents reordering; a seq_cst store; followed by a; seq_cst load. (Note; that seq_cst is; stronger than; acquire/release as; the reordering of; load acquire; followed by a store; release is; prevented by the; s_waitcnt of; the release, but; there is nothing; preventing a store; release followed by; load acquire from; completing out of; order. The s_waitcnt; could be placed after; seq_store or before; the seq_load. We; choose the load to; make the s_waitcnt be; as late as possible; so that the store; may have already; completed.). 2. *Following; instructions same as; corresponding load; atomic acquire,; except must generate; all instructions even; for OpenCL.*; store atomic seq_cst - singlethread - global *Same as corresponding; - wavefront - local store atomic release,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; atomicrmw seq_cst - singlethread - global *Same as corresponding; - wavefront - local atomicrmw acq_rel,; - workgroup - generic except must generate; - agent all instructions even; - system for OpenCL.*; fence seq_cst - singlethread *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:234811,Performance,perform,performed,234811,"ead *none* *Same as corresponding; - wavefront fence acq_rel,; - workgroup except must generate; - agent all instructions even; - system for OpenCL.*; ============ ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; glo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:234991,Performance,queue,queues,234991,"======== ============ ============== ========== ================================. .. _amdgpu-amdhsa-memory-model-gfx90a:. Memory Model GFX90A; +++++++++++++++++++. For GFX90A:. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for cohe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235058,Performance,perform,performed,235058,":. * Each agent has multiple shader arrays (SA).; * Each SA has multiple compute units (CU).; * Each CU has multiple SIMDs that execute wavefronts.; * The wavefronts for a single work-group are executed in the same CU but may be; executed by different SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235484,Performance,perform,performed,235484,"ferent SIMDs. The exception is when in tgsplit execution mode; when the wavefronts may be executed by different SIMDs in different CUs.; * Each CU has a single LDS memory shared by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence be",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235553,Performance,perform,performed,235553," by the wavefronts of the work-groups; executing on it. The exception is when in tgsplit execution mode when no LDS; is allocated as wavefronts of the same work-group can be in different CUs.; * All LDS operations of a CU are performed as wavefront wide operations in a; global order and involve no caching. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:235904,Performance,cache,cache,235904,"g. Completion is reported to a wavefront in; execution order.; * The LDS memory has multiple request queues shared by the SIMDs of a; CU. Therefore, the LDS operations performed by different wavefronts of a; work-group can be reordered relative to each other, which can result in; reordering the visibility of vector memory operations with respect to LDS; operations of other wavefronts in the same work-group. A ``s_waitcnt; lgkmcnt(0)`` is required to ensure synchronization between LDS operations and; vector memory operations between wavefronts of a work-group, but not between; operations performed by the same wavefront.; * The vector memory operations are performed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236555,Performance,cache,cache,236555,"erformed as wavefront wide operations and; completion is reported to a wavefront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to mee",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236631,Performance,cache,caches,236631,"ront in execution order. The exception is; that ``flat_load/store/atomic`` instructions can report out of vector memory; order if they access LDS memory, and out of LDS operation order if they access; global memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent ca",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236842,Performance,cache,cache,236842,"l memory.; * The vector memory operations access a single vector L1 cache shared by all; SIMDs a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:236895,Performance,cache,cache,236895," a CU. Therefore:. * No special action is required for coherence between the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines w",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237010,Performance,queue,queue,237010,"n the lanes of a single; wavefront. * No special action is required for coherence between wavefronts in the same; work-group since they execute on the same CU. The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with oth",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237081,Performance,perform,performed,237081,". The exception is when in; tgsplit execution mode as wavefronts of the same work-group can be in; different CUs and so a ``buffer_wbinvl1_vol`` is required as described in; the following item. * A ``buffer_wbinvl1_vol`` is required for coherence between wavefronts; executing in different work-groups as they may be executing on different; CUs. * The scalar memory operations access a scalar L1 cache shared by all wavefronts; on a group of CUs. The scalar and vector L1 caches are not coherent. However,; scalar operations are used in a restricted way so do not impact the memory; model. See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237609,Performance,cache,cache,237609,". See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237717,Performance,cache,cache-coherent,237717,". See :ref:`amdgpu-amdhsa-memory-spaces`.; * The vector and scalar memory operations use an L2 cache shared by all CUs on; the same agent. * The L2 cache has independent channels to service disjoint ranges of virtual; addresses.; * Each CU has a separate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeb",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:237917,Performance,cache,cache,237917,"eparate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238008,Performance,cache,caches,238008,"eparate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238052,Performance,cache,cache,238052,"eparate request queue per channel. Therefore, the vector and; scalar memory operations performed by wavefronts executing in different; work-groups (which may be executing on different CUs), or the same; work-group if executing in tgsplit mode, of an agent can be reordered; relative to each other. A ``s_waitcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238319,Performance,cache,cached,238319,"tcnt vmcnt(0)`` is required to ensure; synchronization between vector memory operations of different CUs. It; ensures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note tha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238422,Performance,cache,cache,238422,"nsures a previous vector memory operation has completed before executing a; subsequent vector memory or LDS operation and so can be used to meet the; requirements of acquire and release.; * The L2 cache of one agent can be kept coherent with other agents by:; using the MTYPE RW (read-write) or MTYPE CC (cache-coherent) with the PTE; C-bit for memory local to the L2; and using the MTYPE NC (non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads t",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:238762,Performance,cache,cache,238762,"(non-coherent) with; the PTE C-bit set or MTYPE UC (uncached) for memory not local to the L2. * Any local memory cache lines will be automatically invalidated by writes; from CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are on",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239068,Performance,cache,cache,239068," CUs associated with other L2 caches, or writes from the CPU, due to; the cache probe caused by coherent requests. Coherent requests are caused; by GPU accesses to pages with the PTE C-bit set, by CPU accesses over; XGMI, and by PCIe requests that are configured to be coherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for progra",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239228,Performance,cache,cache,239228,"oherent requests.; * XGMI accesses from the CPU to local memory may be cached on the CPU.; Subsequent access from the GPU will automatically invalidate or writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239480,Performance,cache,cache,239480," writeback; the CPU cache due to the L2 probe filter and and the PTE C-bit being set.; * Since all work-groups on the same agent share the same L2, no L2; invalidation or writeback is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR regi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:239614,Performance,cache,cache,239614,"is required for coherence.; * To ensure coherence of local and remote memory writes of work-groups in; different agents a ``buffer_wbl2`` is required. It will writeback dirty L2; cache lines of MTYPE RW (used for local coarse grain memory) and MTYPE NC; ()used for remote coarse grain memory). Note that MTYPE CC (used for local; fine grain memory) causes write through to DRAM, and MTYPE UC (used for; remote fine grain memory) bypasses the L2, so both will never result in; dirty L2 cache lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:240080,Performance,cache,cache,240080,"che lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:240128,Performance,cache,caches,240128,"che lines.; * To ensure coherence of local and remote memory reads of work-groups in; different agents a ``buffer_invl2`` is required. It will invalidate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:240158,Performance,cache,caches,240158,"validate L2; cache lines with MTYPE NC (used for remote coarse grain memory). Note that; MTYPE CC (used for local fine grain memory) and MTYPE RW (used for local; coarse memory) cause local reads to be invalidated by remote writes with; with the PTE C-bit so these cache lines are not invalidated. Note that; MTYPE UC (used for remote fine grain memory) bypasses the L2, so will; never result in L2 cache lines that need to be invalidated. * PCIe access from the GPU to the CPU memory is kept coherent by using the; MTYPE UC (uncached) which bypasses the L2. Scalar memory operations are only used to access memory that is proven to not; change during the execution of the kernel dispatch. This includes constant; address space and global address space for program scope ``const`` variables.; Therefore, the kernel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241017,Performance,cache,cache,241017,"nel machine code does not have to maintain the scalar cache to; ensure it is coherent with the vector caches. The scalar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241217,Performance,cache,cache,241217,"calar and vector caches are; invalidated between kernel dispatches by CP since constant address space data; may change between kernel dispatch executions. See; :ref:`amdgpu-amdhsa-memory-spaces`. The one exception is if scalar writes are used to spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ===",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241377,Performance,cache,cache,241377,"spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ==================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241408,Performance,cache,cache,241408,"spill SGPR registers. In this; case the AMDGPU backend ensures the memory location used to spill is never; accessed by vector memory operations at the same time. If scalar writes are used; then a ``s_dcache_wb`` is inserted before the ``s_endpgm`` and before a function; return since the locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ==================",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241756,Performance,cache,cache,241756,"locations may be used for vector memory instructions by a; future wavefront that uses the same scratch area, or a function call that; creates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241773,Performance,cache,cache,241773,"reates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; glo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:241846,Performance,cache,cache,241846,"reates a frame at the same address, respectively. There is no need for a; ``s_dcache_inv`` as all scalar writes are write-before-read in the same thread. For kernarg backing memory:. * CP invalidates the L1 cache at the start of each kernel dispatch.; * On dGPU over XGMI or PCIe the kernarg backing memory is allocated in host; memory accessed as MTYPE UC (uncached) to avoid needing to invalidate the L2; cache. This also causes it to be treated as non-volatile and so is not; invalidated by ``*_vol``.; * On APU the kernarg backing memory is accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; glo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:242506,Performance,load,load,242506,"accessed as MTYPE CC (cache coherent) and; so the L2 cache will be coherent with the CPU and other agents. Scratch backing memory (which is used for the private address space) is accessed; with MTYPE NC_NV (non-coherent non-volatile). Since the private address space is; only accessed by a single thread, and is always write-before-read, there is; never a need to invalidate these entries from the L1 cache. Hence all cache; invalidates are done as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; ad",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:242823,Performance,load,load,242823,one as ``*_vol`` to only invalidate the volatile cache lines. The code sequences used to implement the memory model for GFX90A are defined; in table :ref:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; --------------------------------------------------,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:242935,Performance,load,load,242935,f:`amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table`. .. table:: AMDHSA Memory Model Code Sequences GFX90A; :name: amdgpu-amdhsa-memory-model-code-sequences-gfx90a-table. ============ ============ ============== ========== ================================; LLVM Instr LLVM Memory LLVM Memory AMDGPU AMDGPU Machine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monoton,MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243288,Performance,load,load,243288,"achine Code; Ordering Sync Scope Address GFX90A; Space; ============ ============ ============== ========== ================================; **Non-Atomic**; ------------------------------------------------------------------------------------; load *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243549,Performance,load,load,243549," *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_load; - constant; - !volatile & nontemporal. 1. buffer/global/flat_load; glc=1 slc=1. - volatile. 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic m",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243833,Performance,load,load,243833,"ile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:243930,Performance,load,load,243930,"dware. load *none* *none* - local 1. ds_load; store *none* *none* - global - !volatile & !nontemporal; - generic; - private 1. buffer/global/flat_store; - constant; - !volatile & nontemporal. 1. buffer/global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - gene",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:244064,Performance,load,load,244064,"global/flat_store; glc=1 slc=1. - volatile. 1. buffer/global/flat_store; 2. s_waitcnt vmcnt(0). - Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; -----------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:244213,Performance,load,load,244213,"Must happen before; any following volatile; global/generic; load/store.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - glob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:244297,Performance,load,load,244297,"re.; - Ensures that; volatile; operations to; different; addresses will not; be reordered by; hardware. store *none* *none* - local 1. ds_store; **Unordered Atomic**; ------------------------------------------------------------------------------------; load atomic unordered *any* *any* *Same as non-atomic*.; store atomic unordered *any* *any* *Same as non-atomic*.; atomicrmw unordered *any* *any* *Same as monotonic atomic*.; **Monotonic Atomic**; ------------------------------------------------------------------------------------; load atomic monotonic - singlethread - global 1. buffer/global/flat_load; - wavefront - generic; load atomic monotonic - workgroup - global 1. buffer/global/flat_load; - generic glc=1. - If not TgSplit execution; mode, omit glc=1. load atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245188,Performance,load,load,245188,"cal address space cannot; - workgroup be used.*. 1. ds_load; load atomic monotonic - agent - global 1. buffer/global/flat_load; - generic glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245295,Performance,load,load,245295,"ric glc=1; load atomic monotonic - system - global 1. buffer/global/flat_load; - generic glc=1; store atomic monotonic - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; - workgroup; - agent; store atomic monotonic - system - global 1. buffer/global/flat_store; - generic; store atomic monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) i",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245648,Performance,load,load,245648,"ecution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245653,Performance,load,load,245653,"ecution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245725,Performance,load,loads,245725,"s_store; atomicrmw monotonic - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245757,Performance,load,load,245757,"- wavefront - generic; - workgroup; - agent; atomicrmw monotonic - system - global 1. buffer/global/flat_atomic; - generic; atomicrmw monotonic - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/glo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245975,Performance,load,load,245975,"ocal *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:245980,Performance,load,load,245980,"ocal *If TgSplit execution mode,; - wavefront local address space cannot; - workgroup be used.*. 1. ds_atomic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3.",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246096,Performance,load,load,246096,"mic; **Acquire Atomic**; ------------------------------------------------------------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246132,Performance,load,load,246132,"---------------------------------; load atomic acquire - singlethread - global 1. buffer/global/ds/flat_load; - wavefront - local; - generic; load atomic acquire - workgroup - global 1. buffer/global_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246481,Performance,load,load,246481,"on; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246486,Performance,load,load,246486,"on; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/g",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246600,Performance,load,load,246600,"mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246727,Performance,load,loads,246727,"ds will not see; stale data. load atomic acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. fl",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246759,Performance,load,load,246759," workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_load; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0)",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246917,Performance,load,load,246917," before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:246963,Performance,cache,cache,246963," before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_loa",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247046,Performance,load,load,247046,"s any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247051,Performance,load,load,247051,"s any; following global; data read is no; older than the local load; atomic value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247103,Performance,load,loads,247103,"c value being; acquired. load atomic acquire - workgroup - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; f",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247142,Performance,load,load,247142,"up - generic 1. flat_load glc=1. - If not TgSplit execution; mode, omit glc=1. 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247323,Performance,load,load,247323," execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247369,Performance,cache,cache,247369," execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must ha",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247467,Performance,load,load,247467," following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before inv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247472,Performance,load,load,247472," following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before inv",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247524,Performance,load,loads,247524,"owing global; data read is no; older than a local load; atomic value being; acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247685,Performance,load,load,247685,"sures that; following; loads will not see; stale data. load atomic acquire - agent - global 1. buffer/global_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global dat",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:247978,Performance,cache,cache,247978,"validating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248061,Performance,load,load,248061,"ad/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248066,Performance,load,load,248066,"ad/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248117,Performance,load,loads,248117," stale global data. load atomic acquire - system - global 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit exe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248157,Performance,load,load,248157,"al 1. buffer/global/flat_load; glc=1; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the load; has completed; before invalidating; the cache. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; followi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248469,Performance,cache,caches,248469," following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; fol",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248568,Performance,load,load,248568,"obal data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248573,Performance,load,load,248573,"obal data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; lo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:248625,Performance,load,loads,248625," in L2 due to; the memory probes. load atomic acquire - agent - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. load atomic acquire - system - generic 1. flat_load glc=1; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249266,Performance,cache,cache,249266,"0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following glob",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249390,Performance,load,load,249390,"2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249395,Performance,load,load,249395,"2 and; buffer_wbinvl1_vol.; - Ensures the flat_load; has completed; before invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - E",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249446,Performance,load,loads,249446,"invalidating; the caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire -",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249704,Performance,load,load,249704,"l data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:249709,Performance,load,load,249709,"l data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw acquire - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw acquire - workgroup - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - If not TgSplit execution; mode, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250157,Performance,load,load,250157,"e, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250162,Performance,load,load,250162,"e, omit.; - Must happen before the; following buffer_wbinvl1_vol.; - Ensures the atomicrmw; has completed; before invalidating; the cache. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250401,Performance,load,loads,250401,"tomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomi",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250636,Performance,cache,cache,250636," 2. s_waitcnt lgkmcnt(0). - If OpenCL, omit.; - Must happen before; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250719,Performance,load,load,250719,"ad/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any followin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250724,Performance,load,load,250724,"ad/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any followin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:250775,Performance,load,loads,250775,"lobal; data read is no; older than the local; atomicrmw value; being acquired. atomicrmw acquire - workgroup - generic 1. flat_atomic; 2. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251036,Performance,cache,caches,251036,"if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251135,Performance,load,load,251135,"nd; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidatin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251140,Performance,load,load,251140,"nd; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidatin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251192,Performance,load,loads,251192,"ny; following global; data read is no; older than a local; atomicrmw value; being acquired. 3. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. atomicrmw acquire - agent - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251642,Performance,cache,cache,251642,"efore; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251725,Performance,load,load,251725,"neric; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgk",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251730,Performance,load,load,251730,"neric; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgk",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:251781,Performance,load,loads,251781," not see stale; global data. atomicrmw acquire - system - global 1. buffer/global_atomic; 2. s_waitcnt vmcnt(0). - Must happen before; following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - Howe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:252129,Performance,cache,caches,252129,"fore; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; glo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:252228,Performance,load,load,252228,"le L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unorde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:252233,Performance,load,load,252233,"le L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unorde",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:252285,Performance,load,loads,252285,"be stale in L2 due to; the memory probes. atomicrmw acquire - agent - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; cache. 3. buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. atomicrmw acquire - system - generic 1. flat_atomic; 2. s_waitcnt vmcnt(0) &; lgkmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Must happen before; following; buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures the; atomicrmw has; completed before; invalidating the; caches. 3. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any p",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:253111,Performance,load,load,253111,"l2;; buffer_wbinvl1_vol. - Must happen before; any following; global/generic; load/load; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:253336,Performance,load,load,253336,"E RW and CC memory will; never be stale in L2 due to; the memory probes. fence acquire - singlethread *none* *none*; - wavefront; fence acquire - workgroup *none* 1. s_waitcnt lgkm/vmcnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must hap",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:253579,Performance,load,load,253579,"cnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:253584,Performance,load,load,253584,"cnt(0). - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - If OpenCL and; address space is; local, omit; vmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:253826,Performance,load,loads,253826,"ss space on; the fence need to; conservatively; always generate. If; fence had an; address space then; set to address; space of OpenCL; fence flag, or to; generic if both; local and global; flags are; specified.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/; atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; b",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:254415,Performance,load,load,254415,"ermed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol and; any following; global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures any; following global; data read is no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently h",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:254638,Performance,load,load,254638,"no; older than the; value read by the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - If not TgSplit execution; mode, omit.; - Ensures that; following; loads will not see; stale data. fence acquire - agent *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independe",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:254929,Performance,cache,cache,254929,"s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than;",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255121,Performance,load,load,255121,"onservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unord",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255126,Performance,load,load,255126,"onservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unord",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255197,Performance,load,loads,255197," into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the followin",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:255795,Performance,load,load,255795,"wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; -----------------------------------------",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256018,Performance,load,load,256018,"_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following loads; will not see stale; global data. fence acquire - system *none* 1. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256326,Performance,cache,cache,256326,"(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - However, since LLVM; currently has no; address space on; the fence need to; conservatively; always generate; (see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - I",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256533,Performance,load,load,256533,"(see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256538,Performance,load,load,256538,"(see comment for; previous fence).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; ato",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:256610,Performance,load,loads,256610,"kmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic load; atomic/atomicrmw; with an equal or; wider sync scope; and memory ordering; stronger than; unordered (this is; termed the; fence-paired-atomic).; - Must happen before; the following buffer_invl2 and; buffer_wbinvl1_vol.; - Ensures that the; fence-paired atomic; has completed; before invalidating; the; cache. Therefore; any following; locations read must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory oper",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257386,Performance,load,load,257386,"must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257399,Performance,load,load,257399,"must; be no older than; the value read by; the; fence-paired-atomic. 2. buffer_invl2;; buffer_wbinvl1_vol. - Must happen before any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257511,Performance,load,load,257511,"fore any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257522,Performance,load,load,257522,"fore any; following global/generic; load/load; atomic/store/store; atomic/atomicrmw.; - Ensures that; following; loads will not see; stale L1 global data,; nor see stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the fo",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:257669,Performance,perform,performing,257669,"e stale L2 MTYPE; NC global data.; MTYPE RW and CC memory will; never be stale in L2 due to; the memory probes.; **Release Atomic**; ------------------------------------------------------------------------------------; store atomic release - singlethread - global 1. buffer/global/flat_store; - wavefront - generic; store atomic release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_store; store atomic release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_sto",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258297,Performance,load,load,258297,"- If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258308,Performance,load,load,258308,"- If OpenCL, omit lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258420,Performance,load,load,258420,"omic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258431,Performance,load,load,258431,"omic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atom",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:258588,Performance,perform,performing,258588,"n before; the following; store.; - Ensures that all; memory operations; have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_store; store atomic release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259263,Performance,load,load,259263,"t happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259274,Performance,load,load,259274,"t happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; a",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259386,Performance,load,load,259386,"ust happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259397,Performance,load,load,259397,"ust happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicr",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:259576,Performance,perform,performing,259576,"ns; to memory have; completed before; performing the; store that is being; released. 2. buffer/global/flat_store; store atomic release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL and; address space is; not generic, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260154,Performance,load,load,260154,"ently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260167,Performance,load,load,260167,"ently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after any; preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; l",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260279,Performance,load,load,260279,"ad/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260290,Performance,load,load,260290,"ad/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after any; preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures ",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:260441,Performance,perform,performing,260441,".; - Must happen before; the following; store.; - Ensures that all; memory operations; to memory and the L2; writeback have; completed before; performing the; store that is being; released. 3. buffer/global/flat_store; atomicrmw release - singlethread - global 1. buffer/global/flat_atomic; - wavefront - generic; atomicrmw release - singlethread - local *If TgSplit execution mode,; - wavefront local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - workgroup - global 1. s_waitcnt lgkm/vmcnt(0); - generic; - Use lgkmcnt(0) if not; TgSplit execution mode; and vmcnt(0) if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw rele",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261034,Performance,load,load,261034," if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261045,Performance,load,load,261045," if TgSplit; execution mode.; - If OpenCL, omit; lgkmcnt(0).; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst:261157,Performance,load,load,261157,"al/generic load/store/; load atomic/store atomic/; atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; have; completed before; performing the; atomicrmw that is; being released. 2. buffer/global/flat_atomic; atomicrmw release - workgroup - local *If TgSplit execution mode,; local address space cannot; be used.*. 1. ds_atomic; atomicrmw release - agent - global 1. s_waitcnt lgkmcnt(0) &; - generic vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/atomicrmw.; - Must happen before; the following; atomicrmw.; - Ensures that all; memory operations; to global and local; have completed; before performing; the atomicrmw that; is being released. 2. buffer/global/flat_atomic; atomicrmw release - system - global 1. buffer_wbl2; - generic; - Must happen before; following s_waitcnt.; - Performs L2 writeback to; ensure previous; global/generic; store/atomicrmw are; visible at system scope. 2. s_waitcnt lgkmcnt(0) &; vmcnt(0). - If TgSplit execution mode,; omit lgkmcnt(0).; - If OpenCL, omit; lgkmcnt(0).; - Could be split into; separate s_waitcnt; vmcnt(0) and; s_waitcnt; lgkmcnt(0) to allow; them to be; independently moved; according to the; following rules.; - s_waitcnt vmcnt(0); must happen after; any preceding; global/generic; load/store/load; atomic/store; atomic/atomicrmw.; - s_waitcnt lgkmcnt(0); must happen after; any preceding; local/generic; load/store/load; atomic/store; atomic/at",MatchSource.DOCS,interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/llvm/docs/AMDGPUUsage.rst
