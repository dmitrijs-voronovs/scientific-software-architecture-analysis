id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:59,Testability,log,logs,59,"""""""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:183,Testability,log,logs,183,"""""""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:204,Testability,log,log,204,"""""""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:275,Testability,log,log,275,"""""""; Build a list of BackpressureEvents from the specified logs, using matched ""start"" and ""end"" events for a particular; pod to delimit the duration of the BackpressureEvent. :param logs: a list of JSON log files, each of which is a list of JSON objects each representing a log entry.; :return: a list of BackpressureEvents.; """"""",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:100,Testability,log,log,100,"# Complete BackpressureEvent objects corresponding to a matched pair of backpressure start and stop log entries for; # a pod.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:20,Testability,log,log,20,"# Already-processed log entry ids to ignore duplicates in overlapping log file ranges.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:70,Testability,log,log,70,"# Already-processed log entry ids to ignore duplicates in overlapping log file ranges.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:62,Integrability,message,messages,62,"# pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:143,Integrability,message,message,143,"# pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:58,Testability,log,log,58,"# pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:139,Testability,log,log,139,"# pod names for which we have seen a ""backpressure start"" log messages and for which we are now awaiting a matching; # ""backpressure stop"" log message for the same pod name.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:12,Testability,log,logs,12,"# Merge the logs so the sorting covers all log entries.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:43,Testability,log,log,43,"# Merge the logs so the sorting covers all log entries.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:48,Testability,log,log,48,"# There are actually two timestamps in the JSON log entries which appear to represent different concepts:; # time emitted ('jsonPayload.localTimestamp') versus time added to the log ('timestamp'). Time emitted would; # seem to be preferable but that value is not specified with a timezone and is ambiguously interpreted by; # the parsing code as being EST when it's actually UTC. This can make reading the report a bit confusing or; # misleading. In practice the timestamps only seem to differ by small amounts, so no big deal to use; # 'timestamp' with its explicit UTC timezone.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py:178,Testability,log,log,178,"# There are actually two timestamps in the JSON log entries which appear to represent different concepts:; # time emitted ('jsonPayload.localTimestamp') versus time added to the log ('timestamp'). Time emitted would; # seem to be preferable but that value is not specified with a timezone and is ambiguously interpreted by; # the parsing code as being EST when it's actually UTC. This can make reading the report a bit confusing or; # misleading. In practice the timestamps only seem to differ by small amounts, so no big deal to use; # 'timestamp' with its explicit UTC timezone.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_event.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_event.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py:28,Integrability,depend,dependent,28,"# The logic below is highly dependent on events being sorted by start timestamp oldest to newest.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py:6,Testability,log,logic,6,"# The logic below is highly dependent on events being sorted by start timestamp oldest to newest.",MatchSource.CODE_COMMENT,scripts/backpressure_report/backpressure_report/lib/backpressure_window.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/backpressure_report/backpressure_report/lib/backpressure_window.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1130,Deployability,install,install,1130,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1161,Deployability,install,install,1161,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1171,Deployability,upgrade,upgrade,1171,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1214,Deployability,install,install,1214,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1224,Deployability,upgrade,upgrade,1224,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:64,Performance,perform,performance,64,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1271,Testability,log,login,1271,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1368,Testability,log,login,1368,"#!/usr/bin/env python3; #; # comparer.py; #; # Purpose: Compare performance metadata JSON files produced by Digester and produce result in CSV format; #; # Usage: python3 -m metadata_comparison.comparer [-h] [-v] [--force]; # --name1 NAME_FOR_DIGEST_1 --name2 NAME_FOR_DIGEST_2; # --digest1 PATH_TO_DIGEST_1 --digest2 PATH_TO_DIGEST_2 --output-path OUTPUT_PATH; # [--call-prefix-to-remove [CALL_PREFIX_TO_REMOVE [CALL_PREFIX_TO_REMOVE ...]]]; #; # For ExomeGermlineSingleSample workflows the local call names are globally unique so all; # FQN prefixes can be removed for ease of interpretation. An invocation to compare PAPI v1; # to PAPI v2 might look like:; #; # python3 -m metadata_comparison.comparer --name1 PAPIv1 --name2 PAPIv2 \; # --digest1 papiv1.json --digest2 papiv2.json --output-path comparison.csv \; # --call-prefix-to-remove ExomeGermlineSingleSample.AggregatedBamQC. \; # ExomeGermlineSingleSample.BamToCram. ExomeGermlineSingleSample.BamToGvcf.VariantCalling. \; # ExomeGermlineSingleSample.UnmappedBamToAlignedBam. ExomeGermlineSingleSample.; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:413,Energy Efficiency,reduce,reduces,413,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:813,Energy Efficiency,reduce,reduced,813,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1095,Energy Efficiency,reduce,reduce,1095,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1160,Energy Efficiency,reduce,reduced,1160,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:892,Performance,perform,performance,892,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py:1201,Testability,test,test,1201,"#; # ($85 / month) / (30.436875 days / month) = $2.792667 / day; # ($2.792667 / day) / (24 hours / day) = $0.116361 / hour; #; # So as we're currently using it the reference disk alone is more expensive than the VM for 90+ % of the jobs; # in the ExomeGermlineSingleSample v1.3 workflows.; #; # Can this be improved? Sure, for EGSS v1.3 a 500 GB disk is way bigger than it needs to be. Making it 50 GB; # instead reduces disk cost by a factor of 10 for a rate of $0.011636 per hour. Better but relative to; # machine pricing that's still way too high. Switching from HDD to SSD also helps:; #; # $0.011636/hour * (HDD / SSD = 0.04 / 0.17 = $0.00273790/hour; #; # Given that running times here; #; # https://docs.google.com/spreadsheets/d/1x8TqiVUGZ7nHU-mxPHFdGnJ3U58fPk5l5dR839XsOBI/edit#gid=804873366; #; # were reduced by < 10%, even after making these adjustments (and that's assuming the performance; # benefits of a 500GB SSD will carry over to a 50GB HDD, which they likely won't, and this is one more; # thing we shouldn't make rosy assumptions about), is using a reference disk going to reduce or increase cost?; # It's possible the disk size could be reduced even more, but mostly this needs test runs.; #; # A machine type-weighted dictionary used for getting more accurate cost estimates.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/comparer.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/comparer.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:259,Deployability,install,install,259,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:290,Deployability,install,install,290,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:300,Deployability,upgrade,upgrade,300,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:343,Deployability,install,install,343,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:353,Deployability,upgrade,upgrade,353,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:392,Deployability,install,install,392,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:402,Deployability,upgrade,upgrade,402,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:63,Performance,perform,performance,63,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:444,Testability,log,login,444,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:541,Testability,log,login,541,"#!/usr/bin/env python3; #; # digester.py; #; # Purpose: Digest performance metadata JSON files produced by the Extractor.; #; # Usage: python3 -m metadata_comparison.digester PATH [PATHs...]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade python-dateutil; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py:416,Performance,perform,performance,416,"# This script should only ever be pointed at successful workflow metadata. All jobs that have a backend status; # other than `Success` must have later been re-run successfully, so any un`Success`ful attempts are ignored.; # It's possible that a future version of the digester might actually want to look at these jobs since they; # may have completed some lifecycle events which could be useful in accumulating more performance data.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:307,Deployability,install,install,307,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:338,Deployability,install,install,338,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:348,Deployability,upgrade,upgrade,348,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:375,Deployability,install,install,375,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:385,Deployability,upgrade,upgrade,385,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:428,Deployability,install,install,428,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:438,Deployability,upgrade,upgrade,438,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:469,Deployability,install,install,469,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:479,Deployability,upgrade,upgrade,479,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:518,Deployability,install,install,518,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:528,Deployability,upgrade,upgrade,528,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:564,Testability,log,login,564,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py:661,Testability,log,login,661,"#!/usr/bin/env python3; #; # extractor.py; #; # Purpose: Read workflow metadata from Cromwell, and all metadata for its jobs,; # and upload it to a GCS bucket; #; # Usage: python3 extractor.py <GCS path> <workflowId> [<workflowId2> [...]]; #; # Python Prereqs (at least, the ones which I needed to manually install... YMMV):; #; # * pip3 install --upgrade requests; # * pip3 install --upgrade google-api-python-client; # * pip3 install --upgrade google-cloud; # * pip3 install --upgrade google-cloud-storage; # * pip3 install --upgrade gitpython; #; # Remember to login to create application default credentials before use:; # % gcloud auth application-default login",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/extractor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/extractor.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py:125,Modifiability,flexible,flexible,125,"""""""; Validates then extract the root of the Cromwell URL from the various URL strings which might be provided.; Deliberately flexible because it's tedious to remember which script requires which type of format.; eg:; 'http://localhost' => 'http://localhost'; 'http://localhost:8000' => 'http://localhost:8000'; 'http://localhost:8000/' => 'http://localhost:8000'; 'http://localhost:8000/api/workflows/' => 'http://localhost:8000'; 'http://localhost:8000/custom/prefix/api/workflows/' => 'http://localhost:8000/custom/prefix'; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/argument_regex.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py:60,Integrability,interface,interface,60,"""""""; Abstract Base Class for Local and GCS paths sharing an interface for the purpose of PAPI metadata comparison.; There's nothing particularly ""Comparison"" about these paths, I just couldn't think of a better name.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/comparison_paths.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py:128,Security,authenticat,authenticated,128,"# Controversial and doesn't seem to work for the tests anyway, YMMV.; # warnings.filterwarnings(""ignore"", ""Your application has authenticated using end user credentials"")",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/logging.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py:49,Testability,test,tests,49,"# Controversial and doesn't seem to work for the tests anyway, YMMV.; # warnings.filterwarnings(""ignore"", ""Your application has authenticated using end user credentials"")",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/logging.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/logging.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py:4,Security,hash,hash,4,"# + hash(self.disk_type)",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py:66,Integrability,interface,interface,66,"""""""; Abstract Base Class for PAPI operation subclasses sharing an interface for the purpose of treating digesters; uniformly regardless of PAPI version.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py:299,Testability,log,logic,299,"# Remove confusing duplication in subworkflow call names.; # A parent workflow would name a subworkflow call ""parent_wf.sub_wf"".; # The subworkflow would name its calls ""sub_wf.sub_call"".; # If those call components were simply joined the result would be; # ""parent_wf.sub_wf.sub_wf.sub_call"". This logic removes the duplication of ""sub_wf"",; # resulting in ""parent_wf.sub_wf.sub_call"".",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py:221,Usability,simpl,simply,221,"# Remove confusing duplication in subworkflow call names.; # A parent workflow would name a subworkflow call ""parent_wf.sub_wf"".; # The subworkflow would name its calls ""sub_wf.sub_call"".; # If those call components were simply joined the result would be; # ""parent_wf.sub_wf.sub_wf.sub_call"". This logic removes the duplication of ""sub_wf"",; # resulting in ""parent_wf.sub_wf.sub_call"".",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/operation_ids.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:32,Security,access,accessing,32,"""""""Gets the relevant client for accessing a PAPI API, or makes a new instance if necessary""""""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:26,Security,access,accessing,26,"""""""Makes a new client for accessing a specified PAPI API""""""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:39,Deployability,pipeline,pipelines,39,"""""""Reads the operations metadata for a pipelines API v1 job ID. Returns a python dict""""""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:39,Deployability,pipeline,pipelines,39,"""""""Reads the operations metadata for a pipelines API v2alpha1 job ID. Returns a python dict""""""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:39,Deployability,pipeline,pipelines,39,"""""""Reads the operations metadata for a pipelines API v2beta job ID. Returns a python dict""""""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py:53,Deployability,pipeline,pipelines,53,"""""""; Reads the operations metadata for any supported pipelines API version.; Returns a python dict; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/metadata_comparison/lib/papi/papi_clients.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:135,Availability,down,down,135,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:481,Modifiability,variab,variable,481,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:48,Performance,perform,performance,48,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:84,Testability,test,testing,84,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:371,Testability,test,testing,371,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive digester testing. The metadata is stored; in GCS and copied down to the local machine if not already present from an earlier run. The digester can run; against either local or GCS paths using `ComparisonPath`s. Local is nicer to iterate on than GCS since it; runs so much more quickly. Since GCS testing is slow it's turned off by default, it can be turned on by setting; the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:4,Performance,cache,cache,4,"# A cache of expensive-to-create GCS comparison paths.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:48,Modifiability,variab,variable,48,"# Skip slow GCS testing unless this environment variable is set.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:16,Testability,test,testing,16,"# Skip slow GCS testing unless this environment variable is set.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:25,Testability,test,test,25,"# Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:33,Testability,assert,assert,33,"# Currently just a smoke test to assert not-completely-insane results for both v1 and v2 digesters.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py:26,Testability,assert,assertions,26,"# insert more intelligent assertions here",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_digester.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_digester.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:146,Availability,down,down,146,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:425,Modifiability,variab,variable,425,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:48,Performance,perform,performance,48,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:95,Testability,test,testing,95,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:315,Testability,test,testing,315,"""""""; This uses ""real"" metadata from the PAPI v2 performance spike to drive operations digester testing.; The metadata is stored in GCS and copied down to the local machine if not already present from an earlier run.; Operations digesters can run against either local or GCS paths using `ComparisonPath`s. Since GCS testing is; slow it's turned off by default, it can be turned on by setting the DIGESTER_TEST_GCS environment variable.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:4,Performance,cache,cache,4,"# A cache of expensive-to-create GCS comparison paths.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:48,Modifiability,variab,variable,48,"# Skip slow GCS testing unless this environment variable is set.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py:16,Testability,test,testing,16,"# Skip slow GCS testing unless this environment variable is set.",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/test_operations_digesters.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/test_operations_digesters.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py:10,Availability,down,down,10,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/lib/test_digester_helper.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py:75,Testability,test,test,75,"""""""; Copy down workflow and PAPI operations metadata from GCS if needed to test Local.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/lib/test_digester_helper.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py
https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py:60,Performance,cache,cache,60,"""""""; GcsComparisonPaths are somewhat expensive to create so cache them.; """"""",MatchSource.CODE_COMMENT,scripts/metadata_comparison/test/lib/test_digester_helper.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/scripts/metadata_comparison/test/lib/test_digester_helper.py
https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:33,Modifiability,variab,variables,33,"### Define constants; # Cromwell variables passed to the container; # through environmental variables",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:92,Modifiability,variab,variables,92,"### Define constants; # Cromwell variables passed to the container; # through environmental variables",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:23,Deployability,continuous,continuously,23,"### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py:183,Safety,detect,detects,183,"### Main loop; #; # It continuously measures runtime metrics every MEASUREMENT_TIME_SEC,; # and reports them to Stackdriver Monitoring API every REPORT_TIME_SEC.; #; # However, if it detects a container termination signal,; # it *should* report the final metric; # right after the current measurement, and then exit normally.",MatchSource.CODE_COMMENT,supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/tree/87/supportedBackends/google/pipelines/v2beta/src/main/resources/cromwell-monitor/monitor.py
